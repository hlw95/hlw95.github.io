<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: 搜索系统 - Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">搜索系统</a></li></ul></nav></div></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-12  <a class="commentCountImg" href="/2021/10/12/text-mod/#comment-container"><span class="display-none-class">98eb157d7ceaec60e3322bfad98ea698</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="98eb157d7ceaec60e3322bfad98ea698">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/12/text-mod/">文本改写和term分析</a></h1><div class="content"><h2 id="1-文本改写"><a href="#1-文本改写" class="headerlink" title="1.文本改写"></a>1.文本改写</h2><p>改写主要步骤query纠错、query对齐、query扩展</p>
<h3 id="1-1query纠错"><a href="#1-1query纠错" class="headerlink" title="1.1query纠错"></a>1.1query纠错</h3><p>在搜索过程中由于对先验知识的掌握不足或者在使用输入法的时候误输入导致的，本质为去噪过程。</p>
<p>常用的query纠错方法有数字、拼音、漏字、重复字、谐音/形近字等方式。</p>
<h3 id="1-2query对齐"><a href="#1-2query对齐" class="headerlink" title="1.2query对齐"></a>1.2query对齐</h3><p>对于输入query并无错误，但表达上与搜索引擎索引内容不相符而作的一种改写操作。例如“星爷是哪一年生的”，通过实体对齐，可改写为“周星驰的出生时间”。</p>
<p>方法:1.对齐规则 2.文本改写模型</p>
<h3 id="1-3-query扩展"><a href="#1-3-query扩展" class="headerlink" title="1.3 query扩展"></a>1.3 query扩展</h3><p>是将与用户输入的query的相似扩展query进行展示，使得用户可以选择更多的搜索内容，帮助用户挖掘潜在需求。</p>
<h2 id="2-term分析"><a href="#2-term分析" class="headerlink" title="2.term分析"></a>2.term分析</h2><p>一段文本分词后，对于不同的词语，在相同文本中的重要性应该是不同的。</p>
<p>baseline的无监督方法可以是：tf-idf。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/344631739">https://zhuanlan.zhihu.com/p/344631739</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/query%E7%90%86%E8%A7%A3/">query理解</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99%E5%92%8Cterm%E5%88%86%E6%9E%90/">文本改写和term分析</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-09  <a class="commentCountImg" href="/2021/10/09/intent-detect/#comment-container"><span class="display-none-class">2a6a5a61aafe9bcdc6ddb9ffcf130543</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="2a6a5a61aafe9bcdc6ddb9ffcf130543">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/09/intent-detect/">意图识别</a></h1><div class="content"><p>本质是<strong>分类</strong>任务，多用在搜索引擎和智能问答中。</p>
<p><strong>解决方法</strong></p>
<p>1、基于规则模板意图识别</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_16555103/article/details/100767984">https://blog.csdn.net/qq_16555103/article/details/100767984</a></p>
<p>2、基于深度学习模型来对用户的意图进行判别</p>
<p>比如fasttext，LSTM+attention，BERT</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37228811/article/details/104307144?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.no_search_link&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/qq_37228811/article/details/104307144?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.no_search_link&amp;spm=1001.2101.3001.4242</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_16555103/article/details/100767984">https://blog.csdn.net/qq_16555103/article/details/100767984</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/query%E7%90%86%E8%A7%A3/">query理解</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/">意图识别</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-08  <a class="commentCountImg" href="/2021/10/08/query-understanding/#comment-container"><span class="display-none-class">c0aeb70b065e96c79326d878373157e4</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="c0aeb70b065e96c79326d878373157e4">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/08/query-understanding/">query理解</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112719984">https://zhuanlan.zhihu.com/p/112719984</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/383733052">https://zhuanlan.zhihu.com/p/383733052</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/344631739">https://zhuanlan.zhihu.com/p/344631739</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/query%E7%90%86%E8%A7%A3/">query理解</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/query%E7%90%86%E8%A7%A3/">query理解</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-28  <a class="commentCountImg" href="/2021/09/28/tao-emb-search/#comment-container"><span class="display-none-class">f3732a2aa8ad0bf847057df23a7462a0</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="f3732a2aa8ad0bf847057df23a7462a0">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>9 m  <i class="fas fa-pencil-alt"> </i>1.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/28/tao-emb-search/">Embedding based Product Retrieval in Taobao Search</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.09297.pdf">https://arxiv.org/pdf/2106.09297.pdf</a></p>
<p><a target="_blank" rel="noopener" href="http://xtf615.com/2021/10/07/taobao-ebr/">http://xtf615.com/2021/10/07/taobao-ebr/</a></p>
<h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1.INTRODUCTION"></a>1.INTRODUCTION</h2><p><img src="/2021/09/28/tao-emb-search/11.JPG" alt></p>
<p><img src="/2021/09/28/tao-emb-search/22.JPG" alt></p>
<p>框架是搜索系统主流的结构，即匹配/检索，粗排，精排，重排。</p>
<h2 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2.RELATED WORK"></a>2.RELATED WORK</h2><h3 id="2-1-Deep-Matching-in-Search"><a href="#2-1-Deep-Matching-in-Search" class="headerlink" title="2.1 Deep Matching in Search"></a>2.1 Deep Matching in Search</h3><p>fall into two categories: <strong>representation-based learning</strong> and <strong>interaction-based learning.</strong></p>
<p>Other than semantic and relevance matching, more complex factors/trade-offs, e.g., user personalization [2, 3, 10] and retrieval efficiency [5], need to be considered when applying deep models to a large-scale online retrieval system.</p>
<h3 id="2-2-Deep-Retrieval-in-Industry-Search"><a href="#2-2-Deep-Retrieval-in-Industry-Search" class="headerlink" title="2.2 Deep Retrieval in Industry Search"></a>2.2 Deep Retrieval in Industry Search</h3><p>Representation-based models with an ANN (approximate near neighbor) algorithm have become the mainstream trend to efficiently deploy neural retrieval models in industry.</p>
<h2 id="3-MODEL"><a href="#3-MODEL" class="headerlink" title="3 MODEL"></a>3 MODEL</h2><p>整体结构入下：</p>
<p><img src="/2021/09/28/tao-emb-search/33.JPG" alt></p>
<h3 id="3-1-Problem-Formulation"><a href="#3-1-Problem-Formulation" class="headerlink" title="3.1 Problem Formulation"></a>3.1 Problem Formulation</h3><p>$\mathcal{U}=\{u_1,…,u_u,…u_N\}$表示$N$个用户，$\mathcal{Q}=\{q_1,…,q_u,…q_N\}$表示与用户对应的$N$个query，$\mathcal{I}=\{i_1,…,i_u,…i_M\}$表示$M$个商品。将用户$u$的历史行为根据时间分成3个部分：1.real-time，before<br>the current time step，$\mathcal{R}^u=\{i_1^u,…,i_t^u,…i_T^u\}$ 2.short-term, before $\mathcal{R}$ and within ten days,$\mathcal{S}^u=\{i_1^u,…,i_t^u,…i_T^u\}$ 3.long-term sequences,before $\mathcal{S}$ and within one month,$\mathcal{L}^u=\{i_1^u,…,i_t^u,…i_T^u\}$ ，$T$为时间长度。任务可以定义为：</p>
<script type="math/tex; mode=display">
z=\mathcal{F}(\phi(q_u,\mathcal{R}^u,\mathcal{S}^u,\mathcal{L}^u),\varphi(i))</script><p>其中$\mathcal{F}(\cdot),\phi(\cdot),\varphi(\cdot)$分别表示scoring function, query and behaviors encoder, and item encoder</p>
<h3 id="3-2-User-Tower"><a href="#3-2-User-Tower" class="headerlink" title="3.2 User Tower"></a>3.2 User Tower</h3><h4 id="3-2-1-Multi-Granular-Semantic-Unit"><a href="#3-2-1-Multi-Granular-Semantic-Unit" class="headerlink" title="3.2.1 Multi-Granular Semantic Unit"></a>3.2.1 Multi-Granular Semantic Unit</h4><p>挖掘query的语义，原始输入包含当前query和历史query</p>
<p>没有说明为什么这么设计，感觉就是工程试验的结论。有个疑问，直接用BERT等深度语言模型来挖掘query的语义不好吗？</p>
<p>query表示为$q_u=\{w_1^u,…,w_n^u\}$,例如{红色，连衣裙}，$w_u=\{c_1^u,…,c_m^u\}$,例如{红，色}，history query表示为$q_{his}=\{q_1^u,…,q_k^u\} $,例如{绿色，半身裙，黄色，长裙}，其中$w_n \in \mathbb{R}^{1\times d},c_m \in \mathbb{R}^{1\times d},q_k \in \mathbb{R}^{1\times d}$</p>
<script type="math/tex; mode=display">
q_{1\_gram}=mean\_pooling(c_1,...,c_m)
\\q_{2\_gram}=mean\_pooling(c_1c_2,...,c_{m-1}c_m)
\\q_{seq}=mean\_pooling(w_1,...,w_n)
\\q_{seq\_seq}=mean\_pooling(T_{rm}(w_1,...,w_n))
\\q_{his\_seq}=softmax(q_{seg}\cdot(q_{his})^{T})q_{his}
\\q_{mix}=q_{1\_gram}+q_{2\_gram}+q_{seq}+q_{seq\_seq}+q_{his\_seq}
\\Q_{mgs}=concat(q_{1\_gram},q_{2\_gram},q_{seq},q_{seq\_seq},q_{his\_seq},q_{mix})</script><p>其中𝑇𝑟𝑚,𝑚𝑒𝑎𝑛_𝑝𝑜𝑜𝑙𝑖𝑛𝑔, and 𝑐𝑜𝑛𝑐𝑎𝑡 denote the Transformer ,average, and vertical concatenation operation, respectively</p>
<h4 id="3-2-2-User-Behaviors-Attention"><a href="#3-2-2-User-Behaviors-Attention" class="headerlink" title="3.2.2 User Behaviors Attention"></a>3.2.2 User Behaviors Attention</h4><script type="math/tex; mode=display">
e_i^f=W_f\cdot x_i^{f} \in \mathbb{R}^{1\times d_f} \tag{9}
\\i_t^u=concat(\{e_i^f\ | \ f \in \mathcal{F} \})</script><p>其中$W_f$是embedding matrix，$x_i^{f}$是one-hot vector, $\mathcal{F}$是side information  (e.g., leaf category, first-level category, brand and,shop)</p>
<p><strong>real-time sequences</strong></p>
<p>User’s click_item</p>
<script type="math/tex; mode=display">
\mathcal{R}_{lstm}^u=LSTM(\mathcal{R}^u)=\{h_1^{u},...,h_t^{u},...,h_T^{u} \}
\\\mathcal{R}_{self\_att}^u=multihead\_selfattention(\mathcal{R}_{lstm}^u)=\{h_1^{u},...,h_t^{u},...,h_T^{u} \}
\\\mathcal{R}_{zero\_att}^u=\{0,h_1^{u},...,h_t^{u},...,h_T^{u} \} \  \#  add \  a \ zero \ vector \ at \  the \ first \ position \ of \  \mathcal{R}_{self\_att}^u
\\H_{real}=softmax(Q_{mgs}\cdot\mathcal{R}_{zero\_att}^T)\cdot\mathcal{R}_{zero\_att}^T</script><p><strong>short-term sequences</strong></p>
<p>User’s click_item</p>
<script type="math/tex; mode=display">
\mathcal{S}_{self\_att}^u=multihead\_selfattention(\mathcal{S}^u)=\{h_1^{u},...,h_t^{u},...,h_T^{u} \}
\\\mathcal{S}_{zero\_att}^u=\{0,h_1^{u},...,h_t^{u},...,h_T^{u} \} 
\\H_{short}=softmax(Q_{mgs}\cdot\mathcal{S}_{zero\_att}^T)\cdot\mathcal{S}_{zero\_att}^T</script><p><strong>long-term sequence</strong></p>
<p>$\mathcal{L}^u$由四个部分构成，分别为$\mathcal{L}^{u}_{item},\mathcal{L}^{u}_{shop},\mathcal{L}^{u}_{leaf},\mathcal{L}^{u}_{brand}$,每个部分包含3个动作，分别为click，buy，collect。</p>
<script type="math/tex; mode=display">
\\ \mathcal{L}_{click\_item},\mathcal{L}_{buy\_item},\mathcal{L}_{collect\_item}  \rightarrow L^{T}_{item}
\\H_{a\_item}=softmax(Q_{mgs}\cdot  L^{T}_{item})\cdot L^{T}_{item}
\\H_{long}=H_{a\_item}+H_{a\_shop}+H_{a\_leaf}+H_{a\_brand}</script><h4 id="3-2-3-Fusion-of-Semantics-and-Personalization"><a href="#3-2-3-Fusion-of-Semantics-and-Personalization" class="headerlink" title="3.2.3 Fusion of Semantics and Personalization"></a>3.2.3 Fusion of Semantics and Personalization</h4><script type="math/tex; mode=display">
H_{qu}=Self\_Att^{first}([[cls],Q_{mgs},H_{real},H_{short},H_{long}]) \in \mathbb{R}^{1\times d}</script><h3 id="3-3-Item-Tower"><a href="#3-3-Item-Tower" class="headerlink" title="3.3 Item Tower"></a>3.3 Item Tower</h3><p>For the item tower, we experimentally use item ID and title to obtain the item representation 𝐻𝑖𝑡𝑒𝑚.Given the representation of item 𝑖’s ID, $e_i \in \mathbb{R}^{1\times d}$ , and its title segmentation result $T_i=\{w_1^{i},…,w_N^{i}\}$</p>
<script type="math/tex; mode=display">
H_{item}=e+tanh(W_t\cdot\frac{\sum_{i=1}^Nw_i}{N})</script><p>where $W_t$ is the transformation matrix. We empirically find that applying LSTM [12] or Transformer [27] to capture the context of the title is not as effective as simple mean-pooling since the title is stacked by keywords and lacks grammatical structure.</p>
<h3 id="3-4-Loss-Function"><a href="#3-4-Loss-Function" class="headerlink" title="3.4 Loss Function"></a>3.4 Loss Function</h3><p>adapt the softmax cross-entropy loss as the training objective</p>
<script type="math/tex; mode=display">
\hat{y}(i^+|q_u)=\frac{exp(\mathcal{F}(q_u,i^{+}))}{\sum_{i^{'}\in I }exp(\mathcal{F}(q_u,i^{'}))}
\\L(\nabla )=-\sum_{i\in I}y_ilog(\hat{y_i})</script><p>where $\mathcal{F},I,i^+,q_u$denote the inner product, the full item pool, the item tower’s representation $H_{item}$, and the user tower’s representation $H_{qu}$, respectively.</p>
<h4 id="3-4-1-Smoothing-Noisy-Training-Data"><a href="#3-4-1-Smoothing-Noisy-Training-Data" class="headerlink" title="3.4.1 Smoothing Noisy Training Data"></a>3.4.1 Smoothing Noisy Training Data</h4><p>the softmax function with the temperature parameter $\tau$ is defined as follows</p>
<script type="math/tex; mode=display">
\hat{y}(i^+|q_u)=\frac{exp(\mathcal{F}(q_u,i^{+})/\tau)}{\sum_{i^{'}\in I }exp(\mathcal{F}(q_u,i^{'})/\tau)}</script><p>If 𝜏-&gt;0, the fitted distribution is close to one hot distribution,If 𝜏-&gt;∞, the fitted distribution is close to a uniform distribution</p>
<h4 id="3-4-2-Generating-Relevance-improving-Hard-Negative-Samples"><a href="#3-4-2-Generating-Relevance-improving-Hard-Negative-Samples" class="headerlink" title="3.4.2 Generating Relevance-improving Hard Negative Samples"></a>3.4.2 Generating Relevance-improving Hard Negative Samples</h4><p>We first select the negative items of $i^-$ that have the top-𝑁 inner product scores with $q_u $ to form the hard sample set $I_{hard}$</p>
<script type="math/tex; mode=display">
I_{mix}=\alpha i^++(1-\alpha)I_{hard}</script><p>其中$\alpha\in \mathbb{R}^{N\times1}$is sampled from the uniform distribution 𝑈 (𝑎, 𝑏) (0 ≤ 𝑎 &lt; 𝑏 ≤ 1).</p>
<script type="math/tex; mode=display">
\hat{y}(i^+|q_u)=\frac{exp(\mathcal{F}(q_u,i^{+})/\tau)}{\sum_{i^{'}\in (I\cup I_{mix}) }exp(\mathcal{F}(q_u,i^{'})/\tau)}</script></div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/">召回</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/%E5%90%91%E9%87%8F/">向量</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/Embedding-based-Product-Retrieval-in-Taobao-Search/">Embedding based Product Retrieval in Taobao Search</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-21  <a class="commentCountImg" href="/2021/08/21/meituan/#comment-container"><span class="display-none-class">0621e1cfe84648350430593241d756d2</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0621e1cfe84648350430593241d756d2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/21/meituan/">美团排序</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2022/08/11/coarse-ranking-exploration-practice.html">https://tech.meituan.com/2022/08/11/coarse-ranking-exploration-practice.html</a></p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2021/07/08/multi-business-modeling.html">https://tech.meituan.com/2021/07/08/multi-business-modeling.html</a></p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2021/11/19/exploration-and-practice-of-multi-business-commodities-ranking-in-meituan-search.html">https://tech.meituan.com/2021/11/19/exploration-and-practice-of-multi-business-commodities-ranking-in-meituan-search.html</a></p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html">https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html</a> </p>
<h2 id="BERT在美团搜索核心排序的探索和实践"><a href="#BERT在美团搜索核心排序的探索和实践" class="headerlink" title="BERT在美团搜索核心排序的探索和实践"></a>BERT在美团搜索核心排序的探索和实践</h2><h3 id="模型层面"><a href="#模型层面" class="headerlink" title="模型层面"></a>模型层面</h3><p>整体结构如下</p>
<p><img src="/2021/08/21/meituan/1.png" alt></p>
<p>1 BERT预训练</p>
<p>2 多任务学习</p>
<p>​    场景层：根据业务场景进行划分，每个业务场景单独设计网络结构</p>
<p>3 联合训练</p>
<p>两个任务分别为：</p>
<p>​    1 相关性任务：相关性+NER（多任务增强相关性）</p>
<p>​    2 排序任务</p>
<p>怎么联合没看出来</p>
<p>之前是两阶段finetune： 1. 先相关性任务 2 然后排序任务</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E7%BE%8E%E5%9B%A2%E6%8E%92%E5%BA%8F/">美团排序</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-18  <a class="commentCountImg" href="/2021/08/18/dssm/#comment-container"><span class="display-none-class">570287b2ff5e99b7d97bfc663dbb86fb</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="570287b2ff5e99b7d97bfc663dbb86fb">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>9 m  <i class="fas fa-pencil-alt"> </i>1.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/18/dssm/">DSSM双塔模型系列</a></h1><div class="content"><p>简单介绍微软出品的DSSM,CNN-DSSM,LSTM-DSSM</p>
<p>原文分别为：</p>
<p>《Learning Deep Structured Semantic Models for Web Search using Clickthrough Data》</p>
<p>《A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval》</p>
<p>《SEMANTIC MODELLING WITH LONG-SHORT-TERM MEMORY FOR INFORMATION RETRIEVAL》</p>
<p>首先为什么叫做双塔，query塔做在线serving，doc塔离线计算embeding建索引，推到线上即可。</p>
<p>注意， DSSM中query和不同的doc是<strong>共享参数</strong>的， <a target="_blank" rel="noopener" href="https://flashgene.com/archives/72820.html">https://flashgene.com/archives/72820.html</a></p>
<h2 id="一-DSSM"><a href="#一-DSSM" class="headerlink" title="一.DSSM"></a>一.DSSM</h2><h3 id="1-1-模型整体结构"><a href="#1-1-模型整体结构" class="headerlink" title="1.1 模型整体结构"></a>1.1 模型整体结构</h3><p><img src="/2021/08/18/dssm/dssm1.JPG" alt></p>
<p>模型的整体结构如上图所示，$Q$为query，$D_i$为文档。</p>
<p>文本的初始词袋表示为$x$，因为参数过多，不利于训练，所以降低维度，就提出了word hashing</p>
<script type="math/tex; mode=display">
l_1=W_1x</script><p>word hashing其实就是利于char n-gram分词，然后用向量表示（只是这里依然用词袋表示向量，而不是稠密向量），如下所示</p>
<p><img src="/2021/08/18/dssm/cnn_dssm4.JPG" alt></p>
<p>这里有个顾虑为是否存在不同的词使用相同的向量表示。关于这个作者做了实验，结果如下。</p>
<p><img src="/2021/08/18/dssm/dssm2.JPG" alt></p>
<p>对于词汇数量500K大小的词表，采用3-gram后，此表压缩到30k，而且重复表示的仅为22个。重复表示率为0.0044%，维度压缩到原来6%，可以说非常有效。</p>
<p>然后为多层的非线性映射，每层都为全连接网络，得到</p>
<script type="math/tex; mode=display">
l_i=f(W_il_{i-1}+b_{i}),i=2,...,N-1\\</script><p>非线性映射层的最后一层得到语义特征$y$为</p>
<script type="math/tex; mode=display">
y=f(W_Nl_{N-1}+b_N)\\
f(x)=tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}</script><p>利用余弦相似度衡量$Q$和$D$相似度得到</p>
<script type="math/tex; mode=display">
R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^Ty_D}{||y_Q||||y_D||}</script><p>最后的概率输出为</p>
<script type="math/tex; mode=display">
P(D|Q)=\frac{e^{\gamma R(Q,D)}}{\sum_{D^{'}\in \textbf{D}}e^{\gamma R(Q,D^{'})}}</script><p>其中$\gamma$为smoothing factor。</p>
<h3 id="1-2-训练"><a href="#1-2-训练" class="headerlink" title="1.2 训练"></a>1.2 训练</h3><p>样本集构造，对每个正样本$(Q,D^+)$，搭配4个随机负样本$(Q,D_j^-;j=1,..,4)$</p>
<p>损失函数为：</p>
<script type="math/tex; mode=display">
L(\wedge)=-log \prod \limits_{(Q,D^+)}P(D^+|Q)</script><p>其中$\wedge$为模型参数。</p>
<h2 id="二-CNN-DSSM"><a href="#二-CNN-DSSM" class="headerlink" title="二.CNN-DSSM"></a>二.CNN-DSSM</h2><h3 id="2-1-CLSM结构"><a href="#2-1-CLSM结构" class="headerlink" title="2.1 CLSM结构"></a>2.1 CLSM结构</h3><p><img src="/2021/08/18/dssm/cnn_dssm1.JPG" alt></p>
<p>模型包括几个部分：(1) a word-n-gram layer obtained by running a contextual sliding window over the input word sequence (2) a letter-trigram layer that transforms each word-trigram into a letter-trigram representation vector (3) a convolutional layer that extracts contextual features for each word with its neighboring words defined by a window (4) a max-pooling layer that discovers and combines salient word-n-gram features to form a fixed-length sentence-level feature vector  (5) a semantic layer that extracts a high-level semantic feature vector for the input word sequence.</p>
<h3 id="2-2-Letter-trigram-based-Word-n-gram-Representation"><a href="#2-2-Letter-trigram-based-Word-n-gram-Representation" class="headerlink" title="2.2 Letter-trigram based Word-n-gram Representation"></a>2.2 Letter-trigram based Word-n-gram Representation</h3><p>在DSSM的Letter-trigram的基础上加了Word-n-gram，Word-n-gram就是对原始输入文本做滑窗，对于第$t$个word-n-gram可以表示为：</p>
<script type="math/tex; mode=display">
l_t=[f^T_{t-d},...,f^T_{t},...,f^T_{t+d}]^T,\ t=1,2,...,T</script><p>其中$n=2d+1,f_t$为的第$t$个词语的letter-trigram。一个letter-trigram的维度为$30K$，那么一个word-n-gram维度为$n\times30K$</p>
<p>举个例子，如上图，输入文本为$(s) \ online \ auto\ body \ (s)$，滑动窗口大小为n=3，可得$(s)\ online \ auto，\ online \ auto  \ body ，auto\  body \ (s)  $，那么</p>
<p>$l_1=[f^T((s)),f^T(online ),f^T(auto)]^T,\\l_2=[f^T(online ),f^T(auto),f^T(body)]^T,\\l_3=[f^T(auto),f^T(body),f^T((s))]^T$</p>
<h3 id="2-3-Modeling-Word-n-gram-Level-Contextual-Features-at-the-Convolutional-Layer"><a href="#2-3-Modeling-Word-n-gram-Level-Contextual-Features-at-the-Convolutional-Layer" class="headerlink" title="2.3 Modeling Word-n-gram-Level Contextual Features at the Convolutional Layer"></a>2.3 Modeling Word-n-gram-Level Contextual Features at the Convolutional Layer</h3><p>语境相关特征向量$h_t$可以表示为：</p>
<script type="math/tex; mode=display">
h_t=tanh(W_c\cdot l_t),\ t=1,...,T</script><p>其中$W_c$为特征转换矩阵，也就是卷积矩阵，对于全部的word n-grams，$W_c$共享。有小伙伴肯定好奇，这不就是全连接吗，和卷积什么关系，俺也疑惑？</p>
<p>下图为作者做的一个实验。</p>
<p><img src="/2021/08/18/dssm/cnn_dssm2.JPG" alt></p>
<h3 id="2-4-Modeling-Sentence-Level-Semantic-Features-Using-Max-Pooling"><a href="#2-4-Modeling-Sentence-Level-Semantic-Features-Using-Max-Pooling" class="headerlink" title="2.4 Modeling Sentence-Level Semantic Features Using Max Pooling"></a>2.4 Modeling Sentence-Level Semantic Features Using Max Pooling</h3><p>获取局部的语境相关的特征向量后，我们需要把它们合在一起组合句子级别的特征向量。由于语句中某些词语不重要，我们可以忽略它，有些词语很重要，要保留。为了达到这个目的，使用了max pooling，用式子描述如下</p>
<script type="math/tex; mode=display">
v(i)= \mathop{\max}_{t=1,..,T} \{h_t(i)\},\ i=1,...,K</script><p>其中$v(i)$表示池化层输出$v$的第$i$个元素，$K$为$v$的维度和$h_t$的维度一样，$h_t(i)$是第$t$个局部语境特征向量的第$i$个元素。举个例子如下，</p>
<p><img src="/2021/08/18/dssm/cnn_dssm3.JPG" alt></p>
<h3 id="2-5-Latent-Semantic-Vector-Representations"><a href="#2-5-Latent-Semantic-Vector-Representations" class="headerlink" title="2.5 Latent Semantic Vector Representations"></a>2.5 Latent Semantic Vector Representations</h3><p>语义向量表示$y$，用公式描述如下</p>
<script type="math/tex; mode=display">
y=tanh(W_s\cdot v)</script><h3 id="2-6-Using-the-CLSM-for-IR"><a href="#2-6-Using-the-CLSM-for-IR" class="headerlink" title="2.6 Using the CLSM for IR"></a>2.6 Using the CLSM for IR</h3><p>和DSSM都一样，</p>
<script type="math/tex; mode=display">
R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^Ty_D}{||y_Q||||y_D||}
\\P(D|Q)=\frac{e^{\gamma R(Q,D)}}{\sum_{D^{'}\in \textbf{D}}e^{\gamma R(Q,D^{'})}}</script><h3 id="2-7-损失函数"><a href="#2-7-损失函数" class="headerlink" title="2.7 损失函数"></a>2.7 损失函数</h3><script type="math/tex; mode=display">
L(\wedge)=-log \prod \limits_{(Q,D^+)}P(D^+|Q)</script><h2 id="三-LSTM-DSSM"><a href="#三-LSTM-DSSM" class="headerlink" title="三.LSTM-DSSM"></a>三.LSTM-DSSM</h2><p>cnn-dssm只能捕获局部的文本信息，lstm对于长序列的信息捕获能力强于lstm，因此使用lstm改进dssm。</p>
<h3 id="3-1-模型结构"><a href="#3-1-模型结构" class="headerlink" title="3.1 模型结构"></a>3.1 模型结构</h3><p>整体结构如下图，注意红色的部分为残差传递的方向。</p>
<p><img src="/2021/08/18/dssm/lstm_dssm1.JPG" alt></p>
<p>图中的LSTM单元是LSTM的变种，加入了<strong>peep hole</strong>的 LSTM，具体结构如下。</p>
<p><img src="/2021/08/18/dssm/lstm_dssm2.JPG" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/guoyaohua/p/9229190.html">https://www.cnblogs.com/guoyaohua/p/9229190.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/DSSM/">DSSM</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-06  <a class="commentCountImg" href="/2021/08/06/search-rank-init/#comment-container"><span class="display-none-class">54c38d42e6b06e14ec6cde05f228369a</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="54c38d42e6b06e14ec6cde05f228369a">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/06/search-rank-init/">搜索系统</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112719984">https://zhuanlan.zhihu.com/p/112719984</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/382001982">https://zhuanlan.zhihu.com/p/382001982</a></p>
<h2 id="1-离线"><a href="#1-离线" class="headerlink" title="1.离线"></a>1.离线</h2><p>物料获取-&gt; 处理物料 -&gt; 1.构建索引 2.属性库</p>
<h2 id="2-在线"><a href="#2-在线" class="headerlink" title="2.在线"></a>2.在线</h2><p>query -&gt; query理解 -&gt; 召回 -&gt; 排序 -&gt; 结果</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></div><hr></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">1</a></li><li><a class="pagination-link is-current" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">461</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">137</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">440</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-21T13:18:47.000Z">2024-04-21</time></p><p class="title"><a href="/2024/04/21/proxy-service/">proxy,vpn</a></p><p class="categories"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-21T13:14:19.000Z">2024-04-21</time></p><p class="title"><a href="/2024/04/21/mmap/">mmap</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-21T12:58:25.000Z">2024-04-21</time></p><p class="title"><a href="/2024/04/21/fuzz/">fuzz</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-21T12:47:54.000Z">2024-04-21</time></p><p class="title"><a href="/2024/04/21/uml/">uml</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-21T12:36:17.000Z">2024-04-21</time></p><p class="title"><a href="/2024/04/21/cpp-call-func/">函数调用图</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/LTR/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/listwise/"><span class="level-start"><span class="level-item">listwise</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pairwise/"><span class="level-start"><span class="level-item">pairwise</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pointwise/"><span class="level-start"><span class="level-item">pointwise</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">79</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96/"><span class="tag">优化</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F/"><span class="tag">排序</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2024 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>