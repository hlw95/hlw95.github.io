<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: NLP - Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">NLP</a></li></ul></nav></div></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-26  <a class="commentCountImg" href="/2021/10/26/transformer-survey/#comment-container"><span class="display-none-class">9f00e3da6337f991e5da2420e8a4f308</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="9f00e3da6337f991e5da2420e8a4f308">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/26/transformer-survey/">transformer综述</a></h1><div class="content"><p>Transformer-XL</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.02860v3">https://arxiv.org/abs/1901.02860v3</a></p>
<p>RoFormer</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.09864.pdf">https://arxiv.org/pdf/2104.09864.pdf</a></p>
<p>google2020出品的transformer的综述</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2009.06732.pdf">https://arxiv.org/pdf/2009.06732.pdf</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8/">特征提取器</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/transformer%E7%BB%BC%E8%BF%B0/">transformer综述</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-26  <a class="commentCountImg" href="/2021/10/26/T5/#comment-container"><span class="display-none-class">9b456cc8675c74a5066445aae3f9352b</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="9b456cc8675c74a5066445aae3f9352b">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/26/T5/">T5</a></h1><div class="content"><p><strong>T5</strong></p>
<p>原文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1910.10683.pdf">https://arxiv.org/pdf/1910.10683.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/88438851">https://zhuanlan.zhihu.com/p/88438851</a></p>
<p><strong>mT5</strong></p>
<p>原文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.11934.pdf">https://arxiv.org/pdf/2010.11934.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/302380842">https://zhuanlan.zhihu.com/p/302380842</a></p>
<p><strong>Sentence-T5</strong>（文本表示新SOTA）</p>
<p>原文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2108.08877.pdf">https://arxiv.org/pdf/2108.08877.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/403153114">https://zhuanlan.zhihu.com/p/403153114</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/PTM/">PTM</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-20  <a class="commentCountImg" href="/2021/10/20/simcse/#comment-container"><span class="display-none-class">2a05431bc7f7001f01cf0651967ad934</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="2a05431bc7f7001f01cf0651967ad934">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.4 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/20/simcse/">SimCSE Simple Contrastive Learning of Sentence Embeddings</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.08821.pdf">https://arxiv.org/pdf/2104.08821.pdf</a></p>
<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h2><p> <strong>1 target</strong></p>
<p>对于$D=\{(x_i,x_i^{+})\}_{i=1}^{m}$,where $x_i$ and $x_i^{+}$ are semantically related. xi,xj+ are not semantically related</p>
<p>x-&gt;h</p>
<p>Contrastive learning aims to learn effective representation by pulling semantically close neighbors together and pushing apart non-neighbors</p>
<p><img src="/2021/10/20/simcse/1.GIF" alt></p>
<p>N is mini-batch size，分子是正样本，分母为负样本（有一个正样本,感觉是可以忽略）</p>
<p>分母会包含分子的项吗？从代码看，会的</p>
<p>loss</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d73e499ec859">https://www.jianshu.com/p/d73e499ec859</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def loss(self,y_pred,y_true,lamda=0.05):</span><br><span class="line"></span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">    exist a query q1 and  ranked condidat list  [d1,d2,d3,...,dn]</span><br><span class="line">     loss=  -log( exp^sim(q1,d1)/t  /   sum(exp^sim(q1,di)/t) i=2,...,n)</span><br><span class="line"></span><br><span class="line">    [q1,q2]    [[d11,d12,d13],[d21,d22,d23]]</span><br><span class="line">     similarities=[[sim(q1d11),sim(q1d12),sim(q1d13)],[sim(q2d21),sim(q2d22),sim(q2d23)] ] y_true=[y1 ,y2 ]</span><br><span class="line"></span><br><span class="line">        loss = F.cross_entropy(similarities, y_true)</span><br><span class="line">    ref ： https://www.jianshu.com/p/d73e499ec859</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">    # idxs = torch.arange(0, y_pred.shape[0])</span><br><span class="line">    # y_true = idxs + 1 - idxs % 2 * 2</span><br><span class="line">    y_pred = y_pred.reshape(-1, y_true.shape[1])</span><br><span class="line"></span><br><span class="line">    # y_true=[0]*y_pred.sha pe[0]</span><br><span class="line">    # similarities = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=2)</span><br><span class="line">    # similarities = similarities - torch.eye(y_pred.shape[0]) * 1e12</span><br><span class="line">    y_pred = y_pred / lamda</span><br><span class="line">    y_true = torch.argmax(y_true, dim=1)</span><br><span class="line">    loss = F.cross_entropy(y_pred, y_true)</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<p><strong>2 representations评价指标</strong></p>
<p>Alignment： calculates expected distance between embeddings of the paired instances（paired instances就是正例）</p>
<p><img src="/2021/10/20/simcse/2.GIF" alt></p>
<p>uniformity： measures how well the embeddings are uniformly distributed</p>
<p><img src="/2021/10/20/simcse/3.GIF" alt></p>
<h2 id="2-结构"><a href="#2-结构" class="headerlink" title="2.结构"></a>2.结构</h2><p><img src="/2021/10/20/simcse/11.GIF" alt></p>
<h3 id="2-1-Unsupervised"><a href="#2-1-Unsupervised" class="headerlink" title="2.1 Unsupervised"></a>2.1 Unsupervised</h3><p>$x_i-&gt;h_i^{z_i},x_i-&gt;h_i^{z_i^{‘}}$</p>
<p>z is a random mask for dropout，loss为</p>
<p><img src="/2021/10/20/simcse/4.GIF" alt></p>
<h3 id="2-2-Supervised"><a href="#2-2-Supervised" class="headerlink" title="2.2 Supervised"></a>2.2 Supervised</h3><p>引入非目标任务的有标签数据集，比如NLI任务，$(x_i,x_i^{+},x_i^{-})$,where $x_i$ is the premise, $x_i^{+}$and $x_i^{-}$are entailment and contradiction hypotheses.</p>
<p><img src="/2021/10/20/simcse/5.GIF" alt></p>
<p>$(h_i,h_j^{+})$为normal negatives，$(h_i,h_j^{-})$为hard negatives</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/">文本表示</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/">文本表示</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-20  <a class="commentCountImg" href="/2021/10/20/NLP-task/#comment-container"><span class="display-none-class">0a66fbf35eebb3771f139fec91c600b0</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0a66fbf35eebb3771f139fec91c600b0">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/20/NLP-task/">NLP任务的评价指标</a></h1><div class="content"><h2 id="1-文本分类"><a href="#1-文本分类" class="headerlink" title="1.文本分类"></a>1.文本分类</h2><p>采用分类任务的评价指标，比如accuracy，recall，F1等</p>
<h2 id="2-文本匹配"><a href="#2-文本匹配" class="headerlink" title="2.文本匹配"></a>2.文本匹配</h2><p>重点说下一些paper的sts（Semantic Textual Similarity）任务，为什么采用相关系数（Pearson correlation或者spearman correlation）来衡量，比如 S-bert <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.10084">https://arxiv.org/abs/1908.10084</a>  ，consert  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.11741">https://arxiv.org/abs/2105.11741</a>   。 这是因为S-bert和consert 都是文本表示的方法，最后计算文本相似度是利用余弦相似度计算的，相似度的值域为0-1，但是sts数据集的相似度值域为0-5。值域范围不同，不能直接进行比较，用相关系数来间接评价。</p>
<h2 id="3-文本生成"><a href="#3-文本生成" class="headerlink" title="3.文本生成"></a>3.文本生成</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/144182853">https://zhuanlan.zhihu.com/p/144182853</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.14799.pdf">https://arxiv.org/pdf/2006.14799.pdf</a></p>
<p>文本改写（算是特殊的生成）</p>
<p><a target="_blank" rel="noopener" href="https://aclanthology.org/2020.findings-emnlp.111.pdf">https://aclanthology.org/2020.findings-emnlp.111.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.01187.pdf">https://arxiv.org/pdf/1909.01187.pdf</a></p>
<p>Exact score: percentage of exactly correctly predicted fusions</p>
<p>SARI: the average F1 scores of the added, kept, and deleted n-grams</p>
<h2 id="4-文本表示"><a href="#4-文本表示" class="headerlink" title="4.文本表示"></a>4.文本表示</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1908.10084.pdf">https://arxiv.org/pdf/1908.10084.pdf</a></p>
<p>SentEval (Conneau and Kiela, 2018) is a popular toolkit to evaluate the quality of sentence embeddings. </p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/NLP/">NLP</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/NLP%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/">NLP任务的评价指标</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-10-12  <a class="commentCountImg" href="/2021/10/12/attention/#comment-container"><span class="display-none-class">0d7bf89d0a0926a20bc7682e4c4a5c18</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0d7bf89d0a0926a20bc7682e4c4a5c18">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/10/12/attention/">attention总结</a></h1><div class="content"><p>1.Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</p>
<p>提出了两种 attention 模式，即 hard attention 和 soft attention</p>
<p>2.Effective Approaches to Attention-based Neural Machine Translation</p>
<p>文章提出了两种 attention 的改进版本，即 global attention 和 local attention。</p>
<p>3.Attention Is All You Need</p>
<p>提出self attention</p>
<p>4.Hierarchical Attention Networks for Document Classification</p>
<p>提出了Hierarchical Attention用于文档分类</p>
<p>5.Attention-over-Attention Neural Networks for Reading Comprehension</p>
<p>提出了Attention Over Attention的Attention机制</p>
<p>6.Convolutional Sequence to Sequence Learning</p>
<p>论文中还采用了 Multi-step Attention</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8/">特征提取器</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/attention/">attention</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-30  <a class="commentCountImg" href="/2021/09/30/felix/#comment-container"><span class="display-none-class">439b8b1d934392a5881d2cae5276da81</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="439b8b1d934392a5881d2cae5276da81">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>4 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/30/felix/">Felix Flexible Text Editing Through Tagging and Insertion</a></h1><div class="content"><p>google继lasertagger之后的又一篇text edit paper</p>
<p>In contrast to conventional sequence-to-sequence (seq2seq) models, FELIX is efficient in <strong>low-resource settings</strong> and <strong>fast</strong> at inference time, while being <strong>capable</strong> of modeling flexible input-output transformations. We achieve this by decomposing the text-editing task into two sub-tasks: <strong>tagging</strong> to decide on the subset of input tokens and their order in the output text and <strong>insertion</strong> to in-fill the missing tokens in the output not present in the input.</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p><img src="/2021/09/30/felix/11.JPG" alt></p>
<p>In particular, we have designed FELIX with the following requirements in mind: Sample efficiency, Fast inference time, Flexible text editing</p>
<h2 id="2-Model-description"><a href="#2-Model-description" class="headerlink" title="2 Model description"></a>2 Model description</h2><p>FELIX decomposes the conditional probability of generating an output sequence $y$ from an input<br>$x$ as follows:</p>
<script type="math/tex; mode=display">
p(\textbf{y}|\textbf{x})=p_{ins}(\textbf{y}|\textbf{y}^m)p_{tag}(\textbf{y}^t,\pi|\textbf{x})</script><h3 id="2-1-Tagging-Model"><a href="#2-1-Tagging-Model" class="headerlink" title="2.1 Tagging Model"></a>2.1 Tagging Model</h3><p>trained to optimize both the tagging and pointing loss:</p>
<script type="math/tex; mode=display">
\mathcal{L}=\mathcal{L}_{pointing  }+\lambda\mathcal{L}_{tagging   }</script><p><strong>Tagging</strong> :</p>
<p>tag sequence $\textbf{y}^t$由3种tag组成：$KEEP$，$DELETE$，$INSERT (INS)$</p>
<p>Tags are predicted by applying a single feedforward layer $f$ to the output of the encoder $\textbf{h}^L$ (the source sentence is first encoded using a 12-layer BERT-base model). $\textbf{y}^t_i=argmax(f(\textbf{h}^L_i))$</p>
<p><strong>Pointing</strong>:</p>
<p><img src="/2021/09/30/felix/33.JPG" alt></p>
<p>Given a sequence $\textbf{x}$ and the predicted tags $\textbf{y}^t$ , the re-ordering model generates a permutation $\pi$ so that from $\pi$and  $\textbf{y}^t$ we can reconstruct the insertion model input $\textbf{y}^m$. Thus we have: </p>
<script type="math/tex; mode=display">
p(\textbf{y}^m|\textbf{x}) \approx \prod \limits_{i}p(\pi(i)|\textbf{x},\textbf{y}^t,i)p(\textbf{y}_i^t|\textbf{x})</script><p>Our implementation is based on a <strong>pointer network</strong>. The output of this model is a series of predicted pointers (source token → next target token)</p>
<p>The input to the Pointer layer at position $i$:</p>
<script type="math/tex; mode=display">
\textbf{h}^{L+1}_{i}=f([\textbf{h}^{L}_{i};e(\textbf{y}_i^t);e(\textbf{p}_i)])</script><p>其中$e(\textbf{y}_i^t)$is the embedding of the predicted tag，$e(\textbf{p}_i)$ is the positional embedding</p>
<p>The pointer network attends over all hidden states, as such:</p>
<script type="math/tex; mode=display">
p(\pi(i)|\textbf{h}_i^{L+1})=attention(\textbf{h}_i^{L+1},\textbf{h}_{\pi(i)}^{L+1})</script><p>其中$\textbf{h}_i^{L+1}$ as $Q $, $\textbf{h}_{\pi(i)}^{L+1}$ as $K$</p>
<p>When realizing the pointers, we use a constrained beam search</p>
<h3 id="2-2-Insertion-Model"><a href="#2-2-Insertion-Model" class="headerlink" title="2.2 Insertion Model"></a>2.2 Insertion Model</h3><p><img src="/2021/09/30/felix/22.JPG" alt></p>
<p>To represent masked token spans we consider two options: <strong>masking</strong> and <strong>infilling</strong>. In the former case the tagging model predicts how many tokens need to be inserted by specializing the $INSERT$ tag into $INS_k$, where $k$ translates the span into $ k$  $MASK$ tokens. For the infilling case the tagging model predicts a generic $INS$ tag. </p>
<p>Note that we preserve the deleted​ span in the input to the insertion model by enclosing it between $[REPL]$ and $[/REPL]$ tags.</p>
<p>our insertion model is also based on a 12-layer BERT-base and we can directly take advantage of the BERT-style pretrained checkpoints.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://aclanthology.org/2020.findings-emnlp.111.pdf">https://aclanthology.org/2020.findings-emnlp.111.pdf</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/">文本生成</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/">文本改写</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-17  <a class="commentCountImg" href="/2021/09/17/doc-bert/#comment-container"><span class="display-none-class">497ee909ce15293540c44e2680c35f52</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="497ee909ce15293540c44e2680c35f52">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/17/doc-bert/">HIERARCHICAL TRANSFORMERS FOR LONG DOCUMENT CLASSIFICATION</a></h1><div class="content"><p>原版BERT的最大输入为512，为了使得BERT能解决超长文本的问题，作者在finetune阶段提出了两种策略来弥补这个问题，即利用BERT+LSTM或者BERT+transformer。</p>
<p>核心步骤：</p>
<p>1.split the input sequence into segments of a fixed size with overlap.</p>
<p>2.For each of these segments, we obtain H or P from BERT model.</p>
<p><img src="/2021/09/17/doc-bert/11.JPG" alt></p>
<p>3.We then stack these segment-level representations into a sequence, which serves as input to a small (100-dimensional) LSTM layer.//replacing the LSTM recurrent layer in favor of a small Transformer model</p>
<p>4.Finally, we use two fully connected layers with ReLU (30-dimensional) and softmax (the same dimensionality as the number of classes) activations to obtain the final predictions.</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">文本分类</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC/">超长文本</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-15  <a class="commentCountImg" href="/2021/09/15/rnn/#comment-container"><span class="display-none-class">0d9efcf05de62def8a88e43181dbe72e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0d9efcf05de62def8a88e43181dbe72e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/15/rnn/">RNN总结</a></h1><div class="content"><h2 id="1-单元"><a href="#1-单元" class="headerlink" title="1.单元"></a>1.单元</h2><h3 id="1-1-普通RNN单元"><a href="#1-1-普通RNN单元" class="headerlink" title="1.1 普通RNN单元"></a>1.1 普通RNN单元</h3><h3 id="1-2-LSTM"><a href="#1-2-LSTM" class="headerlink" title="1.2 LSTM"></a>1.2 LSTM</h3><h3 id="1-3-GRU"><a href="#1-3-GRU" class="headerlink" title="1.3 GRU"></a>1.3 GRU</h3><h2 id="2-结构"><a href="#2-结构" class="headerlink" title="2.结构"></a>2.结构</h2><h3 id="1-1-输入、输出"><a href="#1-1-输入、输出" class="headerlink" title="1.1 输入、输出"></a>1.1 输入、输出</h3><p><img src="/2021/09/15/rnn/11.JPG" alt></p>
<h3 id="1-2-是否双向"><a href="#1-2-是否双向" class="headerlink" title="1.2 是否双向"></a>1.2 是否双向</h3><p><img src="/2021/09/15/rnn/22.png" alt></p>
<h3 id="1-3-是否堆叠"><a href="#1-3-是否堆叠" class="headerlink" title="1.3 是否堆叠"></a>1.3 是否堆叠</h3><p><img src="/2021/09/15/rnn/33.png" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/gaohanjie123/article/details/88699664">https://blog.csdn.net/gaohanjie123/article/details/88699664</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Luv-GEM/p/10788849.html">https://www.cnblogs.com/Luv-GEM/p/10788849.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8/">特征提取器</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/RNN/">RNN</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-15  <a class="commentCountImg" href="/2021/09/15/roberta/#comment-container"><span class="display-none-class">607add707f93360424dff10eb802fe91</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="607add707f93360424dff10eb802fe91">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/15/roberta/">RoBERTa A Robustly Optimized BERT Pretraining Approach</a></h1><div class="content"><h2 id="1-和BERT比较"><a href="#1-和BERT比较" class="headerlink" title="1.和BERT比较"></a>1.和BERT比较</h2><p>在结构上和原版BERT没有差异，主要的改动在于：</p>
<p><img src="/2021/09/15/roberta/55.JPG" alt></p>
<h2 id="2-改动分析"><a href="#2-改动分析" class="headerlink" title="2.改动分析"></a>2.改动分析</h2><h3 id="2-1-Static-vs-Dynamic-Masking"><a href="#2-1-Static-vs-Dynamic-Masking" class="headerlink" title="2.1 Static vs. Dynamic Masking"></a>2.1 Static vs. Dynamic Masking</h3><p>static masking: 原本的BERT采用的是static mask的方式，就是在create pretraining data中，先对数据进行提前的mask</p>
<p>dynamic masking: 每一次将训练example喂给模型的时候，才进行随机mask。</p>
<p>结果对比：</p>
<p><img src="/2021/09/15/roberta/22.JPG" alt></p>
<p>结论：动态占优</p>
<h3 id="2-2-Model-Input-Format-and-Next-Sentence-Prediction"><a href="#2-2-Model-Input-Format-and-Next-Sentence-Prediction" class="headerlink" title="2.2 Model Input Format and Next Sentence Prediction"></a>2.2 Model Input Format and Next Sentence Prediction</h3><p>做了结果对比试验，结果如下：</p>
<p><img src="/2021/09/15/roberta/33.JPG" alt></p>
<p>结论：</p>
<p>Model Input Format: </p>
<p>​    1.find that using individual sentences hurts performance on downstream tasks</p>
<p>Next Sentence Prediction: </p>
<p>​    1.removing the NSP loss matches or slightly improves downstream task performance</p>
<h3 id="2-3-Training-with-large-batches"><a href="#2-3-Training-with-large-batches" class="headerlink" title="2.3 Training with large batches"></a>2.3 Training with large batches</h3><p><img src="/2021/09/15/roberta/44.JPG" alt></p>
<h3 id="2-4-Text-Encoding"><a href="#2-4-Text-Encoding" class="headerlink" title="2.4 Text Encoding"></a>2.4 Text Encoding</h3><p>采用BBPE而不是wordpiece</p>
<h2 id="3-常见问题"><a href="#3-常见问题" class="headerlink" title="3 常见问题"></a>3 常见问题</h2><p><strong>1 roberta tokenizer 没有token_type_ids？</strong><br>roberta 取消了NSP，所以不需要segment embedding 也就不需要token_type_ids，但是使用的时候发现中文是有token_type_ids的，英文没有token_type_ids的。没有token_type_ids，两句话怎么区别，分隔符sep还是有的，只是没有segment embedding </p>
<p><strong>2 使用避坑</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zwqjoy/article/details/107533184">https://blog.csdn.net/zwqjoy/article/details/107533184</a></p>
<p><a target="_blank" rel="noopener" href="https://hub.fastgit.org/ymcui/Chinese-BERT-wwm">https://hub.fastgit.org/ymcui/Chinese-BERT-wwm</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/103205929">https://zhuanlan.zhihu.com/p/103205929</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/143064748">https://zhuanlan.zhihu.com/p/143064748</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zwqjoy/article/details/107533184">https://blog.csdn.net/zwqjoy/article/details/107533184</a></p>
<p><a target="_blank" rel="noopener" href="https://hub.fastgit.org/ymcui/Chinese-BERT-wwm">https://hub.fastgit.org/ymcui/Chinese-BERT-wwm</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/PTM/">PTM</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-27  <a class="commentCountImg" href="/2021/08/27/xlnet/#comment-container"><span class="display-none-class">1938a114a2321582b8811dce19579c75</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1938a114a2321582b8811dce19579c75">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/27/xlnet/">XLNet Generalized Autoregressive Pretraining for Language Understanding</a></h1><div class="content"><h2 id="1-主要改动"><a href="#1-主要改动" class="headerlink" title="1 主要改动"></a>1 主要改动</h2><p>relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy.</p>
<p>propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation.  (3) , XLNet integrates ideas from Transformer-XL</p>
<p>example：[New, York, is, a, city] . select the two tokens [New, York] as the prediction targets and maximize log p （New York | is a city）</p>
<p>In this case, BERT and XLNet respectively reduce to the following objectives:</p>
<p><img src="/2021/08/27/xlnet/2.JPG" alt></p>
<h2 id="2-现有PTM的问题"><a href="#2-现有PTM的问题" class="headerlink" title="2 现有PTM的问题"></a>2 现有PTM的问题</h2><p><strong>1 AR language modeling</strong></p>
<p>对于给定的句子$\textbf{x}=[x_1,…,x_T]$，AR language modeling performs pretraining by maximizing the likelihood under the forward autoregressive factorization</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \quad logp_{\theta}(\textbf{x})=\sum_{t=1}^{T}logp_{\theta}(x_t|\textbf{x}_{<t})=\sum_{t=1}^{T} log\frac{e^{h_{\theta}(\textbf{x}_{1:t-1})^\top e(x_t)}}{\sum_{x^{'}} e^{h_{\theta}(\textbf{x}_{1:t-1})^\top e(x^{'})}}  \tag{1}</script><p>其中$h_{\theta}(\textbf{x}_{1:t-1})$是考虑上下文的文本表示，$e(x_t)$为$x_t$的词向量</p>
<p><strong>2 AE anguage modeling</strong></p>
<p>对于BERT这种AE模型，首先利用$\textbf{x}$构造遮盖的tokens$\overline{\textbf{x}}$和未遮盖的tokens$\hat{\textbf{x}}$，然后the training objective is to reconstruct $\overline{\textbf{x}}$ from $\hat{\textbf{x}}$:</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \quad logp_{\theta}(\overline{\textbf{x}}\ |\ \hat{\textbf{x}})\approx \sum_{t=1}^{T}m_tlogp_{\theta}(x_t\ |\ \hat{\textbf{x}})=\sum_{t=1}^{T} \ m_t log \frac{e^{H_{\theta}(\hat{\textbf{x}})_t^\top e(x_t)}}{\sum_{x^{'}}e^{H_{\theta}(\hat{\textbf{x}})_t^\top e(x^{'})}} \tag{2}</script><p>其中$m_t=1$表示$x_t$被遮盖了，AR语言模型$t$时刻只能看到之前的时刻，因此记号是$h_{\theta}(\textbf{x}_{1:t-1})$；而AE模型可以同时看到整个句子的所有Token，因此记号是$H_{\theta}(\hat{\textbf{x}})_t$</p>
<p>这两个模型的优缺点分别为：</p>
<p><strong>3 对比</strong></p>
<p>1.AE因为遮盖词只是假设相互独立不是严格相互独立，因此为$\approx$。</p>
<p>2.AE在预训练时会出现特殊的token为[MASK]，但是它在下游的fine-tuning中不会出现，这就出现了预训练 — finetune的不一致问题。而AR语言模型不会有这个问题。</p>
<p>3.AR语言模型只能参考一个方向的上下文，而AE可以参考双向的上下文。</p>
<h2 id="3-改动"><a href="#3-改动" class="headerlink" title="3 改动"></a>3 改动</h2><h3 id="3-1-排列语言模型"><a href="#3-1-排列语言模型" class="headerlink" title="3.1 排列语言模型"></a>3.1 排列语言模型</h3><p>we propose the permutation language modeling objective that not only retains the benefits of AR models but also allows models to capture bidirectional context</p>
<p>给定长度为$T$的序列，总共有$T!$种排列方法。注意输入顺序是不会变的，因为模型在微调期间只会遇到具有自然顺序的文本序列。作者就是通<strong>Attention Mask</strong>，把其它没有被选到的单词Mask掉，不让它们在预测单词$x_i$的时候发生作用，看着就类似于把这些被选中的单词放到了上文。</p>
<p>举个例子，如下图，输入序列为$\{x_1,x_2,x_3,x_4\}$，总共有4!，24种情况，作者取了其中4个。假如预测$x_3$，第一个排列为$x_3 \rightarrow x_2 \rightarrow x_4 \rightarrow x_1 $，没有排在$x_3$前面对象，所以只连接了mem，对于真实情况就是输入还是$x_1 \rightarrow x_2 \rightarrow x_3 \rightarrow x_4 $，然后mask掉全部输入，即只利用mem预测$ x_3 $；第二个排列为$x_2 \rightarrow x_4 \rightarrow x_3 \rightarrow x_1 $，$x_2,x_4$排在$x_3$前面，所以连接了$x_2,x_4$对应的向量表示，对于真实情况就是输入还是$x_1 \rightarrow x_2 \rightarrow x_3 \rightarrow x_4 $，然后mask掉$x_1,x_3$，剩余$x_2,x_4$，即利用mem，$x_2,x_4$预测$ x_3 $。</p>
<p><img src="/2021/08/27/xlnet/22.JPG" alt></p>
<p>排列语言模型的目标是调整模型参数使得下面的似然概率最大</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \ \mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[\sum_{t=1}^Tlogp_{\theta}(x_{z_t}|\textbf{x}_{\textbf{z}_{<t}})] \tag{3}</script><p>其中$\textbf{z}$为随机变量，表示某个位置排列，$\mathcal{Z}_T$表示全部的排列，$z_t$，$\textbf{z}_{&lt;t}$分别表示某个位置排列的第$t$个元素和与其挨着的前面$t-1$个元素。</p>
<h3 id="3-2-Two-Stream-Self-Attention"><a href="#3-2-Two-Stream-Self-Attention" class="headerlink" title="3.2 Two-Stream Self-Attention"></a>3.2 Two-Stream Self-Attention</h3><p><strong>Target-Aware Representations</strong></p>
<p>采用AE原来的表达形式来描述下一个token的分布$p_{\theta}(X_{z_t}|\textbf{x}_{\textbf{z}_{&lt;t}})$如下</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t}=x|\textbf{x}_{\textbf{z}_{<t}})= \frac{e^{ e(x)^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}{\sum_{x^{'}} e^{ e(x^{'})^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}</script><p>这样表达有一个问题就是没有考虑预测目标词的位置，即没有考虑$ z_t$，这会导致ambiguity in target prediction。证明如下：假设有两个不同的排列$\textbf{z}^{(1)}$和$\textbf{z}^{(2)}$，并且满足如下关系：</p>
<script type="math/tex; mode=display">
\textbf{z}^{(1)}_{<t}=\textbf{z}^{(2)}_{<t}=\textbf{z}_{<t} \ but \ {z}^{(1)}_{t}\neq{z}^{(2)}_{t}</script><p>可以推导出</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t^{(1)}}=x|\textbf{x}_{\textbf{z}_{<t}^{(1)}})=p_{\theta}(X_{z_t^{(2)}}=x|\textbf{x}_{\textbf{z}_{<t}^{(2)}})=\frac{e^{ e(x)^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}{\sum_{x^{'}} e^{ e(x^{'})^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}</script><p>但是$p_{\theta}(X_{z_t^{(1)}}=x|\textbf{x}_{\textbf{z}_{&lt;t}^{(1)}}),p_{\theta}(X_{z_t^{(2)}}=x|\textbf{x}_{\textbf{z}_{&lt;t}^{(2)}})$应该不一样，因为目标词的位置不同</p>
<p>为了解决这个问题，提出了Target-Aware Representations，其实就是考虑了目标词的位置</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t}=x|\textbf{x}_{\textbf{z}_{<t}})= \frac{e^{ e(x)^\top g_{\theta}(\textbf{x}_{\textbf{z}_{<t}},z_t)}}{\sum_{x^{'}} e^{ e(x^{'})^\top g_{\theta}(\textbf{x}_{\textbf{z}_{<t}},z_t)}} \tag{4}</script><p><strong>Two-Stream Self-Attention</strong></p>
<p> contradiction</p>
<p><img src="/2021/08/27/xlnet/4.JPG" alt></p>
<p>To resolve such a contradiction，we propose to use two sets of hidden representations instead of one:</p>
<p><img src="/2021/08/27/xlnet/3.JPG" alt></p>
<p>假设有self-attention的层号为$m=1,2,…,M$，$g_i^{(0)}=w$，$h_i^{(0)}=e(x_i)$，Two-Stream Self-Attention可以表示为</p>
<script type="math/tex; mode=display">
g_{z_t}^{(m)}\leftarrow Attention(Q=g_{z_t}^{(m-1)},KV=\textbf{h}^{(m-1)}_{z_{<t}};\theta)
\\h_{z_t}^{(m)}\leftarrow Attention(Q=h_{z_t}^{(m-1)},KV=\textbf{h}^{(m-1)}_{z_{\le t}};\theta)</script><p>举个例子，如下图</p>
<p><img src="/2021/08/27/xlnet/11.JPG" alt></p>
<p>预训练最终使用$g_{z_t}^{(M)}$计算公式（4）,during finetuning, we can simply drop the query stream and use the content stream </p>
<p>during  pretrain， we can use the last-layer query representation $g_{z_t}^{(M)}$  to compute Eq. (4).</p>
<p>during finetuning, we can simply drop the query stream and use the content stream as a normal Transformer(-XL). </p>
<h3 id="3-3-Partial-Prediction"><a href="#3-3-Partial-Prediction" class="headerlink" title="3.3 Partial Prediction"></a>3.3 Partial Prediction</h3><p>因为排序很多，计算量很大，所以需要采样。将$z$分隔成$z_{t_\le c}$和 $z_{t_&gt;c}$，$c$为分隔点，我们选择预测后面的词语，因为后面的词语包含的信息更加丰富。引入超参数$K$调整$c$，使得需要预测$\frac{1}{K}$的词（$\frac{|z|-c}{|z|}\approx\frac{1}{K}$），优化目标为:</p>
<script type="math/tex; mode=display">
\max \limits_{\theta}\mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[logp_{\theta}(\textbf{x}_{\textbf{z}_{>c}}|\textbf{x}_{\textbf{z}_{ \le c}})]=\mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[\sum_{t=c+1}^{|\textbf{z}|}logp_{\theta}(x_{z_t}|\textbf{x}_{\textbf{z}_{<t}})]</script><h3 id="3-4-融合Transformer-XL的思想"><a href="#3-4-融合Transformer-XL的思想" class="headerlink" title="3.4 融合Transformer-XL的思想"></a>3.4 融合Transformer-XL的思想</h3><p>We integrate two important techniques in Transformer-XL, namely the relative positional encoding scheme and the segment recurrence mechanism</p>
<p><strong>Relative Segment Encodings</strong></p>
<p><strong>recurrence mechanism</strong></p>
<p><img src="/2021/08/27/xlnet/1.JPG" alt></p>
<h3 id="3-5-Modeling-Multiple-Segments"><a href="#3-5-Modeling-Multiple-Segments" class="headerlink" title="3.5  Modeling Multiple Segments"></a>3.5  Modeling Multiple Segments</h3><p>the input to our model is the same as BERT: [CLS, A, SEP, B, SEP], where “SEP” and “CLS” are two special symbols and “A” and “B” are the two segments. Although we follow the two-segment data format, XLNet-Large does not use the objective of next sentence prediction</p>
<p>BERT that adds an absolute segment embedding，这里采用Relative Segment Encodings</p>
<p>There are two benefits of using relative segment encodings. First, the inductive bias of relative encodings improves generalization [9]. Second, it opens the possibility of finetuning on tasks that have more than two input segments, which is not possible using absolute segment encodings.</p>
<p>这里有个疑问，对于多于两个seg的情况，比如3个seg，输入格式是否变成[CLS, A, SEP, B, SEP,C,SEP]</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/107350079">https://zhuanlan.zhihu.com/p/107350079</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_37947156/article/details/93035607">https://blog.csdn.net/weixin_37947156/article/details/93035607</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/nsw0419/p/12892241.html">https://www.cnblogs.com/nsw0419/p/12892241.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/mantch/archive/2019/09/30/11611554.html">https://www.cnblogs.com/mantch/archive/2019/09/30/11611554.html</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1492776">https://cloud.tencent.com/developer/article/1492776</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/96023284">https://zhuanlan.zhihu.com/p/96023284</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.08237.pdf">https://arxiv.org/pdf/1906.08237.pdf</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/XLNet/">XLNet</a></div><hr></div></article></div><!--!--><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/NLP/page/4/">Previous</a></div><div class="pagination-next"><a href="/categories/NLP/page/6/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/NLP/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/categories/NLP/page/4/">4</a></li><li><a class="pagination-link is-current" href="/categories/NLP/page/5/">5</a></li><li><a class="pagination-link" href="/categories/NLP/page/6/">6</a></li><li><a class="pagination-link" href="/categories/NLP/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">435</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">135</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">414</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-16T15:26:32.000Z">2024-04-16</time></p><p class="title"><a href="/2024/04/16/zhihu/">知乎搜索</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-16T15:19:47.000Z">2024-04-16</time></p><p class="title"><a href="/2024/04/16/deepmatch/">deepmatch</a></p><p class="categories"><a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a> / <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/">召回</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-16T14:54:16.000Z">2024-04-16</time></p><p class="title"><a href="/2024/04/16/recommend-rank/">排序</a></p><p class="categories"><a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a> / <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-16T14:39:51.000Z">2024-04-16</time></p><p class="title"><a href="/2024/04/16/code-reconstruct/">重构</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-15T15:09:25.000Z">2024-04-15</time></p><p class="title"><a href="/2024/04/15/vector-retrieval/">向量检索</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/">召回</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/%E5%90%91%E9%87%8F/">向量</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/LTR/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/listwise/"><span class="level-start"><span class="level-item">listwise</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pairwise/"><span class="level-start"><span class="level-item">pairwise</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pointwise/"><span class="level-start"><span class="level-item">pointwise</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">48</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96/"><span class="tag">优化</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F/"><span class="tag">排序</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2024 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>