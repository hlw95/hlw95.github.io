<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: 机器学习 - Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">机器学习</a></li></ul></nav></div></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-02  <a class="commentCountImg" href="/2021/09/02/gradient/#comment-container"><span class="display-none-class">77676acf8cf2b5dd00ba3fb30e35ef79</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="77676acf8cf2b5dd00ba3fb30e35ef79">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/02/gradient/">梯度爆炸、梯度消失和解决方法</a></h1><div class="content"><h2 id="1-梯度"><a href="#1-梯度" class="headerlink" title="1.梯度"></a>1.梯度</h2><p>设二元函数$z=f(x,y)$ 在平面区域$D$上具有一阶连续偏导数，则对于每一个点$P(x，y)$的梯度为</p>
<script type="math/tex; mode=display">
grad \ f(x,y)=\nabla f(x,y)=f_x(x,y)\vec{j}+ f_y(x,y)\vec{j}</script><h2 id="2-BP算法图示"><a href="#2-BP算法图示" class="headerlink" title="2.BP算法图示"></a>2.BP算法图示</h2><p><img src="/2021/09/02/gradient/11.JPG" alt></p>
<h2 id="3-梯度消失和梯度爆炸"><a href="#3-梯度消失和梯度爆炸" class="headerlink" title="3.梯度消失和梯度爆炸"></a>3.梯度消失和梯度爆炸</h2><p>梯度爆炸和梯度消失问题都是因为<strong>网络太深</strong>，<strong>网络权值更新不稳定</strong>造成的，本质上是因为梯度反向传播中的连乘效应。</p>
<p><img src="/2021/09/02/gradient/22.jpg" alt></p>
<p>举个例子，现有如上链式连接的网络$(x\rightarrow z \rightarrow y)$</p>
<script type="math/tex; mode=display">
\frac{\partial C }{\partial b_1}=\frac{\partial C }{\partial y_4}\frac{\partial y_4 }{\partial z_4}\frac{\partial z_4 }{\partial x_4}\frac{\partial x_4 }{\partial z_3}\frac{\partial z_3 }{\partial x_3}\frac{\partial x_3 }{\partial z_2}\frac{\partial z_2 }{\partial x_2}\frac{\partial x_2 }{\partial z_1}\frac{\partial z_1 }{\partial b_1}=\frac{\partial C }{\partial y_4}g^{'}(z_4)w_4g^{'}(z_3)w_3g^{'}(z_2)w_2g^{'}(z_1)w_1</script><p>假设$g$为sigmoid，那么$g^{‘}(z)$最大值为$\frac{1}{4}$，而我们初始化的网络权值通常都小于1，所以$g^{‘}(z)w \le \frac{1}{4}$，因此对于上面的链式求导，层数越多，求导结果$\frac{\partial C }{\partial b_1}$越小，因而导致梯度消失的情况出现。</p>
<p>这样，梯度爆炸问题的出现原因就显而易见了，当$w$比较大的时候或者激活函数的梯度较大，即$g^{‘}(z)w &gt; 1$，层数越多，求导结果$\frac{\partial C }{\partial b_1}$越大，直到爆炸。</p>
<h2 id="4-梯度消失和梯度爆炸解决方法"><a href="#4-梯度消失和梯度爆炸解决方法" class="headerlink" title="4.梯度消失和梯度爆炸解决方法"></a>4.梯度消失和梯度爆炸解决方法</h2><h3 id="4-1-解决梯度消失"><a href="#4-1-解决梯度消失" class="headerlink" title="4.1 解决梯度消失"></a>4.1 解决梯度消失</h3><p>1.用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。</p>
<p>2.用Batch Normalization。</p>
<p>3.LSTM的结构设计也可以改善RNN中的梯度消失问题。</p>
<p>4.残差网络</p>
<p>5.合适的初始化权重</p>
<h3 id="4-2解决梯度爆炸"><a href="#4-2解决梯度爆炸" class="headerlink" title="4.2解决梯度爆炸"></a>4.2解决梯度爆炸</h3><p>1.梯度剪切：对梯度设定阈值</p>
<p>2.权重正则化(L1 和 L2 )</p>
<p>3.合适的初始化权重</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/">https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25631496">https://zhuanlan.zhihu.com/p/25631496</a></p>
<p><a target="_blank" rel="noopener" href="https://aijishu.com/a/1060000000100195">https://aijishu.com/a/1060000000100195</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">训练技巧</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/">梯度爆炸、梯度消失</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-29  <a class="commentCountImg" href="/2021/08/29/MLE/#comment-container"><span class="display-none-class">8d601e9afadaa797f4cb9fc88b0cad31</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="8d601e9afadaa797f4cb9fc88b0cad31">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>5 m  <i class="fas fa-pencil-alt"> </i>0.7 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/MLE/">极大似然估计</a></h1><div class="content"><h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h2><p>就是利用已知的样本结果信息，反推最具有可能导致这些样本结果出现的模型参数值。换句话说，即：“<strong>模型已定，结果已知，反推参数</strong>”。</p>
<h2 id="2-极大似然构造损失函数"><a href="#2-极大似然构造损失函数" class="headerlink" title="2.极大似然构造损失函数"></a>2.极大似然构造损失函数</h2><p><strong>大多数常见的损失函数就是基于极大似然推导的。</strong>例子参考 <a target="_blank" rel="noopener" href="https://www.cnblogs.com/hello-ai/p/11000899.html">https://www.cnblogs.com/hello-ai/p/11000899.html</a></p>
<p><strong>判别模型下的极大似然估计</strong></p>
<p>最大似然估计很容易扩展到估计条件概率$P\left (y|x;\theta \right)$，从而给定$x$预测$y$。实际上这是最常见的情况，因为这构成了大多数监督学习的基础。如果$X$表示所有的输入，$Y$表示我们观测到的目标，那么条件最大似然估计是：</p>
<script type="math/tex; mode=display">
\theta_{ML} = \mathop\arg\max_{\theta}P\left(Y|X;\theta \right)</script><p>如果假设样本是独立同分布的，那么这可以分解成</p>
<script type="math/tex; mode=display">
\theta_{ML} = \mathop\arg\max_{\theta}\sum_{i=1}^m logP\left(y^{(i)}|x^{(i)};\theta \right)</script><p><strong>生成模型下的极大似然估计</strong></p>
<p>考虑一组含有m个样本的数据集$X = \left \{ x^{(1)}, …, x^{(m)} \right \}$，由$p_{data}(x)$生成，独立同分布</p>
<p>对独立同分布的样本，生成样本集$X$的概率如下:</p>
<script type="math/tex; mode=display">
p_{model}(X; \theta)= \prod _{i=1}^m p_{model}\left (x^{(i)}; \theta \right )</script><p>对$\theta$的最大似然估计被定义为：</p>
<script type="math/tex; mode=display">
\theta_{ML} = \mathop{\arg\max}_{\theta}p_{model}\left (X;\theta \right ) = \mathop{\arg\max}_{\theta}\prod _{i=1}^m p_{model}\left (x^{(i)}; \theta \right )</script><p>多个概率的乘积公式会因很多原因不便于计算。例如，计算中很可能会因为多个过小的数值相乘而出现数值下溢。为了得到一个便于计算的等价优化问题，两边取对数：</p>
<script type="math/tex; mode=display">
\theta_{ML} = \mathop{\arg\max}_{\theta}\sum_{i=1}^{m}logp_{model}\left (x^{(i)};\theta\right )</script><p><img src="/2021/08/29/MLE/11.png" alt></p>
<p>可以发现，使用极大似然估计时，每个样本$x^{(i)}$都希望拉高它所对应的模型概率值$p_{model}(x^{(i)};\theta)$，如上图所示，但是由于所有样本的密度函数$p_{model}(x^{(i)};\theta)$的总和必须是1，所以不可能将所有样本点都拉高到最大的概率，一个样本点的概率密度函数值被拉高将不可避免的使其他点的函数值被拉低，最终的达到一个平衡态。我们也可以将上式除以$m$，便可以看到极大似然法最大化的目标是在经验分布$\widehat{p}_{data}$下样本概率对数的期望值，即</p>
<script type="math/tex; mode=display">
\theta_{ML} = \mathop{\arg\max}_{\theta}E_{x\sim \widehat{p}_{data}}logp_{model}\left (x^{(i)};\theta \right )</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">https://zhuanlan.zhihu.com/p/26614750</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hello-ai/p/11000899.html">https://www.cnblogs.com/hello-ai/p/11000899.html</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hustqb/article/details/77168436">https://blog.csdn.net/hustqb/article/details/77168436</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/273246971">https://zhuanlan.zhihu.com/p/273246971</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/">极大似然估计</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-29  <a class="commentCountImg" href="/2021/08/29/prior-Posterior/#comment-container"><span class="display-none-class">3dd0c522f612523fd1463e04899e1be2</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3dd0c522f612523fd1463e04899e1be2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/prior-Posterior/">先验概率与后验概率</a></h1><div class="content"><p>$P(X=玩 lol)=0.6；P(X=不玩lol)=0.4$，这个概率是统计得到的,或者你自身依据经验给出的一个概率值，我们称其为<strong>先验概率(prior probability)</strong>；</p>
<p>$P(X=玩lol|Y=男性)$称之为$X$的<strong>后验概率</strong>，即它获得是在观察到事件$Y=男性$发生后得到的</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26464206">https://zhuanlan.zhihu.com/p/26464206</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/">概率统计</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-18  <a class="commentCountImg" href="/2021/08/18/entropy/#comment-container"><span class="display-none-class">d7c5f9c356e864c91498d933feea99eb</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d7c5f9c356e864c91498d933feea99eb">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/18/entropy/">熵，KL散度，交叉熵，JS散度</a></h1><div class="content"><p>GAN需要KL散度和JS散度，所以先预热。</p>
<h2 id="1-熵"><a href="#1-熵" class="headerlink" title="1.熵"></a>1.熵</h2><p>信息量为：</p>
<script type="math/tex; mode=display">
\begin{align}
I(x) &= - \log(p(x)) \tag{1}
\end{align}</script><p>熵为信息量的算术平均：</p>
<script type="math/tex; mode=display">
H(x) = - \sum_{i=1}^{n}p(x_i)log(p(x_i)) \tag{2}</script><h2 id="2-交叉熵"><a href="#2-交叉熵" class="headerlink" title="2.交叉熵"></a>2.交叉熵</h2><p>交叉熵为</p>
<script type="math/tex; mode=display">
H(P,Q) = -\sum_{i=1}^np(x_i)logq(x_i)\tag{3}</script><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="3-KL散度"><a href="#3-KL散度" class="headerlink" title="3.KL散度"></a>3.KL散度</h2><p>对于同一个随机变量有两个单独的概率分布，我们可以使用KL散度(Kullback-Leibler divergence)来衡量两个分布的差异。在机器学习的损失函数的计算中，我们可以假设$P$为样本的真实分布，$Q$用来表示模型所预测的分布，使用KL散度来衡量两个分布之间的差异。KL散度等于交叉熵减去熵</p>
<script type="math/tex; mode=display">
\begin{align}
D_{KL}(P||Q) &= \sum_{i=1}^np(x_i)log(\frac{p(x_i)}{q(x_i)}) \notag\\
&=\sum_{i=1}^np(x_i)(logp(x_i)-logq(x_i)) \notag\\
&=\sum_{i=1}^n[p(x_i)logp(x_i)-p(x_i)logq(x_i)] \notag\\
&=\sum_{i=1}^np(x_i)logp(x_i)-\sum_{i=1}^np(x_i)logq(x_i) \\
&=-H(P)+H(P,Q)\tag{4}
\end{align}</script><p>$P$和$Q$概率分布越接近，$D_{KL}(P||Q)$越小。</p>
<p><strong>KL散度与交叉熵区别与联系</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Dby_freedom/article/details/83374650">https://blog.csdn.net/Dby_freedom/article/details/83374650</a></p>
<p><strong>KL散度主要有两个性质：</strong></p>
<p>（1）不对称性</p>
<p>尽管KL散度从直观上是个距离函数，但它并不是一个真正的度量，因为它不具有对称性，即$D_{KL}(P||Q)\neq D_{KL}(Q||P)$。</p>
<p>（2）非负性</p>
<p>即$D_{KL}(P||Q) \geq 0$。</p>
<h2 id="4-JS散度"><a href="#4-JS散度" class="headerlink" title="4.JS散度"></a>4.JS散度</h2><p>JS散度也是用于度量两个概率分布的相似度，其解决了KL散度不对称的缺点</p>
<script type="math/tex; mode=display">
JS(P||Q) = \frac{1}{2}KL(P||\frac{P+Q}{2})+\frac{1}{2}KL(Q||\frac{P+Q}{2}) \tag{5}</script><p><strong>不同于KL主要在两方面：</strong></p>
<p>（1）值域范围</p>
<p>JS散度的值域范围是[0,1]，相同则是0，相反为1。</p>
<p>（2）对称性</p>
<p>即$ JS(P||Q)=JS(Q||P)$，从数学表达式中就可以看出。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Mrfanl/p/11938139.html">https://www.cnblogs.com/Mrfanl/p/11938139.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/346518942">https://zhuanlan.zhihu.com/p/346518942</a></p>
<p><a target="_blank" rel="noopener" href="https://www.w3cschool.cn/article/83016451.html">https://www.w3cschool.cn/article/83016451.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/entropy/">entropy</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-07-24  <a class="commentCountImg" href="/2021/07/24/feature-extractor/#comment-container"><span class="display-none-class">27df59e6ff951a0511278478b54672f6</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="27df59e6ff951a0511278478b54672f6">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/24/feature-extractor/">特征提取器</a></h1><div class="content"><p>大致分为三类：CNN，LSTM，transformer block</p>
<h2 id="1-CNN"><a href="#1-CNN" class="headerlink" title="1.CNN"></a>1.CNN</h2><p><img src="/2021/07/24/feature-extractor/22.png" alt></p>
<p>滑动部分为卷积核</p>
<h2 id="2-LSTM"><a href="#2-LSTM" class="headerlink" title="2.LSTM"></a>2.LSTM</h2><p><img src="/2021/07/24/feature-extractor/11.png" alt></p>
<h2 id="3-transformer-block"><a href="#3-transformer-block" class="headerlink" title="3.transformer block"></a>3.transformer block</h2><p><img src="/2021/07/24/feature-extractor/33.png" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sandwichnlp/p/11612596.html#transformer">https://www.cnblogs.com/sandwichnlp/p/11612596.html#transformer</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/">模型结构</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">特征提取</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-07-20  <a class="commentCountImg" href="/2021/07/20/torch-cuda/#comment-container"><span class="display-none-class">a49a5bfffe20414104e0e4cabcefcc52</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="a49a5bfffe20414104e0e4cabcefcc52">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.4 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/20/torch-cuda/">TensorFlow，pytorch，cuda，cudnn，显卡驱动之间的区别以及对应关系</a></h1><div class="content"><h2 id="一-概念理解"><a href="#一-概念理解" class="headerlink" title="一.概念理解"></a>一.概念理解</h2><p>显卡驱动连接操作系统与底层硬件。</p>
<p>CUDA和NVIDIA的显卡驱动程序完全是两个不同的概念。CUDA是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行，而且只有当要解决的计算问题是可以大量并行计算的时候才能发挥CUDA的作用。CUDA的本质是一个工具包（ToolKit）。</p>
<p>cuDNN是一个SDK，是一个专门用于神经网络的加速包，注意，它跟我们的CUDA没有一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般有一个最新版本的cuDNN版本与CUDA对应更好。</p>
<p>TensorFlow为谷歌推出的深度学习框架，pytorch是Facebook 推出的深度学习框架。</p>
<h2 id="二-版本对应关系"><a href="#二-版本对应关系" class="headerlink" title="二.版本对应关系"></a>二.版本对应关系</h2><p>深度学习框架基于GPU运算效率远高于CPU，但是需要满足框架的版本和cuda，cudnn以及显卡驱动版本匹配才可以正常工作。</p>
<h3 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h3><p><img src="/2021/07/20/torch-cuda/11.png" alt></p>
<h3 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h3><p><img src="/2021/07/20/torch-cuda/torch.JPG" alt></p>
<h3 id="cuDNN与CUDA"><a href="#cuDNN与CUDA" class="headerlink" title="cuDNN与CUDA"></a>cuDNN与CUDA</h3><p><img src="/2021/07/20/torch-cuda/cuda.JPG" alt></p>
<h3 id="CUDA和NVIDIA显卡驱动关系"><a href="#CUDA和NVIDIA显卡驱动关系" class="headerlink" title="CUDA和NVIDIA显卡驱动关系"></a>CUDA和NVIDIA显卡驱动关系</h3><p><img src="/2021/07/20/torch-cuda/22.png" alt></p>
<h2 id="三-常用命令"><a href="#三-常用命令" class="headerlink" title="三.常用命令"></a>三.常用命令</h2><p>查看GPU型号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia</span><br></pre></td></tr></table></figure>
<p>查看NVIDIA驱动版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/driver/nvidia/version</span><br></pre></td></tr></table></figure>
<p>Python 查看pytorch版本、判断CUDA是否可用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">print(torch.__version__) </span><br><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure>
<p>查看cuda版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/cuda/version.txt</span><br><span class="line">conda list | grep cuda</span><br></pre></td></tr></table></figure>
<p>Tensorflow中查看GPU是否可用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure>
<h2 id="四-参考文献"><a href="#四-参考文献" class="headerlink" title="四.参考文献"></a>四.参考文献</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/caiguanhong/article/details/112184290">https://blog.csdn.net/caiguanhong/article/details/112184290</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%A1%86%E6%9E%B6%E4%BE%9D%E8%B5%96/">框架依赖</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-07-18  <a class="commentCountImg" href="/2021/07/18/classify-performance/#comment-container"><span class="display-none-class">ce9206e22a233f02b45bae16d7714ee3</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="ce9206e22a233f02b45bae16d7714ee3">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>11 m  <i class="fas fa-pencil-alt"> </i>1.7 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/18/classify-performance/">分类任务的衡量指标</a></h1><div class="content"><h2 id="一、二分类"><a href="#一、二分类" class="headerlink" title="一、二分类"></a>一、二分类</h2><h3 id="1-1-confusion-matrix"><a href="#1-1-confusion-matrix" class="headerlink" title="1.1 confusion matrix"></a>1.1 confusion matrix</h3><p><img src="/2021/07/18/classify-performance/22.png" alt></p>
<p><img src="/2021/07/18/classify-performance/11.png" alt></p>
<h3 id="1-2-accuracy"><a href="#1-2-accuracy" class="headerlink" title="1.2 accuracy"></a>1.2 accuracy</h3><script type="math/tex; mode=display">
accuracy={\frac{TP+TN}{TP+TN+FP+FN}}</script><p>accuracy 衡量全局分类正确的数量占总样本的比例</p>
<h3 id="1-3-precision"><a href="#1-3-precision" class="headerlink" title="1.3 precision"></a>1.3 precision</h3><script type="math/tex; mode=display">
precision={\frac{TP}{TP+FP}}</script><p>precision为预测正确正样本数占预测的全部正样本数的比例，即系统判定为正样本的正确率。通俗地说，假如医生给病人检查，医生判断病人有疾病，然后医生判断的正确率有多少。</p>
<h3 id="1-4-recall"><a href="#1-4-recall" class="headerlink" title="1.4 recall"></a>1.4 recall</h3><script type="math/tex; mode=display">
recall={\frac{TP}{TP+FN}}</script><p>recall为预测正确的正样本数量占真实正样本数量的比例，即衡量正样本的召回比例。通俗说，假如有一批病人，医生能从中找出病人的比例</p>
<h3 id="1-5-F1"><a href="#1-5-F1" class="headerlink" title="1.5 F1"></a>1.5 F1</h3><p>由于precision和recall往往是矛盾的，因此为了综合考虑二者，引入F1，即为precision和recall的调和平均</p>
<script type="math/tex; mode=display">
F_{1}={2\frac{precision\cdot recall}{precision+recall}}</script><p>当$precision$和$recall$的任一个值为0，$F_1$都为0</p>
<p>之所以采用调和平均，是因为调和平均数受极端值影响较大，更适合评价不平衡数据的分类问题</p>
<p>通用的F值表达式：</p>
<script type="math/tex; mode=display">
F_{\beta}={(1+\beta^2)\frac{precision\cdot recall}{\beta^2\cdot precision+recall}}</script><p>除了$F_1$分数之外，$F_2$ 分数和$F_{0.5}$分数在统计学中也得到大量的应用。其中，$F_2$分数中，召回率的权重高于精确率，而$F_{0.5}$分数中，精确率的权重高于召回率。</p>
<h3 id="1-6-ROC"><a href="#1-6-ROC" class="headerlink" title="1.6 ROC"></a>1.6 ROC</h3><p><img src="/2021/07/18/classify-performance/11.jfif" alt></p>
<p><img src="/2021/07/18/classify-performance/22.jpg" alt></p>
<p>roc曲线：接收者操作特征(receiver operating characteristic), roc曲线上每个点反映某个阈值下的FPR和TPR的组合。</p>
<p>横轴：$FPR$，叫做假正类率，表示预测为正例但真实情况为反例的占所有真实情况中反例的比率，公式为$FPR=\frac{FP}{TN+FP}$。</p>
<p>纵轴：$TPR$ ，叫做真正例率，表示预测为正例且真实情况为正例的占所有真实情况中正例的比率，公式为​</p>
<p>$TPR=\frac{TP}{TP+FN}$。</p>
<h3 id="1-7-AUC"><a href="#1-7-AUC" class="headerlink" title="1.7 AUC"></a>1.7 AUC</h3><p>$AUC$(Area under Curve)：ROC曲线下的面积，数值可以直观评价分类器的好坏，值越大越好，对于二分类，结果介于0.5和1之间，1为完美分类器，0.5是因为二分类分类效果最差也是0.5。</p>
<h2 id="二、多分类"><a href="#二、多分类" class="headerlink" title="二、多分类"></a>二、多分类</h2><h3 id="2-1-混淆矩阵"><a href="#2-1-混淆矩阵" class="headerlink" title="2.1 混淆矩阵"></a>2.1 混淆矩阵</h3><p><img src="/2021/07/18/classify-performance/11.jpg" alt></p>
<h3 id="2-2-accuracy"><a href="#2-2-accuracy" class="headerlink" title="2.2 accuracy"></a>2.2 accuracy</h3><script type="math/tex; mode=display">
accuracy=\frac{分类正确的样本数,即对角线上的数}{总样本数，即矩阵全部元素相加}</script><h3 id="2-3-某个类别的precision，recall，F1"><a href="#2-3-某个类别的precision，recall，F1" class="headerlink" title="2.3 某个类别的precision，recall，F1"></a>2.3 某个类别的precision，recall，F1</h3><p>与二分类公式一样</p>
<p><img src="/2021/07/18/classify-performance/case1.JPG" alt></p>
<script type="math/tex; mode=display">
precision_{pig}=\frac{20}{20+(10+40)}=\frac{2}{7}
\\recall_{pig}=\frac{20}{20+10}=\frac{2}{3}
\\F_{1pig}={2\frac{precision_{pig}\cdot recall_{pig}}{precision_{pig}+recall_{pig}}}</script><h3 id="2-4-系统的precision，recall，F1"><a href="#2-4-系统的precision，recall，F1" class="headerlink" title="2.4 系统的precision，recall，F1"></a>2.4 系统的precision，recall，F1</h3><p>系统的precision，recall，$F_1$需要综合考虑所有类别，即同时考虑猫、狗、猪的precision，recall，$F_1$。有如下几种方案：</p>
<h4 id="2-4-1-Macro-average"><a href="#2-4-1-Macro-average" class="headerlink" title="2.4.1 Macro average"></a>2.4.1 Macro average</h4><script type="math/tex; mode=display">
Macro-precision=\frac{precision_{cat}+precision_{dog}+precision_{pig}}{3}
\\Macro-recall=\frac{recall{cat}+recall{dog}+recall{pig}}{3}
\\Macro-F_{1}=\frac{F_{1cat}+F_{1dog}+F_{1pig}}{3}</script><h4 id="2-4-2-Weighted-average"><a href="#2-4-2-Weighted-average" class="headerlink" title="2.4.2 Weighted average"></a>2.4.2 Weighted average</h4><p>对macro的推广</p>
<script type="math/tex; mode=display">
Weighted-precision=W_{cat}\cdot precision_{cat}+W_{dog}\cdot precision_{dog}+W_{pig}\cdot precision_{pig}
\\Weighted-recall=W_{cat}\cdot recall{cat}+W_{dog}\cdot recall{dog}+W_{pig}\cdot recall{pig}
\\Weighted-F_{1}=W_{cat}\cdot F_{1cat}+W_{dog}\cdot F_{1dog}+W_{pig}\cdot F_{1pig}
\\W_{cat}:W_{dog}:W_{pig}=N_{cat}:N_{dog}:N_{pig},其中N为样本数量，W为权重</script><h4 id="2-4-3-Micro-average"><a href="#2-4-3-Micro-average" class="headerlink" title="2.4.3 Micro average"></a>2.4.3 Micro average</h4><script type="math/tex; mode=display">
Micro-precision={\frac{TP_{总}}{TP_{总}+FP_{总}}}={\frac{\sum_{i=1}^{n}TP_{i}}{\sum_{i=1}^{n}TP_{i}+\sum_{i=1}^{n}FP_{i}}}
\\Micro-recall={\frac{TP_{总}}{TP_{总}+FN_{总}}}={\frac{\sum_{i=1}^{n}TP_{i}}{\sum_{i=1}^{n}TP_{i}+\sum_{i=1}^{n}FN_{i}}}
\\Micro-F_{1}={2\frac{Micro-precision\cdot Micro-recall}{Micro-precision+Micro-recall}}</script><h3 id="2-5-ROC"><a href="#2-5-ROC" class="headerlink" title="2.5 ROC"></a>2.5 ROC</h3><p><img src="/2021/07/18/classify-performance/33.jpg" alt></p>
<p>对于多分类分类器整体效果的ROC如上micro或者macro曲线，其余3条描述单个类别的分类效果。对于多分类，ROC上的点，同样是某个阈值下的FPR和TPR的组合。</p>
<p>对于多分类的$FPR$,$TPR$，有几种计算方式</p>
<p>a. micro average</p>
<script type="math/tex; mode=display">
FPR_{micro } =\frac{FP_总}{TN_总+FP_总}=\frac{\sum_{i=1}^{n}FP_{i}}{\sum_{i=1}^{n}TN_{i}+\sum_{i=1}^{n}FP_{i}}\\
TPR_{micro }=\frac{TP_总}{TP_总+FN_总}=\frac{\sum_{i=1}^{n}TP_{i}}{\sum_{i=1}^{n}TP_{i}+\sum_{i=1}^{n}FN_{i}}
\\n表示类别数量，FP_i，TN_i，TP_i，FN_i为某个类别的FP，TN，TP，FN</script><p>b. macro average</p>
<script type="math/tex; mode=display">
FPR_{macro}=\frac{1}{n}\sum_{i=1}^{n}FPR_{i}\\
TPR_{macro}=\frac{1}{n}\sum_{i=1}^{n}TPR_{i}，其中FPR_i，TPR_i为某个类别的FPR和TPR</script><h3 id="2-6-AUC"><a href="#2-6-AUC" class="headerlink" title="2.6 AUC"></a>2.6 AUC</h3><p>$AUC$依旧为ROC曲线下的面积，对于多分类个人认为取值范围为[0,1]。</p>
<h2 id="三-代码"><a href="#三-代码" class="headerlink" title="三.代码"></a>三.代码</h2><p><strong>accuracy，precision，recall，F1</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import precision_recall_fscore_support, accuracy_score</span><br><span class="line">def eval_acc_f1(y_true, y_pred):</span><br><span class="line">    acc = accuracy_score(y_true, y_pred)</span><br><span class="line">    prf = precision_recall_fscore_support(y_true, y_pred, average=&quot;macro&quot;)</span><br><span class="line">    return acc, prf</span><br></pre></td></tr></table></figure>
<p><strong>ROC和AUC</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"># 引入必要的库</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from itertools import cycle</span><br><span class="line">from sklearn import svm, datasets</span><br><span class="line">from sklearn.metrics import roc_curve, auc</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import label_binarize</span><br><span class="line">from sklearn.multiclass import OneVsRestClassifier</span><br><span class="line">from scipy import interp</span><br><span class="line"></span><br><span class="line"># 加载数据</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"># 将标签二值化</span><br><span class="line">y = label_binarize(y, classes=[0, 1, 2])</span><br><span class="line"># 设置种类</span><br><span class="line">n_classes = y.shape[1]</span><br><span class="line"></span><br><span class="line"># 训练模型并预测</span><br><span class="line">random_state = np.random.RandomState(0)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line"></span><br><span class="line"># shuffle and split training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,random_state=0)</span><br><span class="line"></span><br><span class="line"># Learn to predict each class against the other</span><br><span class="line">classifier = OneVsRestClassifier(svm.SVC(kernel=&#x27;linear&#x27;, probability=True,</span><br><span class="line">                                 random_state=random_state))</span><br><span class="line">y_score = classifier.fit(X_train, y_train).decision_function(X_test)</span><br><span class="line"></span><br><span class="line"># 计算每一类的ROC</span><br><span class="line">fpr = dict()</span><br><span class="line">tpr = dict()</span><br><span class="line">roc_auc = dict()</span><br><span class="line">for i in range(n_classes):</span><br><span class="line">    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])</span><br><span class="line">    roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line"># Compute micro-average ROC curve and ROC area（方法二）</span><br><span class="line">fpr[&quot;micro&quot;], tpr[&quot;micro&quot;], _ = roc_curve(y_test.ravel(), y_score.ravel())</span><br><span class="line">roc_auc[&quot;micro&quot;] = auc(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;])</span><br><span class="line"></span><br><span class="line"># Compute macro-average ROC curve and ROC area（方法一）</span><br><span class="line"># First aggregate all false positive rates</span><br><span class="line">all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))</span><br><span class="line"># Then interpolate all ROC curves at this points</span><br><span class="line">mean_tpr = np.zeros_like(all_fpr)</span><br><span class="line">for i in range(n_classes):</span><br><span class="line">    mean_tpr += interp(all_fpr, fpr[i], tpr[i])</span><br><span class="line"># Finally average it and compute AUC</span><br><span class="line">mean_tpr /= n_classes</span><br><span class="line">fpr[&quot;macro&quot;] = all_fpr</span><br><span class="line">tpr[&quot;macro&quot;] = mean_tpr</span><br><span class="line">roc_auc[&quot;macro&quot;] = auc(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;])</span><br><span class="line"></span><br><span class="line"># Plot all ROC curves</span><br><span class="line">lw=2</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;],</span><br><span class="line">         label=&#x27;micro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br><span class="line">               &#x27;&#x27;.format(roc_auc[&quot;micro&quot;]),</span><br><span class="line">         color=&#x27;deeppink&#x27;, linestyle=&#x27;:&#x27;, linewidth=4)</span><br><span class="line"></span><br><span class="line">plt.plot(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;],</span><br><span class="line">         label=&#x27;macro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br><span class="line">               &#x27;&#x27;.format(roc_auc[&quot;macro&quot;]),</span><br><span class="line">         color=&#x27;navy&#x27;, linestyle=&#x27;:&#x27;, linewidth=4)</span><br><span class="line"></span><br><span class="line">colors = cycle([&#x27;aqua&#x27;, &#x27;darkorange&#x27;, &#x27;cornflowerblue&#x27;])</span><br><span class="line">for i, color in zip(range(n_classes), colors):</span><br><span class="line">    plt.plot(fpr[i], tpr[i], color=color, lw=lw,</span><br><span class="line">             label=&#x27;ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span><br><span class="line">             &#x27;&#x27;.format(i, roc_auc[i]))</span><br><span class="line"></span><br><span class="line">plt.plot([0, 1], [0, 1], &#x27;k--&#x27;, lw=lw)</span><br><span class="line">plt.xlim([0.0, 1.0])</span><br><span class="line">plt.ylim([0.0, 1.05])</span><br><span class="line">plt.xlabel(&#x27;False Positive Rate&#x27;)</span><br><span class="line">plt.ylabel(&#x27;True Positive Rate&#x27;)</span><br><span class="line">plt.title(&#x27;Some extension of Receiver operating characteristic to multi-class&#x27;)</span><br><span class="line">plt.legend(loc=&quot;lower right&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839">https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/147663370">https://zhuanlan.zhihu.com/p/147663370</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81202617">https://zhuanlan.zhihu.com/p/81202617</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/266386193">https://zhuanlan.zhihu.com/p/266386193</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/">评价指标</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87/">分类任务的衡量指标</a></div><hr></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/page/7/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/page/9/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/page/7/">7</a></li><li><a class="pagination-link is-current" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/page/8/">8</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">405</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">142</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">386</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:58:45.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/gray-test/">灰度测试</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> / <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:53:30.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/abtest/">abtest</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> / <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:51:45.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/diff/">diff评测</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:44:10.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/seach-evluation/">搜索系统评价指标</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:29:10.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/nlp_evalution/">NLP评价指标</a></p><p class="categories"><a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/NLP/">NLP</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/LTR/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/listwise/"><span class="level-start"><span class="level-item">listwise</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pairwise/"><span class="level-start"><span class="level-item">pairwise</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pointwise/"><span class="level-start"><span class="level-item">pointwise</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96/"><span class="tag">优化</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIEN/"><span class="tag">DIEN</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2024 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>