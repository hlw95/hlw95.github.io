{"pages":[{"title":"","text":"ä¸ªäººç®€ä»‹ åˆ†äº«å¾ˆå–œæ¬¢çš„è€ç½—çš„ä¸€æ®µè¯ï¼š â€œæ¯ä¸€ä¸ªç”Ÿå‘½æ¥åˆ°ä¸–é—´éƒ½æ³¨å®šæ”¹å˜ä¸–ç•Œï¼Œåˆ«æ— é€‰æ‹©ã€‚è¦ä¹ˆå˜å¾—å¥½ä¸€ç‚¹ï¼Œè¦ä¹ˆå˜å¾—åä¸€ç‚¹ã€‚ä½ å¦‚æœèµ°è¿›ç¤¾ä¼šä¸ºäº†ç”Ÿå­˜ä¸ºäº†ä»€ä¹ˆä¸è¦è„¸çš„ç†ç”±ï¼Œå˜æˆäº†ä¸€ä¸ªæ¶å¿ƒçš„æˆå¹´äººç¤¾ä¼šä¸­çš„ä¸€å‘˜ï¼Œé‚£ä½ å°±æŠŠè¿™ä¸ªä¸–ç•Œå˜å¾—æ¶å¿ƒäº†ä¸€ç‚¹ç‚¹ã€‚å¦‚æœä½ ä¸€ç”Ÿåˆšæ­£ä¸é˜¿ï¼Œå¦‚æœä½ ä¸€ç”Ÿè€¿ç›´ï¼Œæ²¡æœ‰åšä»»ä½•æ¶å¿ƒçš„äº‹æƒ…ï¼Œæ²¡åšå¯¹åˆ«äººæœ‰å®³çš„äº‹æƒ…ï¼Œä¸€è¾ˆå­æ‹¼äº†è€å‘½å‹‰å¼ºæŠŠè‡ªå·±èº«è¾¹çš„å‡ ä¸ªäººç…§é¡¾å¥½äº†ï¼Œæ²¡æœ‰æˆåæ²¡æœ‰å‘è´¢ï¼Œæ²¡æœ‰æˆå°±ä¼Ÿå¤§çš„äº‹ä¸šï¼Œç„¶åè€¿ç€è„–å­ä¸€ç”Ÿæ­£ç›´ï¼Œåˆ°äº†ä¸ƒå…«åå²è€¿ç€è„–å­å»ä¸–äº†ã€‚ä½ è¿™ä¸€ç”Ÿæ˜¯ä¸æ˜¯æ²¡æœ‰æ”¹å˜ä¸–ç•Œï¼Ÿä½ è¿˜æ˜¯æ”¹å˜ä¸–ç•Œäº†ï¼Œä½ æŠŠè¿™ä¸ªä¸–ç•Œå˜å¾—ç¾å¥½äº†ä¸€ç‚¹ç‚¹ã€‚å› ä¸ºä¸–ç•Œä¸Šåˆå¤šäº†ä¸€ä¸ªå¥½äººã€‚â€œ å–„æ¶ç»ˆæœ‰æŠ¥,å¤©é“å¥½è½®å›ã€‚ä¸ä¿¡æŠ¬å¤´çœ‹,è‹å¤©é¥¶è¿‡è°ã€‚æ— è®ºä½•æ—¶ä½•åœ°ï¼Œæˆ‘ä»¬éƒ½è¦ä¿æŒä¸€é¢—ç§¯æä¹è§‚ã€å–„è‰¯æ„Ÿæ©çš„å¿ƒã€‚ä½†è¡Œå¥½äº‹è«é—®å‰ç¨‹ï¼Œæ°¸è¿œå¹´è½»ï¼Œæ°¸è¿œçƒ­å†…ç›ˆçœ¶ï¼Œæ°¸è¿œä¿æŒæ­£èƒ½é‡ã€‚ğŸ’ªğŸ’ªğŸ’ªğŸ’ªğŸ’ªğŸ’ªå†²é¸­ï¼ï¼ï¼ï¼ -&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;ä¸ªäººä¿¡æ¯ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šä»äº‹JAVAåç«¯å¼€å‘ç ç•œä¸€æšåšä¿¡ä»£ç æ”¹å˜ä¸–ç•Œ åšå®¢ä¿¡æ¯ ç½‘ç«™é‡‡ç”¨çš„Icarusä¸»é¢˜ è¿½æ±‚å°½å¯èƒ½çš„ç®€æ´ï¼Œæ¸…æ™°ï¼Œæ˜“ç”¨ã€‚ åœ¨Icarusä¸»é¢˜ä¹‹ä¸Šè¿›è¡Œäº†éƒ¨åˆ†ä¿®æ”¹ã€‚ æ›´æ–°æ—¥å¿—ï¼šâ€”2020.09.20ï¼šicarus4.0é€‚é…â€”2020.01.18ï¼šicarus3.0é€‚é…â€”2019.11.17ï¼šå¢åŠ æ·±è‰²ä¸»é¢˜å¼€å…³â€”2019.10.30ï¼šå»å›¾ï¼Œç²¾ç®€å¡ç‰‡â€”2019.10.22ï¼šæ”¹ç‰ˆéƒ¨åˆ†æ˜¾ç¤ºï¼Œä¼˜åŒ–é€Ÿåº¦â€”2019.10.16ï¼šæ–‡ç« åˆ—è¡¨åŠ ä¸Šè¯„è®ºæ•°æ˜¾ç¤ºâ€”2019.10.13ï¼šæ”¹ç‰ˆè¯„è®ºâ€”2019.09.25ï¼šå›¾ç‰‡ã€èµ„æºæ¥å…¥CDNå…è´¹jsDelivrã€æ–‡ç« åŠ å…¥ç½®é¡¶â€”2019.09.19ï¼šå¼€æºåšå®¢ä»£ç â€”2019.09.19ï¼šä¿®æ”¹å¸ƒå±€ï¼Œæ‹‰ä¼¸å¸ƒå±€ï¼Œæ›´å®½çš„å±•ç¤ºâ€”2019.09.18ï¼šä¿®æ”¹å‹é“¾uiä¸ºä¸€è¡Œä¸‰ä¸ªï¼Œå¹¶é€‚é…ç§»åŠ¨ç«¯ï¼Œæš—é»‘æ¨¡å¼æ–‡ç« å¢åŠ è¯„è®ºé“¾æ¥ï¼Œå¢åŠ ç•™è¨€é“¾æ¥â€”2019.09.14ï¼šå¢åŠ ç²¾ç®€nextä¸»é¢˜â€”2019.09.14ï¼šåˆ©ç”¨ä¸­ç§‹èŠ‚æ”¾å‡ï¼Œé‡åšäº†é¦–é¡µçš„çƒ­é—¨æ¨èã€åŠ ä¸ªwidgetæœ€æ–°è¯„è®ºæ¡†ã€å½’æ¡£é¡µåŠ å…¥æ–‡ç« è´¡çŒ®æ¦‚è§ˆé¢æ¿ æœ¬ç«™æ¨èç´¢å¼• åšå®¢ä¸»é¢˜ç›¸å…³ github Issue ä½œä¸ºåšå®¢å¾®å‹æ•°æ®åº“çš„åº”ç”¨ github pageç½‘ç«™cdnä¼˜åŒ–åŠ é€Ÿ åšå®¢æºç åˆ†äº« åšå®¢æ¢è‚¤çš„ä¸€ç§å®ç°æ–¹å¼æ€è·¯ åšå®¢ä¸­gitalkæœ€æ–°è¯„è®ºçš„è·å– åšå®¢å›¾ç‰‡ä¸Šä¼ picgoå·¥å…·githubå›¾ä¼ ä½¿ç”¨ å®‰è£…ã€éƒ¨åˆ†é…ç½®icarusä¸»é¢˜ä¸­æ–‡ç‰ˆ æŠ€æœ¯çŸ¥è¯†ç‚¹ Javaå¹¶å‘çŸ¥è¯†ç‚¹ æ³•å¾‹æ³•è§„ æ³•å¾‹æ³•è§„æ•°æ®åº“ ä¸­åäººæ°‘å…±å’Œå›½å›½æ——æ³• ä¸­åäººæ°‘å…±å’Œå›½å®ªæ³• ä¸­åäººæ°‘å…±å’Œå›½æ¶ˆè´¹è€…æƒç›Šä¿æŠ¤æ³• ä¸­åäººæ°‘å…±å’Œå›½åˆ‘äº‹è¯‰è®¼æ³• ä¸­åäººæ°‘å…±å’Œå›½å©šå§»æ³• ä¸­åäººåå…±å’Œå›½ç½‘ç»œå®‰å…¨æ³• ä¸­åäººæ°‘å…±å’Œå›½åŠ³åŠ¨æ³• å…¶ä»– ç½‘æ˜“äº‘éŸ³ä¹æ­Œå•åˆ†äº« è®¡åˆ’2020è®¡åˆ’ 2019.12.31 2020-GOALS [ ] è·‘ä¸¤ä¸‰åœºé©¬æ‹‰æ¾ 2019è®¡åˆ’ 2018.12.31/21:59:00-&gt;æ›´æ–°äº2019.12.31 2019-GOALS [x] è´­ä¹°çš„ä¸“ä¸šä¹¦ç±è‡³å°‘çœ‹å®Œä¸€éï¼ˆå¹¶å‘ã€é‡æ„ã€è®¾è®¡æ¨¡å¼â€¦ï¼‰-&gt; 95%é¢å¤–ï¼š [x] è¿½äº†å¾ˆå¤šå‰§æ€»ç»“ï¼š æœ‰ä¼˜ç‚¹æœ‰ç¼ºç‚¹ï¼Œæ²¡åšæŒä¸‹æ¥çš„è¿˜æ˜¯å¤ªå¤šï¼Œè¿½äº†å¤ªå¤šå‰§ã€‚ä»¥åå¤šå­¦ä¹ ï¼Œå¤šæ€è€ƒï¼ æ—¶é—´è½´è®°å½•","link":"/about/index.html"},{"title":"","text":"&nbsp;&nbsp;å¬å¬éŸ³ä¹ éŸ³ä¹æ’­æ”¾å™¨ç”±mePlayeræä¾›ï¼Œå¸ƒå±€å‚ç…§ç½‘å‹åšå®¢æ‰€ä½œï¼Œæ„Ÿè°¢ä½œè€…çš„è¾›å‹¤ä»˜å‡ºã€‚æ›´å¤šéŸ³ä¹åˆ†äº«è¯·æŸ¥çœ‹æ­Œå•ã€‚ &nbsp;&nbsp;çœ‹çœ‹è§†é¢‘ ->ç‚¹å‡»ä»¥ä¸‹æ¡ç›®å¼€å§‹æ’­æ”¾è§†é¢‘,å‘ä¸‹æ»‘åŠ¨æŸ¥çœ‹æ›´å¤š","link":"/media/index.html"},{"title":"","text":"ğŸˆğŸˆå¾®ç¬‘å¢™ğŸˆğŸˆ å½­å°è‹’ &lt;/div&gt; å”è‰ºæ˜• &lt;/div&gt; æä¸€æ¡ &lt;/div&gt; gakki &lt;/div&gt; å›¾ç‰‡æœé›†äºäº’è”ç½‘ï¼Œä¾µæƒè¯·ç•™è¨€ï¼Œé©¬ä¸Šå¤„ç†ğŸ˜Šã€‚","link":"/album/index.html"},{"title":"","text":"æ¥è€Œä¸å¾€éç¤¼ä¹Ÿç•…æ‰€æ¬²è¨€ï¼Œæœ‰ç•™å¿…åº”","link":"/message/index.html"},{"title":"","text":"ç”³è¯·å‹é“¾é¡»çŸ¥ åŸåˆ™ä¸Šåªå’ŒæŠ€æœ¯ç±»åšå®¢äº¤æ¢ï¼Œä½†ä¸åŒ…æ‹¬å«æœ‰å’Œè‰²æƒ…ã€æš´åŠ›ã€æ”¿æ²»æ•æ„Ÿçš„ç½‘ç«™ã€‚ ä¸å’Œå‰½çªƒã€ä¾µæƒã€æ— è¯šä¿¡çš„ç½‘ç«™äº¤æ¢ï¼Œä¼˜å…ˆå’Œå…·æœ‰åŸåˆ›ä½œå“çš„ç½‘ç«™äº¤æ¢ã€‚ ç”³è¯·è¯·æä¾›ï¼šç«™ç‚¹åç§°ã€ç«™ç‚¹é“¾æ¥ã€ç«™ç‚¹æè¿°ã€logoæˆ–å¤´åƒï¼ˆä¸è¦è®¾ç½®é˜²ç›—é“¾ï¼‰ã€‚ æ’åä¸åˆ†å…ˆåï¼Œåˆ·æ–°åé‡æ’ï¼Œæ›´æ–°ä¿¡æ¯åè¯·ç•™è¨€å‘ŠçŸ¥ã€‚ ä¼šå®šæœŸæ¸…ç†å¾ˆä¹…å¾ˆä¹…ä¸æ›´æ–°çš„ã€ä¸ç¬¦åˆè¦æ±‚çš„å‹é“¾ï¼Œä¸å†å¦è¡Œé€šçŸ¥ã€‚ æœ¬ç«™ä¸å­˜å‚¨å‹é“¾å›¾ç‰‡ï¼Œå¦‚æœå‹é“¾å›¾ç‰‡æ¢äº†æ— æ³•æ›´æ–°ã€‚å›¾ç‰‡è£‚äº†çš„ä¼šæ›¿æ¢æˆé»˜è®¤å›¾ï¼Œéœ€è¦æ›´æ¢çš„è¯·ç•™è¨€å‘ŠçŸ¥ã€‚ æœ¬ç«™å‹é“¾ä¿¡æ¯å¦‚ä¸‹ï¼Œç”³è¯·å‹é“¾å‰è¯·å…ˆæ·»åŠ æœ¬ç«™ä¿¡æ¯ï¼š ç½‘ç«™å›¾æ ‡ï¼šhttps://removeif.github.io/images/avatar.jpg ç½‘ç«™åç§°ï¼šè¾£æ¤’ã®é…± ç½‘ç«™åœ°å€ï¼šhttps://removeif.github.io ç½‘ç«™ç®€ä»‹ï¼šåç«¯å¼€å‘ï¼ŒæŠ€æœ¯åˆ†äº« åŠ è½½ä¸­ï¼Œç¨ç­‰å‡ ç§’...","link":"/friend/index.html"},{"title":"éŸ³ä¹æ­Œå•æ”¶è—","text":"&lt;/meting-js&gt; æ¸©é¦¨æç¤ºï¼šé€‰æ‹©å–œæ¬¢çš„éŸ³ä¹åŒå‡»æ’­æ”¾ï¼Œç”±äºç‰ˆæƒåŸå› éƒ¨åˆ†ä¸èƒ½æ’­æ”¾ã€‚å¦‚æœå–œæ¬¢æ­Œå•æ”¶è—ä¸€ä¸‹ï¼Œå»ç½‘æ˜“äº‘éƒ½èƒ½æ’­æ”¾å“Ÿï¼","link":"/music/index.html"},{"title":"","text":"ç¢ç¢å¿µ tipsï¼šgithubç™»å½•åæŒ‰æ—¶é—´æ­£åºæŸ¥çœ‹ã€å¯ç‚¹èµåŠ â¤ï¸ã€æœ¬æ’ä»¶åœ°å€..ã€Œ+99æ¬¡æŸ¥çœ‹ã€&lt;/span&gt;&lt;/div&gt; ç¢ç¢å¿µåŠ è½½ä¸­ï¼Œè¯·ç¨ç­‰...&lt;/div&gt; $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '46a9f3481b46ea0129d8', clientSecret: '79c7c9cb847e141757d7864453bcbf89f0655b24', id: '666666', repo: 'issue_database', owner: 'removeif', admin: \"removeif\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"ç¥ç»ç½‘ç»œè¿›è¡ŒäºŒåˆ†ç±»æ—¶ï¼Œè¾“å‡ºå±‚ä½¿ç”¨ä¸¤ä¸ªç¥ç»å…ƒå’Œåªä½¿ç”¨ä¸€ä¸ªç¥ç»å…ƒï¼Œæ¨¡å‹çš„æ€§èƒ½æœ‰ä½•å·®å¼‚ï¼Œä¸ºä»€ä¹ˆï¼Ÿ","text":"https://www.zhihu.com/question/397625619","link":"/2021/11/04/2-classify/"},{"title":"å³å¸­æŸ¥è¯¢(Ad hoc)","text":"å®šä¹‰å³å¸­æŸ¥è¯¢ï¼ˆAd Hocï¼‰æ˜¯ç”¨æˆ·æ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œçµæ´»çš„é€‰æ‹©æŸ¥è¯¢æ¡ä»¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ç”Ÿæˆç›¸åº”çš„ç»Ÿè®¡æŠ¥è¡¨ã€‚å³å¸­æŸ¥è¯¢ä¸æ™®é€šåº”ç”¨æŸ¥è¯¢æœ€å¤§çš„ä¸åŒæ˜¯æ™®é€šçš„åº”ç”¨æŸ¥è¯¢æ˜¯å®šåˆ¶å¼€å‘çš„ï¼Œè€Œå³å¸­æŸ¥è¯¢æ˜¯ç”±ç”¨æˆ·è‡ªå®šä¹‰æŸ¥è¯¢æ¡ä»¶çš„ã€‚ ä¸¾ä¾‹è¯´æ˜ ä»¥ç”µå•†çš„æ•°ä»“åˆ†æé¡¹ç›®ä¸ºä¾‹ï¼Œæœ‰ä¸€äº›åº”ç”¨ä¾§/ä¸šåŠ¡ä¾§çš„åˆ†ææŒ‡æ ‡ï¼šæ¯æ—¥æ´»è·ƒç”¨æˆ·æ•°ï¼ˆæ—¥æ´»ï¼‰ï¼Œæ¯æ—¥ç•™å­˜ç”¨æˆ·æ•°ï¼ˆç•™å­˜ï¼‰ï¼Œæ–°æ³¨å†Œç”¨æˆ·æœ‰å¤šå°‘ä¸‹äº†å•ï¼ˆè½¬æ¢ç‡ï¼‰ï¼Œå› ä¸ºè®¡ç®—æ–¹æ³•å›ºå®šï¼Œå˜åŒ–çš„æ˜¯æ¯å¤©çš„æ•°æ®ï¼Œå› æ­¤è¿™äº›æŒ‡æ ‡çš„æŸ¥è¯¢/è®¡ç®—SQLæ˜¯æå‰å†™å¥½çš„ï¼Œåˆ°åº—è¢«è°ƒåº¦ï¼ˆAzkabanï¼‰æ‰§è¡Œå³å¯ï¼› ä½†æœ‰ä¸€äº›æŒ‡æ ‡æˆ–è€…ä¸´æ—¶å¢åŠ çš„æŒ‡æ ‡ã€ä¸´æ—¶å¢åŠ çš„ä¸€äº›åˆ†æéœ€æ±‚ï¼Œæ˜¯æ— æ³•é¢„çŸ¥å…¶è®¡ç®—é€»è¾‘çš„ï¼Œæ‰€ä»¥è¦ç°å†™æŸ¥è¯¢SQLï¼Œå¹¶ä¸”å¸Œæœ›èƒ½å¾ˆå¿«æ‹¿åˆ°æŸ¥è¯¢/è®¡ç®—ç»“æœï¼Œè¿™å°±æ˜¯å³å¸­æŸ¥è¯¢ å·¥å…·Kylinã€druidã€prestoã€impala https://zhuanlan.zhihu.com/p/266695601","link":"/2022/02/05/Ad-hoc/"},{"title":"Atlas","text":"1.æ¦‚è¿°Apache Atlasä¸ºç»„ç»‡æä¾›å¼€æ”¾å¼å…ƒæ•°æ®ç®¡ç†å’Œæ²»ç†åŠŸèƒ½ï¼Œç”¨ä»¥æ„å»ºå…¶æ•°æ®èµ„äº§ç›®å½•ï¼Œå¯¹è¿™äº›èµ„äº§è¿›è¡Œåˆ†ç±»å’Œç®¡ç†ï¼Œå¹¶ä¸ºæ•°æ®åˆ†æå¸ˆå’Œæ•°æ®æ²»ç†+å›¢é˜Ÿï¼Œæä¾›å›´ç»•è¿™äº›æ•°æ®èµ„äº§çš„åä½œåŠŸèƒ½ã€‚ 2.Atlasçš„å…·ä½“åŠŸèƒ½ å…ƒæ•°æ®åˆ†ç±» æ”¯æŒå¯¹å…ƒæ•°æ®è¿›è¡Œåˆ†ç±»ç®¡ç†ï¼Œä¾‹å¦‚ä¸ªäººä¿¡æ¯ï¼Œæ•æ„Ÿä¿¡æ¯ç­‰ å…ƒæ•°æ®æ£€ç´¢ å¯æŒ‰ç…§å…ƒæ•°æ®ç±»å‹ã€å…ƒæ•°æ®åˆ†ç±»è¿›è¡Œæ£€ç´¢ï¼Œæ”¯æŒå…¨æ–‡æ£€ç´¢ è¡€ç¼˜ä¾èµ– æ”¯æŒè¡¨åˆ°è¡¨å’Œå­—æ®µåˆ°å­—æ®µä¹‹é—´çš„è¡€ç¼˜ä¾èµ–ï¼Œä¾¿äºè¿›è¡Œé—®é¢˜å›æº¯å’Œå½±å“åˆ†æç­‰ 1ï¼‰è¡¨ä¸è¡¨ä¹‹é—´çš„è¡€ç¼˜ä¾èµ– 2ï¼‰å­—æ®µä¸å­—æ®µä¹‹é—´çš„è¡€ç¼˜ä¾èµ– 3.Atlasæ¶æ„åŸç† 4.ä½¿ç”¨4.1 Hiveå…ƒæ•°æ®åˆæ¬¡å¯¼å…¥æ“ä½œï¼š Atlasæä¾›äº†ä¸€ä¸ªHiveå…ƒæ•°æ®å¯¼å…¥çš„è„šæœ¬ï¼Œç›´æ¥æ‰§è¡Œè¯¥è„šæœ¬ï¼Œå³å¯å®ŒæˆHiveå…ƒæ•°æ®çš„åˆæ¬¡å…¨é‡å¯¼å…¥ã€‚ /opt/module/atlas/hook-bin/import-hive.sh é—®é¢˜ï¼š Failed to import Hive Meta Data!!! æ³¨æ„ï¼šhive â€”service metastore &amp; 4.2 Hiveå…ƒæ•°æ®å¢é‡åŒæ­¥Hiveå…ƒæ•°æ®çš„å¢é‡åŒæ­¥ï¼Œæ— éœ€äººä¸ºå¹²é¢„ï¼Œåªè¦Hiveä¸­çš„å…ƒæ•°æ®å‘ç”Ÿå˜åŒ–ï¼ˆæ‰§è¡ŒDDLè¯­å¥ï¼‰ï¼ŒHive Hookå°±ä¼šå°†å…ƒæ•°æ®çš„å˜åŠ¨é€šçŸ¥Atlasã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒAtlasè¿˜ä¼šæ ¹æ®DMLè¯­å¥è·å–æ•°æ®ä¹‹é—´çš„è¡€ç¼˜å…³ç³»ã€‚","link":"/2022/02/07/Atlas/"},{"title":"Azkaban","text":"https://blog.csdn.net/wtzhm/article/details/89220508 1 ä¸ºä»€ä¹ˆéœ€è¦å·¥ä½œæµè°ƒåº¦ç³»ç»Ÿ1ï¼‰ä¸€ä¸ªå®Œæ•´çš„æ•°æ®åˆ†æç³»ç»Ÿé€šå¸¸éƒ½æ˜¯ç”±å¤§é‡ä»»åŠ¡å•å…ƒç»„æˆï¼šShellè„šæœ¬ç¨‹åºï¼ŒJavaç¨‹åºï¼ŒMapReduceç¨‹åºã€Hiveè„šæœ¬ç­‰ 2ï¼‰å„ä»»åŠ¡å•å…ƒä¹‹é—´å­˜åœ¨æ—¶é—´å…ˆååŠå‰åä¾èµ–å…³ç³» 3ï¼‰ä¸ºäº†å¾ˆå¥½åœ°ç»„ç»‡èµ·è¿™æ ·çš„å¤æ‚æ‰§è¡Œè®¡åˆ’ï¼Œéœ€è¦ä¸€ä¸ªå·¥ä½œæµè°ƒåº¦ç³»ç»Ÿæ¥è°ƒåº¦æ‰§è¡Œ 2 å¸¸è§å·¥ä½œæµè°ƒåº¦ç³»ç»Ÿ1ï¼‰ç®€å•çš„ä»»åŠ¡è°ƒåº¦ ç›´æ¥ä½¿ç”¨Linuxçš„Crontabæ¥å®šä¹‰ï¼› 2ï¼‰å¤æ‚çš„ä»»åŠ¡è°ƒåº¦ å¼€å‘è°ƒåº¦å¹³å°æˆ–ä½¿ç”¨ç°æˆçš„å¼€æºè°ƒåº¦ç³»ç»Ÿï¼Œæ¯”å¦‚Ooizeã€Azkabanã€ Airflowã€DolphinSchedulerç­‰ã€‚ 3ï¼‰Azkaban Azkaban is a batch workflow job scheduler created at LinkedIn to run Hadoop jobs. Azkaban resolves the ordering through job dependencies and provides an easy to use web user interface to maintain and track your workflows. Azkabanæ˜¯ä¸€ä¸ªå¼€æºçš„ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼Œç”¨äºè´Ÿè´£ä»»åŠ¡çš„è°ƒåº¦è¿è¡Œï¼ˆå¦‚æ•°æ®ä»“åº“è°ƒåº¦ï¼‰ï¼Œç”¨ä»¥æ›¿ä»£linuxä¸­çš„crontabã€‚ å’ŒOozieå¯¹æ¯” æ€»ä½“æ¥è¯´ï¼ŒOoizeç›¸æ¯”Azkabanæ˜¯ä¸€ä¸ªé‡é‡çº§çš„ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼ŒåŠŸèƒ½å…¨é¢ï¼Œä½†é…ç½®ä½¿ç”¨ä¹Ÿæ›´å¤æ‚ã€‚å¦‚æœå¯ä»¥ä¸åœ¨æ„æŸäº›åŠŸèƒ½çš„ç¼ºå¤±ï¼Œè½»é‡çº§è°ƒåº¦å™¨Azkabanæ˜¯å¾ˆä¸é”™çš„å€™é€‰å¯¹è±¡ã€‚ 3 ä½¿ç”¨ 1 ä½¿ç”¨æµç¨‹1.æ•°æ®å‡†å¤‡ 2.ç¼–å†™Azkabanå·¥ä½œæµç¨‹é…ç½®æ–‡ä»¶ â€‹ a.ç¼–å†™azkaban.project â€‹ b.ç¼–å†™gmall.flowæ–‡ä»¶ 2 å¤šExecutoræ¨¡å¼ä¸‹æ³¨æ„äº‹é¡¹æ–¹æ¡ˆä¸€ï¼šæŒ‡å®šç‰¹å®šçš„Executorï¼ˆhadoop102ï¼‰å»æ‰§è¡Œä»»åŠ¡ã€‚ â€‹ a.åœ¨MySQLä¸­azkabanæ•°æ®åº“executorsè¡¨ä¸­ï¼ŒæŸ¥è¯¢hadoop102ä¸Šçš„Executorçš„idã€‚ â€‹ b.åœ¨æ‰§è¡Œå·¥ä½œæµç¨‹æ—¶åŠ å…¥useExecutorå±æ€§ æ–¹æ¡ˆäºŒï¼šåœ¨Executoræ‰€åœ¨æ‰€æœ‰èŠ‚ç‚¹éƒ¨ç½²ä»»åŠ¡æ‰€éœ€è„šæœ¬å’Œåº”ç”¨ã€‚ æ¨èä½¿ç”¨æ–¹æ¡ˆäºŒ","link":"/2022/02/04/Azkaban/"},{"title":"å†·å¯åŠ¨","text":"æ¨èç³»ç»Ÿå†·å¯åŠ¨ mark https://zhuanlan.zhihu.com/p/79950668","link":"/2021/10/25/Cold-start/"},{"title":"DGL","text":"https://docs.dgl.ai/api/python/nn.html å®ç°äº†å¸¸è§çš„å›¾å·ç§¯å’Œå›¾æ± åŒ– ä»¥graphconvä¸ºä¾‹ï¼Œä¸ä»…ç»™å‡ºäº†æ¥å£å’Œä»£ç è¿˜æœ‰è®ºæ–‡ä»‹ç»","link":"/2021/12/27/DGL/"},{"title":"Wide&amp;Deepå’ŒDeepFM","text":"https://zhuanlan.zhihu.com/p/66928413 https://blog.csdn.net/sinat_29819401/article/details/91359217","link":"/2021/11/05/DeepFM/"},{"title":"Factorization Machines","text":"åŸæ–‡åœ°å€ https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/Rendle2010FM.pdf https://zhuanlan.zhihu.com/p/50426292 a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models I. INTRODUCTIONIn total, the advantages of our proposed FM are:1) FMs allow parameter estimation under very sparse data where SVMs fail.2) FMs have linear complexity, can be optimized in the primal and do not rely on support vectors like SVMs.3) FMs are a general predictor that can work with any real valued feature vector. II. PREDICTION UNDER SPARSITY III. FACTORIZATION MACHINES (FM)A. Factorization Machine Model1) æ¨¡å‹: \\hat{y}(x):=w_0+\\sum_{i=1}^nw_ix_i+\\sum_{i=1}^n\\sum_{j=i+1}^n \\bbox[border: 2px solid red]{w_{i,j}}x_ix_j$x_i$è¡¨ç¤ºç¬¬$i$ä¸ªç‰¹å¾ï¼Œä½†æ˜¯é’ˆå¯¹ä¸Šå¼ï¼Œä¸€ä¸ªå¾ˆå¤§çš„é—®é¢˜ï¼Œç”¨æˆ·äº¤äº’çŸ©é˜µå¾€å¾€æ˜¯æ¯”è¾ƒç¨€ç–çš„ï¼Œè¿™æ ·å°±ä¼šå¯¼è‡´å¯¹$w_{i,j}$çš„ä¼°ç®—å­˜åœ¨å¾ˆå¤§çš„é—®é¢˜ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡å¦‚æƒ³è¦ä¼°è®¡Alice(A)å’ŒStar Trek(ST)çš„äº¤äº’å‚æ•°$w_{A,ST}$ï¼Œç”±äºè®­ç»ƒé›†ä¸­æ²¡æœ‰å®ä¾‹åŒæ—¶æ»¡è¶³$x_A$å’Œ$x_{ST}$éé›¶ï¼Œè¿™ä¼šé€ æˆ$w_{A,ST}=0$ã€‚å› æ­¤è¿™é‡Œä½¿ç”¨äº†çŸ©é˜µåˆ†è§£çš„æ€æƒ³ï¼š \\textbf{W} = \\textbf{V}\\textbf{V}^T,\\textbf{V}=\\begin{pmatrix} \\textbf{v}_1 \\\\ \\textbf{v}_2\\\\...\\\\\\textbf{v}_n \\end{pmatrix} \\in {R}^{n\\times k} \\\\\\bbox[border: 2px solid red]{w_{i,j}==\\sum_{f=1}^k v_{i,f}\\cdot v_{j,f}} \\\\\\hat{y}(x):=w_0+\\sum_{i=1}^nw_ix_i+\\sum_{i=1}^n\\sum_{j=i+1}^n \\bbox[border: 2px solid red]{}x_ix_j2) æå‡æ•ˆç‡: ç›´æ¥è®¡ç®—ä¸Šé¢çš„å…¬å¼æ±‚è§£$\\hat{y}(x)$çš„æ—¶é—´å¤æ‚åº¦ä¸º$O ( k n^2 ) $ï¼Œå› ä¸ºæ‰€æœ‰çš„ç‰¹å¾äº¤å‰éƒ½éœ€è¦è®¡ç®—ã€‚ä½†æ˜¯å¯ä»¥é€šè¿‡å…¬å¼å˜æ¢ï¼Œå°†æ—¶é—´å¤æ‚åº¦å‡å°‘åˆ°$O(kn)$ï¼Œå¦‚ä¸‹å…¬å¼æ¨å¯¼ \\begin{align*} \\\\\\sum_{i=1}^n\\sum_{j=i+1}^n x_ix_j&=\\frac{1}{2}\\sum_{i=1}^n\\sum_{j=1}^n x_ix_j-\\frac{1}{2}\\sum_{i=1}^n\\ x_ix_i \\\\&=... \\\\&=\\frac{1}{2}\\sum_{f=1}^k((\\sum_{i=1}^nv_{i,f}x_i)^2-\\sum_{i=1}^nv_{i,f}^2x_i^2) \\end{align*}B. Factorization Machines as PredictorsFM can be applied to a variety of prediction tasks. Among them are: Regressionï¼ŒBinary classificationï¼ŒRanking C. Learning Factorization Machinesthe model parameters of FMs can be learned efficiently by gradient descent methods â€“ e.g. stochastic gradient descent (SGD).The gradient of the FM model is: \\\\\\begin{equation} \\frac{\\partial \\hat{y}(x)}{\\partial \\theta}=\\left\\{ \\begin{array}{rcl} 1& & {if \\ \\theta \\ is \\ w_0 }\\\\ x_i & & {if \\ \\theta \\ is \\ w_i}\\\\ x_i\\sum_{j=1}^nv_{j,f}x_j-v_{i,f}x_i^2 & & {if \\ \\theta \\ is \\ v_{i,f}} \\end{array} \\right. \\end{equation}D. d-way Factorization MachineThe 2-way FM described so far can easily be generalized to a d-way FM: \\hat{y}(x):=w_0+\\sum_{i=1}^nw_ix_i+\\sum_{l=2}^d\\sum_{i_l=1}^n ...\\sum_{i_l=i_{l-1}+1}^n (\\prod \\limits_{j=1}^lx_{i_j})(\\sum_{f=1}^{k_l}\\prod \\limits_{j=1}^lv_{i_j,f}^{(l)})ç›´æ¥è®¡ç®—ä¸Šå¼çš„æ—¶é—´å¤æ‚åº¦ä¸º$O(k_dn^d)$ï¼Œåˆ©ç”¨ç±»ä¼¼ä¸Šé¢çš„å…¬å¼å˜å½¢ä¹Ÿå¯ä»¥å°†å…¶é™ä½ä¸º$O(k_d n )$ E. SummaryFMs model all possible interactions between values in the feature vector $x$ using factorized interactions instead of full parametrized ones. This has two main advantages: 1) The interactions between values can be estimated even under high sparsity. Especially, it is possible to generalize to unobserved interactions.2) The number of parameters as well as the time for prediction and learning is linear. IV. FMS VS. SVMSV. FMS VS. OTHER FACTORIZATION MODELSå‚è€ƒhttps://blog.csdn.net/qq_26822029/article/details/103993243","link":"/2021/09/30/FM/"},{"title":"ConvGNNs","text":"ConvGNNs fall into two categories, spectral-based and spatial-based. Spectral based approaches define graph convolutions by introducing filters from the perspective of graph signal processing [82] where the graph convolutional operation is interpreted as removing noises from graph signals. Spatial-based approaches inherit ideas from RecGNNs to define graph convolutions by information propagation. spatial-based methods have developed rapidly recently due to its attractive efficiency, flexibility, and generality. è°±åŸŸå›¾å·ç§¯æ˜¯ç©ºåŸŸå›¾å·ç§¯çš„ç‰¹ä¾‹ https://zhuanlan.zhihu.com/p/139682302 https://zhuanlan.zhihu.com/p/122968925 https://blog.csdn.net/weixin_45901519/article/details/106388964 https://blog.csdn.net/weixin_45901519/article/details/106436591 https://blog.csdn.net/weixin_45901519/article/details/106492963","link":"/2021/12/27/GCN/"},{"title":"Grafana","text":"Operational dashboards for your data here, there, or anywhere Grafanaæ˜¯ä¸€æ¬¾ç”¨Goè¯­è¨€å¼€å‘çš„å¼€æºæ•°æ®å¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥åšæ•°æ®ç›‘æ§å’Œæ•°æ®ç»Ÿè®¡ï¼Œå¸¦æœ‰å‘Šè­¦åŠŸèƒ½ã€‚","link":"/2022/02/05/Grafana/"},{"title":"GNNæ ¸å¿ƒæ„æˆ","text":"GNNç§ç±»å¾ˆå¤šï¼ŒåŒ…æ‹¬GCNï¼ŒGAEsï¼ŒRecGNNsç­‰ï¼Œä»–ä»¬çš„å·®å¼‚åœ¨äºå›¾ç»“æ„ï¼Œæ¶ˆæ¯ä¼ é€’ 1.å›¾ç»“æ„åŒæ„å›¾ï¼Œå¼‚æ„å›¾ï¼Œç»“ç‚¹å’Œè¾¹çš„è®¾è®¡ç­‰ åŒæ„å›¾ï¼šåªæœ‰ä¸€ç§ç±»å‹çš„èŠ‚ç‚¹å’Œè¾¹ å¼‚æ„å›¾ï¼šå¯ä»¥æœ‰ä¸åŒç±»å‹çš„èŠ‚ç‚¹å’Œè¾¹ 2.æ¶ˆæ¯ä¼ é€’æ¶ˆæ¯ä¼ é€’æ˜¯å®ç°GNNçš„ä¸€ç§é€šç”¨æ¡†æ¶å’Œç¼–ç¨‹èŒƒå¼ã€‚åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªè¿‡ç¨‹ï¼š 1 Message Propagation èšåˆé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œå½¢æˆä¸€ä¸ªæ¶ˆæ¯å‘é‡ 2 Representation Updating æ›´æ–°å½“å‰æ—¶åˆ»çš„èŠ‚ç‚¹è¡¨ç¤º å‚è€ƒhttps://docs.dgl.ai/guide/message.html# https://zhuanlan.zhihu.com/p/352510643 https://aclanthology.org/2020.acl-main.547.pdf https://zhuanlan.zhihu.com/p/350900048 https://docs.dgl.ai/guide_cn/graph-heterogeneous.html#guide-cn-graph-heterogeneous https://zhuanlan.zhihu.com/p/376062090","link":"/2022/01/17/GNN-component/"},{"title":"Kerberos","text":"1.å®šä¹‰Kerberosæ˜¯ä¸€ç§è®¡ç®—æœºç½‘ç»œè®¤è¯åè®®ï¼Œç”¨æ¥åœ¨éå®‰å…¨ç½‘ç»œä¸­ï¼Œå¯¹ä¸ªäººé€šä¿¡ä»¥å®‰å…¨çš„æ‰‹æ®µè¿›è¡Œèº«ä»½è®¤è¯ã€‚è¿™ä¸ªè¯åˆæŒ‡éº»çœç†å·¥å­¦é™¢ä¸ºè¿™ä¸ªåè®®å¼€å‘çš„ä¸€å¥—è®¡ç®—æœºè½¯ä»¶ã€‚è½¯ä»¶è®¾è®¡ä¸Šé‡‡ç”¨å®¢æˆ·ç«¯/æœåŠ¡å™¨ç»“æ„ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¿›è¡Œç›¸äº’è®¤è¯ï¼Œå³å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯å‡å¯å¯¹å¯¹æ–¹è¿›è¡Œèº«ä»½è®¤è¯ã€‚å¯ä»¥ç”¨äºé˜²æ­¢çªƒå¬ã€é˜²æ­¢é‡æ”¾æ”»å‡»ã€ä¿æŠ¤æ•°æ®å®Œæ•´æ€§ç­‰åœºåˆï¼Œæ˜¯ä¸€ç§åº”ç”¨å¯¹ç§°å¯†é’¥ä½“åˆ¶è¿›è¡Œå¯†é’¥ç®¡ç†çš„ç³»ç»Ÿã€‚ 1ï¼‰KDCï¼ˆKey Distribute Centerï¼‰ï¼šå¯†é’¥åˆ†å‘ä¸­å¿ƒï¼Œè´Ÿè´£å­˜å‚¨ç”¨æˆ·ä¿¡æ¯ï¼Œç®¡ç†å‘æ”¾ç¥¨æ®ã€‚ 2ï¼‰Realmï¼šKerberosæ‰€ç®¡ç†çš„ä¸€ä¸ªé¢†åŸŸæˆ–èŒƒå›´ã€‚ 3ï¼‰Rrincipalï¼šå¯ä»¥ç†è§£ä¸ºKerberosä¸­ä¿å­˜çš„ä¸€ä¸ªè´¦å·ï¼Œå…¶æ ¼å¼é€šå¸¸å¦‚ä¸‹ï¼šprimary/instance@realm 4ï¼‰keytabï¼šå¯†é’¥æ–‡ä»¶ã€‚ æœ‰ä¸ªç–‘é—® ï¼Œå¯¹è°è®¤è¯ï¼Ÿæ˜¯å¯¹ä¸åŒç”¨æˆ·å—ï¼ˆrootï¼Œuser1ï¼Œuser2ï¼‰ï¼Ÿ 2.è®¤è¯åŸç† https://cloud.tencent.com/developer/article/1496451 https://blog.csdn.net/jewes/article/details/20792021 3.åŸºæœ¬æ“ä½œhttps://blog.csdn.net/Happy_Sunshine_Boy/article/details/102801386 1 åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ· 2 æ³¨å†Œ 3 è®¤è¯ 4.HADOOPé…ç½® https://www.cnblogs.com/yjt1993/p/11769515.html https://makeling.github.io/bigdata/39395030.html è®¿é—®HDFSé›†ç¾¤æ–‡ä»¶ Shellå‘½ä»¤ kinit admin/admin klist webé¡µé¢ 1.å®‰è£…Kerberoså®¢æˆ·ç«¯ 2.é…ç½®ç«ç‹æµè§ˆå™¨ 3.è®¤è¯ 5.HIVEé…ç½® https://zhuanlan.zhihu.com/p/137424234 å®¢æœç«¯è®¿é—® beeline 0.é¦–å…ˆéœ€ä½¿ç”¨hiveç”¨æˆ·å¯åŠ¨hiveserver2 [root@hadoop102 ~]# sudo -i -u hive hiveserver2 1.è®¤è¯ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå¹¶æŒ‰ç…§æç¤ºè¾“å…¥å¯†ç  [atguigu@hadoop102 ~]$ kinit atguigu 2.ä½¿ç”¨beelineå®¢æˆ·ç«¯è¿æ¥hiveserver2 [atguigu@hadoop102 ~]$ beeline 3.ä½¿ç”¨å¦‚ä¸‹urlè¿›è¡Œè¿æ¥ 1!connect jdbc:hive2://hadoop102:10000/;principal=hive/hadoop102@EXAMPLE.COM DataGripå®¢æˆ·ç«¯ https://blog.csdn.net/github_39319229/article/details/112692897 ç»å¸¸è¿æ¥ä¸ç¨³å®šï¼Œè¿æ¥å¤±è´¥å¯ä»¥å°è¯•é‡å¯DataGrip 6.æ•°ä»“æ­¤å¤„ç»Ÿä¸€å°†æ•°ä»“çš„å…¨éƒ¨æ•°æ®èµ„æºçš„æ‰€æœ‰è€…è®¾ä¸ºhiveç”¨æˆ·ï¼Œå…¨æµç¨‹çš„æ¯æ­¥æ“ä½œå‡è®¤è¯ä¸ºhiveç”¨æˆ·ã€‚ 7.å³å¸­æŸ¥è¯¢8.sparkhttps://www.cnblogs.com/bainianminguo/p/12639887.html 9 hbase1 hbase shell kerberosè®¤è¯é”™è¯¯ 1root:kinit atguigu å‚è€ƒhttps://blog.csdn.net/jewes/article/details/20792021","link":"/2022/02/06/Kerberos/"},{"title":"Kylin","text":"æ¶æ„ Apache Kylinæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼åˆ†æå¼•æ“ï¼Œæä¾›Hadoop/Sparkä¹‹ä¸Šçš„SQLæŸ¥è¯¢æ¥å£åŠå¤šç»´åˆ†æï¼ˆOLAPï¼‰èƒ½åŠ›ä»¥æ”¯æŒè¶…å¤§è§„æ¨¡æ•°æ®ï¼Œæœ€åˆç”±eBay Incå¼€å‘å¹¶è´¡çŒ®è‡³å¼€æºç¤¾åŒºã€‚å®ƒèƒ½åœ¨äºšç§’å†…æŸ¥è¯¢å·¨å¤§çš„Hiveè¡¨ã€‚ 1ï¼‰REST Server REST Serveræ˜¯ä¸€å¥—é¢å‘åº”ç”¨ç¨‹åºå¼€å‘çš„å…¥å£ç‚¹ï¼Œæ—¨åœ¨å®ç°é’ˆå¯¹Kylinå¹³å°çš„åº”ç”¨å¼€å‘å·¥ä½œã€‚ æ­¤ç±»åº”ç”¨ç¨‹åºå¯ä»¥æä¾›æŸ¥è¯¢ã€è·å–ç»“æœã€è§¦å‘cubeæ„å»ºä»»åŠ¡ã€è·å–å…ƒæ•°æ®ä»¥åŠè·å–ç”¨æˆ·æƒé™ç­‰ç­‰ã€‚å¦å¤–å¯ä»¥é€šè¿‡Restfulæ¥å£å®ç°SQLæŸ¥è¯¢ã€‚ 2ï¼‰æŸ¥è¯¢å¼•æ“ï¼ˆQuery Engineï¼‰ å½“cubeå‡†å¤‡å°±ç»ªåï¼ŒæŸ¥è¯¢å¼•æ“å°±èƒ½å¤Ÿè·å–å¹¶è§£æç”¨æˆ·æŸ¥è¯¢ã€‚å®ƒéšåä¼šä¸ç³»ç»Ÿä¸­çš„å…¶å®ƒç»„ä»¶è¿›è¡Œäº¤äº’ï¼Œä»è€Œå‘ç”¨æˆ·è¿”å›å¯¹åº”çš„ç»“æœã€‚ 3ï¼‰è·¯ç”±å™¨ï¼ˆRoutingï¼‰ åœ¨æœ€åˆè®¾è®¡æ—¶æ›¾è€ƒè™‘è¿‡å°†Kylinä¸èƒ½æ‰§è¡Œçš„æŸ¥è¯¢å¼•å¯¼å»Hiveä¸­ç»§ç»­æ‰§è¡Œï¼Œä½†åœ¨å®è·µåå‘ç°Hiveä¸Kylinçš„é€Ÿåº¦å·®å¼‚è¿‡å¤§ï¼Œå¯¼è‡´ç”¨æˆ·æ— æ³•å¯¹æŸ¥è¯¢çš„é€Ÿåº¦æœ‰ä¸€è‡´çš„æœŸæœ›ï¼Œå¾ˆå¯èƒ½å¤§å¤šæ•°æŸ¥è¯¢å‡ ç§’å†…å°±è¿”å›ç»“æœäº†ï¼Œè€Œæœ‰äº›æŸ¥è¯¢åˆ™è¦ç­‰å‡ åˆ†é’Ÿåˆ°å‡ ååˆ†é’Ÿï¼Œå› æ­¤ä½“éªŒéå¸¸ç³Ÿç³•ã€‚æœ€åè¿™ä¸ªè·¯ç”±åŠŸèƒ½åœ¨å‘è¡Œç‰ˆä¸­é»˜è®¤å…³é—­ã€‚ 4ï¼‰å…ƒæ•°æ®ç®¡ç†å·¥å…·ï¼ˆMetadataï¼‰ Kylinæ˜¯ä¸€æ¬¾å…ƒæ•°æ®é©±åŠ¨å‹åº”ç”¨ç¨‹åºã€‚å…ƒæ•°æ®ç®¡ç†å·¥å…·æ˜¯ä¸€å¤§å…³é”®æ€§ç»„ä»¶ï¼Œç”¨äºå¯¹ä¿å­˜åœ¨Kylinå½“ä¸­çš„æ‰€æœ‰å…ƒæ•°æ®è¿›è¡Œç®¡ç†ï¼Œå…¶ä¸­åŒ…æ‹¬æœ€ä¸ºé‡è¦çš„cubeå…ƒæ•°æ®ã€‚å…¶å®ƒå…¨éƒ¨ç»„ä»¶çš„æ­£å¸¸è¿ä½œéƒ½éœ€ä»¥å…ƒæ•°æ®ç®¡ç†å·¥å…·ä¸ºåŸºç¡€ã€‚ Kylinçš„å…ƒæ•°æ®å­˜å‚¨åœ¨hbaseä¸­ã€‚ 5ï¼‰ä»»åŠ¡å¼•æ“ï¼ˆCube Build Engineï¼‰ è¿™å¥—å¼•æ“çš„è®¾è®¡ç›®çš„åœ¨äºå¤„ç†æ‰€æœ‰ç¦»çº¿ä»»åŠ¡ï¼Œå…¶ä¸­åŒ…æ‹¬shellè„šæœ¬ã€Java APIä»¥åŠMap Reduceä»»åŠ¡ç­‰ç­‰ã€‚ä»»åŠ¡å¼•æ“å¯¹Kylinå½“ä¸­çš„å…¨éƒ¨ä»»åŠ¡åŠ ä»¥ç®¡ç†ä¸åè°ƒï¼Œä»è€Œç¡®ä¿æ¯ä¸€é¡¹ä»»åŠ¡éƒ½èƒ½å¾—åˆ°åˆ‡å®æ‰§è¡Œå¹¶è§£å†³å…¶é—´å‡ºç°çš„æ•…éšœã€‚ Kylin Cubeæ„å»ºåŸç†ï¼Œæ„å»ºä¼˜åŒ–https://jishuin.proginn.com/p/763bfbd2bb9c BIå·¥å…·é›†æˆå¯ä»¥ä¸Kylinç»“åˆä½¿ç”¨çš„å¯è§†åŒ–å·¥å…·å¾ˆå¤šï¼Œä¾‹å¦‚ï¼š ODBCï¼šä¸Tableauã€Excelã€PowerBIç­‰å·¥å…·é›†æˆ JDBCï¼šä¸Saikuã€BIRTç­‰Javaå·¥å…·é›†æˆ RestAPIï¼šä¸JavaScriptã€Webç½‘é¡µé›†æˆ Kylinå¼€å‘å›¢é˜Ÿè¿˜è´¡çŒ®äº†Zepplinçš„æ’ä»¶ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨Zepplinæ¥è®¿é—®KylinæœåŠ¡ã€‚","link":"/2022/02/05/Kylin/"},{"title":"æ’åºå­¦ä¹ ","text":"Literature survey for Learning to rank https://www.eecis.udel.edu/~vijay/fall13/snlp/lit-survey/LearningToRank.pdf a short introduction to learning to rankï¼ˆæèˆªï¼‰ https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en Learning to Rank for Information Retrieval â€” By Tie-Yan Liu http://didawikinf.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf Feature Selection For Ranking https://dl.acm.org/doi/10.1145/1277741.1277811 A Deep Look into Neural Ranking Models for Information Retrieval ä¸­ç§‘é™¢ https://par.nsf.gov/servlets/purl/10277191 ç›¸å…³å‚è€ƒï¼š https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en https://blog.csdn.net/anshuai_aw1/article/details/86018105 https://blog.csdn.net/pearl8899/article/details/102920628 https://blog.csdn.net/lipengcn/article/details/80373744 åˆ†ç±»","link":"/2021/08/16/L2R/"},{"title":"æå¤§ä¼¼ç„¶ä¼°è®¡","text":"1.å®šä¹‰å°±æ˜¯åˆ©ç”¨å·²çŸ¥çš„æ ·æœ¬ç»“æœä¿¡æ¯ï¼Œåæ¨æœ€å…·æœ‰å¯èƒ½å¯¼è‡´è¿™äº›æ ·æœ¬ç»“æœå‡ºç°çš„æ¨¡å‹å‚æ•°å€¼ã€‚æ¢å¥è¯è¯´ï¼Œå³ï¼šâ€œæ¨¡å‹å·²å®šï¼Œç»“æœå·²çŸ¥ï¼Œåæ¨å‚æ•°â€ã€‚ 2.æå¤§ä¼¼ç„¶æ„é€ æŸå¤±å‡½æ•°å¤§å¤šæ•°å¸¸è§çš„æŸå¤±å‡½æ•°å°±æ˜¯åŸºäºæå¤§ä¼¼ç„¶æ¨å¯¼çš„ã€‚ä¾‹å­å‚è€ƒ https://www.cnblogs.com/hello-ai/p/11000899.html åˆ¤åˆ«æ¨¡å‹ä¸‹çš„æå¤§ä¼¼ç„¶ä¼°è®¡ æœ€å¤§ä¼¼ç„¶ä¼°è®¡å¾ˆå®¹æ˜“æ‰©å±•åˆ°ä¼°è®¡æ¡ä»¶æ¦‚ç‡$P\\left (y|x;\\theta \\right)$ï¼Œä»è€Œç»™å®š$x$é¢„æµ‹$y$ã€‚å®é™…ä¸Šè¿™æ˜¯æœ€å¸¸è§çš„æƒ…å†µï¼Œå› ä¸ºè¿™æ„æˆäº†å¤§å¤šæ•°ç›‘ç£å­¦ä¹ çš„åŸºç¡€ã€‚å¦‚æœ$X$è¡¨ç¤ºæ‰€æœ‰çš„è¾“å…¥ï¼Œ$Y$è¡¨ç¤ºæˆ‘ä»¬è§‚æµ‹åˆ°çš„ç›®æ ‡ï¼Œé‚£ä¹ˆæ¡ä»¶æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ˜¯ï¼š \\theta_{ML} = \\mathop\\arg\\max_{\\theta}P\\left(Y|X;\\theta \\right)å¦‚æœå‡è®¾æ ·æœ¬æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œé‚£ä¹ˆè¿™å¯ä»¥åˆ†è§£æˆ \\theta_{ML} = \\mathop\\arg\\max_{\\theta}\\sum_{i=1}^m logP\\left(y^{(i)}|x^{(i)};\\theta \\right)ç”Ÿæˆæ¨¡å‹ä¸‹çš„æå¤§ä¼¼ç„¶ä¼°è®¡ è€ƒè™‘ä¸€ç»„å«æœ‰mä¸ªæ ·æœ¬çš„æ•°æ®é›†$X = \\left \\{ x^{(1)}, â€¦, x^{(m)} \\right \\}$ï¼Œç”±$p_{data}(x)$ç”Ÿæˆï¼Œç‹¬ç«‹åŒåˆ†å¸ƒ å¯¹ç‹¬ç«‹åŒåˆ†å¸ƒçš„æ ·æœ¬ï¼Œç”Ÿæˆæ ·æœ¬é›†$X$çš„æ¦‚ç‡å¦‚ä¸‹: p_{model}(X; \\theta)= \\prod _{i=1}^m p_{model}\\left (x^{(i)}; \\theta \\right )å¯¹$\\theta$çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡è¢«å®šä¹‰ä¸ºï¼š \\theta_{ML} = \\mathop{\\arg\\max}_{\\theta}p_{model}\\left (X;\\theta \\right ) = \\mathop{\\arg\\max}_{\\theta}\\prod _{i=1}^m p_{model}\\left (x^{(i)}; \\theta \\right )å¤šä¸ªæ¦‚ç‡çš„ä¹˜ç§¯å…¬å¼ä¼šå› å¾ˆå¤šåŸå› ä¸ä¾¿äºè®¡ç®—ã€‚ä¾‹å¦‚ï¼Œè®¡ç®—ä¸­å¾ˆå¯èƒ½ä¼šå› ä¸ºå¤šä¸ªè¿‡å°çš„æ•°å€¼ç›¸ä¹˜è€Œå‡ºç°æ•°å€¼ä¸‹æº¢ã€‚ä¸ºäº†å¾—åˆ°ä¸€ä¸ªä¾¿äºè®¡ç®—çš„ç­‰ä»·ä¼˜åŒ–é—®é¢˜ï¼Œä¸¤è¾¹å–å¯¹æ•°ï¼š \\theta_{ML} = \\mathop{\\arg\\max}_{\\theta}\\sum_{i=1}^{m}logp_{model}\\left (x^{(i)};\\theta\\right ) å¯ä»¥å‘ç°ï¼Œä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ—¶ï¼Œæ¯ä¸ªæ ·æœ¬$x^{(i)}$éƒ½å¸Œæœ›æ‹‰é«˜å®ƒæ‰€å¯¹åº”çš„æ¨¡å‹æ¦‚ç‡å€¼$p_{model}(x^{(i)};\\theta)$ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œä½†æ˜¯ç”±äºæ‰€æœ‰æ ·æœ¬çš„å¯†åº¦å‡½æ•°$p_{model}(x^{(i)};\\theta)$çš„æ€»å’Œå¿…é¡»æ˜¯1ï¼Œæ‰€ä»¥ä¸å¯èƒ½å°†æ‰€æœ‰æ ·æœ¬ç‚¹éƒ½æ‹‰é«˜åˆ°æœ€å¤§çš„æ¦‚ç‡ï¼Œä¸€ä¸ªæ ·æœ¬ç‚¹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°å€¼è¢«æ‹‰é«˜å°†ä¸å¯é¿å…çš„ä½¿å…¶ä»–ç‚¹çš„å‡½æ•°å€¼è¢«æ‹‰ä½ï¼Œæœ€ç»ˆçš„è¾¾åˆ°ä¸€ä¸ªå¹³è¡¡æ€ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ä¸Šå¼é™¤ä»¥$m$ï¼Œä¾¿å¯ä»¥çœ‹åˆ°æå¤§ä¼¼ç„¶æ³•æœ€å¤§åŒ–çš„ç›®æ ‡æ˜¯åœ¨ç»éªŒåˆ†å¸ƒ$\\widehat{p}_{data}$ä¸‹æ ·æœ¬æ¦‚ç‡å¯¹æ•°çš„æœŸæœ›å€¼ï¼Œå³ \\theta_{ML} = \\mathop{\\arg\\max}_{\\theta}E_{x\\sim \\widehat{p}_{data}}logp_{model}\\left (x^{(i)};\\theta \\right )å‚è€ƒhttps://zhuanlan.zhihu.com/p/26614750 https://www.cnblogs.com/hello-ai/p/11000899.html https://blog.csdn.net/hustqb/article/details/77168436 https://zhuanlan.zhihu.com/p/273246971","link":"/2021/08/29/MLE/"},{"title":"å¤šè·¯å¬å›","text":"1.å®šä¹‰ æ‰€è°“çš„â€œå¤šè·¯å¬å›â€ç­–ç•¥ï¼Œå°±æ˜¯æŒ‡é‡‡ç”¨ä¸åŒçš„ç­–ç•¥ã€ç‰¹å¾æˆ–ç®€å•æ¨¡å‹ï¼Œåˆ†åˆ«å¬å›ä¸€éƒ¨åˆ†å€™é€‰é›†ï¼Œç„¶åå†æŠŠè¿™äº›å€™é€‰é›†æ··åˆåœ¨ä¸€èµ·åä¾›åç»­æ’åºæ¨¡å‹ä½¿ç”¨çš„ç­–ç•¥ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ¯ä¸€è·¯å¬å›éœ€è¦å°½å¯èƒ½çš„ä¿æŒç‹¬ç«‹æ€§ä¸äº’æ–¥æ€§ï¼Œä»è€Œåœ¨ä¿è¯å„é“¾è·¯èƒ½å¤Ÿå¹¶è¡Œå¬å›çš„åŒæ—¶ï¼Œå¢åŠ å¬å›çš„å¤šæ ·æ€§ã€‚ 2.å¤šè·¯å¬å›èåˆç­–ç•¥ï¼ˆå¯ä»¥ç®—æ˜¯ç²—æ’ï¼‰ å¹³å‡æ³•ï¼šCçš„è®¡ç®—æ–¹æ³•ï¼š(0.7 + 0.5 + 0.3)/3 åŠ æƒå¹³å‡ï¼šå‡è®¾ä¸‰ç§ç­–ç•¥çš„æƒé‡æŒ‡å®šä¸º0.4ã€0.3ã€0.2ï¼ˆäººä¸ºç»™å®šæˆ–è€…ç®—æ³•æ‹Ÿåˆï¼‰ï¼Œåˆ™Bçš„æƒé‡ä¸ºï¼ˆ0.4 0.8 + 0.3 0.6 + 0.2* 0ï¼‰/ ï¼ˆ0.4+0.3+0.2ï¼‰ åŠ¨æ€åŠ æƒæ³•:è®¡ç®—ä¸‰ç§å¬å›ç­–ç•¥çš„CTRï¼Œä½œä¸ºæ¯å¤©æ›´æ–°çš„åŠ¨æ€æƒé‡ã€‚ä½†æ˜¯åªè€ƒè™‘äº†ç‚¹å‡»ç‡ï¼Œå¹¶ä¸å…¨é¢ã€‚ 3.ä¾‹å­https://tianchi.aliyun.com/notebook-ai/detail?postId=144452 å‚è€ƒhttps://zhuanlan.zhihu.com/p/388601198","link":"/2021/10/08/Multiple-recall/"},{"title":"NER","text":"Named Entity Recognitionï¼Œå‘½åå®ä½“è¯†åˆ« æ—¨åœ¨ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºå‘½åå®ä½“ï¼Œæ¯”å¦‚äººåã€åœ°åã€æœºæ„åç­‰ åˆ†ç±» æ–‡æœ¬æ•°æ®æ ‡æ³¨ä¸ºä»€ä¹ˆæ ‡æ³¨ï¼Ÿè¯´ç™½äº†å°±æ˜¯æ ‡ç­¾ https://blog.csdn.net/scgaliguodong123_/article/details/121303421 ä¸¾ä¸ªä¾‹å­ï¼š 1234567891011121314151617181920212223BIO-ä¸‰ä½åºåˆ—æ ‡æ³¨æ³•(B-beginï¼ŒI-insideï¼ŒO-outside)B-Xä»£è¡¨å®ä½“Xçš„å¼€å¤´ x:PER(person) , ORG(orgnization),LOC(location)I-Xä»£è¡¨å®ä½“Xçš„ä¸­é—´æˆ–ç»“å°¾Oä»£è¡¨ä¸å±äºä»»ä½•ç±»å‹çš„æ ·ä¾‹ï¼š æˆ‘ O æ˜¯ O æ B-PER æœ I-PER å†» I-PER ï¼Œ O æˆ‘ O çˆ± O ä¸­ B-ORG å›½ I-ORG ï¼Œ O æˆ‘ O æ¥ O è‡ª O å›› B-LOC å· I-LOC ã€‚ O å‚è€ƒhttps://www.cnblogs.com/huangyc/p/10064853.html https://www.cnblogs.com/YoungF/p/13488220.htmlhttps://www.cnblogs.com/YoungF/p/13488220.html https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html https://zhuanlan.zhihu.com/p/156914795 https://blog.csdn.net/scgaliguodong123_/article/details/121303421","link":"/2021/11/26/NER/"},{"title":"Negative Sampling è´Ÿé‡‡æ ·","text":"é¦–å…ˆåŒºåˆ«äºæ¬ é‡‡æ · ( under sampling )å’Œè¿‡é‡‡æ · (oversampling) ä½œç”¨ï¼š å‡å°‘è®¡ç®—é‡ï¼Œè°ƒé«˜è®­ç»ƒæ•ˆç‡ æ˜¯ä»€ä¹ˆ è´Ÿé‡‡æ ·ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯ä»ä¸€å †è´Ÿæ ·æœ¬ä¸­é‡‡æ ·å‡ºä¸€éƒ¨åˆ†è´Ÿæ ·æœ¬ï¼Œç”¨äºæ¨¡å‹çš„è®­ç»ƒã€‚ 1 ä½œç”¨åœ¨è®­ç»ƒæ—¶å€™ ä¹Ÿå°±æ˜¯è¯´åœ¨è®­ç»ƒçš„æ—¶å€™é‡‡æ · ä¸€ä¸ªå…¨è¿æ¥ç½‘ç»œä¸º100X10X100,å¤šåˆ†ç±»ï¼Œ100é€‰1ï¼Œä¹Ÿå°±æ˜¯è¯´è¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªæ­£æ ·æœ¬ï¼Œ99ä¸ªè´Ÿæ ·æœ¬ï¼Œä¸ºäº†å‡å°‘è®¡ç®—é‡ï¼Œæ¯æ¬¡åªé€‰éƒ¨åˆ†è´Ÿæ ·æœ¬ï¼Œæ¯”å¦‚5ä¸ªï¼Œé‚£ä¹ˆæ¢¯åº¦æ›´æ–°çš„æ—¶å€™ï¼Œåªæ›´æ–°æ­£æ ·æœ¬å’Œ5ä¸ªè´Ÿæ ·æœ¬çš„ï¼Œè¿™æ ·è¿˜å‰©94ä¸ªå°±ä¸æ›´æ–°äº† 2 ä½œç”¨åœ¨è®­ç»ƒå‰é¢ ä¹Ÿå°±æ˜¯è¯´åœ¨è®­ç»ƒå‰ï¼Œæ ·æœ¬å·²ç»é‡‡å¥½äº† åˆ†ç±» åœ¨è´Ÿé‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œæœ‰å‡ ä¸ªé—®é¢˜éœ€è¦é‡ç‚¹è€ƒè™‘ï¼šï¼ˆ1ï¼‰è¿™ä¹ˆå¤šè´Ÿæ ·æœ¬ä¸­ï¼Œåˆ°åº•éœ€è¦é‡‡å‡ºå“ªä¸€éƒ¨åˆ†ä½œä¸ºè´Ÿæ ·æœ¬å‘¢ï¼ˆ2ï¼‰éœ€è¦é‡‡å‡ºå¤šå¤§æ•°é‡çš„è´Ÿæ ·æœ¬ï¼Ÿ https://kaiyuan.blog.csdn.net/article/details/122264543 https://zhuanlan.zhihu.com/p/456088223 å‚è€ƒhttps://kaiyuan.blog.csdn.net/article/details/122264543 https://blog.csdn.net/ningyanggege/article/details/87869393 https://zhuanlan.zhihu.com/p/456088223","link":"/2022/05/21/Negative-sample/"},{"title":"NLPå­ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡","text":"1.æ–‡æœ¬åˆ†ç±»é‡‡ç”¨åˆ†ç±»ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡ï¼Œæ¯”å¦‚accuracyï¼Œrecallï¼ŒF1ç­‰ 2.æ–‡æœ¬åŒ¹é…é‡ç‚¹è¯´ä¸‹ä¸€äº›paperçš„stsï¼ˆSemantic Textual Similarityï¼‰ä»»åŠ¡ï¼Œä¸ºä»€ä¹ˆé‡‡ç”¨ç›¸å…³ç³»æ•°ï¼ˆPearson correlationæˆ–è€…spearman correlationï¼‰æ¥è¡¡é‡ï¼Œæ¯”å¦‚ S-bert https://arxiv.org/abs/1908.10084 ï¼Œconsert https://arxiv.org/abs/2105.11741 ã€‚ è¿™æ˜¯å› ä¸ºS-bertå’Œconsert éƒ½æ˜¯æ–‡æœ¬è¡¨ç¤ºçš„æ–¹æ³•ï¼Œæœ€åè®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦æ˜¯åˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—çš„ï¼Œç›¸ä¼¼åº¦çš„å€¼åŸŸä¸º0-1ï¼Œä½†æ˜¯stsæ•°æ®é›†çš„ç›¸ä¼¼åº¦å€¼åŸŸä¸º0-5ã€‚å€¼åŸŸèŒƒå›´ä¸åŒï¼Œä¸èƒ½ç›´æ¥è¿›è¡Œæ¯”è¾ƒï¼Œç”¨ç›¸å…³ç³»æ•°æ¥é—´æ¥è¯„ä»·ã€‚ 3.æ–‡æœ¬ç”Ÿæˆhttps://zhuanlan.zhihu.com/p/144182853 https://arxiv.org/pdf/2006.14799.pdf æ–‡æœ¬æ”¹å†™ï¼ˆç®—æ˜¯ç‰¹æ®Šçš„ç”Ÿæˆï¼‰ https://aclanthology.org/2020.findings-emnlp.111.pdf https://arxiv.org/pdf/1909.01187.pdf Exact score: percentage of exactly correctly predicted fusions SARI: the average F1 scores of the added, kept, and deleted n-grams 4.æ–‡æœ¬è¡¨ç¤ºhttps://arxiv.org/pdf/1908.10084.pdf SentEval (Conneau and Kiela, 2018) is a popular toolkit to evaluate the quality of sentence embeddings.","link":"/2021/10/20/NLP-task/"},{"title":"æ·±åº¦å­¦ä¹ ä¸­çš„äº”ç§å½’ä¸€åŒ–ï¼ˆBNã€LNã€INã€GNå’ŒSNï¼‰æ–¹æ³•ç®€ä»‹","text":"mark https://blog.csdn.net/u013289254/article/details/99690730 https://blog.csdn.net/qq_35290785/article/details/95879067 https://zhuanlan.zhihu.com/p/34879333","link":"/2021/10/18/Normalization/"},{"title":"Presto","text":"æ¦‚å¿µ æ¶æ„ Prestoä¼˜ç¼ºç‚¹ Prestoã€Impalaæ€§èƒ½æ¯”è¾ƒhttps://blog.csdn.net/u012551524/article/details/79124532 æµ‹è¯•ç»“è®ºï¼šImpalaæ€§èƒ½ç¨é¢†å…ˆäºPrestoï¼Œä½†æ˜¯Prestoåœ¨æ•°æ®æºæ”¯æŒä¸Šéå¸¸ä¸°å¯Œï¼ŒåŒ…æ‹¬Hiveã€å›¾æ•°æ®åº“ã€ä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“ã€Redisç­‰ã€‚","link":"/2022/02/05/Presto/"},{"title":"Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing","text":"0 å’Œpre-trainï¼ŒfinetuneåŒºåˆ« promptæ„Ÿè§‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„finetuneæ–¹å¼ï¼Œè¿˜æ˜¯å…ˆpre-trainç„¶åprompt tuning ç›®çš„ï¼šprompt narrowing the gap between pre-training and fine-tuning 1 æ€ä¹ˆåš3æ­¥ 1 Prompt Addition $x^{â€˜}=f_{prompt}(x)$ xæ˜¯input text Apply a template, which is a textual string that has two slots: an input slot [X] for input x and an answer slot[Z] for an intermediate generated answer text z that will later be mapped into y. Fill slot [X] with the input text x. 2 Answer Search fï¼šfills in the location [Z] in prompt $x^{â€˜}$ with the potential answer z Zï¼ša set of permissible values for z 3 Answer Mappingå› ä¸ºä¸Šé¢çš„ $\\hat{z}$ è¿˜ä¸æ˜¯ $\\hat{y}$ï¼Œæ¯”å¦‚æƒ…æ„Ÿåˆ†æï¼Œâ€œexcellentâ€, â€œfabulousâ€, â€œwonderfulâ€ -ã€‹positive go from the highest-scoring answer $\\hat{z}$ to the highest-scoring output $\\hat{y}$ 4 ä¸¾ä¸ªä¾‹å­ï¼Œæ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»çš„ä»»åŠ¡åŸæ¥ â€œ I love this movie.â€ -ã€‹ positive ç°åœ¨ 1 $x=$ â€œ I love this movie.â€ -ã€‹æ¨¡æ¿ä¸ºï¼š â€œ [x] Overall, it was a [z] movie.â€ -ã€‹$x^{â€˜}$ä¸ºâ€I love this movie. Overall ,it was a [z] movie.â€ 2 ä¸‹ä¸€æ­¥ä¼šè¿›è¡Œç­”æ¡ˆæœç´¢ï¼Œé¡¾åæ€ä¹‰å°±æ˜¯LMå¯»æ‰¾å¡«åœ¨[z] å¤„å¯ä»¥ä½¿å¾—åˆ†æ•°æœ€é«˜çš„æ–‡æœ¬ $\\hat{z}$(æ¯”å¦‚â€excellentâ€, â€œgreatâ€, â€œwonderfulâ€ ) 3 æœ€åæ˜¯ç­”æ¡ˆæ˜ å°„ã€‚æœ‰æ—¶LMå¡«å……çš„æ–‡æœ¬å¹¶éä»»åŠ¡éœ€è¦çš„æœ€ç»ˆå½¢å¼(æœ€ç»ˆä¸ºpositiveï¼Œä¸Šè¿°ä¸ºâ€excellentâ€, â€œgreatâ€, â€œwonderfulâ€)ï¼Œå› æ­¤è¦å°†æ­¤æ–‡æœ¬æ˜ å°„åˆ°æœ€ç»ˆçš„è¾“å‡º$\\hat{y}$ 2 Promptæ–¹æ³•åˆ†ç±» 3 Prompt Engineering1 one must first consider the prompt shape, 2 then decide whether to take a manual or automated approach to create prompts of the desired shape 1 Prompt ShapePromptçš„å½¢çŠ¶ä¸»è¦æŒ‡çš„æ˜¯[X]å’Œ[Z]çš„ä½ç½®å’Œæ•°é‡ã€‚ å¦‚æœåœ¨å¥ä¸­ï¼Œä¸€èˆ¬ç§°è¿™ç§promptä¸ºcloze promptï¼›å¦‚æœåœ¨å¥æœ«ï¼Œä¸€èˆ¬ç§°è¿™ç§promptä¸ºprefix promptã€‚ åœ¨å®é™…åº”ç”¨è¿‡ç¨‹ä¸­é€‰æ‹©å“ªä¸€ç§ä¸»è¦å–å†³äºä»»åŠ¡çš„å½¢å¼å’Œæ¨¡å‹çš„ç±»åˆ«ã€‚cloze promptså’ŒMasked Language Modelçš„è®­ç»ƒæ–¹å¼éå¸¸ç±»ä¼¼ï¼Œå› æ­¤å¯¹äºä½¿ç”¨MLMçš„ä»»åŠ¡æ¥è¯´cloze promptsæ›´åŠ åˆé€‚ï¼›å¯¹äºç”Ÿæˆä»»åŠ¡æ¥è¯´ï¼Œæˆ–è€…ä½¿ç”¨è‡ªå›å½’LMè§£å†³çš„ä»»åŠ¡ï¼Œprefix promptså°±ä¼šæ›´åŠ åˆé€‚ï¼›Full text reconstruction modelsè¾ƒä¸ºé€šç”¨ï¼Œå› æ­¤ä¸¤ç§promptå‡é€‚ç”¨ã€‚å¦å¤–ï¼Œå¯¹äºæ–‡æœ¬å¯¹çš„åˆ†ç±»ï¼Œpromptæ¨¡æ¿é€šå¸¸è¦ç»™è¾“å…¥é¢„ç•™ä¸¤ä¸ªç©ºï¼Œ[x1]å’Œ[x2]ã€‚ 2 create prompts1 Manual Template Engineering2 Automated Template Learning1 Discrete Promptsthe prompt ä½œç”¨åœ¨æ–‡æœ¬ä¸Š D1: Prompt Mining D2: Prompt Paraphrasing D3: Gradient-based Search D4: Prompt Generation D5: Prompt Scoring 2 Continuous Promptsthe prompt ç›´æ¥ä½œç”¨åˆ°æ¨¡å‹çš„embeddingç©ºé—´ C1: Prefix Tuning C2: Tuning Initialized with Discrete Prompts C3: Hard-Soft Prompt Hybrid Tuning 4 Answer Engineeringtwo dimensions that must be considered when performing answerengineering:1 deciding the answer shape and 2 choosing an answer design method. 1 Answer Shapeå’ŒPrompt Shapeå•¥åŒºåˆ«ï¼Ÿï¼Ÿï¼Ÿ 2 Answer Space Design Methods1 Manual Design2 automatic automatic1 Discrete Answer Search2 Continuous Answer Search5 Multi-Prompt Learningä¹‹å‰åœ¨è®¨è®ºsingle promptï¼Œç°åœ¨ä»‹ç»multiple prompts 6 Training Strategies for Prompting Methods1 Training Settings full-data few-shot /zero-shot 2 Parameter Update Methods å‚è€ƒhttps://arxiv.org/abs/2107.13586 åˆ˜é¹é£åšå£« https://zhuanlan.zhihu.com/p/395115779 https://zhuanlan.zhihu.com/p/399295895 https://zhuanlan.zhihu.com/p/440169921 https://zhuanlan.zhihu.com/p/399295895","link":"/2021/12/12/Prompt_survey/"},{"title":"T5","text":"T5 åŸæ–‡ https://arxiv.org/pdf/1910.10683.pdf https://zhuanlan.zhihu.com/p/88438851 mT5 åŸæ–‡ https://arxiv.org/pdf/2010.11934.pdf https://zhuanlan.zhihu.com/p/302380842 Sentence-T5ï¼ˆæ–‡æœ¬è¡¨ç¤ºæ–°SOTAï¼‰ åŸæ–‡ https://arxiv.org/pdf/2108.08877.pdf https://zhuanlan.zhihu.com/p/403153114","link":"/2021/10/26/T5/"},{"title":"Zabbix","text":"æ¦‚è¿°Zabbixæ˜¯ä¸€æ¬¾èƒ½å¤Ÿç›‘æ§å„ç§ç½‘ç»œå‚æ•°ä»¥åŠæœåŠ¡å™¨å¥åº·æ€§å’Œå®Œæ•´æ€§çš„è½¯ä»¶ã€‚Zabbixä½¿ç”¨çµæ´»çš„é€šçŸ¥æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·ä¸ºå‡ ä¹ä»»ä½•äº‹ä»¶é…ç½®åŸºäºé‚®ä»¶çš„å‘Šè­¦ã€‚è¿™æ ·å¯ä»¥å¿«é€Ÿåé¦ˆæœåŠ¡å™¨çš„é—®é¢˜ã€‚åŸºäºå·²å­˜å‚¨çš„æ•°æ®ï¼ŒZabbixæä¾›äº†å‡ºè‰²çš„æŠ¥å‘Šå’Œæ•°æ®å¯è§†åŒ–åŠŸèƒ½ã€‚ åŸºç¡€æ¶æ„","link":"/2022/02/05/Zabbix/"},{"title":"å¯¹æ¯”å­¦ä¹ åœ¨NLPåº”ç”¨","text":"https://zhuanlan.zhihu.com/p/435367182 1.åº”ç”¨åœ¨é¢„è®­ç»ƒ Pre-trained Models for Natural Language Processing A Survey https://arxiv.org/pdf/2003.08271v4.pdf 2.åº”ç”¨åœ¨finetune simcseï¼Œconsert","link":"/2021/11/22/acl-contrasive-nlp/"},{"title":"å¸¸è§æ¿€æ´»å‡½æ•°","text":"ä½œç”¨ï¼šæ¿€æ´»å‡½æ•°æ˜¯æ¥å‘ç¥ç»ç½‘ç»œä¸­å¼•å…¥éçº¿æ€§å› ç´ çš„ï¼Œé€šè¿‡æ¿€æ´»å‡½æ•°ï¼Œç¥ç»ç½‘ç»œå°±å¯ä»¥æ‹Ÿåˆå„ç§æ›²çº¿ 1.sigmoid \\begin{align*} y&=\\frac{1}{1+e^{-x}} \\\\y^{'}&=\\frac{1}{1+e^{-x}}(1-\\frac{1}{1+e^{-x}})=y(1-y) \\end{align*}ä¸€èˆ¬åº”ç”¨åœ¨äºŒåˆ†ç±»çš„è¾“å‡ºå±‚ ç¼ºç‚¹ï¼š â€‹ 1.sigmoid æå®¹æ˜“å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¯ä»¥ä»å¯¼æ•°æ›²çº¿å¯ä»¥çœ‹å‡ºï¼Œç»å¤§å¤šæ•°çš„å¯¼æ•°å€¼ä¸º0 â€‹ 2.Sigmoid å‡½æ•°çš„è¾“å‡ºä¸æ˜¯ä»¥é›¶ä¸ºä¸­å¿ƒçš„ï¼ˆnon-zero-centeredï¼‰ï¼Œè¿™ä¼šå¯¼è‡´ç¥ç»ç½‘ç»œæ”¶æ•›è¾ƒæ…¢ï¼Œè¯¦ç»†åŸå› è¯·å‚è€ƒ https://liam.page/2018/04/17/zero-centered-active-function/ 2.softmax S_i=\\frac{e^i}{\\sum_je^j}å’Œsigmoidå…³ç³»ï¼šSoftmaxå‡½æ•°æ˜¯äºŒåˆ†ç±»å‡½æ•°Sigmoidåœ¨å¤šåˆ†ç±»ä¸Šçš„æ¨å¹¿ https://zhuanlan.zhihu.com/p/356976844 3.tanh \\begin{align*} y&=tanh(x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} \\\\y^{'}&=1-(tanh(x))^{2} \\end{align*}ä¼˜ç‚¹: â€‹ 1.tanhè§£å†³äº†sigmoidä¸­çš„ zero-centered é—®é¢˜ ç¼ºç‚¹ï¼š â€‹ 2.å¯¹äºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ä¾æ—§æ— èƒ½ä¸ºåŠ›ã€‚ 4.Reluç³»åˆ—4.1 Relu \\begin{align*} y&=max(0,x) \\\\ y^{'}&=\\left\\{ \\begin{array}{cl} 1 & \\ x \\ge 0 \\\\ 0 & \\ x < 0 \\\\ \\end{array} \\right. \\end{align*}ä¼˜ç‚¹: â€‹ 1.å¯ä»¥ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼Œå› ä¸ºå¯¼æ•°åœ¨æ­£æ•°éƒ¨åˆ†æ˜¯æ’ç­‰äº1çš„ ç¼ºç‚¹ï¼š â€‹ 1.Reluçš„è¾“å‡ºä¸æ˜¯zero-centered â€‹ 2.ç”±äºè´Ÿæ•°éƒ¨åˆ†å¯¼æ•°æ’ä¸º0ï¼Œä¼šå¯¼è‡´ä¸€äº›ç¥ç»å…ƒæ— æ³•æ¿€æ´»ï¼Œå«åšDead ReLU Problem 4.2 leaky Reluleaky Reluå°±æ˜¯ä¸ºäº†è§£å†³Reluçš„0åŒºé—´å¸¦æ¥çš„å½±å“ï¼Œå…¶æ•°å­¦è¡¨è¾¾ä¸ºï¼š \\begin{align*} y&=\\left\\{ \\begin{array}{cl} x & \\ x \\ge 0 \\\\ kx & \\ x < 0 \\\\ \\end{array} \\right. \\\\ y^{'}&=\\left\\{ \\begin{array}{cl} 1 & \\ x \\ge 0 \\\\ k & \\ x < 0 \\\\ \\end{array} \\right. \\end{align*}å…¶ä¸­$k$æ˜¯ä¸ºè¶…å‚æ•°ï¼Œä¸€èˆ¬æ•°å€¼è¾ƒå°ï¼Œæ¯”å¦‚0.01 4.3 Elu Eluæ¿€æ´»å‡½æ•°ä¹Ÿæ˜¯ä¸ºäº†è§£å†³Reluçš„0åŒºé—´å¸¦æ¥çš„å½±å“ï¼Œå…¶æ•°å­¦è¡¨è¾¾ä¸ºï¼š \\begin{align*} y&=\\left\\{ \\begin{array}{cl} x & \\ x \\ge 0 \\\\ \\alpha(e^{x}-1) & \\ x < 0 \\\\ \\end{array} \\right. \\\\ y^{'}&=\\left\\{ \\begin{array}{cl} 1 & \\ x \\ge 0 \\\\ \\alpha e^{x} & \\ x < 0 \\\\ \\end{array} \\right. \\end{align*}Eluç›¸å¯¹äºleaky Reluæ¥è¯´ï¼Œè®¡ç®—è¦æ›´è€—æ—¶é—´ä¸€äº› å‚è€ƒhttps://zhuanlan.zhihu.com/p/44398148 https://liam.page/2018/04/17/zero-centered-active-function/ https://www.cnblogs.com/tornadomeet/p/3428843.html https://www.cnblogs.com/chamie/p/8665251.html https://zhuanlan.zhihu.com/p/33006526?from_voters_page=true","link":"/2021/09/06/activate-func/"},{"title":"ad hocå’Œrouting","text":"0 åŒºåˆ«https://blog.csdn.net/memray/article/details/41149633 ad hocç±»ä¼¼äºå›¾ä¹¦é¦†é‡Œçš„ä¹¦ç±æ£€ç´¢ï¼Œå³ä¹¦ç±åº“(æ•°æ®åº“)ç›¸å¯¹ç¨³å®šä¸å˜ï¼Œä¸åŒç”¨æˆ·çš„æŸ¥è¯¢è¦æ±‚æ˜¯åƒå˜ä¸‡åŒ–çš„ã€‚ routingçš„æƒ…å†µä¸ad hocç›¸å¯¹ï¼Œç”¨æˆ·çš„æŸ¥è¯¢è¦æ±‚ç›¸å¯¹ç¨³å®šã€‚åœ¨routingä¸­ï¼ŒæŸ¥è¯¢å¸¸å¸¸ç§°ä¸ºpro fileï¼Œä¹Ÿå°±æ˜¯é€šå¸¸æ‰€è¯´çš„å…´è¶£ï¼Œç”¨æˆ·çš„å…´è¶£åœ¨ä¸€æ®µæ—¶é—´å†…æ˜¯ç¨³å®šä¸å˜çš„ï¼Œä½†æ˜¯æ•°æ®åº“(æ›´ç¡®åˆ‡çš„è¯´ï¼Œæ˜¯æ•°æ®æµ)æ˜¯ä¸æ–­å˜åŒ–çš„ã€‚è¿™ç§ä»»åŠ¡å¾ˆåƒæˆ‘ä»¬æ‰€è¯´çš„æ–°é—»å®šåˆ¶ä»€ä¹ˆçš„ï¼Œæ¯”å¦‚ç”¨æˆ·å–œæ¬¢ä½“è‚²ï¼Œè¿™ä¸ªå…´è¶£åœ¨ä¸€æ®µæ—¶é—´å†…æ˜¯ä¸å˜çš„ï¼Œè€Œä½“è‚²æ–°é—»åœ¨ä¸æ–­å˜åŒ–ã€‚ 1 ad hochttps://ils.unc.edu/courses/2017_fall/inls509_002/lectures/03-IntroductionToAdhocRetrieval.pdf Ad-hoc Retrieval æ˜¯ä»€ä¹ˆ Given a query and a corpus, find the relevant items â€£ query: textual description of information need â€£ corpus: a collection of textual documents â€£ relevance: satisfaction of the userâ€™s information need 2 routing","link":"/2022/04/01/ad-doc-routing/"},{"title":"lossä¸ä¸‹é™çš„è§£å†³æ–¹æ³•","text":"https://blog.csdn.net/zongza/article/details/89185852","link":"/2021/11/10/adjust-loss/"},{"title":"è°ƒå‚","text":"1. è°ƒä»€ä¹ˆå‚æ•°1 è®­ç»ƒå±‚é¢ 0 æƒé‡åˆå§‹åŒ– 1 å­¦ä¹ ç‡ 2 batch size 3 epoch 4 dropout 5 æ­£åˆ™åŒ– 6 ä¼˜åŒ–ç®—æ³• 2 æ¨¡å‹å±‚é¢ 1 æ¿€æ´»å‡½æ•° 2 ç½‘ç»œå°ºå¯¸ 2. è¶…å‚æ•°æ€ä¹ˆè°ƒ1.æ‰‹åŠ¨è°ƒå‚ ç»éªŒå€¼ 2.è‡ªåŠ¨åŒ–è°ƒå‚ â€‹ a.ç½‘æ ¼æœç´¢ è¶…å‚æ•°æ’åºç»„åˆï¼Œå¦‚æœæœ‰nä¸ªå‚æ•°ï¼Œæ¯ä¸ªå‚æ•°éƒ½æœ‰mä¸ªå€™é€‰å€¼ï¼Œé‚£ä¹ˆç½‘æ ¼æœç´¢ä¸­å°±è¦è®­ç»ƒmçš„næ¬¡æ–¹ä¸ªæ¨¡å‹ã€‚ â€‹ b.éšæœºæœç´¢ æ¯”èµ·ç½‘æ ¼æœç´¢ï¼š1ã€æœç´¢æ¬¡æ•°å°‘ï¼Œå¿« 2. å› ä¸ºæœ‰å¶ç„¶æ€§ï¼Œå¯èƒ½ä¸æ˜¯æœ€ä¼˜ â€‹ c.è´å¶æ–¯ä¼˜åŒ– https://zhuanlan.zhihu.com/p/146633409 Bayesian optimization algorithmï¼Œç®€ç§°BOA ç½‘æ ¼æœç´¢å’Œéšæœºæœç´¢ï¼Œæ¯æ¬¡éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œè´å¶æ–¯ä¼˜åŒ–åˆ©ç”¨ä¹‹å‰å·²æœç´¢ç‚¹çš„ä¿¡æ¯ç¡®å®šä¸‹ä¸€ä¸ªæœç´¢ç‚¹ å‚è€ƒhttps://zhuanlan.zhihu.com/p/340578370 https://www.jianshu.com/p/92d8943fb0ba https://zhuanlan.zhihu.com/p/146633409 https://blog.csdn.net/weixin_45884316/article/details/109828084 https://www.cnblogs.com/zingp/p/11352012.html#_label8 https://www.jianshu.com/p/71f39c2ea512","link":"/2021/11/04/adjust-papameter/"},{"title":"ALBERT A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS","text":"There are three main contributions that ALBERT makes over the design choices of BERTï¼š 1 Factorized embedding parameterization åŸæ¥embeddingå±‚æ˜¯ä¸€ä¸ªçŸ©é˜µ$M_{emb[V\\times H]} $,ç°åœ¨å˜ä¸ºä¸¤ä¸ª$M_{emb1[V\\times E]}$å’Œ$M_{emb2[E\\times H]}$,å‚æ•°é‡ä»VHå˜ä¸ºVE+EHï¼ˆThis parameter reduction is significant when H &gt;&gt; E.ï¼‰ 2 Cross-layer parameter sharing The default decision for ALBERT is to share all parameters across layersï¼ˆattentionï¼ŒFFN)ï¼‰ 3 Inter-sentence coherence loss åŸæ¥çš„NSPæ”¹ä¸ºç°åœ¨çš„sopï¼Œæ­£ä¾‹çš„æ„å»ºå’ŒNSPæ˜¯ä¸€æ ·çš„ï¼Œä¸è¿‡è´Ÿä¾‹åˆ™æ˜¯å°†ä¸¤å¥è¯åè¿‡æ¥ã€‚ å‚è€ƒ https://zhuanlan.zhihu.com/p/88099919 https://blog.csdn.net/weixin_37947156/article/details/101529943 https://openreview.net/pdf?id=H1eA7AEtvS","link":"/2021/11/04/albert/"},{"title":"answer select","text":"1 é—®é¢˜å®šä¹‰ Given a question and a set of candidate sentences, the task is to identify candidate sentences that contain the correct answer to the question. From the definition, the problem can be formulated as a ranking problem, where the goal is to give better rank to the candidate sentences that are relevant to the question. 2 åšå®¢ï¼š https://zhuanlan.zhihu.com/p/39920446 3 A Review on Deep Learning Techniques Applied to Answer Selection https://aclanthology.org/C18-1181.pdf 4 BAS: An Answer Selection Method Using BERT Language Model https://arxiv.org/ftp/arxiv/papers/1911/1911.01528.pdf","link":"/2021/11/26/anser-select/"},{"title":"itçš„æŠ€æœ¯åœºæ™¯","text":"å‰åç«¯ æŒ‡çš„webå‰åç«¯ ç§»åŠ¨ç«¯ ioså’Œå®‰å“ æœåŠ¡ç«¯ ï¼Œå®¢æˆ·ç«¯ å®¢æˆ·ç«¯ï¼ˆClientï¼‰æ˜¯æŒ‡ä¸æœåŠ¡å™¨ç›¸å¯¹åº”å¹¶ä¸ºå®¢æˆ·æä¾›æœ¬åœ°æœåŠ¡çš„ç¨‹åºã€‚ é™¤äº†ä»…åœ¨æœ¬åœ°è¿è¡Œçš„æŸäº›åº”ç”¨ç¨‹åºå¤–ï¼Œå®ƒä»¬é€šå¸¸å®‰è£…åœ¨æ™®é€šå®¢æˆ·ç«¯ä¸Šï¼Œå¹¶ä¸”éœ€è¦ä¸æœåŠ¡å™¨ä¸€èµ·ä½¿ç”¨ã€‚ æœåŠ¡ç«¯ï¼šé¡¾åæ€ä¹‰æ˜¯æœåŠ¡çš„ï¼Œå®¢æˆ·ç«¯å‘é€çš„è¯·æ±‚äº¤ç»™æœåŠ¡å™¨ç«¯å¤„ç†ï¼Œæ˜¯ä»¥responseå¯¹è±¡å­˜åœ¨ï¼ŒæœåŠ¡ç«¯å¤„ç†å®Œæ¯•ååé¦ˆç»™å®¢æˆ·ç«¯ã€‚","link":"/2022/03/06/application/"},{"title":"attentionæ€»ç»“","text":"1.Show, Attend and Tell: Neural Image Caption Generation with Visual Attention æå‡ºäº†ä¸¤ç§ attention æ¨¡å¼ï¼Œå³ hard attention å’Œ soft attention 2.Effective Approaches to Attention-based Neural Machine Translation æ–‡ç« æå‡ºäº†ä¸¤ç§ attention çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå³ global attention å’Œ local attentionã€‚ 3.Attention Is All You Need æå‡ºself attention 4.Hierarchical Attention Networks for Document Classification æå‡ºäº†Hierarchical Attentionç”¨äºæ–‡æ¡£åˆ†ç±» 5.Attention-over-Attention Neural Networks for Reading Comprehension æå‡ºäº†Attention Over Attentionçš„Attentionæœºåˆ¶ 6.Convolutional Sequence to Sequence Learning è®ºæ–‡ä¸­è¿˜é‡‡ç”¨äº† Multi-step Attention","link":"/2021/10/12/attention/"},{"title":"AutoTokenizerå’ŒBertTokenizeråŒºåˆ«","text":"https://github.com/huggingface/transformers/issues/5587","link":"/2021/12/09/autotokenizer/"},{"title":"auxiliary loss(è¾…åŠ©æŸå¤±)","text":"å¤šä»»åŠ¡å­¦ä¹ ä¸­ç»å¸¸å¯ä»¥çœ‹åˆ° å‚è€ƒhttps://blog.nowcoder.net/n/600d5e96508d4b818009227fdc9b8cbc","link":"/2022/05/21/auxiliary-loss/"},{"title":"basic algorithm","text":"å¿«æ’æ ¸å¿ƒæ€æƒ³ï¼šå–ä¸€ä¸ªæ•°ä½œä¸ºåŸºå‡†ï¼Œæ¯”è¿™ä¸ªæ•°å°çš„æ”¾åœ¨å·¦è¾¹ï¼Œå¤§çš„æ”¾åœ¨å³è¾¹ï¼Œç„¶åå·¦è¾¹é‡å¤ï¼Œå³è¾¹é‡å¤ã€‚ åŸºå‡†å…ƒç´ ï¼Œä¸€èˆ¬æ¥è¯´é€‰å–æœ‰å‡ ç§æ–¹æ³• å–ç¬¬ä¸€ä¸ªå…ƒç´  å–æœ€åä¸€ä¸ªå…ƒç´  å–ç¬¬ä¸­é—´ä½ç½®å…ƒç´  å®ç°æ–¹å¼ï¼šä¸€èˆ¬é€’å½’+åŒæŒ‡é’ˆ ä¼ªä»£ç  12341ï¼šé¦–å…ˆå–åºåˆ—ç¬¬ä¸€ä¸ªå…ƒç´ ä¸ºåŸºå‡†å…ƒç´ pivot=R[low]ã€‚i=low,j=highã€‚2ï¼šä»åå‘å‰æ‰«æï¼Œæ‰¾å°äºç­‰äºpivotçš„æ•°ï¼Œå¦‚æœæ‰¾åˆ°ï¼ŒR[i]ä¸R[j]äº¤æ¢ï¼Œi++ã€‚3ï¼šä»å‰å¾€åæ‰«æï¼Œæ‰¾å¤§äºpivotçš„æ•°ï¼Œå¦‚æœæ‰¾åˆ°ï¼ŒR[i]ä¸R[j]äº¤æ¢ï¼Œj--ã€‚ 4: é‡å¤2~3ï¼Œç›´åˆ°i=j,è¿”å›è¯¥ä½ç½®mid=i,è¯¥ä½ç½®æ­£å¥½ä¸ºpivotå…ƒç´ ã€‚ å®Œæˆä¸€è¶Ÿæ’åºåï¼Œä»¥midä¸ºç•Œï¼Œå°†åºåˆ—åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå·¦åºåˆ—éƒ½æ¯”pivotå°ï¼Œæœ‰åºåˆ—éƒ½æ¯”pivotå¤§ï¼Œç„¶åå†åˆ†åˆ«å¯¹è¿™ä¸¤ä¸ªå­åºåˆ—è¿›è¡Œå¿«é€Ÿæ’åºã€‚ æ—¶é—´å¤æ‚åº¦ï¼ˆ0nlognï¼‰ å‚è€ƒï¼š https://zhuanlan.zhihu.com/p/63227573","link":"/2022/05/18/basic-algorithm/"},{"title":"Bertç³»åˆ—ä¹‹å¥å‘é‡ç”Ÿæˆ","text":"https://zhuanlan.zhihu.com/p/444346578 1 sentence-bertstsä»»åŠ¡ï¼Œæ•°æ®åˆ†ä¸ºstsæ— æ ‡ç­¾æ•°æ®ï¼Œstsæœ‰æ ‡ç­¾æ•°æ®ï¼Œnliæœ‰æ ‡ç­¾ æ— ç›‘ç£,æœ‰ç›‘ç£lossä¸€æ ·ï¼Œæ–‡ä¸­æœ‰3ç§lossï¼ŒåŒºåˆ«åœ¨äºæ•°æ®é›† æ— ç›‘ç£:nliæœ‰æ ‡ç­¾;æœ‰ç›‘ç£:stsæœ‰æ ‡ç­¾æ•°æ® 2 simcsestsä»»åŠ¡ï¼Œæ•°æ®åˆ†ä¸ºstsæ— æ ‡ç­¾æ•°æ®ï¼Œstsæœ‰æ ‡ç­¾æ•°æ® æ— ç›‘ç£ï¼Œæœ‰ç›‘ç£åŒºåˆ«åœ¨äºï¼šæ ·æœ¬æ„é€ ä¸åŒ æ— ç›‘ç£æ ·æœ¬æ­£è´Ÿæ¥æºäºstsæ— æ ‡ç­¾æ•°æ®æ•°æ®å¢å¼ºï¼Œæœ‰ç›‘ç£æ ·æœ¬æ­£è´Ÿæ¥æºäºstsæœ‰æ ‡ç­¾æ•°æ® 3 consertstsä»»åŠ¡ï¼Œæ•°æ®åˆ†ä¸ºstsæ— æ ‡ç­¾æ•°æ®ï¼Œstsæœ‰æ ‡ç­¾æ•°æ®ï¼Œè¿˜æœ‰nliæ•°æ®é›†ï¼ˆæœ‰æ ‡ç­¾ï¼‰ ç›¸åŒ å’Œsimcseç›¸åŒä¹‹å¤„ï¼šéƒ½æ˜¯åœ¨finetuneå¼•å…¥å¯¹æ¯” ä¸åŒ 1 æ— ç›‘ç£ å’Œsimces lossä¸€æ ·ä¸ºNT-Xentï¼Œä¸åŒåœ¨äºstsæ— æ ‡ç­¾æ•°æ®æ•°æ®å¢å¼ºæ–¹å¼ä¸åŒ 2 æœ‰ç›‘ç£ åŒºåˆ«åœ¨äºlosså’Œæ•°æ®æº simcse lossä¸ºNT-Xentï¼Œæ•°æ®æºä¸ºstsæœ‰æ ‡ç­¾æ•°æ® consert lossä¸º NT-Xent + åˆ«çš„æœ‰ç›‘ç£lossï¼ˆæ¯”å¦‚cross entropyï¼‰ï¼Œæ•°æ®æºä¸ºstsæ— æ ‡ç­¾æ•°æ®å’Œnliæ•°æ®é›†ï¼ˆæœ‰æ ‡ç­¾ï¼‰ï¼Œ+è¡¨ç¤ºèåˆ ï¼Œè®ºæ–‡æœ‰3ç§èåˆæ–¹å¼","link":"/2021/12/21/bert-emb/"},{"title":"åˆ†ç±»å›å½’æ¨¡å‹æ€»ç»“","text":"å¾ˆå¤šçš„æ·±åº¦æ¨¡å‹éƒ½å±äºè¡¨ç¤ºå­¦ä¹ ï¼Œæ˜¯ä¸ºäº†å¾—åˆ°å¥½çš„ç‰¹å¾è¡¨ç¤ºï¼Œæ¯”å¦‚æ–‡æœ¬è¡¨ç¤ºä¹‹ç±»çš„æ¨¡å‹ï¼Œæœ‰äº†å¥½çš„ç‰¹å¾è¡¨ç¤ºï¼Œæ‰èƒ½å¢å¼ºåˆ†ç±»æˆ–è€…å›å½’çš„æ•ˆæœã€‚æŸäº›ç«¯åˆ°ç«¯çš„æ¨¡å‹å…¶å®å¯ä»¥æ‹†è§£æˆå‡ ä¸ªéƒ¨åˆ†ï¼Œæ¯”å¦‚å‰ç½®çš„ç¯èŠ‚åŒ…æ‹¬äº†ç‰¹å¾æå–ï¼Œç‰¹å¾è¡¨ç¤ºï¼Œç„¶åé¡¶å±‚æ˜¯åˆ†ç±»æˆ–è€…å›å½’å±‚ã€‚ä¸‹æ–‡æ€»ç»“çš„æ˜¯çº¯ç²¹çš„åˆ†ç±»å’Œå›å½’çš„æ¨¡å‹ã€‚ 1.åˆ†ç±»https://www.jianshu.com/p/169dc01f0589 2.å›å½’https://blog.csdn.net/ChenVast/article/details/82107490","link":"/2021/10/29/basic-regression-classfify/"},{"title":"bert_serving","text":"bertè¯å‘é‡æœåŠ¡ï¼Œç”Ÿæˆè¯å‘é‡å¹¶èšç±»å¯è§†åŒ– å‚è€ƒhttps://www.jianshu.com/p/61323d366f7c","link":"/2022/07/01/bert-serving/"},{"title":"BertGCN Transductive Text Classification by Combining GCN and BERT","text":"origin paperï¼š https://arxiv.org/abs/2105.05727 ori code gitï¼š https://github.com/ZeroRin/BertGCN å®˜æ–¹çŸ¥ä¹ï¼š https://zhuanlan.zhihu.com/p/378798855 TextGCNï¼š https://arxiv.org/abs/1809.05679 å›¾ç»“æ„ we construct a heterogeneous graph containing both word nodes and document nodes following TextGCN. å¦‚ä¸‹å›¾ node ï¼šword nodes and document nodes edge ï¼š We build edges among nodes based on word occurrence in documents (document-word edges) and word co-occurrence in the whole corpus (word-word edges) edge weight ä¹Ÿå’ŒTextGCNä¸€æ · node data ä¸åŒ é‡ç‚¹æ˜¯è§£å†³äº†TextGCNå’ŒBERTä¸€èµ·è”è°ƒçš„æ”¶æ•›é—®é¢˜","link":"/2022/01/17/bert-gcn/"},{"title":"bert(Pre-training of Deep Bidirectional Transformers for Language Understanding)","text":"https://arxiv.org/abs/1810.04805 1 ç»“æ„ æ•´ä½“ç»“æ„å¦‚ä¸Šå›¾ï¼ŒåŸºæœ¬å•å…ƒä¸ºTransformer çš„encoderéƒ¨åˆ†ã€‚ä½œè€…å¯¹ç»“æ„çš„æè¿°ä¸ºï¼šBERTâ€™s model architecture is a multi-layer bidirectional Transformer encoderã€‚ 2 Input/Output Representations [CLS]è¡¨å¾å¥å­å¼€å§‹ï¼Œ[SEP]è¡¨ç¤ºå¥å­ç»“æŸä»¥åŠåˆ†å‰²ä¸¤ä¸ªå¥å­ Token Embeddingä¸ºè¯å‘é‡çš„è¡¨ç¤ºï¼ŒPosition Embeddingä¸ºä½ç½®ä¿¡æ¯ï¼ŒSegment Embeddingè¡¨ç¤ºAï¼ŒBä¸¤å¥è¯ï¼Œæœ€åçš„è¾“å…¥å‘é‡ä¸ºä¸‰è€…ç›¸åŠ ã€‚æ¯”èµ·transformerå¤šä¸€ä¸ªSegment Embeddingã€‚ å…·ä½“ä¾‹å­ï¼šhttps://www.cnblogs.com/d0main/p/10447853.html 3 é¢„è®­ç»ƒä»»åŠ¡ 1 Masked LM standard conditional language models can only be trained left-to-right or right-to-left , since bidirectional conditioning would allow each word to indirectly â€œsee itselfâ€.In order to train a deep bidirectional representation,MLM The training data generator chooses 15% of the token positions at random for prediction. If the i-th token is chosen, we replace the i-th token with (1) the [MASK] token 80% of the time (2) a random token 10% of the time (3) the unchanged i-th token 10% of the time. 2 Next Sentence Prediction (NSP) In order to train a model that understands sentence relationships choosing the sentences A and B for each pretraining example, 50% of the time B is the actual next sentence that follows A (labeled as IsNext), and 50% of the time it is a random sentence from the corpus (labeled as NotNext). 4 Fine-tuning BERT For each task, we simply plug in the task specific inputs and outputs into BERT and finetune all the parameters end-to-end. è¾“å…¥: å¯ä»¥ä¸ºå¥å­å¯¹æˆ–è€…å•å¥ï¼Œå–å†³äºç‰¹å®šä»»åŠ¡ è¾“å‡ºï¼šAt the output, the token representations are fed into an output layer for token level tasks, such as sequence tagging or question answering, and the [CLS] representation is fed into an output layer for classification, such as entailment or sentiment analysis. 5 å¸¸è§é—®é¢˜1 bertä¸ºä»€ä¹ˆåŒå‘ï¼Œgptå•å‘ï¼Ÿ 1.ç»“æ„çš„ä¸åŒ å› ä¸ºBERTç”¨äº†transformerçš„encoderï¼Œåœ¨ç¼–ç æŸä¸ªtokençš„æ—¶å€™åŒæ—¶åˆ©ç”¨äº†å…¶ä¸Šä¸‹æ–‡çš„tokenï¼Œä½†æ˜¯gptTç”¨äº†transformerçš„decoderï¼Œåªèƒ½åˆ©ç”¨ä¸Šæ–‡ 2.é¢„è®­ç»ƒä»»åŠ¡çš„ä¸åŒ 2 ä¸ºä»€ä¹ˆberté•¿åº¦å›ºå®šï¼Ÿ å› ä¸ºbertæ˜¯åŸºäºtransformer encoderçš„ï¼Œä¸åŒä½ç½®çš„è¯è¯­éƒ½æ˜¯å¹¶è¡Œçš„ï¼Œæ‰€ä»¥é•¿åº¦è¦æå‰å›ºå®šï¼Œä¸å¯å˜ bertçš„è¾“å…¥è¾“å‡ºé•¿åº¦ä¸ºmax_length,å¤§äºæˆªæ–­ï¼Œå°äºpaddingï¼Œmax_lengthçš„æœ€å¤§å€¼ä¸º512 3 ä¸ºä»€ä¹ˆbertéœ€è¦è¡¥å……ä½ç½®ä¿¡æ¯ï¼Ÿ å› ä¸ºæ˜¯å¹¶è¡Œï¼Œä¸åƒè¿­ä»£ï¼Œæ²¡æœ‰å¤©ç„¶çš„ä½ç½®ä¿¡æ¯ï¼Œéœ€è¦è¡¥å……position embeddingã€‚","link":"/2021/07/20/bert/"},{"title":"Pre-Training with Whole Word Masking for Chinese BERT","text":"BERT-wwm-ext wwmï¼šwhole word mask extï¼š we also use extended training data (mark with ext in the model name) é¢„è®­ç»ƒ1 æ”¹å˜maskç­–ç•¥ Whole Word Maskingï¼Œwwm cws: Chinese Word Segmentation å¯¹æ¯”å››ç§maskç­–ç•¥ å‚è€ƒPre-Training with Whole Word Masking for Chinese BERT https://arxiv.org/abs/1906.08101v3 Revisiting Pre-trained Models for Chinese Natural Language Processing https://arxiv.org/abs/2004.13922 githubï¼šhttps://hub.fastgit.org/ymcui/Chinese-BERT-wwm","link":"/2021/11/04/bert-wwm/"},{"title":"bertviz:attentionå¯è§†åŒ–å·¥å…·","text":"çœ‹ä¸åŒlayerï¼Œä¸åŒheadçš„attention æ³¨æ„ï¼š 12345678910111213141516from bertviz.neuron_view import showfrom bertviz.transformers_neuron_view import BertModel, BertTokenizermodel1=BertModel.from_pretrained(path)model_type = 'bert'show(model1, model_type, tokenizer, sentence_a, sentence_b, layer=4, head=3)å¯ä»¥###########################from bertviz.neuron_view import showfrom transformers import BertTokenizer, BertModelmodel1=BertModel.from_pretrained(path)model_type = 'bert'show(model1, model_type, tokenizer, sentence_a, sentence_b, layer=4, head=3)æŠ¥é”™ å‚è€ƒhttps://zhuanlan.zhihu.com/p/457043243","link":"/2022/06/30/bertviz/"},{"title":"å¤§æ•°æ®ç»„ä»¶","text":"å¤§æ•°æ®ç»„ä»¶åˆ†ç±» å‘è¡Œç‰ˆæœ¬ å…è´¹ï¼šApache æ”¶è´¹ï¼šï¼ˆCDHï¼ŒHDPï¼ŒäºŒåˆä¸€ï¼‰ï¼Œé˜¿é‡Œäº‘ï¼Œäºšé©¬é€Šäº‘ï¼Œåä¸ºäº‘ç­‰","link":"/2022/01/18/bigdata-component/"},{"title":"å¤§æ•°æ®","text":"mark https://github.com.cnpmjs.org/heibaiying/BigData-Notes","link":"/2021/10/14/bigdata/"},{"title":"bm25ï¼ˆbest matchingï¼‰","text":"æ˜¯TD-IDFçš„ä¼˜åŒ–ç‰ˆæœ¬ https://zhuanlan.zhihu.com/p/79202151 https://blog.csdn.net/weixin_42486623/article/details/121498706","link":"/2021/11/26/bm25/"},{"title":"GB, GBDT, XGBoost, LightGBM","text":"GBï¼šboostingç®—æ³•ï¼Œæ˜¯ä¸€ç§ç®—æ³•æ€æƒ³ GBDT ï¼šè¯´ç™½äº†å°±æ˜¯gradient boostingåŸºå­¦ä¹ å™¨ä¸ºcartå›å½’æ ‘ XGBoostï¼šGBDTçš„é«˜æ•ˆå®ç° LightGBMï¼šGBDTçš„é«˜æ•ˆå®ç°ï¼Œå¯¹XGBoostæ”¹è¿› å‚è€ƒhttps://www.jianshu.com/p/765efe2b951a","link":"/2022/06/09/boost-relation/"},{"title":"bpç®—æ³•","text":"Error Back Propagation ä¸¤ä¸ªè¿‡ç¨‹ï¼š1.ä¿¡å·çš„æ­£å‘ä¼ æ’­ 2.è¯¯å·®çš„åå‘ä¼ æ’­","link":"/2022/05/28/bp/"},{"title":"ç¦»çº¿æ•°ä»“æ­å»ºä¾‹å­(ç”µå•†ä¸ºä¾‹)","text":"0 æ¶æ„ 1.æ•°æ®æ¥æº1.1 ç”¨æˆ·è¡Œä¸ºæ•°æ®ç”¨æˆ·åœ¨ä½¿ç”¨äº§å“è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡åŸ‹ç‚¹æ”¶é›†ä¸å®¢æˆ·ç«¯äº§å“äº¤äº’è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ•°æ®ï¼Œå¹¶å‘å¾€æ—¥å¿—æœåŠ¡å™¨è¿›è¡Œä¿å­˜ã€‚æ¯”å¦‚é¡µé¢æµè§ˆã€ç‚¹å‡»ã€åœç•™ã€è¯„è®ºã€ç‚¹èµã€æ”¶è—ç­‰ã€‚ç”¨æˆ·è¡Œä¸ºæ•°æ®é€šå¸¸å­˜å‚¨åœ¨æ—¥å¿—æ–‡ä»¶ä¸­ã€‚ æˆ‘ä»¬çš„æ—¥å¿—ç»“æ„å¤§è‡´å¯åˆ†ä¸ºä¸¤ç±»ï¼Œä¸€æ˜¯æ™®é€šé¡µé¢åŸ‹ç‚¹æ—¥å¿—ï¼ŒäºŒæ˜¯å¯åŠ¨æ—¥å¿—ã€‚ æ™®é€šé¡µé¢æ—¥å¿—ç»“æ„å¦‚ä¸‹ï¼Œæ¯æ¡æ—¥å¿—åŒ…å«äº†ï¼Œå½“å‰é¡µé¢çš„é¡µé¢ä¿¡æ¯ï¼Œæ‰€æœ‰äº‹ä»¶ï¼ˆåŠ¨ä½œï¼‰ã€æ‰€æœ‰æ›å…‰ä¿¡æ¯ä»¥åŠé”™è¯¯ä¿¡æ¯ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜åŒ…å«äº†ä¸€ç³»åˆ—å…¬å…±ä¿¡æ¯ï¼ŒåŒ…æ‹¬è®¾å¤‡ä¿¡æ¯ï¼Œåœ°ç†ä½ç½®ï¼Œåº”ç”¨ä¿¡æ¯ç­‰ï¼Œå³ä¸‹è¾¹çš„commonå­—æ®µã€‚ å¯åŠ¨æ—¥å¿—ç»“æ„ç›¸å¯¹ç®€å•ï¼Œä¸»è¦åŒ…å«å…¬å…±ä¿¡æ¯ï¼Œå¯åŠ¨ä¿¡æ¯å’Œé”™è¯¯ä¿¡æ¯ã€‚ 1.2 ä¸šåŠ¡æ•°æ®å°±æ˜¯å„è¡Œä¸šåœ¨å¤„ç†äº‹åŠ¡è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ•°æ®ã€‚æ¯”å¦‚ç”¨æˆ·åœ¨ç”µå•†ç½‘ç«™ä¸­ç™»å½•ã€ä¸‹å•ã€æ”¯ä»˜ç­‰è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å’Œç½‘ç«™åå°æ•°æ®åº“è¿›è¡Œå¢åˆ æ”¹æŸ¥äº¤äº’ï¼Œäº§ç”Ÿçš„æ•°æ®å°±æ˜¯ä¸šåŠ¡æ•°æ®ã€‚ä¸šåŠ¡æ•°æ®é€šå¸¸å­˜å‚¨åœ¨MySQLã€Oracleç­‰æ•°æ®åº“ä¸­ã€‚ æ€»å…±47å¼ è¡¨ï¼Œé€‰äº†27å¼ ä¸šåŠ¡è¡¨ 2 æ•°æ®é‡‡é›†1 ç”¨æˆ·è¡Œä¸ºæ•°æ® jar-ã€‹logï¼ˆæ—¥å¿—æœåŠ¡å™¨ï¼‰-ã€‹flume-ã€‹kafka-ã€‹flume-ã€‹hdfs 2 ä¸šåŠ¡æ•°æ® jar-ã€‹mysql-ã€‹sqoop-ã€‹hdfs 3.ODShdfsï¼ˆoriï¼‰-ã€‹hdfsï¼ˆodsï¼‰ 1 ç”¨æˆ·è¡Œä¸ºæ•°æ®1å¼ è¡¨ï¼Œtopic_log -&gt; ods_log a.å»ºè¡¨ å°±ä¸€ä¸ªå­—æ®µâ€lineâ€œ b åˆ†åŒº é¦–æ—¥ï¼Œæ¯æ—¥éƒ½æ˜¯å…¨é‡ c .æ•°æ®è£…è½½ 2 ä¸šåŠ¡æ•°æ®27å¼ è¡¨ 0 æ•´ä½“ â€‹ b åŒæ­¥ â€‹ c .æ•°æ®è£…è½½ 1.æ´»åŠ¨ä¿¡æ¯è¡¨ â€‹ activity_info -&gt; ods_activity_info â€‹ a å»ºè¡¨ â€‹ å°‘äº†ä¸ªâ€œactivity_descâ€ï¼Œå¤šäº†â€dtâ€ â€‹ b åŒæ­¥ â€‹ é¦–æ—¥ï¼Œæ¯æ—¥éƒ½æ˜¯å…¨é‡ â€‹ c .æ•°æ®è£…è½½ 4.DIMhdfsï¼ˆodsï¼‰-ã€‹hdfsï¼ˆdimï¼‰ æ„å»º6å¼ ç»´åº¦è¡¨ 1 å•†å“ç»´åº¦è¡¨ â€‹ a å»ºè¡¨ â€‹ b åˆ†åŒº â€‹ é¦–æ—¥ï¼Œæ¯æ—¥éƒ½æ˜¯å…¨é‡ â€‹ c æ•°æ®è£…è½½ 2 ä¼˜æƒ åˆ¸ç»´åº¦è¡¨ 3 æ´»åŠ¨ç»´åº¦è¡¨ 4 åœ°åŒºç»´åº¦è¡¨ â€‹ b åˆ†åŒº â€‹ åœ°åŒºç»´åº¦è¡¨æ•°æ®ç›¸å¯¹ç¨³å®šï¼Œå˜åŒ–æ¦‚ç‡è¾ƒä½ï¼Œæ•…æ— éœ€æ¯æ—¥è£…è½½ï¼Œé¦–æ—¥å…¨é‡ 5 æ—¶é—´ç»´åº¦è¡¨ â€‹ b åˆ†åŒº â€‹ é€šå¸¸æƒ…å†µä¸‹ï¼Œæ—¶é—´ç»´åº¦è¡¨çš„æ•°æ®å¹¶ä¸æ˜¯æ¥è‡ªäºä¸šåŠ¡ç³»ç»Ÿï¼Œè€Œæ˜¯æ‰‹åŠ¨å†™å…¥ï¼Œå¹¶ä¸”æ—¶é—´ç»´åº¦è¡¨æ•°æ®å…·æœ‰å¯é¢„è§æ€§ï¼Œæ— é¡»æ¯æ—¥å¯¼å…¥ï¼Œä¸€èˆ¬é¦–æ—¥å¯ä¸€æ¬¡æ€§å¯¼å…¥ä¸€å¹´çš„æ•°æ® â€‹ c æ•°æ®è£…è½½ â€‹ 1ï¼‰åˆ›å»ºä¸´æ—¶è¡¨tmp_dim_date_info â€‹ 2ï¼‰å°†æ•°æ®æ–‡ä»¶ä¸Šä¼ åˆ°HFDSä¸Šä¸´æ—¶è¡¨æŒ‡å®šè·¯å¾„/warehouse/gmall/tmp/tmp_dim_date_info/ â€‹ 3ï¼‰æ‰§è¡Œä»¥ä¸‹è¯­å¥å°†å…¶å¯¼å…¥æ—¶é—´ç»´åº¦è¡¨ 1insert overwrite table dim_date_info select * from tmp_dim_date_info; 6 ç”¨æˆ·ç»´åº¦è¡¨ â€‹ b åˆ†åŒº â€‹ æ‹‰é“¾è¡¨ https://cloud.tencent.com/developer/article/1752848# â€‹ c æ•°æ®è£…è½½ 5.DWDhdfsï¼ˆodsï¼‰-ã€‹hdfsï¼ˆdwdï¼‰ 1 ç”¨æˆ·è¡Œä¸ºæ—¥å¿—0 æ—¥å¿—æ•°æ®æ‹†è§£ ods_logç”±ä¸¤éƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«ä¸ºé¡µé¢æ—¥å¿—å’Œå¯åŠ¨æ—¥å¿—ï¼Œæ‹†è§£æˆ5å¼ è¡¨ 1 å¯åŠ¨æ—¥å¿—è¡¨ â€‹ b åˆ†åŒº â€‹ é¦–æ—¥ï¼Œæ¯æ—¥å…¨é‡ â€‹ c æ•°æ®è£…è½½ 2 é¡µé¢æ—¥å¿—è¡¨ 3 åŠ¨ä½œæ—¥å¿—è¡¨ 4 æ›å…‰æ—¥å¿—è¡¨ 5 é”™è¯¯æ—¥å¿—è¡¨ 2 ä¸šåŠ¡æ•°æ®1 è¯„ä»·äº‹å®è¡¨ï¼ˆäº‹åŠ¡å‹äº‹å®è¡¨ï¼‰ â€‹ b åˆ†åŒº â€‹ c æ•°æ®è£…è½½ â€‹ é¦–æ—¥ï¼ŒåŠ¨æ€åˆ†åŒºï¼›æ¯æ—¥ï¼Œé™æ€åˆ†åŒº 2 è®¢å•æ˜ç»†äº‹å®è¡¨ï¼ˆäº‹åŠ¡å‹äº‹å®è¡¨ï¼‰ 3 é€€å•äº‹å®è¡¨ï¼ˆäº‹åŠ¡å‹äº‹å®è¡¨ï¼‰ 4 åŠ è´­äº‹å®è¡¨ï¼ˆå‘¨æœŸå‹å¿«ç…§äº‹å®è¡¨ï¼‰ â€‹ b åˆ†åŒº â€‹ c æ•°æ®åŠ è½½ 5 æ”¶è—äº‹å®è¡¨ï¼ˆå‘¨æœŸå‹å¿«ç…§äº‹å®è¡¨ï¼‰ 6 ä¼˜æƒ åˆ¸é¢†ç”¨äº‹å®è¡¨ï¼ˆç´¯ç§¯å‹å¿«ç…§äº‹å®è¡¨ï¼‰ â€‹ b åˆ†åŒº â€‹ c æ•°æ®åŠ è½½ â€‹ ï¼ˆ1ï¼‰é¦–æ—¥ 123456789101112131415insert overwrite table dwd_coupon_use partition(dt)select id, coupon_id, user_id, order_id, coupon_status, get_time, using_time, used_time, expire_time, coalesce(date_format(used_time,'yyyy-MM-dd'),date_format(expire_time,'yyyy-MM-dd'),'9999-99-99')from ods_coupon_usewhere dt='2020-06-14'; â€‹ ï¼ˆ2ï¼‰æ¯æ—¥ 7 æ”¯ä»˜äº‹å®è¡¨ï¼ˆç´¯ç§¯å‹å¿«ç…§äº‹å®è¡¨ï¼‰ 8 é€€æ¬¾äº‹å®è¡¨ï¼ˆç´¯ç§¯å‹å¿«ç…§äº‹å®è¡¨ï¼‰ 9 è®¢å•äº‹å®è¡¨ï¼ˆç´¯ç§¯å‹å¿«ç…§äº‹å®è¡¨ï¼‰ 6.DWShdfsï¼ˆdwdï¼‰-ã€‹hdfsï¼ˆdwsï¼‰ 0 æ•´ä½“ â€‹ b åˆ†åŒº â€‹ â€‹ c æ•°æ®è£…è½½ â€‹ 1 è®¿å®¢ä¸»é¢˜ 2 ç”¨æˆ·ä¸»é¢˜ 3 å•†å“ä¸»é¢˜ 4 ä¼˜æƒ åˆ¸ä¸»é¢˜ 5 æ´»åŠ¨ä¸»é¢˜ 6 åœ°åŒºä¸»é¢˜ 7.DWThdfsï¼ˆdwsï¼‰-ã€‹hdfsï¼ˆDWTï¼‰ 0 æ•´ä½“ c æ•°æ®è£…è½½ åªä¿ç•™å½“å¤©å’Œå‰ä¸€å¤©çš„åˆ†åŒºï¼Œè¿‡æ—¶çš„éœ€è¦æ¸…ç†æ‰i 1 è®¿å®¢ä¸»é¢˜ 2 ç”¨æˆ·ä¸»é¢˜ 3 å•†å“ä¸»é¢˜ 4 ä¼˜æƒ åˆ¸ä¸»é¢˜ 5 æ´»åŠ¨ä¸»é¢˜ 6 åœ°åŒºä¸»é¢˜ 8.ADShdfsï¼ˆDWTï¼‰-ã€‹hdfsï¼ˆADSï¼‰-ã€‹mysql 1 è®¿å®¢ä¸»é¢˜1 è®¿å®¢ç»Ÿè®¡ a å»ºè¡¨ æŒ‡æ ‡ è¯´æ˜ å¯¹åº”å­—æ®µ è®¿å®¢æ•° ç»Ÿè®¡è®¿é—®äººæ•° uv_count é¡µé¢åœç•™æ—¶é•¿ ç»Ÿè®¡æ‰€æœ‰é¡µé¢è®¿é—®è®°å½•æ€»æ—¶é•¿ï¼Œä»¥ç§’ä¸ºå•ä½ duration_sec å¹³å‡é¡µé¢åœç•™æ—¶é•¿ ç»Ÿè®¡æ¯ä¸ªä¼šè¯å¹³å‡åœç•™æ—¶é•¿ï¼Œä»¥ç§’ä¸ºå•ä½ avg_duration_sec é¡µé¢æµè§ˆæ€»æ•° ç»Ÿè®¡æ‰€æœ‰é¡µé¢è®¿é—®è®°å½•æ€»æ•° page_count å¹³å‡é¡µé¢æµè§ˆæ•° ç»Ÿè®¡æ¯ä¸ªä¼šè¯å¹³å‡æµè§ˆé¡µé¢æ•° avg_page_count ä¼šè¯æ€»æ•° ç»Ÿè®¡ä¼šè¯æ€»æ•° sv_count è·³å‡ºæ•° ç»Ÿè®¡åªæµè§ˆä¸€ä¸ªé¡µé¢çš„ä¼šè¯ä¸ªæ•° bounce_count è·³å‡ºç‡ åªæœ‰ä¸€ä¸ªé¡µé¢çš„ä¼šè¯çš„æ¯”ä¾‹ bounce_rate b åˆ†åŒº c æ•°æ®è£…è½½ ç¬¬ä¸€æ­¥ï¼šå¯¹æ‰€æœ‰é¡µé¢è®¿é—®è®°å½•è¿›è¡Œä¼šè¯çš„åˆ’åˆ†ã€‚ ç¬¬äºŒæ­¥ï¼šç»Ÿè®¡æ¯ä¸ªä¼šè¯çš„æµè§ˆæ—¶é•¿å’Œæµè§ˆé¡µé¢æ•°ã€‚ ç¬¬ä¸‰æ­¥ï¼šç»Ÿè®¡ä¸Šè¿°å„æŒ‡æ ‡ã€‚ 2 è·¯å¾„åˆ†æ ç”¨æˆ·è®¿é—®è·¯å¾„çš„å¯è§†åŒ–é€šå¸¸ä½¿ç”¨æ¡‘åŸºå›¾ 2 ç”¨æˆ·ä¸»é¢˜3 å•†å“ä¸»é¢˜4 è®¢å•ä¸»é¢˜5 ä¼˜æƒ åˆ¸ä¸»é¢˜6 æ´»åŠ¨ä¸»é¢˜9.Azkabanå…¨æµç¨‹è°ƒåº¦ å°±æ˜¯å°†åŸæ¥å†™çš„è„šæœ¬æ–‡ä»¶ä¸²èµ·æ¥","link":"/2022/02/03/build-datawarehouse/"},{"title":"CDCï¼ˆChange Data Captureï¼‰å·¥å…·å¯¹æ¯”","text":"https://blog.csdn.net/u013411339/article/details/120917907","link":"/2022/04/23/cdc/"},{"title":"ä¸­æ–‡è¯ç²’åº¦BERT","text":"1 Is Word Segmentation Necessary for Deep Learning of Chinese Representations? we find that charbasedï¼ˆå­—ç²’åº¦ï¼‰ models consistently outperform wordbased ï¼ˆè¯ç²’åº¦ï¼‰models. We show that it is because word-based models are more vulnerable to data sparsity and the presence of out-of-vocabulary (OOV) words, and thus more prone to overfitting. 2 è…¾è®¯ä¸­æ–‡è¯æ¨¡å‹ è¯æ¨¡å‹åœ¨å…¬å¼€æ•°æ®é›†çš„è¡¨ç°é€Šäºå­—æ¨¡å‹ å‚è€ƒhttps://arxiv.org/pdf/1905.05526.pdf https://www.jiqizhixin.com/articles/2019-06-27-17","link":"/2021/10/26/ch-word-bert/"},{"title":"ååŒè¿‡æ»¤","text":"https://www.jianshu.com/p/5463ab162a58 https://www.jianshu.com/p/20041e72e9ec https://www.cnblogs.com/pinard/p/6349233.html","link":"/2021/10/21/cf/"},{"title":"chatbot","text":"https://zhuanlan.zhihu.com/p/55201625# https://zhuanlan.zhihu.com/p/88546027 https://blog.csdn.net/m0_37565948/article/details/81582585","link":"/2021/11/26/chatbot/"},{"title":"checkpoints_iterator","text":"12for ckpt in tf.contrib.training.checkpoints_iterator( FLAGS.output_dir, timeout=FLAGS.eval_timeout) æŒç»­æ•æ‰æœ€æ–°çš„checkpointï¼Œä¸¤æ¬¡æ•æ‰ä¹‹é—´çš„æœ€å¤§ç­‰å¾…æ—¶é—´ä¸º eval_timeout ä»€ä¹ˆç”¨ï¼Ÿ ç”¨äºè®­ç»ƒéªŒè¯å¹¶è¡Œï¼Œä¹‹å‰æ˜¯äº¤æ›¿ ä¸€ä¸ªè®¾å¤‡è®­ç»ƒï¼Œäº§ç”Ÿcheckpointï¼Œä¸€ä¸ªè®¾å¤‡æ•æ‰éªŒè¯","link":"/2022/06/06/checkpoints-iterator/"},{"title":"ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information","text":"è€ƒè™‘å­—å½¢å’Œæ‹¼éŸ³çš„ä¸­æ–‡PTM 1 æ¨¡å‹ç»“æ„ å˜åŠ¨åœ¨bertçš„è¾“å…¥ åŸæ¥Char embedding+Position embedding+segment embedding-&gt; ç°åœ¨ Fusion embedding+Position embedding ï¼ˆomit the segment embeddingï¼‰ Char embedding +Glyph ( å­—å½¢ ) embedding +Pinyin ï¼ˆæ‹¼éŸ³ï¼‰embedding -ã€‹Fusion embedding 2 é¢„è®­ç»ƒä»»åŠ¡ Whole Word Masking (WWM) and Char Masking (CM) 3 ä½¿ç”¨1234567891011121314151617181920&gt;&gt;&gt; from datasets.bert_dataset import BertDataset&gt;&gt;&gt; from models.modeling_glycebert import GlyceBertModel&gt;&gt;&gt; tokenizer = BertDataset([CHINESEBERT_PATH])&gt;&gt;&gt; chinese_bert = GlyceBertModel.from_pretrained([CHINESEBERT_PATH])&gt;&gt;&gt; sentence = 'æˆ‘å–œæ¬¢çŒ«'&gt;&gt;&gt; input_ids, pinyin_ids = tokenizer.tokenize_sentence(sentence)&gt;&gt;&gt; length = input_ids.shape[0]&gt;&gt;&gt; input_ids = input_ids.view(1, length)&gt;&gt;&gt; pinyin_ids = pinyin_ids.view(1, length, 8)&gt;&gt;&gt; output_hidden = chinese_bert.forward(input_ids, pinyin_ids)[0]&gt;&gt;&gt; print(output_hidden)tensor([[[ 0.0287, -0.0126, 0.0389, ..., 0.0228, -0.0677, -0.1519], [ 0.0144, -0.2494, -0.1853, ..., 0.0673, 0.0424, -0.1074], [ 0.0839, -0.2989, -0.2421, ..., 0.0454, -0.1474, -0.1736], [-0.0499, -0.2983, -0.1604, ..., -0.0550, -0.1863, 0.0226], [ 0.1428, -0.0682, -0.1310, ..., -0.1126, 0.0440, -0.1782], [ 0.0287, -0.0126, 0.0389, ..., 0.0228, -0.0677, -0.1519]]], grad_fn=&lt;NativeLayerNormBackward&gt;) å‚è€ƒhttps://github.com/ShannonAI/ChineseBert https://arxiv.org/pdf/2106.16038.pdf","link":"/2022/06/17/chinesebert/"},{"title":"åˆ†ç±»ä»»åŠ¡çš„è¡¡é‡æŒ‡æ ‡","text":"ä¸€ã€äºŒåˆ†ç±»1.1 confusion matrix 1.2 accuracy accuracy={\\frac{TP+TN}{TP+TN+FP+FN}}accuracy è¡¡é‡å…¨å±€åˆ†ç±»æ­£ç¡®çš„æ•°é‡å æ€»æ ·æœ¬çš„æ¯”ä¾‹ 1.3 precision precision={\\frac{TP}{TP+FP}}precisionä¸ºé¢„æµ‹æ­£ç¡®æ­£æ ·æœ¬æ•°å é¢„æµ‹çš„å…¨éƒ¨æ­£æ ·æœ¬æ•°çš„æ¯”ä¾‹ï¼Œå³ç³»ç»Ÿåˆ¤å®šä¸ºæ­£æ ·æœ¬çš„æ­£ç¡®ç‡ã€‚é€šä¿—åœ°è¯´ï¼Œå‡å¦‚åŒ»ç”Ÿç»™ç—…äººæ£€æŸ¥ï¼ŒåŒ»ç”Ÿåˆ¤æ–­ç—…äººæœ‰ç–¾ç—…ï¼Œç„¶ååŒ»ç”Ÿåˆ¤æ–­çš„æ­£ç¡®ç‡æœ‰å¤šå°‘ã€‚ 1.4 recall recall={\\frac{TP}{TP+FN}}recallä¸ºé¢„æµ‹æ­£ç¡®çš„æ­£æ ·æœ¬æ•°é‡å çœŸå®æ­£æ ·æœ¬æ•°é‡çš„æ¯”ä¾‹ï¼Œå³è¡¡é‡æ­£æ ·æœ¬çš„å¬å›æ¯”ä¾‹ã€‚é€šä¿—è¯´ï¼Œå‡å¦‚æœ‰ä¸€æ‰¹ç—…äººï¼ŒåŒ»ç”Ÿèƒ½ä»ä¸­æ‰¾å‡ºç—…äººçš„æ¯”ä¾‹ 1.5 F1ç”±äºprecisionå’Œrecallå¾€å¾€æ˜¯çŸ›ç›¾çš„ï¼Œå› æ­¤ä¸ºäº†ç»¼åˆè€ƒè™‘äºŒè€…ï¼Œå¼•å…¥F1ï¼Œå³ä¸ºprecisionå’Œrecallçš„è°ƒå’Œå¹³å‡ F_{1}={2\\frac{precision\\cdot recall}{precision+recall}}å½“$precision$å’Œ$recall$çš„ä»»ä¸€ä¸ªå€¼ä¸º0ï¼Œ$F_1$éƒ½ä¸º0 ä¹‹æ‰€ä»¥é‡‡ç”¨è°ƒå’Œå¹³å‡ï¼Œæ˜¯å› ä¸ºè°ƒå’Œå¹³å‡æ•°å—æç«¯å€¼å½±å“è¾ƒå¤§ï¼Œæ›´é€‚åˆè¯„ä»·ä¸å¹³è¡¡æ•°æ®çš„åˆ†ç±»é—®é¢˜ é€šç”¨çš„Få€¼è¡¨è¾¾å¼ï¼š F_{\\beta}={(1+\\beta^2)\\frac{precision\\cdot recall}{\\beta^2\\cdot precision+recall}}é™¤äº†$F_1$åˆ†æ•°ä¹‹å¤–ï¼Œ$F_2$ åˆ†æ•°å’Œ$F_{0.5}$åˆ†æ•°åœ¨ç»Ÿè®¡å­¦ä¸­ä¹Ÿå¾—åˆ°å¤§é‡çš„åº”ç”¨ã€‚å…¶ä¸­ï¼Œ$F_2$åˆ†æ•°ä¸­ï¼Œå¬å›ç‡çš„æƒé‡é«˜äºç²¾ç¡®ç‡ï¼Œè€Œ$F_{0.5}$åˆ†æ•°ä¸­ï¼Œç²¾ç¡®ç‡çš„æƒé‡é«˜äºå¬å›ç‡ã€‚ 1.6 ROC rocæ›²çº¿ï¼šæ¥æ”¶è€…æ“ä½œç‰¹å¾(receiver operating characteristic), rocæ›²çº¿ä¸Šæ¯ä¸ªç‚¹åæ˜ æŸä¸ªé˜ˆå€¼ä¸‹çš„FPRå’ŒTPRçš„ç»„åˆã€‚ æ¨ªè½´ï¼š$FPR$ï¼Œå«åšå‡æ­£ç±»ç‡ï¼Œè¡¨ç¤ºé¢„æµ‹ä¸ºæ­£ä¾‹ä½†çœŸå®æƒ…å†µä¸ºåä¾‹çš„å æ‰€æœ‰çœŸå®æƒ…å†µä¸­åä¾‹çš„æ¯”ç‡ï¼Œå…¬å¼ä¸º$FPR=\\frac{FP}{TN+FP}$ã€‚ çºµè½´ï¼š$TPR$ ï¼Œå«åšçœŸæ­£ä¾‹ç‡ï¼Œè¡¨ç¤ºé¢„æµ‹ä¸ºæ­£ä¾‹ä¸”çœŸå®æƒ…å†µä¸ºæ­£ä¾‹çš„å æ‰€æœ‰çœŸå®æƒ…å†µä¸­æ­£ä¾‹çš„æ¯”ç‡ï¼Œå…¬å¼ä¸ºâ€‹ $TPR=\\frac{TP}{TP+FN}$ã€‚ 1.7 AUC$AUC$(Area under Curve)ï¼šROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œæ•°å€¼å¯ä»¥ç›´è§‚è¯„ä»·åˆ†ç±»å™¨çš„å¥½åï¼Œå€¼è¶Šå¤§è¶Šå¥½ï¼Œå¯¹äºäºŒåˆ†ç±»ï¼Œç»“æœä»‹äº0.5å’Œ1ä¹‹é—´ï¼Œ1ä¸ºå®Œç¾åˆ†ç±»å™¨ï¼Œ0.5æ˜¯å› ä¸ºäºŒåˆ†ç±»åˆ†ç±»æ•ˆæœæœ€å·®ä¹Ÿæ˜¯0.5ã€‚ äºŒã€å¤šåˆ†ç±»2.1 æ··æ·†çŸ©é˜µ 2.2 accuracy accuracy=\\frac{åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬æ•°,å³å¯¹è§’çº¿ä¸Šçš„æ•°}{æ€»æ ·æœ¬æ•°ï¼Œå³çŸ©é˜µå…¨éƒ¨å…ƒç´ ç›¸åŠ }2.3 æŸä¸ªç±»åˆ«çš„precisionï¼Œrecallï¼ŒF1ä¸äºŒåˆ†ç±»å…¬å¼ä¸€æ · precision_{pig}=\\frac{20}{20+(10+40)}=\\frac{2}{7} \\\\recall_{pig}=\\frac{20}{20+10}=\\frac{2}{3} \\\\F_{1pig}={2\\frac{precision_{pig}\\cdot recall_{pig}}{precision_{pig}+recall_{pig}}}2.4 ç³»ç»Ÿçš„precisionï¼Œrecallï¼ŒF1ç³»ç»Ÿçš„precisionï¼Œrecallï¼Œ$F_1$éœ€è¦ç»¼åˆè€ƒè™‘æ‰€æœ‰ç±»åˆ«ï¼Œå³åŒæ—¶è€ƒè™‘çŒ«ã€ç‹—ã€çŒªçš„precisionï¼Œrecallï¼Œ$F_1$ã€‚æœ‰å¦‚ä¸‹å‡ ç§æ–¹æ¡ˆï¼š 2.4.1 Macro average Macro-precision=\\frac{precision_{cat}+precision_{dog}+precision_{pig}}{3} \\\\Macro-recall=\\frac{recall{cat}+recall{dog}+recall{pig}}{3} \\\\Macro-F_{1}=\\frac{F_{1cat}+F_{1dog}+F_{1pig}}{3}2.4.2 Weighted averageå¯¹macroçš„æ¨å¹¿ Weighted-precision=W_{cat}\\cdot precision_{cat}+W_{dog}\\cdot precision_{dog}+W_{pig}\\cdot precision_{pig} \\\\Weighted-recall=W_{cat}\\cdot recall{cat}+W_{dog}\\cdot recall{dog}+W_{pig}\\cdot recall{pig} \\\\Weighted-F_{1}=W_{cat}\\cdot F_{1cat}+W_{dog}\\cdot F_{1dog}+W_{pig}\\cdot F_{1pig} \\\\W_{cat}:W_{dog}:W_{pig}=N_{cat}:N_{dog}:N_{pig},å…¶ä¸­Nä¸ºæ ·æœ¬æ•°é‡ï¼ŒWä¸ºæƒé‡2.4.3 Micro average Micro-precision={\\frac{TP_{æ€»}}{TP_{æ€»}+FP_{æ€»}}}={\\frac{\\sum_{i=1}^{n}TP_{i}}{\\sum_{i=1}^{n}TP_{i}+\\sum_{i=1}^{n}FP_{i}}} \\\\Micro-recall={\\frac{TP_{æ€»}}{TP_{æ€»}+FN_{æ€»}}}={\\frac{\\sum_{i=1}^{n}TP_{i}}{\\sum_{i=1}^{n}TP_{i}+\\sum_{i=1}^{n}FN_{i}}} \\\\Micro-F_{1}={2\\frac{Micro-precision\\cdot Micro-recall}{Micro-precision+Micro-recall}}2.5 ROC å¯¹äºå¤šåˆ†ç±»åˆ†ç±»å™¨æ•´ä½“æ•ˆæœçš„ROCå¦‚ä¸Šmicroæˆ–è€…macroæ›²çº¿ï¼Œå…¶ä½™3æ¡æè¿°å•ä¸ªç±»åˆ«çš„åˆ†ç±»æ•ˆæœã€‚å¯¹äºå¤šåˆ†ç±»ï¼ŒROCä¸Šçš„ç‚¹ï¼ŒåŒæ ·æ˜¯æŸä¸ªé˜ˆå€¼ä¸‹çš„FPRå’ŒTPRçš„ç»„åˆã€‚ å¯¹äºå¤šåˆ†ç±»çš„$FPR$,$TPR$ï¼Œæœ‰å‡ ç§è®¡ç®—æ–¹å¼ a. micro average FPR_{micro } =\\frac{FP_æ€»}{TN_æ€»+FP_æ€»}=\\frac{\\sum_{i=1}^{n}FP_{i}}{\\sum_{i=1}^{n}TN_{i}+\\sum_{i=1}^{n}FP_{i}}\\\\ TPR_{micro }=\\frac{TP_æ€»}{TP_æ€»+FN_æ€»}=\\frac{\\sum_{i=1}^{n}TP_{i}}{\\sum_{i=1}^{n}TP_{i}+\\sum_{i=1}^{n}FN_{i}} \\\\nè¡¨ç¤ºç±»åˆ«æ•°é‡ï¼ŒFP_iï¼ŒTN_iï¼ŒTP_iï¼ŒFN_iä¸ºæŸä¸ªç±»åˆ«çš„FPï¼ŒTNï¼ŒTPï¼ŒFNb. macro average FPR_{macro}=\\frac{1}{n}\\sum_{i=1}^{n}FPR_{i}\\\\ TPR_{macro}=\\frac{1}{n}\\sum_{i=1}^{n}TPR_{i}ï¼Œå…¶ä¸­FPR_iï¼ŒTPR_iä¸ºæŸä¸ªç±»åˆ«çš„FPRå’ŒTPR2.6 AUC$AUC$ä¾æ—§ä¸ºROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œå¯¹äºå¤šåˆ†ç±»ä¸ªäººè®¤ä¸ºå–å€¼èŒƒå›´ä¸º[0,1]ã€‚ ä¸‰.ä»£ç accuracyï¼Œprecisionï¼Œrecallï¼ŒF1 12345from sklearn.metrics import precision_recall_fscore_support, accuracy_scoredef eval_acc_f1(y_true, y_pred): acc = accuracy_score(y_true, y_pred) prf = precision_recall_fscore_support(y_true, y_pred, average=&quot;macro&quot;) return acc, prf ROCå’ŒAUC 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# å¼•å…¥å¿…è¦çš„åº“import numpy as npimport matplotlib.pyplot as pltfrom itertools import cyclefrom sklearn import svm, datasetsfrom sklearn.metrics import roc_curve, aucfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import label_binarizefrom sklearn.multiclass import OneVsRestClassifierfrom scipy import interp# åŠ è½½æ•°æ®iris = datasets.load_iris()X = iris.datay = iris.target# å°†æ ‡ç­¾äºŒå€¼åŒ–y = label_binarize(y, classes=[0, 1, 2])# è®¾ç½®ç§ç±»n_classes = y.shape[1]# è®­ç»ƒæ¨¡å‹å¹¶é¢„æµ‹random_state = np.random.RandomState(0)n_samples, n_features = X.shape# shuffle and split training and test setsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,random_state=0)# Learn to predict each class against the otherclassifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state=random_state))y_score = classifier.fit(X_train, y_train).decision_function(X_test)# è®¡ç®—æ¯ä¸€ç±»çš„ROCfpr = dict()tpr = dict()roc_auc = dict()for i in range(n_classes): fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i]) roc_auc[i] = auc(fpr[i], tpr[i])# Compute micro-average ROC curve and ROC areaï¼ˆæ–¹æ³•äºŒï¼‰fpr[&quot;micro&quot;], tpr[&quot;micro&quot;], _ = roc_curve(y_test.ravel(), y_score.ravel())roc_auc[&quot;micro&quot;] = auc(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;])# Compute macro-average ROC curve and ROC areaï¼ˆæ–¹æ³•ä¸€ï¼‰# First aggregate all false positive ratesall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))# Then interpolate all ROC curves at this pointsmean_tpr = np.zeros_like(all_fpr)for i in range(n_classes): mean_tpr += interp(all_fpr, fpr[i], tpr[i])# Finally average it and compute AUCmean_tpr /= n_classesfpr[&quot;macro&quot;] = all_fprtpr[&quot;macro&quot;] = mean_tprroc_auc[&quot;macro&quot;] = auc(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;])# Plot all ROC curveslw=2plt.figure()plt.plot(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;], label='micro-average ROC curve (area = {0:0.2f})' ''.format(roc_auc[&quot;micro&quot;]), color='deeppink', linestyle=':', linewidth=4)plt.plot(fpr[&quot;macro&quot;], tpr[&quot;macro&quot;], label='macro-average ROC curve (area = {0:0.2f})' ''.format(roc_auc[&quot;macro&quot;]), color='navy', linestyle=':', linewidth=4)colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])for i, color in zip(range(n_classes), colors): plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))plt.plot([0, 1], [0, 1], 'k--', lw=lw)plt.xlim([0.0, 1.0])plt.ylim([0.0, 1.05])plt.xlabel('False Positive Rate')plt.ylabel('True Positive Rate')plt.title('Some extension of Receiver operating characteristic to multi-class')plt.legend(loc=&quot;lower right&quot;)plt.show() å‚è€ƒèµ„æ–™ï¼šhttps://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839 https://zhuanlan.zhihu.com/p/147663370 https://zhuanlan.zhihu.com/p/81202617 https://zhuanlan.zhihu.com/p/266386193","link":"/2021/07/18/classify-performance/"},{"title":"clickhouse","text":"https://zhuanlan.zhihu.com/p/139948625 å…³ç³»å‹ï¼Œåˆ†å¸ƒå¼ï¼Œå®Œå…¨åˆ—å¼ åˆ—å¼æŒ‡å¾—æ˜¯åˆ—å­˜å‚¨","link":"/2022/04/23/clickhouse/"},{"title":"é—­åŒ…","text":"è°ƒç”¨å‡½æ•°Aï¼Œè¿”å›å‡½æ•°Bç»™ä½ ï¼Œå‡½æ•°Bå°±æ˜¯é—­åŒ…ï¼ŒAçš„å‚æ•°å°±æ˜¯è‡ªç”±å˜é‡","link":"/2022/09/12/closure/"},{"title":"sparkéƒ¨ç½²æ–¹å¼","text":"https://blog.csdn.net/qq_37163925/article/details/106260434 https://spark.apache.org/docs/latest/cluster-overview.html https://book.itheima.net/course/1269935677353533441/1270998166728089602/1270999667882074115 é€šè¿‡è®¾ç½®materæ¥é€‰æ‹©éƒ¨ç½²æ–¹å¼ã€‚è¯¥å±æ€§æ²¡æœ‰é»˜è®¤å€¼ã€‚è¿™æ˜¯Sparkç¨‹åºéœ€è¦è¿æ¥çš„é›†ç¾¤ç®¡ç†å™¨æ‰€åœ¨çš„URLåœ°å€ã€‚å¦‚æœè¿™ä¸ªå±æ€§åœ¨æäº¤åº”ç”¨ç¨‹åºçš„æ—¶å€™æ²¡è®¾ç½®ï¼Œç¨‹åºå°†ä¼šé€šè¿‡System.getenv(â€œMASTERâ€)æ¥è·å–MASTERç¯å¢ƒå˜é‡ï¼›ä½†æ˜¯å¦‚æœMASTERç¯å¢ƒå˜é‡æ²¡æœ‰è®¾å®šï¼Œé‚£ä¹ˆç¨‹åºå°†ä¼šæŠŠmasterçš„å€¼è®¾å®šä¸ºlocal[*]ï¼Œä¹‹åç¨‹åºå°†åœ¨æœ¬åœ°å¯åŠ¨ã€‚ localä¸ºå•æœº standaloneæ˜¯Sparkè‡ªèº«å®ç°èµ„æºè°ƒåº¦ yarnä¸ºä½¿ç”¨hadoop yarnæ¥å®ç°èµ„æºè°ƒåº¦ 1 localæœ¬åœ°æ¨¡å¼å°±æ˜¯ä»¥ä¸€ä¸ªç‹¬ç«‹çš„è¿›ç¨‹ï¼Œé€šè¿‡å…¶å†…éƒ¨çš„å¤šä¸ªçº¿ç¨‹æ¥æ¨¡æ‹Ÿæ•´ä¸ªSparkè¿è¡Œæ—¶ç¯å¢ƒ localã€Nã€‘ï¼šNä¸ºçº¿ç¨‹æ•°é‡ï¼Œé€šå¸¸Nä¸ºcpuçš„coreçš„æ•°é‡ localã€*ã€‘ï¼šcpuçš„coreæ•°é‡ è·‘localå¯ä»¥ä¸ä¾èµ–hadoop https://blog.csdn.net/wangmuming/article/details/37695619 https://blog.csdn.net/bettesu/article/details/68512570 2 Standalonehttps://sfzsjx.github.io/2019/08/26/spark-standalone-%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86 2.1 client æ‰§è¡Œæµç¨‹ client æ¨¡å¼æäº¤ä»»åŠ¡åï¼Œä¼šåœ¨å®¢æˆ·ç«¯å¯åŠ¨Driverè¿›ç¨‹ã€‚ Driver ä¼šå‘Masterç”³è¯·å¯åŠ¨Applicationå¯åŠ¨èµ„æºã€‚ èµ„æºç”³è¯·æˆåŠŸåï¼ŒDriverç«¯ä¼šå°†taskå‘é€åˆ°workerç«¯æ‰§è¡Œã€‚ workerç«¯æ‰§è¡ŒæˆåŠŸåå°†æ‰§è¡Œç»“æœè¿”å›ç»™Driverç«¯ 2.2 cluster æ‰§è¡Œæµç¨‹ï¼š å®¢æˆ·ç«¯ä½¿ç”¨å‘½ä»¤spark-submit â€“deploy-mode cluster åä¼šå¯åŠ¨spark-submitè¿›ç¨‹ æ­¤è¿›ç¨‹ä¸ºDriverå‘Master ç”³è¯·èµ„æºã€‚ Masterä¼šéšæœºåœ¨ä¸€å°WorkerèŠ‚ç‚¹æ¥å¯åŠ¨Driverè¿›ç¨‹ã€‚ Driverå¯åŠ¨æˆåŠŸåï¼Œspark-submitå…³é—­ï¼Œç„¶åDriverå‘Masterç”³è¯·èµ„æºã€‚ Masteræ¥æ”¶åˆ°è¯·æ±‚åï¼Œä¼šåœ¨èµ„æºå……è¶³çš„WorkerèŠ‚ç‚¹ä¸Šå¯åŠ¨Executorè¿›ç¨‹ã€‚ Driveråˆ†å‘Taskåˆ°Executorä¸­æ‰§è¡Œã€‚ 2.3 é«˜å¯ç”¨HA 3 Mesosa general cluster manager that can also run Hadoop MapReduce and service applications. (Deprecated) 4 YARNä¸ºä»€ä¹ˆè¦YARNï¼Ÿ Spark On YARNæ˜¯æœ‰ä¸¤ç§è¿è¡Œæ¨¡å¼çš„,ä¸€ç§æ˜¯Clusteræ¨¡å¼ä¸€ç§æ˜¯Clientæ¨¡å¼.è¿™ä¸¤ç§æ¨¡å¼çš„åŒºåˆ«å°±æ˜¯Driverè¿è¡Œçš„ä½ç½®. Clusteræ¨¡å¼å³:Driverè¿è¡Œåœ¨YARNå®¹å™¨å†…éƒ¨, å’ŒApplicationMasteråœ¨åŒä¸€ä¸ªå®¹å™¨å†… Clientæ¨¡å¼å³:Driverè¿è¡Œåœ¨å®¢æˆ·ç«¯è¿›ç¨‹ä¸­, æ¯”å¦‚Driverè¿è¡Œåœ¨spark-submitç¨‹åºçš„è¿›ç¨‹ä¸­ 4.1 cluster å…·ä½“æµç¨‹æ­¥éª¤å¦‚ä¸‹ï¼š1ï¼‰ã€ä»»åŠ¡æäº¤åä¼šå’ŒResourceManageré€šè®¯ç”³è¯·å¯åŠ¨ApplicationMaster;2ï¼‰ã€éšåResourceManageråˆ†é…Containerï¼Œåœ¨åˆé€‚çš„NodeManagerä¸Šå¯åŠ¨ApplicationMasterï¼Œæ­¤æ—¶çš„ApplicationMasterå°±æ˜¯Driverï¼›3ï¼‰ã€Driverå¯åŠ¨åå‘ResourceManagerç”³è¯·Executorå†…å­˜ï¼ŒResourceManageræ¥åˆ°ApplicationMasterçš„èµ„æºç”³è¯·åä¼šåˆ†é…Container,ç„¶ååœ¨åˆé€‚çš„NodeManagerä¸Šå¯åŠ¨Executorè¿›ç¨‹;4ï¼‰ã€Executorè¿›ç¨‹å¯åŠ¨åä¼šå‘Driveråå‘æ³¨å†Œ;5ï¼‰ã€Executorå…¨éƒ¨æ³¨å†Œå®ŒæˆåDriverå¼€å§‹æ‰§è¡Œmainå‡½æ•°ï¼Œä¹‹åæ‰§è¡Œåˆ°Actionç®—å­æ—¶ï¼Œè§¦å‘ä¸€ä¸ªjobï¼Œå¹¶æ ¹æ®å®½ä¾èµ–å¼€å§‹åˆ’åˆ†stageï¼Œæ¯ä¸ªstageç”Ÿæˆå¯¹åº”çš„taskSetï¼Œä¹‹åå°†taskåˆ†å‘åˆ°å„ä¸ªExecutorä¸Šæ‰§è¡Œ; 4.2 client å…·ä½“æµç¨‹æ­¥éª¤å¦‚ä¸‹ï¼š1ï¼‰ã€Driveråœ¨ä»»åŠ¡æäº¤çš„æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œï¼ŒDriverå¯åŠ¨åä¼šå’ŒResourceManageré€šè®¯ç”³è¯·å¯åŠ¨ApplicationMasterï¼›2ï¼‰ã€éšåResourceManageråˆ†é…Containerï¼Œåœ¨åˆé€‚çš„NodeManagerä¸Šå¯åŠ¨ApplicationMasterï¼Œæ­¤æ—¶çš„ApplicationMasterçš„åŠŸèƒ½ç›¸å½“äºä¸€ä¸ªExecutorLaucherï¼Œåªè´Ÿè´£å‘ResourceManagerç”³è¯·Executorå†…å­˜ï¼›3ï¼‰ã€ResourceManageræ¥åˆ°ApplicationMasterçš„èµ„æºç”³è¯·åä¼šåˆ†é…Containerï¼Œç„¶åApplicationMasteråœ¨èµ„æºåˆ†é…æŒ‡å®šçš„NodeManagerä¸Šå¯åŠ¨Executorè¿›ç¨‹ï¼›4ï¼‰ã€Executorè¿›ç¨‹å¯åŠ¨åä¼šå‘Driveråå‘æ³¨å†Œï¼ŒExecutorå…¨éƒ¨æ³¨å†Œå®ŒæˆåDriverå¼€å§‹æ‰§è¡Œmainå‡½æ•°ï¼›5ï¼‰ã€ä¹‹åæ‰§è¡Œåˆ°Actionç®—å­æ—¶ï¼Œè§¦å‘ä¸€ä¸ªJobï¼Œå¹¶æ ¹æ®å®½ä¾èµ–å¼€å§‹åˆ’åˆ†Stageï¼Œæ¯ä¸ªStageç”Ÿæˆå¯¹åº”çš„TaskSetï¼Œä¹‹åå°†Taskåˆ†å‘åˆ°å„ä¸ªExecutorä¸Šæ‰§è¡Œã€‚ 5 Kubernetesan open-source system for automating deployment, scaling, and management of containerized applications.","link":"/2022/01/18/cluster-clinet/"},{"title":"colab","text":"æ²¡æœ‰GPUæ€ä¹ˆåŠï¼Œè–…å¤§æˆ·ï¼ï¼ï¼ https://blog.csdn.net/zhang_li_ke/article/details/89704682 https://www.jianshu.com/p/a42d69568966 https://blog.csdn.net/oldmao_2001/article/details/90737735?","link":"/2021/11/21/colab/"},{"title":"è¡¨å­—æ®µçš„æ•°æ®ç±»å‹","text":"https://www.html.cn/qa/other/20219.html","link":"/2022/02/15/column_type/"},{"title":"ConSERT A Contrastive Framework for Self-Supervised Sentence Representation Transfer","text":"https://arxiv.org/abs/2105.11741 https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html 1.èƒŒæ™¯é¦–å…ˆï¼ŒBERTå…¶è‡ªèº«å¯¼å‡ºçš„å¥å‘é‡ï¼ˆä¸ç»è¿‡Fine-tuneï¼Œå¯¹æ‰€æœ‰è¯å‘é‡æ±‚å¹³å‡ï¼‰ä¼šå‡ºç°â€œåç¼©ï¼ˆCollapseï¼‰â€ç°è±¡ï¼Œå³æ‰€æœ‰çš„å¥å­éƒ½å€¾å‘äºç¼–ç åˆ°ä¸€ä¸ªè¾ƒå°çš„ç©ºé—´åŒºåŸŸå†…ï¼Œå¦‚å›¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°†å¯¹æ¯”å­¦ä¹ ç»“åˆåˆ°finetuneè¿‡ç¨‹ï¼Œå€ŸåŠ©æ— æ ‡ç­¾æ•°æ®æ¥æå‡æ¨¡å‹çš„èƒ½åŠ›ã€‚ 2.åŸç†ç»™å®šä¸€ä¸ªç±»ä¼¼BERTçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹$\\textbf{M}$ï¼Œä»¥åŠä»ç›®æ ‡é¢†åŸŸæ•°æ®åˆ†å¸ƒä¸­æ”¶é›†çš„æ— æ ‡ç­¾æ–‡æœ¬è¯­æ–™åº“$\\mathcal{D}$ï¼Œæˆ‘ä»¬å¸Œæœ›é€šè¿‡æ„å»ºè‡ªç›‘ç£ä»»åŠ¡åœ¨$\\mathcal{D}$ä¸Šå¯¹$\\textbf{M}$è¿›è¡ŒFine-tuneï¼Œä½¿å¾—Fine-tuneåçš„æ¨¡å‹èƒ½å¤Ÿåœ¨ç›®æ ‡ä»»åŠ¡ï¼ˆæ–‡æœ¬è¯­ä¹‰åŒ¹é…ï¼‰ä¸Šè¡¨ç°æœ€å¥½ã€‚ 2.1 æ•´ä½“æ¡†æ¶ æ¨¡å‹æ•´ä½“ç»“æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œä¸»è¦ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆ A data augmentation module that generates different views for input samples at the token embedding layer. A shared BERT encoder that computes sentence representations for each input text. During training, we use the average pooling of the token embeddings at the last layer to obtain sentence representations. A contrastive loss layer on top of the BERT encoder. It maximizes the agreement between one representation and its corresponding version that is augmented from the same sentence while keeping it distant from other sentence representations in the same batch. å¯¹äºä»»æ„ä¸€ä¸ªå¥å­è¾“å…¥$x$ï¼Œå¾—åˆ°å…¶å¯¹åº”çš„ä¸¤ä¸ªå¢å¼ºå‘é‡$e_i=T_1(x),e_j=T_2(x),e_i,e_j\\in \\mathbb{R}^{L\\times d}$ï¼Œç„¶åç»è¿‡shared BERT encoderç¼–ç ä¸º$r_i,r_j$,å…¶ä¸­$T_1,T_2$ä¸ºä¸åŒçš„æ•°æ®å¢å¼ºæ–¹å¼ï¼Œ$L$ä¸ºå¥å­$x$çš„é•¿åº¦ï¼Œ$d$ä¸ºéšè—å•å…ƒçš„æ•°é‡ã€‚å¯¹äºæ¯ä¸ªtrain stepï¼Œä»$\\mathcal{D}$éšæœºé€‰å–$N$ä¸ªæ ·æœ¬ä½œä¸ºmini-batchï¼Œç„¶åå¾—åˆ°$2N$ä¸ªå¢å¼ºæ ·æœ¬ï¼Œä½¿ç”¨NT-Xentæ„é€ lossä¸º \\mathcal{L}_{i,j}=-log\\frac{exp(sim(r_i,r_j)/\\tau)}{\\sum_{k=1}^{2N} \\mathbb{1}_{[k\\neq i]}exp(sim(r_i,r_k)/\\tau)} \\\\\\mathcal{L}_{con}=\\frac{1}{2N}\\sum_{(i,j)}\\mathcal{L}_{i,j}å…¶ä¸­$sim(.)$ä¸ºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼Œ$\\tau$è¡¨ç¤ºtemperatureï¼Œæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå®éªŒä¸­å–0.1,$\\mathbb{1}$æ˜¯æŒ‡ç¤ºå™¨ï¼Œå½“$k=i$æ—¶ï¼Œå€¼ä¸º0ã€‚ä¸Šå¼åˆ†å­ä¸ºæ­£æ ·æœ¬ï¼Œåˆ†æ¯ä¸ºå…¨éƒ¨ï¼ˆä½†æ˜¯åŸºæœ¬ä¸ºè´Ÿæ ·æœ¬ï¼Œæ‰€ä»¥å¯ä»¥çœ‹æˆè´Ÿæ ·æœ¬ï¼‰ï¼Œæ‰€ä»¥losså˜å°å°±æ˜¯è®©åˆ†å­å˜å¤§ï¼Œåˆ†æ¯å˜å°ï¼Œä¹Ÿå°±æ˜¯è®©æ­£æ ·æœ¬ç›¸ä¼¼åº¦å˜å¤§ï¼Œè´Ÿæ ·æœ¬ç›¸ä¼¼åº¦å˜å° 2.2 æ•°æ®å¢å¼ºç­–ç•¥æ˜¾å¼ç”Ÿæˆå¢å¼ºæ ·æœ¬çš„æ–¹æ³•åŒ…æ‹¬ï¼šå›è¯‘ã€åŒä¹‰è¯æ›¿æ¢ã€æ„è¯‘ç­‰ï¼Œç„¶è€Œè¿™äº›æ–¹æ³•ä¸€æ–¹é¢ä¸ä¸€å®šèƒ½ä¿è¯è¯­ä¹‰ä¸€è‡´ã€‚æ‰€ä»¥è€ƒè™‘äº†åœ¨Embeddingå±‚éšå¼ç”Ÿæˆå¢å¼ºæ ·æœ¬çš„æ–¹æ³•ã€‚ å¯¹æŠ—æ”»å‡»ï¼ˆAdversarial Attackï¼‰ï¼šè¿™ä¸€æ–¹æ³•é€šè¿‡æ¢¯åº¦åä¼ ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ï¼Œå°†è¯¥æ‰°åŠ¨åŠ åˆ°åŸæœ¬çš„EmbeddingçŸ©é˜µä¸Šï¼Œå°±èƒ½å¾—åˆ°å¢å¼ºåçš„æ ·æœ¬ã€‚ç”±äºç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨éœ€è¦æ¢¯åº¦åä¼ ï¼Œå› æ­¤è¿™ä¸€æ•°æ®å¢å¼ºæ–¹æ³•ä»…é€‚ç”¨äºæœ‰ç›‘ç£è®­ç»ƒçš„åœºæ™¯ã€‚ æ‰“ä¹±è¯åºï¼ˆToken Shufflingï¼‰ï¼šè¿™ä¸€æ–¹æ³•æ‰°ä¹±è¾“å…¥æ ·æœ¬çš„è¯åºã€‚ç”±äºTransformerç»“æ„æ²¡æœ‰â€œä½ç½®â€çš„æ¦‚å¿µï¼Œæ¨¡å‹å¯¹Tokenä½ç½®çš„æ„ŸçŸ¥å…¨é Embeddingä¸­çš„Position Idså¾—åˆ°ã€‚å› æ­¤åœ¨å®ç°ä¸Šï¼Œæˆ‘ä»¬åªéœ€è¦å°†Position Idsè¿›è¡ŒShuffleå³å¯ã€‚ è£å‰ªï¼ˆCutoffï¼‰ ï¼šåˆå¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºä¸¤ç§ï¼š Token Cutoffï¼šéšæœºé€‰å–Tokenï¼Œå°†å¯¹åº”Tokençš„Embeddingæ•´è¡Œç½®ä¸ºé›¶ã€‚ Feature Cutoffï¼šéšæœºé€‰å–Embeddingçš„Featureï¼Œå°†é€‰å–çš„Featureç»´åº¦æ•´åˆ—ç½®ä¸ºé›¶ã€‚ Dropoutï¼šEmbeddingä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½ä»¥ä¸€å®šæ¦‚ç‡ç½®ä¸ºé›¶ï¼Œä¸Cutoffä¸åŒçš„æ˜¯ï¼Œè¯¥æ–¹æ³•å¹¶æ²¡æœ‰æŒ‰è¡Œæˆ–è€…æŒ‰åˆ—çš„çº¦æŸã€‚ 2.3 èåˆç›‘ç£ä¿¡å·é™¤äº†æ— ç›‘ç£è®­ç»ƒä»¥å¤–ï¼Œä½œè€…ç»™å‡º3ç§è¿›ä¸€æ­¥èåˆç›‘ç£ä¿¡å·çš„ç­–ç•¥ï¼Œä»¥NLIä»»åŠ¡ä¸ºä¾‹ï¼š f=Concat(r_1,r_2,|r_1-r_2|) \\\\\\mathcal{L}_{ce}=CrossEntropy(Wf+b,y)Joint training (joint): \\mathcal{L}_{joint}=\\mathcal{L}_{ce}+\\alpha\\mathcal{L}_{con}\\ \\# on\\ NLI \\ datasetSupervised training then unsupervised transfer (sup-unsup): first train the model with $\\mathcal{L}_{ce}$on NLI dataset, then use $\\mathcal{L}_{con}$to finetune it on the target dataset. Joint training then unsupervised transfer (joint-unsup): first train the model with the $\\mathcal{L}_{joint}$on NLI dataset, then use $\\mathcal{L}_{con }$to fine-tune it on the target dataset. 3.å®šæ€§åˆ†æååˆå‘ç°BERTå¥å‘é‡è¡¨ç¤ºçš„åç¼©å’Œå¥å­ä¸­çš„é«˜é¢‘è¯æœ‰å…³ã€‚å…·ä½“æ¥è¯´ï¼Œå½“é€šè¿‡å¹³å‡è¯å‘é‡çš„æ–¹å¼è®¡ç®—å¥å‘é‡æ—¶ï¼Œé‚£äº›é«˜é¢‘è¯çš„è¯å‘é‡å°†ä¼šä¸»å¯¼å¥å‘é‡ï¼Œä½¿ä¹‹éš¾ä»¥ä½“ç°å…¶åŸæœ¬çš„è¯­ä¹‰ã€‚å½“è®¡ç®—å¥å‘é‡æ—¶å»é™¤è‹¥å¹²é«˜é¢‘è¯æ—¶ï¼Œåç¼©ç°è±¡å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¾—åˆ°ç¼“è§£ï¼ˆå¦‚å›¾2è“è‰²æ›²çº¿æ‰€ç¤ºï¼‰ã€‚ 4 å®éªŒç»“æœ4.1 Unsupervised Results 4.2 Supervised Results","link":"/2021/08/27/consert/"},{"title":"ä½¿ç”¨DGLæ„é€ å›¾","text":"https://www.cnblogs.com/liyinggang/p/13360917.html https://zhuanlan.zhihu.com/p/406833147 https://blog.csdn.net/wufeil7/article/details/107106299","link":"/2022/01/11/construct-graph-dgl/"},{"title":"SparkSessionã€SparkContextã€HiveContextã€SQLContext","text":"https://blog.csdn.net/weixin_43648241/article/details/108917865 SparkSessionåŒ…å«SparkContext SparkContextåŒ…å«HiveContext HiveContextåŒ…å«SQLContext SparkSession &gt; SparkContext &gt; HiveContext &gt; SQLContext 12345678910111213141516171819SparkSession.builder.\\config(&quot;hive.metastore.uris&quot;, &quot;thrift://xxx.xx.x.xx:xxxx&quot;).\\config(&quot;spark.pyspark.python&quot;, &quot;/opt/dm_python3/bin/python&quot;).\\config('spark.default.parallelism ', 10 ).\\config('spark.sql.shuffle.partitions', 200 ).\\config(&quot;spark.driver.maxResultSize&quot;, &quot;16g&quot;).\\config(&quot;spark.port.maxRetries&quot;, &quot;100&quot;).\\config(&quot;spark.driver.memory&quot;,&quot;16g&quot;).\\config(&quot;spark.yarn.queue&quot;, &quot;dcp&quot; ).\\config(&quot;spark.executor.memory&quot;, &quot;16g&quot; ).\\config( &quot;spark.executor.cores&quot;, 20).\\config(&quot;spark.files&quot;, addfile).\\config( &quot;spark.executor.instances&quot;, 6 ).\\config(&quot;spark.speculation&quot;, False).\\config( &quot;spark.submit.pyFiles&quot;, zipfile).\\appName(&quot;testing&quot;).\\master(&quot;yarn&quot;).\\enableHiveSupport().\\getOrCreate()","link":"/2022/02/23/context/"},{"title":"Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting","text":"åŸæ–‡ï¼šhttps://arxiv.org/abs/1907.00235 ä½œè€…åˆ©ç”¨transformeråšæ—¶é—´åºåˆ—é¢„æµ‹ï¼Œå‘ç°äº†ä¸¤ä¸ªé—®é¢˜ï¼Œç„¶åæå‡ºäº†æ”¹è¿›ã€‚ä¸€ä¸ªé—®é¢˜æ˜¯locality-agnosticsï¼Œthe point-wise dot product self-attention in canonical Transformer architecture is insensitive to local contextã€‚å¦å¤–ä¸€ä¸ªé—®é¢˜æ˜¯memory bottleneck ï¼šspace complexity of canonical Transformer grows quadratically with sequence length L, making directly modeling long time series infeasible.ä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œä½œè€…æå‡ºäº†convolutional self-attentionå’ŒLogSparse Transformerã€‚ 3.èƒŒæ™¯é—®é¢˜å®šä¹‰ å…¶ä¸­$\\Phi$æ˜¯å‚æ•°ï¼Œ$\\textbf{X}$æ˜¯è¾…åŠ©è¾“å…¥ï¼Œå°±æ˜¯é™¤äº†è§‚æµ‹å€¼ä»¥å¤–çš„è¾“å…¥ï¼Œ$\\textbf{Z}_{i,t}$è¡¨ç¤ºåºåˆ—$i$åœ¨æ—¶åˆ»$t$çš„å€¼ ä¸ºäº†ç®€åŒ–å¼å­ï¼Œå®šä¹‰äº† ç›®æ ‡å°±å˜æˆäº†$\\textbf{z}_t \\sim f(\\textbf{Y}_t)$ Transformer $h$è¡¨ç¤ºæŸä¸ªå¤´ï¼Œ$M$è¡¨ç¤ºmask matrix 4.æ–¹æ³•è®º4.1 Enhancing the locality of Transformer æ”¹è¿›æ€æƒ³å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒåŸç‰ˆçš„transformerï¼Œåˆ©ç”¨äº†point-wiseä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä¸‡ä¸€å­˜åœ¨å¼‚å¸¸ç‚¹ï¼Œå°±ä¼šé€ æˆåå·®ã€‚æ”¹è¿›æ–¹å‘å°±æ˜¯å°†ç‚¹å’Œç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦å˜ä¸ºlocal context basedï¼Œä¹Ÿå°±æ˜¯å…ˆåˆ©ç”¨å·ç§¯å¾—åˆ°localçš„è¡¨ç¤ºï¼Œç„¶ååŸºäºlocalåšQå’ŒKçš„ç›¸ä¼¼åº¦ã€‚å½“å·ç§¯æ ¸çš„å°ºå¯¸ä¸º1å°±é€€åŒ–ä¸ºåŸç‰ˆçš„transformerã€‚ 4.2 Breaking the memory bottleneck of Transformer åŸæ¥çš„transformeréœ€è¦$O(L^2)$çš„ç©ºé—´å¤æ‚åº¦ï¼Œæ¯å±‚æ¯ä¸ªcellä¸º$O(L)$ï¼Œæ¯å±‚æ‰€æœ‰cellä¸º$O(L^2)$ï¼Œç„¶åå †å $h$å±‚ï¼Œ$h$ä¸ºå¸¸æ•°ï¼Œæ‰€ä»¥ä¸º$O(L^2)$ï¼Œå¦‚å›¾(a)ã€‚ä½œè€…æå‡ºäº†LogSparse Transformerï¼Œå¦‚å›¾ï¼ˆbï¼‰,ç©ºé—´å¤æ‚åº¦ä¸º$O(L(logL)^2)$ã€‚é¦–å…ˆæ¯å±‚æ¯ä¸€ä¸ªcelléœ€è¦$logL$ï¼Œæ¯å±‚æ‰€æœ‰cellå°±æ˜¯$LlogL$ï¼Œç„¶åå †å $logL$å±‚ï¼Œæœ€åä¸º$O(L(logL)^2)$ã€‚ å¯¹äºLogSparse Transformerï¼Œç­›é€‰è§„åˆ™ä¸ºï¼š å›¾ï¼ˆcï¼‰å’Œå›¾ï¼ˆdï¼‰æ˜¯å¯¹ï¼ˆbï¼‰çš„æ”¹è¿›ã€‚ 5.å®éªŒè¯„çº§æŒ‡æ ‡:p-quantile loss $R_p$ with $p\\in(0,1)$ å‚è€ƒhttps://zhuanlan.zhihu.com/p/412800154","link":"/2021/11/01/convtrans/"},{"title":"CRFå’ŒHMM","text":"å¤§ä½¬å†™çš„å¾ˆè¯¦ç»†ï¼ŒMarkä¸€ä¸‹ CRFhttps://www.cnblogs.com/pinard/p/7048333.html https://zhuanlan.zhihu.com/p/148813079# HMMhttps://www.cnblogs.com/pinard/p/6945257.html","link":"/2021/10/12/crf/"},{"title":"å¸¸è§é—®é¢˜","text":"CTRæ¨¡å‹ä¸ºä»€ä¹ˆæ™®éé‡‡ç”¨äºŒåˆ†ç±»å»ºæ¨¡è€Œä¸æ˜¯å›å½’å»ºæ¨¡ https://zhuanlan.zhihu.com/p/372110635 CTR é¢„ä¼°å’Œæ¨èç³»ç»Ÿæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿï¼Ÿï¼Ÿ https://blog.csdn.net/qiqi123i/article/details/105259351 CTR é¢„ä¼°å’Œæ’åºå­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿï¼Ÿï¼Ÿ CTRé¢„ä¼°æ¨¡å‹å±äºpoint-wiseæ¨¡å‹ https://www.zhihu.com/question/359973444#","link":"/2021/10/14/ctr/"},{"title":"Deep Match to Rank Model for Personalized Click-Through Rate Prediction","text":"1 è¾“å…¥ç‰¹å¾ç”±4ä¸ªéƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«ä¸ºUser Profile, User Behavior, Target Item and Contextï¼Œæ¯ä¸ªç‰¹å¾éƒ½åŒ…å«å­ç‰¹å¾ï¼Œæ¯”å¦‚User Profile contains user ID, consumption level and so onã€‚æœ€åˆçš„è¡¨ç¤ºä¸ºone-hotå½¢å¼ï¼Œç»è¿‡embeddingå±‚ï¼Œè½¬æˆé«˜çº¬å‘é‡ï¼Œé€šè¿‡æŸ¥æ‰¾è¡¨æ¥å®ç°ã€‚æœ€å4ä¸ªç‰¹å¾åˆ†åˆ«è¡¨ç¤ºä¸º$\\textbf{x}_p,\\textbf{x}_b,\\textbf{x}_t,\\textbf{x}_c$ï¼Œä»¥$\\textbf{x}_b$æ¥ä¸¾ä¾‹ï¼Œ$\\textbf{x}_b=[e_1ï¼Œe_2ï¼Œâ€¦ï¼Œe_T]\\in \\mathbb{R}^{T\\times d_e}$ 2 User-to-Item Networkwe apply attention mechanism with positional encoding as query to adaptively learn the weight for each behaviorï¼Œwhere the position of user behavior is the serial number in the behavior sequence ordered by occurred time å…¶ä¸­$\\textbf{z}\\in \\mathbb{R}^{d_h}$æ˜¯å­¦ä¹ çš„å‚æ•°ï¼Œ$\\textbf{p}_t\\in \\mathbb{P}^{d_p}$æ˜¯ä½ç½®$t$çš„embedding ä¸ºä»€ä¹ˆä¸ç”¨$\\textbf{x}_t$,è€Œç”¨$\\textbf{v}^{â€˜}$è¡¨ç¤ºTarget Itemã€‚ä½œè€…çš„æ„æ€æ˜¯å¯¹äºTarget Itemï¼Œæœ‰ä¸¤ä¸ªæŸ¥æ‰¾è¡¨ï¼Œwe call $\\textbf{V}$ the input representation and $\\textbf{V}^{â€˜}$ the output representation of Target Itemã€‚we apply inner product operation to represent the user-to-item relevance 3 Item-to-Item Network 4 finalAnd the final input of MLP is represented by $\\textbf{c}=[\\textbf{x}_p,\\textbf{x}_t,\\textbf{x}_c,\\hat{\\textbf{u}},r,\\hat{r}]$ 5 losstarget The loss for input feature vector $\\textbf{x}=[\\textbf{x}_p,\\textbf{x}_b,\\textbf{x}_t,\\textbf{x}_c]$ and click label $ y \\in \\{0, 1\\} $is: auxiliary match network ä¸»è¦æ˜¯æé«˜$r$å¯¹äºuser-to-item relevanceçš„è¡¨ç°èƒ½åŠ›è€Œå¼•å…¥ã€‚ The probability that user with the first $T âˆ’1$ behaviors click item $j$ next can be formulated with the softmax function as: å…¶ä¸­$\\textbf{v}^{â€˜}_j$è¡¨ç¤ºç¬¬$j$ä¸ªå•†å“çš„output representationã€‚With cross-entropy as loss function, we have the loss as follows: However, the cost of computing $p_j$ in Equation (6) is huge,å¼•å…¥è´Ÿé‡‡æ ·ï¼Œç„¶ålossä¸º final å‚è€ƒé˜¿é‡Œ2020å¹´å‘è¡¨åœ¨AAAIä¸Šçš„å…³äºCTRçš„paperï¼ŒåŸæ–‡é“¾æ¥ https://sci-hub.se/10.1609/aaai.v34i01.5346","link":"/2021/10/15/dMR/"},{"title":"DAG","text":"https://blog.csdn.net/qq_16669583/article/details/106026722 https://blog.csdn.net/u011564172/article/details/70172060 ä½œç”¨æ ¹æ®rddçš„ä¾èµ–å…³ç³»æ„å»ºdagï¼Œæ ¹æ®dagåˆ’åˆ†stage å•¥æ · 1ä¸ªaction=1ä¸ªjob=1ä¸ªdag è°ƒåº¦æµç¨‹","link":"/2022/01/05/dag/"},{"title":"æ•°æ®é‡‡é›†","text":"1 ç¦»çº¿ 1.ç”¨æˆ·è¡Œä¸ºæ•°æ®jar-ã€‹log-ã€‹flume-ã€‹kafka-ã€‹flume-ã€‹hdfs ç”¨æˆ·è¡Œä¸ºæ•°æ®å­˜å‚¨åœ¨æ—¥å¿—æœåŠ¡å™¨ï¼Œä»¥.logæ–‡ä»¶å­˜åœ¨ï¼Œlog-ã€‹flume-ã€‹kafka-ã€‹flume-ã€‹hdfs 2 ä¸šåŠ¡æ•°æ®jar-ã€‹mysql-ã€‹sqoop-ã€‹hdfs ä¸šåŠ¡æ•°æ®å­˜å‚¨åœ¨mysqlï¼Œä½¿ç”¨sqoopå¯¼å…¥hdfs 2 å®æ—¶ 1.ç”¨æˆ·è¡Œä¸ºæ•°æ®å‰ç«¯-ã€‹Nginx-ã€‹æ—¥å¿—æœåŠ¡å™¨-ã€‹ï¼‰logï¼ŒKafkaï¼ˆods 1 å‰ç«¯åŸ‹ç‚¹æ•°æ® é€šè¿‡jaråŒ…æ¨¡æ‹Ÿ 2 Nginx https://blog.csdn.net/qq_40036754/article/details/102463099 è´Ÿè½½å‡è¡¡ 3 æ—¥å¿—æœåŠ¡å™¨ spring bootæ­å»º é¦–å…ˆï¼ŒSpring å°±æ˜¯ä¸€ä¸ªjavaæ¡†æ¶ï¼Œspring bootåœ¨ Spring çš„åŸºç¡€ä¸Šæ¼”è¿› 4 è½ç›˜ï¼Œæ•´åˆ Kafka è½ç›˜æŒ‡çš„æ˜¯å­˜åœ¨æ—¥å¿—æœåŠ¡å™¨ ç”Ÿäº§è€…-ã€‹kafka-ã€‹æ¶ˆè´¹è€… â€‹ ç”Ÿäº§ æ¶ˆè´¹ 2 ä¸šåŠ¡æ•°æ®jar-ã€‹mysql-ã€‹flinkcdc-ã€‹kafkaï¼ˆodsï¼‰ ä¸èƒ½ä½¿ç”¨sqoopï¼Œå› ä¸ºsqoopåº•å±‚ä¸ºmapreduceï¼Œå¤ªæ…¢äº†ï¼Œæ”¹ç”¨canalï¼Œmaxwellæˆ–è€…flinkcdc æ•°æ®ä»mysqlè¯»åˆ°kafkaï¼Œä¸æ˜¯hdfs flink-cdc https://cloud.tencent.com/developer/article/1801766 Change Data Capture(å˜æ›´æ•°æ®è·å–ï¼‰","link":"/2022/02/13/data-collect/"},{"title":"æ•°æ®å­—å…¸","text":"https://www.cnblogs.com/arxive/p/9673830.html https://blog.panoply.io/how-to-create-a-data-dictionary https://www.secoda.co/blog/how-to-create-a-data-dictionary-a-step-by-step-guide","link":"/2022/02/10/data-dict/"},{"title":"æ•°æ®é›†æˆ","text":"https://zhuanlan.zhihu.com/p/269780713 https://help.aliyun.com/document_detail/137663.html å¼‚æ„æ•°æ®é›†æˆ","link":"/2022/04/23/data-ensemble/"},{"title":"æ•°æ®ä¸å¹³è¡¡å¦‚ä½•è§£å†³","text":"1.åŸºäºæ•°æ®a.è¿‡é‡‡æ ·å’Œæ¬ é‡‡æ · å¯¹å°‘æ•°æ•°æ®è¿›è¡Œæœ‰æ”¾å›çš„è¿‡é‡‡æ ·ï¼Œä½¿åŸæœ¬çš„æ•°æ®å˜çš„å‡è¡¡ï¼Œè¿™æ ·å°±æ˜¯å¯¹å°‘æ•°æ•°æ®è¿›è¡Œäº†å¤åˆ¶ï¼Œå®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆã€‚ å¯¹å¤šæ•°æ•°æ®è¿›è¡Œæœ‰æ”¾å›/æ— æ”¾å›çš„æ¬ é‡‡æ ·ï¼Œè¿™æ ·ä¼šä¸¢å¤±ä¸€äº›æ ·æœ¬ï¼ŒæŸå¤±ä¿¡æ¯ï¼Œæ¨¡å‹åªå­¦ä¼šæ•´ä½“æ¨¡å¼çš„ä¸€éƒ¨åˆ†ï¼Œå®¹æ˜“æ¬ æ‹Ÿåˆã€‚ b.SMOTEç®—æ³• c.æ•°æ®å¢å¼º é€šè¿‡äººä¸ºæˆ–ç®—æ³•å¢åŠ å°‘æ•°æ•°æ®çš„æ•°é‡ 2.åŸºäºlossä½¿ç”¨ä»£ä»·å‡½æ•°æ—¶ï¼Œå¯ä»¥å¢åŠ å°ç±»æ ·æœ¬çš„æƒå€¼ï¼Œé™ä½å¤§ç±»æ ·æœ¬çš„æƒå€¼ å‚è€ƒhttps://zhuanlan.zhihu.com/p/62877337 https://blog.csdn.net/asialee_bird/article/details/83714612","link":"/2021/09/04/data-imbalance/"},{"title":"æ•°æ®è´¨é‡","text":"The Challenges of Data Quality and Data Quality Assessment in the Big Data Era https://pdfs.semanticscholar.org/0fb3/7330a4170ec63d60eec7dbb2b86e6829a3de.pdf A Data Quality in Use model for Big Data Automating LargeScale Data Quality Verification Data Sets and Data Quality in Software Engineering Discovering Data Quality Rules Context-aware Data Quality Assessment for Big Data","link":"/2022/02/09/data-quality/"},{"title":"æ•°æ®å®‰å…¨","text":"åˆ†ä¸ºä¸¤æ­¥ï¼š â€‹ 1.ç”¨æˆ·è®¤è¯ â€‹ Kerberos â€‹ 2.æƒé™ç®¡ç† â€‹ ranger","link":"/2022/02/06/data-safety/"},{"title":"æ•°æ®é›†åˆ’åˆ†","text":"è®­ç»ƒ éªŒè¯: è°ƒå‚ æµ‹è¯•","link":"/2022/05/28/data-split/"},{"title":"æ•°æ®ç»“æ„æ±‡æ€»","text":"https://blog.csdn.net/m0_37568814/article/details/81288756 https://zhuanlan.zhihu.com/p/138523723 1 åˆ†ç±» æ•°æ®ç»“æ„åŒ…æ‹¬ï¼šé€»è¾‘ç»“æ„ï¼Œå­˜å‚¨ç»“æ„ï¼Œæ•°æ®è¿ç®— æ•°æ®çš„é€»è¾‘ç»“æ„ä¸»è¦åˆ†ä¸ºçº¿æ€§ç»“æ„å’Œéçº¿æ€§ç»“æ„ã€‚ çº¿æ€§ç»“æ„ï¼šæ•°æ®ç»“æ„çš„å…ƒç´ ä¹‹é—´å­˜åœ¨ä¸€å¯¹ä¸€çº¿æ€§å…³ç³»ï¼Œæ‰€æœ‰ç»“ç‚¹éƒ½æœ€å¤šåªæœ‰ä¸€ä¸ªç›´æ¥å‰è¶‹ç»“ç‚¹å’Œä¸€ä¸ªç›´æ¥åç»§ç»“ç‚¹ã€‚å¸¸è§çš„æœ‰æ•°ç»„ã€é˜Ÿåˆ—ã€é“¾è¡¨ã€æ ˆã€‚ éçº¿æ€§ç»“æ„ï¼šå„ä¸ªç»“ç‚¹ä¹‹é—´å…·æœ‰å¤šä¸ªå¯¹åº”å…³ç³»ï¼Œä¸€ä¸ªç»“ç‚¹å¯èƒ½æœ‰å¤šä¸ªç›´æ¥å‰è¶‹ç»“ç‚¹å’Œå¤šä¸ªç›´æ¥åç»§ç»“ç‚¹ã€‚å¸¸è§çš„æœ‰å¤šç»´æ•°ç»„ã€å¹¿ä¹‰è¡¨ã€æ ‘ç»“æ„å’Œå›¾ç»“æ„ç­‰ã€‚ æ•°æ®çš„ç‰©ç†ç»“æ„ï¼ˆä»¥åæˆ‘éƒ½ç»Ÿä¸€ç§°å­˜å‚¨ç»“æ„ï¼‰ï¼Œè¡¨ç¤ºæ•°æ®å…ƒç´ ä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼Œä¸€ç§æ•°æ®ç»“æ„çš„é€»è¾‘ç»“æ„æ ¹æ®éœ€è¦å¯ä»¥è¡¨ç¤ºæˆå¤šç§å­˜å‚¨ç»“æ„ï¼Œå¸¸ç”¨çš„å­˜å‚¨ç»“æ„æœ‰ï¼š é¡ºåºå­˜å‚¨ï¼šå­˜å‚¨é¡ºåºæ˜¯è¿ç»­çš„ï¼Œåœ¨å†…å­˜ä¸­ç”¨ä¸€ç»„åœ°å€è¿ç»­çš„å­˜å‚¨å•å…ƒä¾æ¬¡å­˜å‚¨çº¿æ€§è¡¨çš„å„ä¸ªæ•°æ®å…ƒç´ ã€‚ é“¾å¼å­˜å‚¨ï¼šåœ¨å†…å­˜ä¸­çš„å­˜å‚¨å…ƒç´ ä¸ä¸€å®šæ˜¯è¿ç»­çš„ï¼Œç”¨ä»»æ„åœ°å€çš„å­˜å‚¨å•å…ƒå­˜å‚¨å…ƒç´ ï¼Œå…ƒç´ èŠ‚ç‚¹å­˜æ”¾æ•°æ®å…ƒç´ ä»¥åŠé€šè¿‡æŒ‡é’ˆæŒ‡å‘ç›¸é‚»å…ƒç´ çš„åœ°å€ä¿¡æ¯ã€‚ ç´¢å¼•å­˜å‚¨ï¼šé™¤å»ºç«‹å­˜å‚¨ç»“ç‚¹ä¿¡æ¯å¤–ï¼Œè¿˜å»ºç«‹é™„åŠ çš„ç´¢å¼•è¡¨æ¥æ ‡è¯†èŠ‚ç‚¹çš„åœ°å€ã€‚ç´¢å¼•è¡¨ç”±è‹¥å¹²ç´¢å¼•é¡¹ç»„æˆã€‚ æ•£åˆ—å­˜å‚¨ï¼šåˆç§°Hashå­˜å‚¨ï¼Œç”±èŠ‚ç‚¹çš„å…³é”®ç å€¼å†³å®šèŠ‚ç‚¹çš„å­˜å‚¨åœ°å€ã€‚ 2 å¸¸ç”¨çš„æ•°æ®ç»“æ„ æ•°ç»„ï¼ˆArrayï¼‰ é˜Ÿåˆ—ï¼ˆQueueï¼‰ é“¾è¡¨ï¼ˆLinked Listï¼‰ æ ˆï¼ˆStackï¼‰ æ ‘ï¼ˆTreeï¼‰ æ•£åˆ—è¡¨ï¼ˆHashï¼‰ å †ï¼ˆHeapï¼‰ å›¾ï¼ˆGraphï¼‰","link":"/2022/05/01/data-struct/"},{"title":"æ•°æ®åŒæ­¥","text":"1.æ•°æ®åŒæ­¥ç­–ç•¥ 1 å…¨é‡å­˜å‚¨å®Œæ•´çš„æ•°æ®ã€‚ 2 å¢é‡å­˜å‚¨æ–°å¢åŠ çš„æ•°æ®ã€‚ 3 æ–°å¢åŠå˜åŒ–å­˜å‚¨æ–°å¢åŠ çš„æ•°æ®å’Œå˜åŒ–çš„æ•°æ®ã€‚ 4 ç‰¹æ®ŠæŸäº›ç‰¹æ®Šçš„è¡¨ï¼Œå¯ä¸å¿…éµå¾ªä¸Šè¿°åŒæ­¥ç­–ç•¥ã€‚ 1.ä¾‹å¦‚æŸäº›ä¸ä¼šå‘ç”Ÿå˜åŒ–çš„è¡¨ åœ°åŒºè¡¨ï¼Œçœä»½è¡¨ï¼Œæ°‘æ—è¡¨ç­‰ï¼Œå¯ä»¥åªå­˜ä¸€ä»½å›ºå®šå€¼ã€‚ 2.æ‹‰é“¾è¡¨ åœ¨ç¬¬ä¸€å¤©åŒæ­¥æ‹‰é“¾è¡¨çš„æ—¶å€™ï¼Œéœ€è¦åŒæ­¥å…¨é‡æ•°æ®ï¼Œå¹¶ä¸”è®¾ç½®endtime = 9999ï¼›é¦–æ—¥è¿‡åï¼Œæ¯æ—¥åŒæ­¥æ•°æ®åˆ°æ‹‰é“¾è¡¨ä¸­å°±æ˜¯æ–°å¢åŠå˜åŒ–çš„æ•°æ®ï¼Œå¯ä»¥é‡‡ç”¨åˆ†åŒºç­–ç•¥ï¼Œä»¥999ä¸ºä¸€ä¸ªåˆ†åŒºè¡¨ç¤ºæœ‰æ•ˆçš„æ•°æ®ï¼ŒåŠ ä¸Šä»¥è¿‡æœŸæ—¶é—´ä¸ºåˆ†åŒºï¼› 2.é¦–æ—¥ï¼Œæ¯æ—¥é¦–æ—¥åŒæ­¥ï¼Œè§†æƒ…å†µï¼Œä¸ä¸€å®šå…¨é‡ æ¯æ—¥åŒæ­¥ï¼Œè§†æƒ…å†µ","link":"/2022/02/09/data-synchronization/"},{"title":"æ•°æ®ä»“åº“ä¹¦å•","text":"https://www.douban.com/doulist/1202941/?start=0&amp;sort=seq&amp;playable=0&amp;sub_type=","link":"/2022/01/05/data-warehouse/"},{"title":"æ•°æ®åº“åˆ†ç±»","text":"å¸¸è§å…³ç³»å‹æ•°æ®åº“ï¼š Oracle MySql Microsoft SQL Server SQLite PostgreSQL IBM DB2 å¸¸è§çš„éå…³ç³»å‹æ•°æ®åº“ï¼š é”®å€¼æ•°æ®åº“ï¼šRedisã€Memcachedã€Riak åˆ—æ—æ•°æ®åº“ï¼šBigtableã€HBaseã€Cassandra æ–‡æ¡£æ•°æ®åº“ï¼šMongoDBã€CouchDBã€MarkLogic å›¾å½¢æ•°æ®åº“ï¼šNeo4jã€InfoGrid","link":"/2022/02/15/database-con/"},{"title":"æ•°æ®åº“å»ºæ¨¡","text":"https://blog.csdn.net/L_zhai/article/details/118650439 https://cloud.tencent.com/developer/article/1644918","link":"/2022/02/10/database-design/"},{"title":"åˆ†åº“åˆ†è¡¨","text":"https://www.zhihu.com/question/4487756131 https://zhuanlan.zhihu.com/p/137368446","link":"/2022/03/30/database-split-table-base/"},{"title":"datastream","text":"1 è½¬æ¢ç®—å­ Transformationfunctionåˆ†ç±»ï¼šæ™®é€šçš„ï¼Œrich æ€ä¹ˆå†™functionï¼š è‡ªå®šä¹‰ åŒ¿åç±» lambdaè¡¨è¾¾å¼ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.atguigu.chapter05;/** * Copyright (c) 2020-2030 å°šç¡…è°· All Rights Reserved * &lt;p&gt; * Project: FlinkTutorial * &lt;p&gt; * Created by wushengran */import org.apache.flink.api.common.functions.MapFunction;import org.apache.flink.api.common.typeinfo.Types;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.datastream.DataStreamSource;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;public class TransReturnTypeTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1); DataStreamSource&lt;Event&gt; clicks = env.fromElements( new Event(&quot;Mary&quot;, &quot;./home&quot;, 1000L), new Event(&quot;Bob&quot;, &quot;./cart&quot;, 2000L) ); // æƒ³è¦è½¬æ¢æˆäºŒå…ƒç»„ç±»å‹ï¼Œéœ€è¦è¿›è¡Œä»¥ä¸‹å¤„ç† // 1) ä½¿ç”¨æ˜¾å¼çš„ &quot;.returns(...)&quot; DataStream&lt;Tuple2&lt;String, Long&gt;&gt; stream3 = clicks .map( event -&gt; Tuple2.of(event.user, 1L) ) .returns(Types.TUPLE(Types.STRING, Types.LONG)); stream3.print(); // 2) ä½¿ç”¨ç±»æ¥æ›¿ä»£Lambdaè¡¨è¾¾å¼ clicks.map(new MyTuple2Mapper()) .print(); // 3) ä½¿ç”¨åŒ¿åç±»æ¥ä»£æ›¿Lambdaè¡¨è¾¾å¼ clicks.map(new MapFunction&lt;Event, Tuple2&lt;String, Long&gt;&gt;() { @Override public Tuple2&lt;String, Long&gt; map(Event value) throws Exception { return Tuple2.of(value.user, 1L); } }).print(); env.execute(); } // è‡ªå®šä¹‰MapFunctionçš„å®ç°ç±» public static class MyTuple2Mapper implements MapFunction&lt;Event, Tuple2&lt;String, Long&gt;&gt;{ @Override public Tuple2&lt;String, Long&gt; map(Event value) throws Exception { return Tuple2.of(value.user, 1L); } }} max maxby åŒºåˆ« 1234567891011121314151617181920212223242526272829303132DataStreamSource&lt;Event&gt; stream = env.fromElements( new Event(&quot;Mary&quot;, &quot;./home&quot;, 5000L), new Event(&quot;Bob&quot;, &quot;./cart&quot;, 2000L), new Event(&quot;Mary&quot;, &quot;./cart&quot;, 3000L), new Event(&quot;ss&quot;, &quot;./fav&quot;, 4000L), new Event(&quot;Mary&quot;, &quot;./fav&quot;, 10000L) ); stream.keyBy(e -&gt; e.user)// .maxBy(&quot;timestamp&quot;) .maxBy(&quot;timestamp&quot;) // æŒ‡å®šå­—æ®µåç§° .print(&quot;maxBy:&quot;); stream.keyBy(e -&gt; e.user)// .(&quot;timestamp&quot;) .max(&quot;timestamp&quot;) // æŒ‡å®šå­—æ®µåç§° .print(&quot;max:&quot;); max:&gt; Event{user='Mary', url='./home', timestamp=1970-01-01 08:00:05.0}maxBy:&gt; Event{user='Mary', url='./home', timestamp=1970-01-01 08:00:05.0}max:&gt; Event{user='Bob', url='./cart', timestamp=1970-01-01 08:00:02.0}maxBy:&gt; Event{user='Bob', url='./cart', timestamp=1970-01-01 08:00:02.0}max:&gt; Event{user='Mary', url='./home', timestamp=1970-01-01 08:00:05.0}max:&gt; Event{user='ss', url='./fav', timestamp=1970-01-01 08:00:04.0}maxBy:&gt; Event{user='Mary', url='./home', timestamp=1970-01-01 08:00:05.0}max:&gt; Event{user='Mary', url='./home', timestamp=1970-01-01 08:00:10.0}maxBy:&gt; Event{user='ss', url='./fav', timestamp=1970-01-01 08:00:04.0}maxBy:&gt; Event{user='Mary', url='./fav', timestamp=1970-01-01 08:00:10.0}maxéƒ¨åˆ†æ›¿æ¢ï¼Œmaxbyå…¨éƒ¨æ›¿æ¢ 2 çª—å£1 ç®€ä»‹ çª—å£[0-10ï¼‰ä¸­æœ‰11,12,ä½†æ˜¯11,12å¹¶ä¸åœ¨çª—å£[0-10ï¼‰å¤„ç†ï¼Œè€Œæ˜¯åœ¨å¯¹åº”çš„çª—å£[10,20)å¤„ç† 2 çª—å£çš„åˆ†ç±» æŒ‰ç…§é©±åŠ¨ç±»å‹åˆ†ç±» ï¼ˆ1ï¼‰æ—¶é—´çª—å£ Time Window ï¼ˆ2ï¼‰è®¡æ•°çª—å£ Count Window æŒ‰ç…§çª—å£åˆ†é…æ•°æ®çš„è§„åˆ™åˆ†ç±» ï¼ˆ1ï¼‰æ»šåŠ¨çª—å£ Tumbling Windows ï¼ˆ2ï¼‰æ»‘åŠ¨çª—å£ Sliding Windows ï¼ˆ3ï¼‰ä¼šè¯çª—å£ Session Windows ï¼ˆ4ï¼‰å…¨å±€çª—å£ Global Windows 3 ä½¿ç”¨ 4 è¿Ÿåˆ°æ•°æ®çš„å¤„ç† çª—å£ä¸­ çš„è¿Ÿåˆ°æ•°æ®é»˜è®¤ä¼šè¢«ä¸¢å¼ƒï¼Œè¿™å¯¼è‡´è®¡ç®—ç»“æœä¸å¤Ÿå‡†ç¡® 1 è®¾ç½®æ°´ä½çº¿å»¶è¿Ÿæ—¶é—´ 1234567assignTimestampsAndWatermarks(WatermarkStrategy.&lt;Event&gt;forBoundedOutOfOrderness(Duration.ofSeconds(2)) .withTimestampAssigner(new SerializableTimestampAssigner&lt;Event&gt;() { @Override public long extractTimestamp(Event element, long recordTimestamp) { return element.timestamp; } })); 2 å…è®¸çª—å£å¤„ç†è¿Ÿåˆ°æ•°æ® 1.allowedLateness(Time.minutes(1)) 3 å°†è¿Ÿåˆ°æ•°æ®æ”¾å…¥ä¾§è¾“å‡ºæµ æ”¶é›†å…³çª—ä¹‹åçš„è¿Ÿåˆ°æ•°æ®ï¼Œç„¶åæ‰‹åŠ¨å¤„ç† 1.sideOutputLateData(outputTag)","link":"/2022/04/24/datastream/"},{"title":"å¤§æ•°æ®å·¥å…·","text":"1 æ•°æ®åº“ç®¡ç†å·¥å…·Navicat ç ´è§£ https://cdmana.com/2022/114/202204240555321952.html DataGrip éœ€è¦ç”¨åˆ°JDBCåè®®è¿æ¥åˆ°Hiveï¼Œæ•…éœ€è¦å¯åŠ¨HiveServer2ã€‚ DataGrip ç‰ˆæ˜¯ç”±JetBrains å…¬å¸ï¼ˆå°±æ˜¯é‚£ä¸ªå‡ºå“Intellij IDEA çš„å…¬å¸ï¼‰æ¨å‡ºçš„æ•°æ®åº“ç®¡ç†è½¯ä»¶ã€‚ 2 æ•°æ®åº“è®¾è®¡å·¥å…·EZDML:æ¥è¾…åŠ©æˆ‘ä»¬æ¢³ç†å¤æ‚çš„ä¸šåŠ¡è¡¨å…³ç³»ï¼Œæ•ˆæœå¦‚ä¸‹","link":"/2022/02/01/datawarehouse-develop-tool/"},{"title":"æ•°ä»“åˆ†å±‚","text":"https://blog.csdn.net/BeiisBei/article/details/105723188#_19 https://www.saoniuhuo.com/article/detail-72.html https://www.dianjilingqu.com/20890.html https://www.i4k.xyz/article/wjt199866/115184169#ODS__100 1.ä¸ºä»€ä¹ˆè¦åˆ†å±‚1.æ¸…æ™°æ•°æ®ç»“æ„ï¼šæ¯ä¸€ä¸ªæ•°æ®åˆ†å±‚éƒ½æœ‰å®ƒçš„ä½œç”¨åŸŸï¼Œè¿™æ ·æˆ‘ä»¬åœ¨ä½¿ç”¨è¡¨çš„æ—¶å€™èƒ½æ›´æ–¹ä¾¿åœ°å®šä½å’Œç†è§£ã€‚2.æ•°æ®è¡€ç¼˜è¿½è¸ªï¼šç®€å•æ¥è®²å¯ä»¥è¿™æ ·ç†è§£ï¼Œæˆ‘ä»¬æœ€ç»ˆç»™ä¸šåŠ¡å‘ˆç°çš„æ˜¯ä¸€å¼ èƒ½ç›´æ¥ä½¿ç”¨çš„å¼ ä¸šåŠ¡è¡¨ï¼Œä½†æ˜¯å®ƒçš„æ¥æºæœ‰å¾ˆå¤šï¼Œå¦‚æœæœ‰ä¸€å¼ æ¥ æºè¡¨å‡ºé—®é¢˜äº†ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå¿«é€Ÿå‡†ç¡®åœ°å®šä½åˆ°é—®é¢˜ï¼Œå¹¶æ¸…æ¥šå®ƒçš„å±å®³èŒƒå›´ã€‚3.å‡å°‘é‡å¤å¼€å‘ï¼šè§„èŒƒæ•°æ®åˆ†å±‚ï¼Œå¼€å‘ä¸€äº›é€šç”¨çš„ä¸­é—´å±‚æ•°æ®ï¼Œèƒ½å¤Ÿå‡å°‘æå¤§çš„é‡å¤è®¡ç®—ã€‚4.æŠŠå¤æ‚é—®é¢˜ç®€å•åŒ–ï¼šå°†ä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡åˆ†è§£æˆå¤šä¸ªæ­¥éª¤æ¥å®Œæˆï¼Œæ¯ä¸€å±‚åªå¤„ç†å•ä¸€çš„æ­¥éª¤ï¼Œæ¯”è¾ƒç®€å•å’Œå®¹æ˜“ç†è§£ã€‚è€Œä¸”ä¾¿äºç»´æŠ¤æ•°æ®çš„å‡†ç¡®æ€§ï¼Œå½“æ•°æ®å‡ºç°é—®é¢˜ä¹‹åï¼Œå¯ä»¥ä¸ç”¨ä¿®å¤æ‰€æœ‰çš„æ•°æ®ï¼Œåªéœ€è¦ä»æœ‰é—®é¢˜çš„æ­¥éª¤å¼€å§‹ä¿®å¤ã€‚5.å±è”½åŸå§‹æ•°æ®çš„å¼‚å¸¸ï¼šå±è”½ä¸šåŠ¡çš„å½±å“ï¼Œä¸å¿…æ”¹ä¸€æ¬¡ä¸šåŠ¡å°±éœ€è¦é‡æ–°æ¥å…¥æ•°æ®ã€‚ 2.åˆ†å±‚ç»“æ„ 2.1 ODSå±‚ä½œç”¨ https://blog.csdn.net/xuebo_911/article/details/8156016# èµ·åˆ°å¤‡ä»½æ•°æ®çš„ä½œç”¨ æ„å»º 1 ç›´æ¥åŠ è½½åŸå§‹æ—¥å¿—ã€æ•°æ®ï¼Œä¿æŒåŸè²Œä¸åšå¤„ç† 2.2 DIMå±‚dimå­˜æ”¾ç»´åº¦è¡¨ï¼Œdwdå­˜æ”¾äº‹å®è¡¨ ä½œç”¨ ç»´åº¦è¡¨å¯ä»¥çœ‹ä½œæ˜¯ç”¨æˆ·æ¥åˆ†ææ•°æ®çš„çª—å£ï¼Œç»´åº¦è¡¨ä¸­åŒ…å«äº‹å®æ•°æ®è¡¨ä¸­äº‹å®è®°å½•çš„ç‰¹æ€§ï¼Œæœ‰äº›ç‰¹æ€§æä¾›æè¿°æ€§ä¿¡æ¯ï¼Œæœ‰äº›ç‰¹æ€§æŒ‡å®šå¦‚ä½•æ±‡æ€»äº‹å®æ•°æ®è¡¨æ•°æ®ï¼Œä»¥ä¾¿ä¸ºåˆ†æè€…æä¾›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œç»´åº¦è¡¨åŒ…å«å¸®åŠ©æ±‡æ€»æ•°æ®çš„ç‰¹æ€§çš„å±‚æ¬¡ç»“æ„ã€‚ æ„å»º https://help.aliyun.com/document_detail/137615.html 1 æ„å»ºç»´åº¦è¡¨ï¼Œä¸»è¦æ˜¯å¯¹ä¸šåŠ¡äº‹å®çš„æè¿°ä¿¡æ¯ï¼Œä¾‹å¦‚ä½•äººï¼Œä½•æ—¶ï¼Œä½•åœ°ç­‰ 2.3 DWDå±‚ä½œç”¨ ä¿å­˜ä¸šåŠ¡äº‹å®æ˜ç»†ï¼Œä¸€è¡Œä¿¡æ¯ä»£è¡¨ä¸€æ¬¡ä¸šåŠ¡è¡Œä¸ºï¼Œä¾‹å¦‚ä¸€æ¬¡ä¸‹å•ã€‚ æ„å»º 1 å¯¹ODSå±‚æ•°æ®è¿›è¡Œæ¸…æ´—ï¼ˆå»é™¤ç©ºå€¼ï¼Œè„æ•°æ®ï¼Œè¶…è¿‡æé™èŒƒå›´çš„æ•°æ®ã€è„±æ•ç­‰ï¼‰ 2 æ„å»ºäº‹å®è¡¨ https://help.aliyun.com/document_detail/114457.html 2.4 DWSä½œç”¨ é¿å…é‡å¤è®¡ç®— 1ï¼‰é—®é¢˜å¼•å‡º ä¸¤ä¸ªéœ€æ±‚ï¼Œç»Ÿè®¡æ¯ä¸ªçœä»½è®¢å•çš„ä¸ªæ•°ã€ç»Ÿè®¡æ¯ä¸ªçœä»½è®¢å•çš„æ€»é‡‘é¢ï¼Œéƒ½æ˜¯å°†çœä»½è¡¨å’Œè®¢å•è¡¨è¿›è¡Œjoinï¼Œgroup byçœä»½ï¼Œç„¶åè®¡ç®—ã€‚åŒæ ·æ•°æ®è¢«è®¡ç®—äº†ä¸¤æ¬¡ï¼Œå®é™…ä¸Šç±»ä¼¼çš„åœºæ™¯è¿˜ä¼šæ›´å¤šã€‚ 2ï¼‰ é‚£æ€ä¹ˆè®¾è®¡èƒ½é¿å…é‡å¤è®¡ç®—å‘¢ï¼Ÿ é’ˆå¯¹ä¸Šè¿°åœºæ™¯ï¼Œå¯ä»¥è®¾è®¡ä¸€å¼ åœ°åŒºå®½è¡¨ï¼Œå…¶ä¸»é”®ä¸ºåœ°åŒºIDï¼Œå­—æ®µåŒ…å«ä¸ºï¼šä¸‹å•æ¬¡æ•°ã€ä¸‹å•é‡‘é¢ã€æ”¯ä»˜æ¬¡æ•°ã€æ”¯ä»˜é‡‘é¢ç­‰ã€‚ä¸Šè¿°æ‰€æœ‰æŒ‡æ ‡éƒ½ç»Ÿä¸€è¿›è¡Œè®¡ç®—ï¼Œå¹¶å°†ç»“æœä¿å­˜åœ¨è¯¥å®½è¡¨ä¸­ï¼Œè¿™æ ·å°±èƒ½æœ‰æ•ˆé¿å…æ•°æ®çš„é‡å¤è®¡ç®—ã€‚ æ„å»º https://help.aliyun.com/document_detail/126913.html 0 åˆ†ä¸»é¢˜ 1 æ„å»ºå®½è¡¨ 2 ä»¥DWDä¸ºåŸºç¡€ï¼ŒæŒ‰å¤©è¿›è¡Œè½»åº¦æ±‡æ€»ã€‚DWSå±‚å­˜æ”¾çš„æ‰€æœ‰ä¸»é¢˜å¯¹è±¡å½“å¤©çš„æ±‡æ€»è¡Œä¸ºï¼Œä¾‹å¦‚æ¯ä¸ªåœ°åŒºå½“å¤©çš„ä¸‹å•æ¬¡æ•°ï¼Œä¸‹å•é‡‘é¢ç­‰ 2.5 DWTå’ŒDWSåŒºåˆ« DWSæŒ‰å¤©è¿›è¡Œè½»åº¦æ±‡æ€»ï¼ŒDWTç´¯ç§¯æ±‡æ€» ä½œç”¨ é¿å…é‡å¤è®¡ç®— æ„å»º 0 åˆ†ä¸»é¢˜ 1 æ„å»ºå®½è¡¨ 2 ä»¥DWSä¸ºåŸºç¡€ï¼Œå¯¹æ•°æ®è¿›è¡Œç´¯ç§¯æ±‡æ€»ã€‚DWTå±‚å­˜æ”¾çš„æ˜¯æ‰€æœ‰ä¸»é¢˜å¯¹è±¡çš„ç´¯ç§¯è¡Œä¸ºï¼Œä¾‹å¦‚æ¯ä¸ªåœ°åŒºæœ€è¿‘ï¼—å¤©ï¼ˆï¼‘ï¼•å¤©ã€ï¼“ï¼å¤©ã€ï¼–ï¼å¤©ï¼‰çš„ä¸‹å•æ¬¡æ•°ã€ä¸‹å•é‡‘é¢ç­‰ 2.6 ADSå±‚ä½œç”¨ ä¸ºå„ç§ç»Ÿè®¡æŠ¥è¡¨æä¾›æ•°æ® æ„å»º 1 ç”±äºè¿™å±‚çš„æ•°æ®é‡ä¸å¤§ï¼Œæ‰€æœ‰æ²¡æœ‰åˆ†åŒºï¼Œåˆ—å¼å­˜å‚¨ï¼Œå‹ç¼© 3.æ„å»ºè¿‡ç¨‹å€ŸåŠ©hiveï¼Œä¸»è¦å°±æ˜¯å†™SQLï¼Œæ ¸å¿ƒæ­¥éª¤å°±æ˜¯ï¼š 1.å»ºè¡¨ 2.åˆ†åŒºè§„åˆ’ â€‹ æŒ‰ä»€ä¹ˆåˆ†åŒºï¼Œæ¯”å¦‚è¯´æŒ‰å¤©ï¼ŒæŒ‰æœˆ â€‹ æ³¨æ„æ•°æ®åŒæ­¥ç­–ç•¥ï¼Œå…¨é‡ï¼Œå¢é‡ç­‰ 3.æ•°æ®è£…è½½ â€‹ æ³¨æ„é¦–æ—¥ï¼Œæ¯æ—¥ è”ç³»ä¸šåŠ¡å’Œä¸åŒå±‚çš„è¦æ±‚ 4.å…¨æµç¨‹è°ƒåº¦Azkaban","link":"/2022/01/13/datawarehouse-multi-layer/"},{"title":"æ•°ä»“æ¶æ„","text":"æ•°ä»“æ¶æ„ https://notomato.blog.csdn.net/article/details/110790403 ç¦»çº¿æ•°æ®ä»“åº“åˆ°å®æ—¶æ•°æ®ä»“åº“ https://blog.csdn.net/fuyipingwml1976124/article/details/105571193","link":"/2022/01/20/datawarehouse-struct/"},{"title":"æ•°ä»“ä¸»é¢˜å’Œä¸»é¢˜åŸŸ","text":"https://blog.csdn.net/qq_22473611/article/details/116702667 1 ä¸»é¢˜åŸŸã€ä¸»é¢˜ã€å®ä½“çš„å…³ç³» ä¸»é¢˜åŸŸä¸‹é¢å¯ä»¥æœ‰å¤šä¸ªä¸»é¢˜ï¼Œä¸»é¢˜è¿˜å¯ä»¥åˆ’åˆ†æˆæ›´å¤šçš„å­ä¸»é¢˜ï¼Œä¸»é¢˜å’Œä¸»é¢˜ä¹‹é—´çš„å»ºè®¾å¯èƒ½ä¼šæœ‰äº¤å‰ç°è±¡ï¼Œè€Œå®ä½“åˆ™æ˜¯ä¸å¯åˆ’åˆ†çš„æœ€å°å•ä½ 2 ä¸»é¢˜åŸŸåˆ’åˆ†1 æŒ‰ç…§ä¸šåŠ¡ç³»ç»Ÿåˆ’åˆ† 2 æŒ‰ç…§ä¸šåŠ¡è¿‡ç¨‹åˆ’åˆ† 3 æŒ‰ç…§éƒ¨é—¨åˆ’åˆ†","link":"/2022/04/02/datawarehouse-subject/"},{"title":"æ—¶é—´åºåˆ—é¢„æµ‹æ»åç°è±¡","text":"https://www.dazhuanlan.com/bb_principessa/topics/1021683","link":"/2021/11/01/decay-time-series/"},{"title":"å†³ç­–æ ‘vsé€»è¾‘å›å½’","text":"æœ€å¤§çš„å·®å¼‚ä¸Šå›¾å°±å¯ä»¥çœ‹å‡ºï¼Œå·¦è¾¹ä¸ºé€»è¾‘å›å½’çš„å†³ç­–é¢ï¼Œå³è¾¹ä¸ºå†³ç­–æ ‘çš„å†³ç­–é¢ å‚è€ƒhttps://www.zhihu.com/question/319481283","link":"/2021/10/10/deci-tree-LR/"},{"title":"å†³ç­–æ ‘","text":"ä¸¤å¹…å›¾æ„æ€ä¸€æ · 1.æ„å»ºç®—æ³•å¸¸è§æ–¹æ³•çš„æœ‰ID3ï¼ŒC4.5ï¼ŒCARTï¼Œæ€»ç»“å¦‚ä¸‹ 1.1 ID3å‡è®¾è®­ç»ƒæ•°æ®é›†ä¸º $D$,âˆ£$Dâˆ£$è¡¨ç¤ºå…¶å¤§å°ã€‚è®¾æœ‰$K$ä¸ªåˆ†ç±»$ C_1,C_2,â€¦,C_K$ã€‚è®¾ç‰¹å¾é›†ä¸º$\\textbf{A}$,å‡è®¾æŸä¸ªç‰¹å¾$ A$ æœ‰$ n$ ä¸ªä¸åŒçš„å–å€¼ $\\{a_1,a_2,â€¦,a_n\\}$,æ ¹æ®ç‰¹å¾$A$çš„å–å€¼å°† $D$ åˆ’åˆ†æˆ$n$ä¸ªå­é›†ã€‚è®°å­é›† $D_i$ä¸­å±äºç±»$ C_k$çš„æ ·æœ¬é›†åˆä¸º $D_{ik}$ã€‚ æ•°æ®é›†$D$çš„ç»éªŒç†µ$H(D)$: H(D) = - \\sum_{j=1}^K \\frac {|C_j|}{|D|} \\log \\frac {|C_j|}{|D|}ç‰¹å¾$A$å¯¹æ•°æ®é›†$ D$çš„ç»éªŒæ¡ä»¶ç†µ$H(D|A)$ % ä¿¡æ¯å¢ç›Š$g(D,A)$ g(D,A)=H(D)-H(D|A)ç®—æ³•æµç¨‹: è‹¥$D$ä¸­æ‰€æœ‰å®ä¾‹éƒ½å±äºåŒä¸€ç±» $C_k$,åˆ™ $T$ ä¸ºå•èŠ‚ç‚¹æ ‘,å¹¶å°†ç±» $C_k$ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°,è¿”å›$T$. è‹¥$\\textbf{A}=\\phi$,åˆ™$T$ä¸ºå•èŠ‚ç‚¹æ ‘,å¹¶å°†$D$ä¸­å®ä¾‹æœ€å¤§çš„ç±»$C_k$ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°,è¿”å›$T$. å¦åˆ™,æŒ‰ç…§ä¿¡æ¯å¢ç›Šçš„ç®—æ³•,è®¡ç®—æ¯ä¸ªç‰¹å¾å¯¹$D$çš„ä¿¡æ¯å¢ç›Š,å–ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ $A_g$. å¦‚æœ$A_g&lt; \\varepsilon$,åˆ™ç½® $T$ä¸ºå•èŠ‚ç‚¹æ ‘,å¹¶å°†$D$ä¸­å®ä¾‹æœ€å¤§çš„ç±»$C_k$ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°,è¿”å›$T$. å¦åˆ™,å¯¹$A_g$çš„æ¯ä¸€å¯èƒ½å€¼ $a_i$,ä¾$A_g=a_i$å°†$D$åˆ†æˆè‹¥å¹²éç©ºå­é›†$D_i$ ä»¥$D_i$ä¸ºè®­ç»ƒé›†,ä»¥$\\textbf{A}- A_g $ä¸ºç‰¹å¾é›†,é€’å½’åœ°è°ƒç”¨æ­¥éª¤1åˆ°æ­¥éª¤5,å¾—åˆ°å­æ ‘ $T_i$,å…¨éƒ¨ $T_i$æ„æˆ$T$,è¿”å›$T$. 1.2 C4.5 C4.5ç®—æ³•æµç¨‹ä¸ID3ç›¸ç±»ä¼¼ï¼Œåªä¸è¿‡å°†ä¿¡æ¯å¢ç›Šæ”¹ä¸ºä¿¡æ¯å¢ç›Šæ¯”ï¼Œä»¥è§£å†³åå‘å–å€¼è¾ƒå¤šçš„å±æ€§çš„é—®é¢˜ï¼Œå¦å¤–å®ƒå¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ã€‚ åˆ†è£‚ä¿¡æ¯ $SplitInformation(D,A)$ SplitInformation(D,A) = -\\sum_{i=1}^n \\frac {|D_i|}{|D|} \\log \\frac {|D_i|}{|D|}ä¿¡æ¯å¢ç›Šæ¯” $GainRatio(D, A)$ GainRatio(D, A) = \\frac {g(D, A)} {SplitInformation(D, A)}1.3 CART1.3.1 CARTåˆ†ç±»æ ‘CARTåˆ†ç±»æ ‘ç®—æ³•ä½¿ç”¨åŸºå°¼ç³»æ•°æ¥ä»£æ›¿ä¿¡æ¯å¢ç›Šï¼ˆæ¯”ï¼‰ï¼ŒåŸºå°¼ç³»æ•°ä»£è¡¨äº†æ¨¡å‹çš„ä¸çº¯åº¦ï¼ŒåŸºå°¼ç³»æ•°è¶Šå°ï¼Œä¸çº¯åº¦è¶Šä½ï¼Œç‰¹å¾è¶Šå¥½ã€‚è¿™å’Œä¿¡æ¯å¢ç›Šï¼ˆæ¯”ï¼‰ç›¸åã€‚ å¯¹äºæ ·æœ¬$D$ï¼Œä¸ªæ•°ä¸º$|D|$ï¼Œå‡è®¾$K$ä¸ªç±»åˆ«ï¼Œç¬¬$k$ä¸ªç±»åˆ«çš„æ•°é‡ä¸º$|C_k|$ï¼Œåˆ™æ ·æœ¬$D$çš„åŸºå°¼ç³»æ•°è¡¨è¾¾å¼ï¼š Gini(D)=1-\\sum_{k=1}^{K}(\\frac{|C_k|}{|D|})^2å¯¹äºæ ·æœ¬$D$ï¼Œä¸ªæ•°ä¸º$|D|$ï¼Œæ ¹æ®ç‰¹å¾$A$çš„æŸä¸ªå€¼$a$ï¼ŒæŠŠ$D$åˆ†æˆ$|D_1|$å’Œ$|D_2|$ï¼Œåˆ™åœ¨ç‰¹å¾$A=a$çš„æ¡ä»¶ä¸‹ï¼Œæ ·æœ¬$D$çš„åŸºå°¼ç³»æ•°è¡¨è¾¾å¼ä¸ºï¼š Gini(D,A)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)ç®—æ³•æµç¨‹ï¼šç®—æ³•è¾“å…¥è®­ç»ƒé›†$D$ï¼ŒåŸºå°¼ç³»æ•°çš„é˜ˆå€¼ï¼Œæ ·æœ¬ä¸ªæ•°é˜ˆå€¼ã€‚è¾“å‡ºçš„æ˜¯å†³ç­–æ ‘$T$ã€‚ (1)ã€å¯¹äºå½“å‰èŠ‚ç‚¹çš„æ•°æ®é›†ä¸º$D$ï¼Œå¦‚æœæ ·æœ¬ä¸ªæ•°å°äºé˜ˆå€¼æˆ–æ²¡æœ‰ç‰¹å¾ï¼Œåˆ™å½“å‰èŠ‚ç‚¹åœæ­¢é€’å½’ï¼Œè¿”å›å†³ç­–æ ‘ã€‚ (2)ã€è®¡ç®—æ ·æœ¬é›†$D$çš„åŸºå°¼ç³»æ•°ï¼Œå¦‚æœåŸºå°¼ç³»æ•°å°äºé˜ˆå€¼ï¼Œåˆ™å½“å‰èŠ‚ç‚¹åœæ­¢é€’å½’ï¼Œè¿”å›å†³ç­–æ ‘ã€‚ (3)ã€è®¡ç®—å½“å‰èŠ‚ç‚¹æ‰€æœ‰ç‰¹å¾çš„å„ä¸ªç‰¹å¾å€¼å¯¹æ•°æ®é›†$D$çš„åŸºå°¼ç³»æ•° (4)ã€åœ¨è®¡ç®—å‡ºæ¥çš„æ‰€æœ‰åŸºå°¼ç³»æ•°ä¸­ï¼Œé€‰æ‹©åŸºå°¼ç³»æ•°æœ€å°çš„ç‰¹å¾$A$å’Œå¯¹åº”çš„ç‰¹å¾å€¼$a$ï¼Œå¹¶æŠŠæ•°æ®é›†åˆ’åˆ†æˆä¸¤éƒ¨åˆ†$D_1$å’Œ$D_2$ï¼ŒåŒæ—¶å»ºç«‹å½“å‰èŠ‚ç‚¹çš„å·¦å³èŠ‚ç‚¹ï¼Œå·¦èŠ‚ç‚¹çš„æ•°æ®é›†$D$ä¸º$D_1$ï¼Œå³èŠ‚ç‚¹çš„æ•°æ®é›†$D$ä¸º$D_2$ã€‚ (5)ã€å¯¹å·¦å³çš„å­èŠ‚ç‚¹é€’å½’çš„è°ƒç”¨1-4æ­¥ï¼Œç”Ÿæˆå†³ç­–æ ‘ã€‚ 1.3.2 CARTå›å½’æ ‘å¯¹å›å½’æ ‘ç”¨å¹³æ–¹è¯¯å·®æœ€å°åŒ–å‡†åˆ™ ç®—æ³•æµç¨‹ï¼šè¾“å…¥ä¸ºè®­ç»ƒæ•°æ®$D$ï¼Œè¾“å‡ºä¸ºå›å½’æ ‘$f(x)$ (1) é€‰æ‹©æœ€ä¼˜çš„åˆ‡åˆ†å˜é‡$j$å’Œåˆ‡åˆ†ç‚¹$s$ï¼Œéå†$j$ï¼Œå¯¹å›ºå®šçš„$j$éå†$s$ï¼Œæ±‚è§£ \\min \\limits_{j,s} \\ [\\min \\limits_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2+\\min \\limits_{c_2}\\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2](2) ç”¨é€‰å®šçš„$(j,s)$åˆ’åˆ†åŒºåŸŸå¹¶å†³å®šè¾“å‡ºå€¼ R_1(j,s)=\\{x|x^{(j)}\\le s\\},R_2(j,s)=\\{x|x^{(j)}> s\\} \\\\\\hat{c}_m=\\frac{1}{N_m}\\sum_{x_i\\in R_m(j,s)}y_i,m=1,2(3) ç»§ç»­å¯¹ä¸¤ä¸ªå­åŒºåŸŸè°ƒç”¨æ­¥éª¤ï¼ˆ1ï¼‰ï¼ˆ2ï¼‰ï¼Œç›´è‡³æ»¡è¶³åœæ­¢æ¡ä»¶ (4) å°†è¾“å…¥ç©ºé—´åˆ’åˆ†æˆ$M$ä¸ªåŒºåŸŸ$R_1,R_2,â€¦,R_M$ï¼Œç”Ÿæˆå›å½’æ ‘ f(x)=\\sum_{m=1}^{M}\\hat{c}_mI(x\\in R_m)1.4 å¤šå˜é‡å†³ç­–æ ‘æ— è®ºID3ï¼ŒC4.5ï¼ŒCARTéƒ½æ˜¯é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„ç‰¹å¾åšåˆ†ç±»å†³ç­–ï¼Œä½†å¤§å¤šæ•°ï¼Œåˆ†ç±»å†³ç­–ä¸æ˜¯ç”±æŸä¸€ä¸ªç‰¹å¾å†³å®šï¼Œè€Œæ˜¯ä¸€ç»„ç‰¹å¾ã€‚è¿™æ ·å¾—åˆ°çš„å†³ç­–æ ‘æ›´åŠ å‡†ç¡®ï¼Œè¿™ç§å†³ç­–æ ‘å«å¤šå˜é‡å†³ç­–æ ‘(multi-variate decision tree)ã€‚åœ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾çš„æ—¶ï¼Œå¤šå˜é‡å†³ç­–æ ‘ä¸æ˜¯é€‰æ‹©æŸä¸€ä¸ªæœ€ä¼˜ç‰¹å¾ï¼Œè€Œæ˜¯é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„ç‰¹å¾çº¿æ€§ç»„åˆåšå†³ç­–ã€‚ ä»£è¡¨ç®—æ³•OC1ã€‚ 2.å‰ªæå‰ªæ(pruning)æ˜¯è§£å†³å†³ç­–æ ‘è¿‡æ‹Ÿåˆçš„ä¸»è¦æ‰‹æ®µï¼Œé€šè¿‡å‰ªæå¯ä»¥å¤§å¤§æå‡å†³ç­–æ ‘çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šå¸¸ï¼Œå‰ªæå¤„ç†å¯åˆ†ä¸ºï¼šé¢„å‰ªæï¼Œåå‰ªæã€‚ é¢„å‰ªæï¼šé€šè¿‡å¯å‘å¼æ–¹æ³•ï¼Œåœ¨ç”Ÿæˆå†³ç­–æ ‘è¿‡ç¨‹ä¸­å¯¹åˆ’åˆ†è¿›è¡Œè€ƒå¯Ÿï¼Œè‹¥å½“å‰ç»“ç‚¹çš„åˆ’åˆ†å½±å“å†³ç­–æ ‘çš„æ³›åŒ–æ€§èƒ½ï¼Œåˆ™åœæ­¢åˆ’åˆ†ï¼Œå¹¶å°†å…¶æ ‡è®°ä¸ºå¶èŠ‚ç‚¹ åå‰ªæï¼šå¯¹å·²æœ‰çš„å†³ç­–æ ‘ï¼Œè‡ªåº•å‘ä¸Šçš„å¯¹éå¶ç»“ç‚¹è¿›è¡Œè€ƒå¯Ÿï¼Œè‹¥è¯¥ç»“ç‚¹å¯¹åº”çš„å­æ ‘æ›¿æ¢ä¸ºå¶ç»“ç‚¹èƒ½æå‡å†³ç­–æ ‘çš„æ³›åŒ–èƒ½åŠ›ï¼Œåˆ™å°†æ”¹å­æ ‘æ›¿æ¢ä¸ºå¶ç»“ç‚¹ å‚è€ƒhttps://zhuanlan.zhihu.com/p/89607509 https://www.cnblogs.com/wxquare/p/5379970.html https://blog.csdn.net/qq_43468807/article/details/105969232 http://leijun00.github.io/2014/09/decision-tree/ https://zhuanlan.zhihu.com/p/89607509 https://www.cnblogs.com/wxquare/p/5379970.html https://blog.csdn.net/qq_43468807/article/details/105969232 http://leijun00.github.io/2014/09/decision-tree/ https://www.cnblogs.com/wqbin/p/11689709.html https://www.cnblogs.com/keye/p/10564914.html https://www.cnblogs.com/keye/p/10601501.html https://cloud.tencent.com/developer/article/1486712 https://blog.csdn.net/weixin_44132485/article/details/106502422","link":"/2021/09/23/decison-tree/"},{"title":"è£…é¥°å™¨","text":"è£…é¥°å™¨@ æœ¬è´¨æ˜¯é—­åŒ… https://www.runoob.com/w3cnote/python-func-decorators.html 1234567891011121314151617181920212223242526272829303132333435363738394041421.æœ¬è´¨###è£…é¥°çš„å‡½æ•°ï¼Œæœ¬è´¨æ˜¯é—­åŒ…def a_new_decorator(a_func): def wrapTheFunction(): print(&quot;I am doing some boring work before executing a_func()&quot;) a_func() print(&quot;I am doing some boring work after executing a_func()&quot;) return wrapTheFunction####è¢«è£…é¥°çš„å‡½æ•°def a_function_requiring_decoration(): print(&quot;I am the function which needs some decoration to remove my foul smell&quot;) ####ä½¿ç”¨a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)#now a_function_requiring_decoration is wrapped by wrapTheFunction() a_function_requiring_decoration()#outputs:I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func()2.@@a_new_decorator ###a_new_decoratorè£…é¥°çš„å‡½æ•°ï¼Œæœ¬è´¨æ˜¯é—­åŒ… def a_function_requiring_decoration(): ####è¢«è£…é¥°çš„å‡½æ•° &quot;&quot;&quot;Hey you! Decorate me!&quot;&quot;&quot; print(&quot;I am the function which needs some decoration to &quot; &quot;remove my foul smell&quot;)####ä½¿ç”¨a_function_requiring_decoration() #outputs: I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func() ä¸€æ¬¡ä¿®é¥°ä¸¤ä¸ªè£…é¥°å™¨ï¼Œé¡ºåºä¸ºä»ä¸‹è‡³ä¸Š å¸¸è§è£…é¥°å™¨@propertyå°†æ–¹æ³•è½¬æ¢ä¸ºç›¸åŒåç§°çš„åªè¯»å±æ€§ 12345678910class dataset(object): @property def fun1(self): return 13 def fun2(self): return 13a=dataset()print(a.fun1)print(a.fun2()) @staticmethod@classmthodhttps://zhuanlan.zhihu.com/p/35643573","link":"/2022/09/12/decorator/"},{"title":"ç»´åº¦é€€åŒ–","text":"https://blog.csdn.net/wzy0623/article/details/49797421 https://www.google.com/search?q=Degenerate+Dimension&amp;sourceid=chrome&amp;ie=UTF-8 https://www.jamesserra.com/archive/2011/11/degenerate-dimensions/ https://blog.csdn.net/yezonghui/article/details/120131320 å½“ä¸€ä¸ªç»´åº¦æ²¡æœ‰æ•°æ®ä»“åº“éœ€è¦çš„ä»»ä½•æ•°æ®çš„æ—¶å€™å°±å¯ä»¥é€€åŒ–æ­¤ç»´åº¦ï¼Œéœ€è¦æŠŠé€€åŒ–çš„ç›¸å…³æ•°æ®è¿ç§»åˆ°äº‹å®è¡¨ä¸­ï¼Œç„¶ååˆ é™¤é€€åŒ–çš„ç»´åº¦ã€‚","link":"/2022/04/04/degenetate-dimension/"},{"title":"dfsï¼Œbfs","text":"https://www.jianshu.com/p/a753d5c733ec dfs1 é€’å½’å®ç° 123def dfs(å½“å‰èŠ‚ç‚¹,å­èŠ‚ç‚¹) for node in å­èŠ‚ç‚¹é›†åˆ dfs(node,new å­èŠ‚ç‚¹) 310. æœ€å°é«˜åº¦æ ‘12#### root å½“å‰èŠ‚ç‚¹ pathå­èŠ‚ç‚¹ depth æ·±åº¦dfs(root,path,depth) 695. å²›å±¿çš„æœ€å¤§é¢ç§¯12###gridå…¨éƒ¨æ ¼ç‚¹ cur_iï¼Œcur_j å½“å‰èŠ‚ç‚¹çš„ä½ç½®ï¼Œç”¨+1-1å¯ä»¥ç¡®å®šå­èŠ‚ç‚¹dfs(self, grid, cur_i, cur_j) : bfs1 è¿­ä»£å®ç° rootè¿›é˜Ÿï¼Œrootå‡ºé˜Ÿï¼Œrootçš„å­èŠ‚ç‚¹ã€a,b,cã€‘è¿›é˜Ÿï¼Œaå‡ºé˜Ÿï¼Œaçš„å­èŠ‚ç‚¹è¿›é˜Ÿï¼Œbå‡ºé˜Ÿï¼Œbçš„å­èŠ‚ç‚¹è¿›é˜Ÿã€‚ã€‚ã€‚ è®¿é—®é¡ºåºï¼ˆå‡ºé˜Ÿé¡ºåºï¼‰ï¼šroot a b c ã€‚ã€‚ã€‚ 1234567891011121314151617class Solution: def levelOrder(self, root: 'Node') -&gt; List[List[int]]: if root==None: return [] ans = [] q = [root] while q: # length = len(q) # arr = [] # for _ in range(length): node = q.pop(0) # arr.append(node.val) for chd in node.children: q.append(chd) # if arr: ans.append(node.val) return ans 429. N å‰æ ‘çš„å±‚åºéå†123456789101112131415161718class Solution: def levelOrder(self, root: 'Node') -&gt; List[List[int]]: ans = [] ##ç»“æœ q = [root] ##é˜Ÿåˆ— while q: length = len(q) arr = [] #å‡ºé˜Ÿ for _ in range(length): node = q.pop(0) if not node: continue arr.append(node.val) for chd in node.children: q.append(chd) if arr: ans.append(arr) return ans åº”ç”¨é€‰æ‹©æ—¶é—´å¤æ‚åº¦éƒ½ä¸ºOï¼ˆnï¼‰,nä¸ºå…¨éƒ¨èŠ‚ç‚¹ BFSæ˜¯ç”¨æ¥æœç´¢æœ€çŸ­å¾„è·¯çš„è§£æ˜¯æ¯”è¾ƒåˆé€‚çš„ï¼Œæ¯”å¦‚æ±‚æœ€å°‘æ­¥æ•°çš„è§£ï¼Œæœ€å°‘äº¤æ¢æ¬¡æ•°çš„è§£ï¼Œå› ä¸ºBFSæœç´¢è¿‡ç¨‹ä¸­é‡åˆ°çš„è§£ä¸€å®šæ˜¯ç¦»æ ¹æœ€è¿‘çš„ï¼Œæ‰€ä»¥é‡åˆ°ä¸€ä¸ªè§£ï¼Œä¸€å®šå°±æ˜¯æœ€ä¼˜è§£ï¼Œæ­¤æ—¶æœç´¢ç®—æ³•å¯ä»¥ç»ˆæ­¢ã€‚è¿™ä¸ªæ—¶å€™ä¸é€‚å®œä½¿ç”¨dfsï¼Œå› ä¸ºDFSæœç´¢åˆ°çš„è§£ä¸ä¸€å®šæ˜¯ç¦»æ ¹æœ€è¿‘çš„ï¼Œåªæœ‰å…¨å±€æœç´¢å®Œæ¯•ï¼Œæ‰èƒ½ä»æ‰€æœ‰è§£ä¸­æ‰¾å‡ºç¦»æ ¹çš„æœ€è¿‘çš„è§£ã€‚ï¼ˆå½“ç„¶è¿™ä¸ªDFSçš„ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨è¿­ä»£åŠ æ·±æœç´¢ID-DFSå»å¼¥è¡¥ï¼‰ DFSé€‚åˆæœç´¢å…¨éƒ¨çš„è§£ï¼Œè€Œæ­£å› ä¸ºè¦æœç´¢å…¨éƒ¨çš„è§£ï¼Œé‚£ä¹ˆBFSæœç´¢è¿‡ç¨‹ä¸­ï¼Œé‡åˆ°ç¦»æ ¹æœ€è¿‘çš„è§£ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆç”¨ï¼Œä¹Ÿå¿…é¡»éå†å®Œæ•´æ£µæœç´¢æ ‘ï¼›DFSæœç´¢ä¼šæœç´¢å…¨éƒ¨ï¼Œä½†æ˜¯ç›¸æ¯”ä¹‹ä¸‹ DFSä¸ç”¨è®°å½•è¿‡å¤šä¿¡æ¯ï¼Œæ‰€ä»¥æœç´ å…¨éƒ¨è§£çš„é—®é¢˜ï¼ŒDFSæ˜¾ç„¶æ›´åŠ åˆé€‚ã€‚ç©ºé—´ä¼˜åŠ£ä¸Šï¼ŒDFSæ˜¯æœ‰ä¼˜åŠ¿çš„ï¼ŒDFSä¸éœ€è¦ä¿å­˜æœç´¢è¿‡ç¨‹ä¸­çš„çŠ¶æ€ï¼Œè€ŒBFSåœ¨æœç´¢è¿‡ç¨‹ä¸­éœ€è¦ä¿å­˜æœç´¢è¿‡çš„çŠ¶æ€ï¼Œè€Œä¸”ä¸€èˆ¬æƒ…å†µéœ€è¦ä¸€ä¸ªé˜Ÿåˆ—æ¥è®°å½•ã€‚ å’Œå›æº¯çš„å…³ç³»å›æº¯æ˜¯ç®—æ³•æ€æƒ³ï¼Œdfså’Œbfsæ˜¯æœç´¢è§£ç©ºé—´çš„æ‰‹æ®µ å‚è€ƒhttps://www.jianshu.com/p/e81a16a6f771 https://blog.csdn.net/weixin_41894030/article/details/95317440","link":"/2022/04/06/dfs/"},{"title":"DGL notice","text":"any graph transformation will result in the loss of batch information. for a workaround , you may should use set_batch_num_nodes and set_batch_num_edges","link":"/2022/01/12/dgl-notice/"},{"title":"listï¼Œdictï¼Œsetçš„æ—¶é—´å¤æ‚åº¦","text":"1 x in slistï¼šO(n) dictï¼šO(1) setï¼šO(1) å‚è€ƒhttps://blog.csdn.net/jmh1996/article/details/78481365 https://www.cnblogs.com/tintinsoft/articles/9743765.html https://blog.csdn.net/weixin_48629601/article/details/107532754 https://blog.csdn.net/ACBattle/article/details/97012800","link":"/2022/05/24/dic-set-list/"},{"title":"è¯è¡¨ç‰¹æ®Šè¯çš„å«ä¹‰","text":"[PAD]ï¼šè¦å°†å¥å­å¤„ç†ä¸ºç‰¹å®šçš„é•¿åº¦ï¼Œå°±è¦åœ¨å¥å­å‰æˆ–åè¡¥[PAD] [CLS]ï¼šå¥å­çš„å¼€å§‹ [SEP]ï¼šåˆ†å¼€ä¸¤ä¸ªè¾“å…¥å¥å­ [mask] ï¼šé®ç›–å¥å­ä¸­çš„ä¸€äº›å•è¯ [UNK]ï¼šæ ‡è®°è¯å…¸å†…æ²¡æœ‰çš„è¯","link":"/2022/05/31/dict-word/"},{"title":"Deep Interest Evolution Network for Click-Through Rate Prediction","text":"1.æ¦‚è¿°å¯¹dinçš„æ”¹è¿› dinï¼šå¼ºè°ƒç”¨æˆ·å…´è¶£æ˜¯å¤šæ ·çš„ï¼Œå¹¶ä½¿ç”¨åŸºäºæ³¨æ„åŠ›æ¨¡å‹æ¥æ•è·ç”¨æˆ·çš„å…´è¶£ dienï¼šä¸ä½†è¦æ‰¾åˆ°ç”¨æˆ·çš„å…´è¶£ï¼Œè¿˜è¦æŠ“ä½ç”¨æˆ·å…´è¶£çš„å˜åŒ–è¿‡ç¨‹ 2.ç»“æ„ 1 behavior layerFeature RepresentationUser Profile, User Behavior, Ad and Context one-hot vector Embeddingtransforms the large scale sparse feature into lowdimensional dense feature 2 Interest Extractor Layeråˆ©ç”¨GRUä½œä¸ºåŸºæœ¬å•å…ƒ 3 Interest Evolving Layerä¸»è¦ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯attentionä¸€ä¸ªæ˜¯AUGRU attention ç”¨å…¬å¼è¡¨ç¤ºä¸ºï¼š \\alpha_t=\\frac{exp(\\textbf{h}_tW_{\\textbf{e}_a})}{\\sum_{j=1}^Texp(\\textbf{h}_jW_{\\textbf{e}_a})}AUGRU ç»“æ„å¦‚ä¸Šå›¾ï¼Œç”¨å¼å­è¡¨è¾¾å¦‚ä¸‹ï¼š 3 losstarget ä¸ºäº†æé«˜å‡†ç¡®ç‡å¼•å…¥Auxiliary loss L_{aux}=-\\frac{1}{N}\\sum_{i=1}^N\\sum_t[log\\sigma(\\textbf{h}_t^i,\\textbf{e}_b^i[t+1])+log(1-\\sigma(\\textbf{h}_t^i,\\tilde{\\textbf{e}}_b^i[t+1]))]å…¶ä¸­$\\sigma$ä¸ºsigmoid global lossï¼š L=L_{target}+\\alpha L_{aux}å‚è€ƒåŸæ–‡åœ°å€ https://arxiv.org/pdf/1809.03672.pdf","link":"/2021/10/13/dien/"},{"title":"é™ç»´","text":"1.æ„ä¹‰1.é«˜çº¬ç©ºé—´æ ·æœ¬å…·æœ‰ç¨€ç–æ€§ï¼Œå®¹æ˜“æ¬ æ‹Ÿåˆ 2.å¯è§†åŒ– 3.ç»´åº¦è¿‡å¤§å¯¼è‡´è®­ç»ƒæ—¶é—´é•¿ï¼Œé¢„æµ‹æ…¢ 2.åˆ†ç±»å¤§è‡´åˆ†ä¸ºçº¿å½¢é™ç»´åº¦å’Œéçº¿æ€§é™ç»´ï¼Œçº¿å½¢é™ç»´åŒ…æ‹¬PCAï¼ŒLDAç­‰ï¼Œéçº¿æ€§é™ç»´åŒ…æ‹¬LLEï¼Œt-SNEï¼Œauto encoderç­‰ã€‚ 3.PCAç³»åˆ—3.1 PCAå‡è®¾çŸ©é˜µ$x\\in \\mathbb{R}^{ n}$ï¼Œå‡è®¾æœ‰$M$ä¸ªæ ·æœ¬ï¼Œå°†åŸå§‹æ•°æ®æŒ‰åˆ—ç»„æˆ$M$ è¡Œ$ n $åˆ—çŸ©é˜µ$ X\\in \\mathbb{R}^{M\\times n}$ï¼ŒPCAçš„ä½¿ç”¨è¿‡ç¨‹ä¸ºï¼š 1.è®¡ç®—åæ–¹å·®çŸ©é˜µ$G_t \\in \\mathbb{R}^{n \\times n}$ G_t=\\frac{1}{M}\\sum_{j=1}^{M}(X-\\overline{X})^T(X-\\overline{X})æ³¨æ„ï¼Œå…¶ä¸­$\\overline{X}\\in \\mathbb{R}^{n}$ä¸ºåˆ—çš„å‡å€¼ï¼Œ$X-\\overline{X}$è¡¨ç¤ºå°†$ X$ çš„æ¯ä¸€åˆ—è¿›è¡Œé›¶å‡å€¼åŒ–ï¼Œå³å‡å»è¿™ä¸€åˆ—çš„å‡å€¼ 2.æ±‚å‡ºåæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼åŠå¯¹åº”çš„ç‰¹å¾å‘é‡ (U,\\sum,V)=SVD(G_t)3.å°†ç‰¹å¾å‘é‡æŒ‰å¯¹åº”çš„ç‰¹å¾å€¼å¤§å°æ’åˆ—ï¼Œå–å‰ $k$ åˆ—ç»„æˆçŸ©é˜µ $P\\in \\mathbb{R}^{n \\times k} $ P=U(:,1:k)4.å®ç°æ•°æ®é™ç»´ y_{[1\\times k]}=x_{[1\\times n ]}P_{[n\\times k]}å±€é™ï¼š â€‹ a. PCAåªèƒ½é’ˆå¯¹1Dçš„å‘é‡ï¼Œå¯¹äº2Dçš„çŸ©é˜µè€Œè¨€ï¼Œæ¯”å¦‚å›¾ç‰‡æ•°æ®ï¼Œéœ€è¦å…ˆflattenæˆå‘é‡ 3.2 2DPCAå°†2Dçš„çŸ©é˜µflattenæˆå‘é‡å…¶å®ä¸¢å¤±äº†è¡Œåˆ—çš„ä½ç½®ä¿¡æ¯ï¼Œä¸ºäº†ç›´æ¥åœ¨2Dçš„çŸ©é˜µä¸Šå®ç°é™ç»´ï¼Œæå‡ºäº†2DPCAã€‚ å‡è®¾æœ‰åŸå§‹çŸ©é˜µ$A\\in\\mathbb{R}^{m \\times n }$ï¼Œä½¿ç”¨è¿‡ç¨‹å¦‚ä¸‹ï¼š 1.è®¡ç®—åæ–¹å·®çŸ©é˜µ G_t=\\frac{1}{M}\\sum_{j=1}^{M}(A_j-\\overline{A})^{T}(A_j-\\overline{A}) \\\\\\overline{A}=\\frac{1}{M}\\sum_{j=1}^{M}A_j2.æ±‚å‡ºåæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼åŠå¯¹åº”çš„ç‰¹å¾å‘é‡ (U,\\sum,V)=SVD(G_t)3.å°†ç‰¹å¾å‘é‡æŒ‰å¯¹åº”çš„ç‰¹å¾å€¼å¤§å°æ’åˆ—ï¼Œå–å‰ $k$ åˆ—ç»„æˆçŸ©é˜µ X=U(:,1:k)4.å®ç°æ•°æ®é™ç»´ Y_{[m\\times k]}=A_{[m\\times n ]}X_{[n\\times k]}3.3 ï¼ˆ2Dï¼‰2PCAä½œè€…è¯æ˜äº†2DPCAåªæ˜¯åœ¨è¡Œä¸Šå·¥ä½œï¼Œç„¶åæå‡ºäº†Alternative 2DPCAå¯ä»¥å·¥ä½œåœ¨åˆ—ä¸Šï¼Œæœ€åå°†å…¶ç»“åˆå¾—åˆ°ï¼ˆ2Dï¼‰2PCAï¼Œä½¿å…¶å¯ä»¥åŒæ—¶åœ¨è¡Œåˆ—å·¥ä½œ å‡è®¾æœ‰åŸå§‹çŸ©é˜µ$A\\in\\mathbb{R}^{m \\times n }$ï¼Œä½¿ç”¨è¿‡ç¨‹å¦‚ä¸‹ï¼š 1.è®¡ç®—åæ–¹å·®çŸ©é˜µ G_x=\\frac{1}{M}\\sum_{k=1}^{M}\\sum_{i=1}^{m}(A_k^{(i)}-\\overline{A}^{(i)})^{T}(A_k^{(i)}-\\overline{A}^{(i)})å…¶ä¸­$A_k=[(A_k^{(1)})^{T} \\ (A_k^{(2)})^{T} \\ â€¦\\ (A_k^{(m)})^{T}]^{T},\\overline{A}=[(\\overline{A}^{(1)})^{T} \\ (\\overline{A}^{(2)})^{T} \\ â€¦\\ (\\overline{A}^{(m)})^{T}]^{T}, \\ A_k^{(i)}, \\overline{A}^{(i)}$è¡¨ç¤º$A_k,\\overline{A}$çš„ç¬¬$i$è¡Œ \\\\G_z=\\frac{1}{M}\\sum_{k=1}^{M}\\sum_{j=1}^{n}(A_k^{(j)}-\\overline{A}^{(j)})(A_k^{(j)}-\\overline{A}^{(j)})^{T}å…¶ä¸­$A_k=[(A_k^{(1)}) \\ (A_k^{(2)}) \\ â€¦\\ (A_k^{(n)})],\\overline{A}=[(\\overline{A}^{(1)}) \\ (\\overline{A}^{(2)}) \\ â€¦\\ (\\overline{A}^{(n)})],A_k^{(j)},\\overline{A}^{(j)}$è¡¨ç¤º$A_k,\\overline{A}$çš„ç¬¬$j$åˆ— 2.æ±‚å‡ºåæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼åŠå¯¹åº”çš„ç‰¹å¾å‘é‡ (U_x,\\sum x,V_x)=SVD(G_x) \\\\(U_z,\\sum z,V_z)=SVD(G_z)3.å°†ç‰¹å¾å‘é‡æŒ‰å¯¹åº”çš„ç‰¹å¾å€¼å¤§å°æ’åˆ— X=U_x(:,1:k) \\in \\mathbb{R}^{n\\times k} \\\\Z=U_z(:,1:q) \\in \\mathbb{R}^{m\\times q}4.å®ç°æ•°æ®é™ç»´ C_{[q\\times k]}=Z^{T}_{[q\\times m]}A_{[m\\times n ]}X_{[n\\times k]}4.t-SNE4.1 åŸç†å¯ä»¥å‚è€ƒ https://blog.csdn.net/scott198510/article/details/76099700 4.2ä»£ç 123456789101112131415161718from sklearn.manifold import TSNEfrom matplotlib import pylabimport torchimport pandas as pdembdding=torch.load(path1)words = pd.read_csv(path2)words_embedded = TSNE(n_components=2).fit_transform(embdding)pylab.figure(figsize=(20, 20))for i, label in enumerate(words): x, y = words_embedded[i, :] pylab.scatter(x, y) pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')pylab.show() 5.auto encoder AutoEncoderåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æ— éœ€ä½¿ç”¨æ ·æœ¬çš„labelï¼Œé€šè¿‡æœ€å°åŒ–é‡æ„è¯¯å·®å¸Œæœ›å­¦ä¹ åˆ°æ ·æœ¬çš„æŠ½è±¡ç‰¹å¾è¡¨ç¤ºzï¼Œè¿™ç§æ— ç›‘ç£çš„ä¼˜åŒ–æ–¹å¼å¤§å¤§æå‡äº†æ¨¡å‹çš„é€šç”¨æ€§ã€‚ å‚è€ƒhttps://zhuanlan.zhihu.com/p/68903857 https://blog.csdn.net/scott198510/article/details/76099700","link":"/2021/09/08/dimension-reduction/"},{"title":"æ•°ä»“å»ºæ¨¡","text":"å…³ç³»å»ºæ¨¡å’Œç»´åº¦å»ºæ¨¡æ˜¯ä¸¤ç§æ•°æ®ä»“åº“çš„å»ºæ¨¡æŠ€æœ¯ã€‚å…³ç³»å»ºæ¨¡ç”±Bill Inmonæ‰€å€¡å¯¼ï¼Œç»´åº¦å»ºæ¨¡ç”±Ralph Kimballæ‰€å€¡å¯¼ã€‚ç›®å‰ä¸»æµä¸ºç»´åº¦å»ºæ¨¡ã€‚ https://zhuanlan.zhihu.com/p/362991213 1.å…³ç³»å»ºæ¨¡ï¼ˆèŒƒå¼å»ºæ¨¡ï¼‰1.1 èŒƒå¼1 ç›®çš„ é™ä½æ•°æ®çš„å†—ä½™æ€§ 2 ç›®å‰ä¸šç•ŒèŒƒå¼ ç¬¬ä¸€èŒƒå¼(1NF)ã€ç¬¬äºŒèŒƒå¼(2NF)ã€ç¬¬ä¸‰èŒƒå¼(3NF)ã€å·´æ–¯-ç§‘å¾·èŒƒå¼(BCNF)ã€ç¬¬å››èŒƒå¼(4NF)ã€ç¬¬äº”èŒƒå¼(5NF)ã€‚é€ä¸ªéµå¾ªï¼Œä¸€èˆ¬è¦æ±‚éµå¾ªç¬¬ä¸€ï¼Œç¬¬äºŒï¼Œç¬¬ä¸‰èŒƒå¼ï¼Œä¹Ÿå°±æ˜¯ä¸‰èŒƒå¼ã€‚ https://blog.csdn.net/Dream_angel_Z/article/details/45175621 1.2 å»ºæ¨¡ 1 å»ºæ¨¡ å…³ç³»å»ºæ¨¡å°†å¤æ‚çš„æ•°æ®æŠ½è±¡ä¸ºä¸¤ä¸ªæ¦‚å¿µâ€”â€”å®ä½“å’Œå…³ç³»ï¼ˆå®ä½“è¡¨ï¼Œå…³ç³»è¡¨ï¼‰ï¼Œå¹¶ä½¿ç”¨è§„èŒƒåŒ–ï¼ˆä¸‰èŒƒå¼ï¼‰çš„æ–¹å¼è¡¨ç¤ºå‡ºæ¥ 2 ç‰¹ç‚¹ å…³ç³»æ¨¡å‹ä¸¥æ ¼éµå¾ªç¬¬ä¸‰èŒƒå¼ï¼ˆ3NFï¼‰ï¼Œæ•°æ®å†—ä½™ç¨‹åº¦ä½ï¼Œæ•°æ®çš„ä¸€è‡´æ€§å®¹æ˜“å¾—åˆ°ä¿è¯ã€‚ ç”±äºæ•°æ®åˆ†å¸ƒäºä¼—å¤šçš„è¡¨ä¸­ï¼ŒæŸ¥è¯¢ä¼šç›¸å¯¹å¤æ‚ï¼Œåœ¨å¤§æ•°æ®çš„åœºæ™¯ä¸‹ï¼ŒæŸ¥è¯¢æ•ˆç‡ç›¸å¯¹è¾ƒä½ã€‚ 2.ç»´åº¦å»ºæ¨¡https://www.jianshu.com/p/daab50a23c56 https://cloud.tencent.com/developer/article/1772027 2.1 äº‹å®è¡¨å’Œç»´åº¦è¡¨1 äº‹å®è¡¨ å­˜å‚¨ä¸šåŠ¡äº‹å®ï¼Œäº‹å®è¡¨ä¸­çš„æ¯è¡Œæ•°æ®ä»£è¡¨ä¸€ä¸ªä¸šåŠ¡äº‹ä»¶ï¼ˆä¸‹å•ã€æ”¯ä»˜ã€é€€æ¬¾ã€è¯„ä»·ç­‰ï¼‰ã€‚ äº‹å®è¡¨çš„ç‰¹å¾ï¼š â€‹ å†…å®¹ç›¸å¯¹çš„çª„ï¼šåˆ—æ•°è¾ƒå°‘ï¼ˆä¸»è¦æ˜¯å¤–é”®idå’Œåº¦é‡å€¼ï¼‰ â€‹ éå¸¸çš„å¤§ â€‹ ç»å¸¸å‘ç”Ÿå˜åŒ–ï¼Œæ¯å¤©ä¼šæ–°å¢åŠ å¾ˆå¤šã€‚ åˆ†ç±»ï¼šäº‹åŠ¡å‹äº‹å®è¡¨ï¼Œå‘¨æœŸå‹å¿«ç…§äº‹å®è¡¨ï¼Œç´¯ç§¯å‹å¿«ç…§äº‹å®è¡¨ 2 ç»´åº¦è¡¨ ç»´åº¦è¡¨ï¼šä¸€èˆ¬æ˜¯å¯¹äº‹å®çš„æè¿°ä¿¡æ¯ã€‚æ¯ä¸€å¼ ç»´è¡¨å¯¹åº”ç°å®ä¸–ç•Œä¸­çš„ä¸€ä¸ªå¯¹è±¡æˆ–è€…æ¦‚å¿µã€‚ ä¾‹å¦‚ï¼šç”¨æˆ·ã€å•†å“ã€æ—¥æœŸã€åœ°åŒºç­‰ã€‚ ç»´è¡¨çš„ç‰¹å¾ï¼š â€‹ ç»´è¡¨çš„èŒƒå›´å¾ˆå®½ï¼ˆå…·æœ‰å¤šä¸ªå±æ€§ã€åˆ—æ¯”è¾ƒå¤šï¼‰ â€‹ è·Ÿäº‹å®è¡¨ç›¸æ¯”ï¼Œè¡Œæ•°ç›¸å¯¹è¾ƒå°ï¼šé€šå¸¸&lt; 10ä¸‡æ¡ â€‹ å†…å®¹ç›¸å¯¹å›ºå®šï¼šç¼–ç è¡¨ 2.2 ç»´åº¦æ¨¡å‹åˆ†ç±»åœ¨ç»´åº¦å»ºæ¨¡çš„åŸºç¡€ä¸Šåˆåˆ†ä¸ºä¸‰ç§æ¨¡å‹ï¼šæ˜Ÿå‹æ¨¡å‹ã€é›ªèŠ±æ¨¡å‹ã€æ˜Ÿåº§æ¨¡å‹ã€‚ æ˜Ÿåº§æ¨¡å‹æ˜¯å¤šä¸ªæ˜Ÿå‹æ¨¡å‹äº¤ç»‡ 2.3 å»ºæ¨¡ 1 å»ºæ¨¡ ç»´åº¦æ¨¡å‹é¢å‘ä¸šåŠ¡ï¼Œå°†ä¸šåŠ¡ç”¨äº‹å®è¡¨å’Œç»´åº¦è¡¨å‘ˆç°å‡ºæ¥ã€‚ æ­¥éª¤ï¼š https://www.cnblogs.com/suheng01/p/13522677.html é€‰æ‹©ä¸šåŠ¡è¿‡ç¨‹â†’å£°æ˜ç²’åº¦â†’ç¡®è®¤ç»´åº¦â†’ç¡®è®¤äº‹å® 2 ç‰¹ç‚¹ ç»´åº¦æ¨¡å‹ä»¥æ•°æ®åˆ†æä½œä¸ºå‡ºå‘ç‚¹ï¼Œä¸éµå¾ªä¸‰èŒƒå¼ï¼Œæ•…æ•°æ®å­˜åœ¨ä¸€å®šçš„å†—ä½™ã€‚ è¡¨ç»“æ„ç®€å•ï¼Œæ•…æŸ¥è¯¢ç®€å•ï¼ŒæŸ¥è¯¢æ•ˆç‡è¾ƒé«˜ã€‚","link":"/2022/01/25/dimention-modeling/"},{"title":"Deep Interest Network for Click-Through Rate Prediction","text":"1.DEEP INTEREST NETWORK 1.1 ç‰¹å¾è¡¨ç¤ºç‰¹å¾å¯ä»¥è¡¨ç¤ºä¸º$\\textbf{x}=[t_1^T,t_2^T,â€¦,t_M^T]^T$ï¼Œone hotè¡¨ç¤ºï¼Œä¸¾ä¸ªä¾‹å­å¦‚ä¸‹ 1.2 embeddingå±‚å¯¹äº$t_i \\in \\mathbb{R}^{K_i}$ï¼Œ$W^i=[w_1^i,â€¦,w_j^i,â€¦,w_{K_i}^i] \\in \\mathbb{R}^{D\\times K_i} $ 1.3 Pooling layer and Concat layer \\textbf{e}_i=pooling(\\textbf{e}_{i_1},\\textbf{e}_{i_2},...,\\textbf{e}_{i_k})Two most commonly used pooling layers are sum pooling and average pooling, which apply element-wise sum/average operations to the list of embedding vectors. 1.4 Activation unitDINå°±æ˜¯åœ¨baseçš„åŸºç¡€ä¸ŠåŠ å…¥local activation unitï¼Œä½œç”¨æ˜¯å¯¹ç”¨æˆ·è¡Œä¸ºç‰¹å¾çš„ä¸åŒå•†å“ç»™ä¸ä¸åŒæƒé‡ï¼Œå…¶ä½™ä¿æŒä¸å˜ï¼Œå¼å­è¡¨ç¤ºå¦‚ä¸‹ \\mathcal{V}_{U}(A)=f(\\mathcal{V}_{A},\\textbf{e}_1,\\textbf{e}_2,...,\\textbf{e}_H)=\\sum_{j=1}^Ha(\\textbf{e}_j,\\mathcal{V}_{A})\\textbf{e}_j=\\sum_{j=1}^H\\textbf{w}_j\\textbf{e}_jå…¶ä¸­$a(\\cdot)$ä¸ºä¸Šå›¾ä¸­activate unit,ä¸attentionå¾ˆåƒï¼ŒåŸæ–‡æ˜¯Local activation unit of Eq.(3) shares similar ideas with attention methods which are developed in NMT task[1]. 1.5 MLP1.6 Lossäº¤å‰ç†µè¡¨ç¤ºä¸ºï¼š L=-\\frac{1}{N}\\sum_{(\\textbf{x},y) \\in \\textbf{S}}(ylogp(\\textbf{x})+(1-y)log(1-p(\\textbf{x})))2.è®­ç»ƒæŠ€å·§Practically, training industrial deep networks with large scale sparse input features is of great challenge. å¼•å…¥Mini-batch Aware Regularizationå’ŒData Adaptive Activation Functionï¼Œå…·ä½“ä¸åœ¨æ­¤ä»‹ç» å‚è€ƒåŸæ–‡ https://arxiv.org/pdf/1706.06978.pdf","link":"/2021/10/13/din/"},{"title":"è·ç¦»&#x2F;ç›¸ä¼¼åº¦","text":"https://zhuanlan.zhihu.com/p/138107999 https://blog.csdn.net/txwh0820/article/details/51791739","link":"/2022/04/13/distance/"},{"title":"HIERARCHICAL TRANSFORMERS FOR LONG DOCUMENT CLASSIFICATION","text":"åŸç‰ˆBERTçš„æœ€å¤§è¾“å…¥ä¸º512ï¼Œä¸ºäº†ä½¿å¾—BERTèƒ½è§£å†³è¶…é•¿æ–‡æœ¬çš„é—®é¢˜ï¼Œä½œè€…åœ¨finetuneé˜¶æ®µæå‡ºäº†ä¸¤ç§ç­–ç•¥æ¥å¼¥è¡¥è¿™ä¸ªé—®é¢˜ï¼Œå³åˆ©ç”¨BERT+LSTMæˆ–è€…BERT+transformerã€‚ æ ¸å¿ƒæ­¥éª¤ï¼š 1.split the input sequence into segments of a fixed size with overlap. 2.For each of these segments, we obtain H or P from BERT model. 3.We then stack these segment-level representations into a sequence, which serves as input to a small (100-dimensional) LSTM layer.//replacing the LSTM recurrent layer in favor of a small Transformer model 4.Finally, we use two fully connected layers with ReLU (30-dimensional) and softmax (the same dimensionality as the number of classes) activations to obtain the final predictions.","link":"/2021/09/17/doc-bert/"},{"title":"dockerå®¹å™¨ä¸è™šæ‹Ÿæœºæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ","text":"https://www.zhihu.com/question/48174633 ä¸€ã€ç‰©ç†æœºæ˜¯è¿™æ ·çš„ äºŒã€è™šæ‹Ÿæœºæ˜¯è¿™æ ·çš„ ä¸‰ã€å®¹å™¨æ˜¯è¿™æ ·çš„","link":"/2022/03/16/docker-vm/"},{"title":"DSSMåŒå¡”æ¨¡å‹ç³»åˆ—","text":"ç®€å•ä»‹ç»å¾®è½¯å‡ºå“çš„DSSM,CNN-DSSM,LSTM-DSSM åŸæ–‡åˆ†åˆ«ä¸ºï¼š ã€ŠLearning Deep Structured Semantic Models for Web Search using Clickthrough Dataã€‹ ã€ŠA Latent Semantic Model with Convolutional-Pooling Structure for Information Retrievalã€‹ ã€ŠSEMANTIC MODELLING WITH LONG-SHORT-TERM MEMORY FOR INFORMATION RETRIEVALã€‹ é¦–å…ˆä¸ºä»€ä¹ˆå«åšåŒå¡”ï¼Œqueryå¡”åšåœ¨çº¿servingï¼Œdocå¡”ç¦»çº¿è®¡ç®—embedingå»ºç´¢å¼•ï¼Œæ¨åˆ°çº¿ä¸Šå³å¯ã€‚ æ³¨æ„ï¼Œ DSSMä¸­queryå’Œä¸åŒçš„docæ˜¯å…±äº«å‚æ•°çš„ï¼Œ https://flashgene.com/archives/72820.html ä¸€.DSSM1.1 æ¨¡å‹æ•´ä½“ç»“æ„ æ¨¡å‹çš„æ•´ä½“ç»“æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œ$Q$ä¸ºqueryï¼Œ$D_i$ä¸ºæ–‡æ¡£ã€‚ æ–‡æœ¬çš„åˆå§‹è¯è¢‹è¡¨ç¤ºä¸º$x$ï¼Œå› ä¸ºå‚æ•°è¿‡å¤šï¼Œä¸åˆ©äºè®­ç»ƒï¼Œæ‰€ä»¥é™ä½ç»´åº¦ï¼Œå°±æå‡ºäº†word hashing l_1=W_1xword hashingå…¶å®å°±æ˜¯åˆ©äºchar n-gramåˆ†è¯ï¼Œç„¶åç”¨å‘é‡è¡¨ç¤ºï¼ˆåªæ˜¯è¿™é‡Œä¾ç„¶ç”¨è¯è¢‹è¡¨ç¤ºå‘é‡ï¼Œè€Œä¸æ˜¯ç¨ å¯†å‘é‡ï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤º è¿™é‡Œæœ‰ä¸ªé¡¾è™‘ä¸ºæ˜¯å¦å­˜åœ¨ä¸åŒçš„è¯ä½¿ç”¨ç›¸åŒçš„å‘é‡è¡¨ç¤ºã€‚å…³äºè¿™ä¸ªä½œè€…åšäº†å®éªŒï¼Œç»“æœå¦‚ä¸‹ã€‚ å¯¹äºè¯æ±‡æ•°é‡500Kå¤§å°çš„è¯è¡¨ï¼Œé‡‡ç”¨3-gramåï¼Œæ­¤è¡¨å‹ç¼©åˆ°30kï¼Œè€Œä¸”é‡å¤è¡¨ç¤ºçš„ä»…ä¸º22ä¸ªã€‚é‡å¤è¡¨ç¤ºç‡ä¸º0.0044%ï¼Œç»´åº¦å‹ç¼©åˆ°åŸæ¥6%ï¼Œå¯ä»¥è¯´éå¸¸æœ‰æ•ˆã€‚ ç„¶åä¸ºå¤šå±‚çš„éçº¿æ€§æ˜ å°„ï¼Œæ¯å±‚éƒ½ä¸ºå…¨è¿æ¥ç½‘ç»œï¼Œå¾—åˆ° l_i=f(W_il_{i-1}+b_{i}),i=2,...,N-1\\\\éçº¿æ€§æ˜ å°„å±‚çš„æœ€åä¸€å±‚å¾—åˆ°è¯­ä¹‰ç‰¹å¾$y$ä¸º y=f(W_Nl_{N-1}+b_N)\\\\ f(x)=tanh(x)=\\frac{1-e^{-2x}}{1+e^{-2x}}åˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡$Q$å’Œ$D$ç›¸ä¼¼åº¦å¾—åˆ° R(Q,D)=cosine(y_Q,y_D)=\\frac{y_Q^Ty_D}{||y_Q||||y_D||}æœ€åçš„æ¦‚ç‡è¾“å‡ºä¸º P(D|Q)=\\frac{e^{\\gamma R(Q,D)}}{\\sum_{D^{'}\\in \\textbf{D}}e^{\\gamma R(Q,D^{'})}}å…¶ä¸­$\\gamma$ä¸ºsmoothing factorã€‚ 1.2 è®­ç»ƒæ ·æœ¬é›†æ„é€ ï¼Œå¯¹æ¯ä¸ªæ­£æ ·æœ¬$(Q,D^+)$ï¼Œæ­é…4ä¸ªéšæœºè´Ÿæ ·æœ¬$(Q,D_j^-;j=1,..,4)$ æŸå¤±å‡½æ•°ä¸ºï¼š L(\\wedge)=-log \\prod \\limits_{(Q,D^+)}P(D^+|Q)å…¶ä¸­$\\wedge$ä¸ºæ¨¡å‹å‚æ•°ã€‚ äºŒ.CNN-DSSM2.1 CLSMç»“æ„ æ¨¡å‹åŒ…æ‹¬å‡ ä¸ªéƒ¨åˆ†ï¼š(1) a word-n-gram layer obtained by running a contextual sliding window over the input word sequence (2) a letter-trigram layer that transforms each word-trigram into a letter-trigram representation vector (3) a convolutional layer that extracts contextual features for each word with its neighboring words defined by a window (4) a max-pooling layer that discovers and combines salient word-n-gram features to form a fixed-length sentence-level feature vector (5) a semantic layer that extracts a high-level semantic feature vector for the input word sequence. 2.2 Letter-trigram based Word-n-gram Representationåœ¨DSSMçš„Letter-trigramçš„åŸºç¡€ä¸ŠåŠ äº†Word-n-gramï¼ŒWord-n-gramå°±æ˜¯å¯¹åŸå§‹è¾“å…¥æ–‡æœ¬åšæ»‘çª—ï¼Œå¯¹äºç¬¬$t$ä¸ªword-n-gramå¯ä»¥è¡¨ç¤ºä¸ºï¼š l_t=[f^T_{t-d},...,f^T_{t},...,f^T_{t+d}]^T,\\ t=1,2,...,Tå…¶ä¸­$n=2d+1,f_t$ä¸ºçš„ç¬¬$t$ä¸ªè¯è¯­çš„letter-trigramã€‚ä¸€ä¸ªletter-trigramçš„ç»´åº¦ä¸º$30K$ï¼Œé‚£ä¹ˆä¸€ä¸ªword-n-gramç»´åº¦ä¸º$n\\times30K$ ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚ä¸Šå›¾ï¼Œè¾“å…¥æ–‡æœ¬ä¸º$(s) \\ online \\ auto\\ body \\ (s)$ï¼Œæ»‘åŠ¨çª—å£å¤§å°ä¸ºn=3ï¼Œå¯å¾—$(s)\\ online \\ autoï¼Œ\\ online \\ auto \\ body ï¼Œauto\\ body \\ (s) $ï¼Œé‚£ä¹ˆ $l_1=[f^T((s)),f^T(online ),f^T(auto)]^T,\\\\l_2=[f^T(online ),f^T(auto),f^T(body)]^T,\\\\l_3=[f^T(auto),f^T(body),f^T((s))]^T$ 2.3 Modeling Word-n-gram-Level Contextual Features at the Convolutional Layerè¯­å¢ƒç›¸å…³ç‰¹å¾å‘é‡$h_t$å¯ä»¥è¡¨ç¤ºä¸ºï¼š h_t=tanh(W_c\\cdot l_t),\\ t=1,...,Tå…¶ä¸­$W_c$ä¸ºç‰¹å¾è½¬æ¢çŸ©é˜µï¼Œä¹Ÿå°±æ˜¯å·ç§¯çŸ©é˜µï¼Œå¯¹äºå…¨éƒ¨çš„word n-gramsï¼Œ$W_c$å…±äº«ã€‚æœ‰å°ä¼™ä¼´è‚¯å®šå¥½å¥‡ï¼Œè¿™ä¸å°±æ˜¯å…¨è¿æ¥å—ï¼Œå’Œå·ç§¯ä»€ä¹ˆå…³ç³»ï¼Œä¿ºä¹Ÿç–‘æƒ‘ï¼Ÿ ä¸‹å›¾ä¸ºä½œè€…åšçš„ä¸€ä¸ªå®éªŒã€‚ 2.4 Modeling Sentence-Level Semantic Features Using Max Poolingè·å–å±€éƒ¨çš„è¯­å¢ƒç›¸å…³çš„ç‰¹å¾å‘é‡åï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬åˆåœ¨ä¸€èµ·ç»„åˆå¥å­çº§åˆ«çš„ç‰¹å¾å‘é‡ã€‚ç”±äºè¯­å¥ä¸­æŸäº›è¯è¯­ä¸é‡è¦ï¼Œæˆ‘ä»¬å¯ä»¥å¿½ç•¥å®ƒï¼Œæœ‰äº›è¯è¯­å¾ˆé‡è¦ï¼Œè¦ä¿ç•™ã€‚ä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®çš„ï¼Œä½¿ç”¨äº†max poolingï¼Œç”¨å¼å­æè¿°å¦‚ä¸‹ v(i)= \\mathop{\\max}_{t=1,..,T} \\{h_t(i)\\},\\ i=1,...,Kå…¶ä¸­$v(i)$è¡¨ç¤ºæ± åŒ–å±‚è¾“å‡º$v$çš„ç¬¬$i$ä¸ªå…ƒç´ ï¼Œ$K$ä¸º$v$çš„ç»´åº¦å’Œ$h_t$çš„ç»´åº¦ä¸€æ ·ï¼Œ$h_t(i)$æ˜¯ç¬¬$t$ä¸ªå±€éƒ¨è¯­å¢ƒç‰¹å¾å‘é‡çš„ç¬¬$i$ä¸ªå…ƒç´ ã€‚ä¸¾ä¸ªä¾‹å­å¦‚ä¸‹ï¼Œ 2.5 Latent Semantic Vector Representationsè¯­ä¹‰å‘é‡è¡¨ç¤º$y$ï¼Œç”¨å…¬å¼æè¿°å¦‚ä¸‹ y=tanh(W_s\\cdot v)2.6 Using the CLSM for IRå’ŒDSSMéƒ½ä¸€æ ·ï¼Œ R(Q,D)=cosine(y_Q,y_D)=\\frac{y_Q^Ty_D}{||y_Q||||y_D||} \\\\P(D|Q)=\\frac{e^{\\gamma R(Q,D)}}{\\sum_{D^{'}\\in \\textbf{D}}e^{\\gamma R(Q,D^{'})}}2.7 æŸå¤±å‡½æ•° L(\\wedge)=-log \\prod \\limits_{(Q,D^+)}P(D^+|Q)ä¸‰.LSTM-DSSMcnn-dssmåªèƒ½æ•è·å±€éƒ¨çš„æ–‡æœ¬ä¿¡æ¯ï¼Œlstmå¯¹äºé•¿åºåˆ—çš„ä¿¡æ¯æ•è·èƒ½åŠ›å¼ºäºlstmï¼Œå› æ­¤ä½¿ç”¨lstmæ”¹è¿›dssmã€‚ 3.1 æ¨¡å‹ç»“æ„æ•´ä½“ç»“æ„å¦‚ä¸‹å›¾ï¼Œæ³¨æ„çº¢è‰²çš„éƒ¨åˆ†ä¸ºæ®‹å·®ä¼ é€’çš„æ–¹å‘ã€‚ å›¾ä¸­çš„LSTMå•å…ƒæ˜¯LSTMçš„å˜ç§ï¼ŒåŠ å…¥äº†peep holeçš„ LSTMï¼Œå…·ä½“ç»“æ„å¦‚ä¸‹ã€‚ å‚è€ƒhttps://www.cnblogs.com/guoyaohua/p/9229190.html","link":"/2021/08/18/dssm/"},{"title":"ç”µå•†ä¸šåŠ¡","text":"1 SPUï¼ŒSKU SPUï¼ˆStandard Product Unitï¼‰ï¼šæ˜¯å•†å“ä¿¡æ¯èšåˆçš„æœ€å°å•ä½ï¼Œæ˜¯ä¸€ç»„å¯å¤ç”¨ã€æ˜“æ£€ç´¢çš„æ ‡å‡†åŒ–ä¿¡æ¯é›†åˆã€‚ SKU = Stock Keeping Unitï¼ˆåº“å­˜é‡åŸºæœ¬å•ä½ï¼‰ã€‚ç°åœ¨å·²ç»è¢«å¼•ç”³ä¸ºäº§å“ç»Ÿä¸€ç¼–å·çš„ç®€ç§°ï¼Œæ¯ç§äº§å“å‡å¯¹åº”æœ‰å”¯ä¸€çš„SKUå·ã€‚ ä¾‹å¦‚ï¼šiPhoneXæ‰‹æœºå°±æ˜¯SPUã€‚ä¸€å°é“¶è‰²ã€128Gå†…å­˜çš„ã€æ”¯æŒè”é€šç½‘ç»œçš„iPhoneXï¼Œå°±æ˜¯SKUã€‚","link":"/2022/04/04/e-commerce-business-knowleage/"},{"title":"early stop","text":"","link":"/2022/06/01/early-stop/"},{"title":"ELMo(Deep contextualized word representations)","text":"å¼•å…¥äº†æ–°çš„æ·±åº¦è€ƒè™‘ä¸Šä¸‹æ–‡çš„è¯è¯­è¡¨ç¤ºï¼Œæ¨¡å‹è€ƒè™‘äº†ä¸¤ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰è¯è¯­çš„å¤æ‚ç‰¹æ€§ï¼ŒåŒ…æ‹¬è¯­æ³•å’Œè¯­ä¹‰ï¼Œï¼ˆ2ï¼‰åœ¨è¯­å¢ƒä¸­çš„ä¸åŒå«ä¹‰ã€‚æ¨¡å‹ä½¿ç”¨äº†æ·±åº¦åŒå‘è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨å¤§é¢„æ–™åº“ä¸Šåšäº†é¢„è®­ç»ƒã€‚è¿™ä¸ªæ¨¡å‹å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å’Œç°æœ‰çš„æ¨¡å‹ç»“åˆï¼Œå¹¶ä¸”åœ¨NLPçš„6ä¸ªä»»åŠ¡ä¸Šå–å¾—äº†SOTAã€‚ä½œè€…è¿˜æ­éœ²äº†é¢„è®­ç»ƒç½‘ç»œçš„æ·±å±‚æ„ä»¶æ˜¯å…³é”®ï¼Œè¿™ä½¿å¾—ä¸‹æ¸¸æ¨¡å‹èƒ½å¤Ÿæ··åˆä¸åŒç±»å‹çš„åŠç›‘ç£ä¿¡å·ã€‚ 3 ELMo: Embeddings from Language Models æ¨¡å‹çš„æ•´ä½“æœºæ„å¦‚ä¸Šæ‰€ç¤ºï¼Œç”±å·¦å³ä¸¤ä¸ªå•å‘çš„å¤šå±‚LSTMç½‘ç»œæ„æˆï¼Œå·¦è¾¹ä¸ºæ­£å‘ï¼Œå³è¾¹ä¸ºåå‘ã€‚ 3.1 Bidirectional language modelsï¼ˆé¢„è®­ç»ƒï¼‰å‡å®šä¸€ä¸ªå¥å­æœ‰$N$ä¸ªtokenï¼Œåˆ†åˆ«ä¸º$(t_1,t_2,â€¦,t_N)$ï¼Œæ­£å‘çš„è¯­è¨€æ¨¡å‹çš„å¥å­æ¦‚ç‡ä¸ºï¼š p(t_1,t_2,...,t_N)=\\prod_{k=1}^{N}p(t_k|t_1,t_2,...,t_{k-1})åå‘çš„è¯­è¨€æ¨¡å‹çš„å¥å­æ¦‚ç‡ä¸ºï¼š p(t_1,t_2,...,t_N)=\\prod_{k=1}^{N}p(t_k|t_{k+1},t_{k+2},...,t_{N})å¾—åˆ°æ­£å‘å’Œåå‘çš„è¯­è¨€åï¼Œå°†å…¶ç»“åˆå¯ä»¥å¾—åˆ°åŒå‘çš„è¯­è¨€æ¨¡å‹ï¼Œè¿™é‡Œå–å¯¹æ•°è¡¨ç¤ºä¸ºï¼š \\sum_{k=1}^N(log\\ p(t_k|t_1,t_2,...,t_{k-1};\\Theta_x,\\overrightarrow{\\Theta}_{LSTM} ,\\Theta_s )+log \\ p(t_k|t_{k+1},t_{k+2},...,t_{N};\\Theta_x,\\overleftarrow{\\Theta}_{LSTM} ,\\Theta_s) )\\\\å…¶ä¸­$\\Theta_x$ä¸ºtokenè¡¨ç¤ºçš„å‚æ•°ï¼Œ$\\Theta_s$ä¸ºsoftmaxå±‚çš„å‚æ•°ï¼Œ$\\overrightarrow{\\Theta}_{LSTM}$è¡¨ç¤ºå‰å‘è¯­è¨€æ¨¡å‹çš„å‚æ•°ï¼Œ$\\overleftarrow{\\Theta}_{LSTM}$è¡¨ç¤ºåå‘è¯­è¨€æ¨¡å‹çš„å‚æ•°ã€‚ 3.2 ELMoï¼ˆå¦‚ä½•è¡¨ç¤ºè¯å‘é‡ï¼‰å¾—åˆ°$L$å±‚çš„é¢„è®­ç»ƒåŒå‘æ·±åº¦è¯­è¨€æ¨¡å‹åï¼Œå¯¹äºtoken $t_k$ï¼Œä¸€å…±åŒ…å«äº†$2L+1$ä¸ªç›¸å…³çš„è¡¨ç¤ºï¼Œé›†åˆå¦‚ä¸‹ R_k=\\{x_{k}^{LM},\\overrightarrow{h^{LM}_{k,j}},\\overleftarrow{h^{LM}_{k,j}}|j=1,2,...,L \\}\\\\=\\{h_{k,j}^{LM} | j=0,...,L\\}æ³¨æ„$h_{k,0}^{LM}=x_{k}^{LM}ï¼Œh_{k,j}^{LM}=[\\overrightarrow{h^{LM}_{k,j}};\\overleftarrow{h^{LM}_{k,j}}]$,å…¶ä¸­$x_{k}^{LM}$ä¸ºtokenè¡¨ç¤ºï¼Œ$\\overrightarrow{h^{LM}_{k,j}},\\overleftarrow{h^{LM}_{k,j}}$åˆ†åˆ«ä¸ºæ­£åå‘è¯­è¨€æ¨¡å‹çš„è¡¨ç¤º å¯¹äºä¸‹æ¸¸ä»»åŠ¡ï¼Œéœ€è¦å°†$2L+1$ä¸ªè¡¨ç¤ºå‹ç¼©åˆ°ä¸€ä¸ªå‘é‡$ELmo_k^{task}$ï¼Œæœ€ç®€å•çš„åšæ³•æ˜¯åªå–é¡¶å±‚çš„è¡¨ç¤ºï¼Œå³ ELmo_k^{task}=E(R_k)=h_{k,L}^{LM}æ›´åŠ é€šç”¨çš„åšæ³•ä¸ºçº¿å½¢ç»„åˆè¾“å‡ºï¼Œå¦‚ä¸‹å›¾ï¼Œå…¬å¼è¡¨è¾¾ä¸º ELmo_k^{task}=E(R_k,\\Theta^{task})=\\gamma^{task}\\sum_{j=0}^{L}s_{j}^{task}h_{k,j}^{LM}å…¶ä¸­$\\gamma^{task}$ç”¨äºç¼©æ”¾å‘é‡ï¼Œ$s_{j}^{task}$è¡¨ç¤ºæƒé‡ï¼Œé€šè¿‡ä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ ã€‚ 3.3 Using biLMs for supervised NLP tasksï¼ˆfine tuneï¼‰å¯¹äºä¸‹æ¸¸ä»»åŠ¡æ¨¡å‹ï¼Œå¯ä»¥å¾—åˆ°ä¸è€ƒè™‘ä¸Šä¸‹æ–‡çš„é™æ€è¯å‘é‡$x_k$å’Œè€ƒè™‘ä¸Šä¸‹æ–‡çš„å‘é‡è¡¨ç¤º$h_k$ å¯¹äºä¸€éƒ¨åˆ†ä»»åŠ¡ï¼Œå°†$x_k$å’Œ$ ELMo_k^{task}$ æ‹¼æ¥ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹å¾ï¼š$[x_k;ELMo_k^{task}]$ å¯¹äºä¸€éƒ¨åˆ†ä»»åŠ¡ï¼Œå°† $h_k$å’Œ $ ELMo_k^{task}$ æ‹¼æ¥å¯æå‡æ•ˆæœï¼š$[h_k;ELMo_k^{task}]$ å‚è€ƒhttps://blog.csdn.net/linchuhai/article/details/97170541 https://zhuanlan.zhihu.com/p/63115885 https://zhuanlan.zhihu.com/p/88993965 https://arxiv.org/abs/1802.05365","link":"/2021/08/19/elmo/"},{"title":"Enhanced-RCNN An Efficient Method for Learning Sentence Similarity","text":"ç‰¹ç‚¹ï¼šéé¢„è®­ç»ƒï¼Œå‚æ•°é‡å°‘ 1 input encodingå¾—åˆ°ä¸¤ä¸ªencodingï¼ŒRNN Encodingï¼ŒRCNN Encoding 1 BiGRU $\\textbf{a}=\\{a_1,a_2,â€¦,a_{l_a}\\},\\textbf{a}$ æ˜¯å¥å­ï¼Œ$l_a$ æ˜¯å¥å­1çš„é•¿åº¦ å¾—åˆ°RNN Encodingï¼Œ$\\overline{\\textbf{p}}_i$ç»Ÿä¸€è¡¨ç¤º$\\overline{\\textbf{a}}_i,\\overline{\\textbf{b}}_i$ 2 CNN åœ¨ BiGRU ç¼–ç çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨ CNN æ¥è¿›è¡ŒäºŒæ¬¡ç¼–ç  ç»“æ„å¦‚ä¸‹ï¼Œâ€œnewtork in networkâ€,k æ˜¯å·ç§¯æ ¸çš„kernel sizeï¼Œæ¯”å¦‚k=1,å·ç§¯æ ¸ä¸º$1 \\times 1$ å¯¹äºæ¯ä¸ª CNN å•å…ƒï¼Œå…·ä½“çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹: å¾—åˆ° RCNN Encoding $\\widetilde{\\textbf{p}}_i$ 2 Interactive Sentence Representation1 Soft-attention Alignment attentionï¼š åŠ äº†attentionçš„rnn encodingï¼š 2 Interaction Modeling $\\overline{\\textbf{p}}$æ˜¯rnn encoding $\\hat{}$æ˜¯åŠ äº†attentionçš„rnn encoding $\\widetilde{}$æ˜¯rcnn encoding æœ€ç»ˆå¾—åˆ°Interactive Sentence Representationä¸º$\\textbf{o}_a,\\textbf{o}_b$ 3 Similarity Modeling1 Fusion Layer gæ˜¯é—¨æ§å‡½æ•° 2 Label Prediction å…¨è¿æ¥å±‚ 4 lossäº¤å‰ç†µ å‚è€ƒhttps://sci-hub.st/10.1145/3366423.3379998 https://zhuanlan.zhihu.com/p/138061003","link":"/2021/12/14/enhanced-rcnn/"},{"title":"ç‰¹å¾å‘é‡åŒ–","text":"ç‰¹å¾-&gt;one hot-&gt; embedding ç›®çš„ï¼šone hot è¡¨ç¤ºç‰¹å¾å¤ªç¨€ç–ï¼Œä¸åˆ©äºè®­ç»ƒï¼Œè€Œä¸”å‚æ•°è¿‡å¤šï¼Œé€Ÿåº¦æ…¢ ä¸¾ä¾‹å­ï¼š https://arxiv.org/pdf/1706.06978.pdf DINè®ºæ–‡ä¸­çš„ç‰¹å¾è¡¨ç¤ºå’Œembddingå±‚","link":"/2021/11/22/emb/"},{"title":"ç†µï¼ŒKLæ•£åº¦ï¼Œäº¤å‰ç†µï¼ŒJSæ•£åº¦","text":"GANéœ€è¦KLæ•£åº¦å’ŒJSæ•£åº¦ï¼Œæ‰€ä»¥å…ˆé¢„çƒ­ã€‚ 1.ç†µä¿¡æ¯é‡ä¸ºï¼š \\begin{align} I(x) &= - \\log(p(x)) \\tag{1} \\end{align}ç†µä¸ºä¿¡æ¯é‡çš„ç®—æœ¯å¹³å‡ï¼š H(x) = - \\sum_{i=1}^{n}p(x_i)log(p(x_i)) \\tag{2}2.äº¤å‰ç†µäº¤å‰ç†µä¸º H(P,Q) = -\\sum_{i=1}^np(x_i)logq(x_i)\\tag{3} 3.KLæ•£åº¦å¯¹äºåŒä¸€ä¸ªéšæœºå˜é‡æœ‰ä¸¤ä¸ªå•ç‹¬çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨KLæ•£åº¦(Kullback-Leibler divergence)æ¥è¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„å·®å¼‚ã€‚åœ¨æœºå™¨å­¦ä¹ çš„æŸå¤±å‡½æ•°çš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾$P$ä¸ºæ ·æœ¬çš„çœŸå®åˆ†å¸ƒï¼Œ$Q$ç”¨æ¥è¡¨ç¤ºæ¨¡å‹æ‰€é¢„æµ‹çš„åˆ†å¸ƒï¼Œä½¿ç”¨KLæ•£åº¦æ¥è¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚KLæ•£åº¦ç­‰äºäº¤å‰ç†µå‡å»ç†µ \\begin{align} D_{KL}(P||Q) &= \\sum_{i=1}^np(x_i)log(\\frac{p(x_i)}{q(x_i)}) \\notag\\\\ &=\\sum_{i=1}^np(x_i)(logp(x_i)-logq(x_i)) \\notag\\\\ &=\\sum_{i=1}^n[p(x_i)logp(x_i)-p(x_i)logq(x_i)] \\notag\\\\ &=\\sum_{i=1}^np(x_i)logp(x_i)-\\sum_{i=1}^np(x_i)logq(x_i) \\\\ &=-H(P)+H(P,Q)\\tag{4} \\end{align}$P$å’Œ$Q$æ¦‚ç‡åˆ†å¸ƒè¶Šæ¥è¿‘ï¼Œ$D_{KL}(P||Q)$è¶Šå°ã€‚ KLæ•£åº¦ä¸äº¤å‰ç†µåŒºåˆ«ä¸è”ç³» https://blog.csdn.net/Dby_freedom/article/details/83374650 KLæ•£åº¦ä¸»è¦æœ‰ä¸¤ä¸ªæ€§è´¨ï¼š ï¼ˆ1ï¼‰ä¸å¯¹ç§°æ€§ å°½ç®¡KLæ•£åº¦ä»ç›´è§‚ä¸Šæ˜¯ä¸ªè·ç¦»å‡½æ•°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„åº¦é‡ï¼Œå› ä¸ºå®ƒä¸å…·æœ‰å¯¹ç§°æ€§ï¼Œå³$D_{KL}(P||Q)\\neq D_{KL}(Q||P)$ã€‚ ï¼ˆ2ï¼‰éè´Ÿæ€§ å³$D_{KL}(P||Q) \\geq 0$ã€‚ 4.JSæ•£åº¦JSæ•£åº¦ä¹Ÿæ˜¯ç”¨äºåº¦é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„ç›¸ä¼¼åº¦ï¼Œå…¶è§£å†³äº†KLæ•£åº¦ä¸å¯¹ç§°çš„ç¼ºç‚¹ JS(P||Q) = \\frac{1}{2}KL(P||\\frac{P+Q}{2})+\\frac{1}{2}KL(Q||\\frac{P+Q}{2}) \\tag{5}ä¸åŒäºKLä¸»è¦åœ¨ä¸¤æ–¹é¢ï¼š ï¼ˆ1ï¼‰å€¼åŸŸèŒƒå›´ JSæ•£åº¦çš„å€¼åŸŸèŒƒå›´æ˜¯[0,1]ï¼Œç›¸åŒåˆ™æ˜¯0ï¼Œç›¸åä¸º1ã€‚ ï¼ˆ2ï¼‰å¯¹ç§°æ€§ å³$ JS(P||Q)=JS(Q||P)$ï¼Œä»æ•°å­¦è¡¨è¾¾å¼ä¸­å°±å¯ä»¥çœ‹å‡ºã€‚ å‚è€ƒhttps://www.cnblogs.com/Mrfanl/p/11938139.html https://zhuanlan.zhihu.com/p/346518942 https://www.w3cschool.cn/article/83016451.html","link":"/2021/08/18/entropy/"},{"title":"é›†æˆå­¦ä¹ ","text":"ç›®å‰å¸¸è§çš„é›†æˆå­¦ä¹ å¯ä»¥åˆ†ç±»ä¸ºï¼š1.Bagging 2.Boosting 3.Stacking 4.Blending 1.Baggingbaggingæ˜¯è§£å†³varianceé—®é¢˜ã€‚ 2.Boostingboostingæ˜¯è§£å†³biasé—®é¢˜ã€‚ Baggingï¼ŒBoostingäºŒè€…ä¹‹é—´çš„åŒºåˆ« https://zhuanlan.zhihu.com/p/81340270 3.Stackingstackingå’Œboostingçš„æœ€å¤§åŒºåˆ«åœ¨äºï¼šboostingçš„åŸºå­¦ä¹ å™¨æ˜¯ä¸€ä¸ªï¼Œstackingçš„åŸºå­¦ä¹ å™¨æ˜¯å¤šä¸ª 4.Blendingå’ŒstackingåŒºåˆ«ï¼š https://www.jianshu.com/p/4380cd1def76 å‚è€ƒhttps://zhuanlan.zhihu.com/p/105038453 https://zhuanlan.zhihu.com/p/126968534 https://blog.csdn.net/starter_____/article/details/79328749","link":"/2021/09/06/ensemble/"},{"title":"ETL","text":"https://www.cnblogs.com/yjd_hycf_space/p/7772722.html https://blog.csdn.net/qq_33269009/article/details/90522087 https://blog.csdn.net/Stubborn_Cow/article/details/48420997 æ³¨æ„ï¼šå¾ˆå¤šäººç†è§£çš„ETLæ˜¯åœ¨ç»è¿‡å‰ä¸¤ä¸ªéƒ¨åˆ†ä¹‹åï¼ŒåŠ è½½åˆ°æ•°æ®ä»“åº“çš„æ•°æ®åº“ä¸­å°±å®Œäº‹äº†ã€‚ETLä¸ä»…ä»…æ˜¯åœ¨æºæ•°æ®â€”&gt;ODSè¿™ä¸€æ­¥ï¼ŒODSâ€”&gt;DW, DWâ€”&gt;DMåŒ…å«æ›´ä¸ºé‡è¦å’Œå¤æ‚çš„ETLè¿‡ç¨‹ã€‚","link":"/2022/02/09/etl/"},{"title":"åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°é‡å¾ˆå¤§(ä¸‡ä»¥ä¸Š)æ€ä¹ˆå¤„ç†ï¼Ÿ","text":"https://www.zhihu.com/question/387899184 Extreme Multi Label Classificationï¼ŒXMLï¼Œå¯ä»¥æä¾›ä¸€äº›å¯å‘ https://zhuanlan.zhihu.com/p/131584886","link":"/2021/10/25/extreme-num-classify/"},{"title":"Deep Learning Recommendation Model for Personalization and Recommendation Systems","text":"Facebook19å¹´å‡ºå“çš„æ¨èç³»ç»Ÿçš„paperï¼ŒåŸæ–‡åœ°å€ https://arxiv.org/pdf/1906.00091.pdf DLRM ç»“æ„(deep learning recommendation model) å‚è€ƒhttps://zhuanlan.zhihu.com/p/82839874","link":"/2021/10/11/facebook-recommend-sys/"},{"title":"fasttext","text":"1ã€æ–‡æœ¬åˆ†ç±»1.1 n-gramç”±äºBag of wordsä¸è€ƒè™‘è¯è¯­çš„é¡ºåºï¼Œå› æ­¤å¼•å…¥bag of n-gramã€‚é’ˆå¯¹è‹±æ–‡ï¼Œè¯å†…çš„æ˜¯char n-gramï¼Œç”¨äºè¯å‘é‡ï¼›è¯ä¹‹é—´çš„æ˜¯word n-gramï¼Œç”¨äºåˆ†ç±»ï¼›å¯¹äºä¸­æ–‡ï¼Œå­˜åœ¨è¯ç²’åº¦å’Œå­—ç²’åº¦ã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œå¥å­Aä¸ºâ€ä»Šå¤©å¤©æ°”çœŸä¸é”™â€ï¼Œè¿™é‡Œä»¥è¯ç²’åº¦ä¸¾ä¾‹ï¼Œå…ˆåˆ†è¯ä¸º[â€œä»Šå¤©â€ï¼Œâ€å¤©æ°”â€ï¼Œâ€çœŸâ€œï¼Œâ€ä¸é”™â€œ] uni-gramï¼šä»Šå¤© å¤©æ°” çœŸ ä¸é”™ 2-gramä¸ºï¼šä»Šå¤©/å¤©æ°” å¤©æ°”/çœŸ çœŸ/ä¸é”™ 3-gramä¸ºï¼šä»Šå¤©/å¤©æ°”/çœŸ å¤©æ°”/çœŸ/ä¸é”™ ç”±äºn-gramçš„é‡è¿œæ¯”wordå¤§çš„å¤šï¼Œå®Œå…¨å­˜ä¸‹æ‰€æœ‰çš„n-gramä¹Ÿä¸ç°å®ã€‚FastTexté‡‡ç”¨äº†hashing trickçš„æ–¹å¼ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ç”¨å“ˆå¸Œçš„æ–¹å¼æ—¢èƒ½ä¿è¯æŸ¥æ‰¾æ—¶O(1)çš„æ•ˆç‡ï¼Œåˆå¯èƒ½æŠŠå†…å­˜æ¶ˆè€—æ§åˆ¶åœ¨O(buckets * dim)èŒƒå›´å†…ã€‚ä¸è¿‡è¿™ç§æ–¹æ³•æ½œåœ¨çš„é—®é¢˜æ˜¯å­˜åœ¨å“ˆå¸Œå†²çªï¼Œä¸åŒçš„n-gramå¯èƒ½ä¼šå…±äº«åŒä¸€ä¸ªembeddingã€‚å¦‚æœbucketså–çš„è¶³å¤Ÿå¤§ï¼Œè¿™ç§å½±å“ä¼šå¾ˆå°ã€‚ ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758def build_dataset(config, ues_word): if ues_word: tokenizer = lambda x: x.split(' ') # word-level else: tokenizer = lambda x: [y for y in x] # char-level if os.path.exists(config.vocab_path): vocab = pkl.load(open(config.vocab_path, 'rb')) else: vocab = build_vocab(config.train_path, tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1) pkl.dump(vocab, open(config.vocab_path, 'wb')) print(f&quot;Vocab size: {len(vocab)}&quot;) def biGramHash(sequence, t, buckets): t1 = sequence[t - 1] if t - 1 &gt;= 0 else 0 return (t1 * 14918087) % buckets def triGramHash(sequence, t, buckets): t1 = sequence[t - 1] if t - 1 &gt;= 0 else 0 t2 = sequence[t - 2] if t - 2 &gt;= 0 else 0 return (t2 * 14918087 * 18408749 + t1 * 14918087) % buckets def load_dataset(path, pad_size=32): contents = [] with open(path, 'r', encoding='UTF-8') as f: for line in tqdm(f): lin = line.strip() if not lin: continue content, label = lin.split('\\t') words_line = [] token = tokenizer(content) seq_len = len(token) if pad_size: if len(token) &lt; pad_size: token.extend([PAD] * (pad_size - len(token))) else: token = token[:pad_size] seq_len = pad_size # word to id for word in token: words_line.append(vocab.get(word, vocab.get(UNK))) # fasttext ngram buckets = config.n_gram_vocab bigram = [] trigram = [] # ------ngram------ for i in range(pad_size): bigram.append(biGramHash(words_line, i, buckets)) trigram.append(triGramHash(words_line, i, buckets)) # ----------------- contents.append((words_line, int(label), seq_len, bigram, trigram)) return contents # [([...], 0), ([...], 1), ...] train = load_dataset(config.train_path, config.pad_size) dev = load_dataset(config.dev_path, config.pad_size) test = load_dataset(config.test_path, config.pad_size) return vocab, train, dev, test 1.2 ç½‘ç»œç»“æ„ æ¨¡å‹ç»“æ„ä¸Šword2vecçš„cbowæ¨¡å‹å¾ˆåƒ è¾“å…¥å±‚ï¼šä¸¾ä¸ªä¾‹å­ï¼Œè¾“å…¥æ–‡æœ¬â€ä»Šå¤©å¤©æ°”çœŸä¸é”™â€ï¼Œè¯ç²’åº¦çš„2-gramä¸º x_2=\\begin{bmatrix} emb_{ä»Šå¤©/å¤©æ°”}ï¼Œemb_{å¤©æ°”/çœŸ}ï¼Œemb_{ çœŸ/ä¸é”™} \\end{bmatrix},embä¸ºè¯å‘é‡çŸ©é˜µ \\\\x_{1},x_{2},...,x_{N}æœ€åè¾“å…¥åˆ°ä¸­é—´å±‚çš„å½¢å¼ä¸º: mean(\\begin{bmatrix}x_1 \\\\ x_2 \\\\...\\\\x_N \\end{bmatrix}),å…¶ä¸­meanä¸ºå¯¹æ¯ä¸ªxçš„åˆ—æ±‚å¹³å‡ä¸­é—´å±‚ï¼šçº¿å½¢å±‚+reluä½œä¸ºæ¿€æ´»å‡½æ•° è¾“å‡ºå±‚ï¼šä¸ºç®€å•çš„çº¿å½¢å±‚ ä»£ç ï¼š 123456789101112131415161718192021222324252627class Model(nn.Module): def __init__(self, config): super(Model, self).__init__() if config.embedding_pretrained is not None: self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False) else: self.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - 1) self.embedding_ngram2 = nn.Embedding(config.n_gram_vocab, config.embed) self.embedding_ngram3 = nn.Embedding(config.n_gram_vocab, config.embed) self.dropout = nn.Dropout(config.dropout) self.fc1 = nn.Linear(config.embed * 3, config.hidden_size) # self.dropout2 = nn.Dropout(config.dropout) self.fc2 = nn.Linear(config.hidden_size, config.num_classes) def forward(self, x): out_word = self.embedding(x[0]) out_bigram = self.embedding_ngram2(x[2]) out_trigram = self.embedding_ngram3(x[3]) out = torch.cat((out_word, out_bigram, out_trigram), -1) out = out.mean(dim=1) out = self.dropout(out) out = self.fc1(out) out = F.relu(out) out = self.fc2(out) return out 1.3 åˆ†å±‚softmaxå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œç¥ç»ç½‘ç»œçš„è¾“å‡ºç»“æœéœ€è¦ç»è¿‡softmaxå°†å…¶è½¬ä¸ºæ¦‚ç‡åˆ†å¸ƒåæ‰å¯ä»¥åˆ©ç”¨äº¤å‰ç†µè®¡ç®—loss ç”±äºæ™®é€šsoftmaxçš„è®¡ç®—æ•ˆç‡æ¯”è¾ƒä½ï¼Œè®¡ç®—æ•ˆç‡ä¸º$O(Kd)$ä½¿ç”¨åˆ†å±‚çš„softmaxæ—¶é—´å¤æ‚åº¦å¯ä»¥è¾¾åˆ°$dlogK$ï¼Œ$K$ä¸ºåˆ†ç±»çš„æ•°é‡ï¼Œ$d$ä¸ºå‘é‡çš„ç»´åº¦ 1.3.1 æ™®é€šsoftmaxå‡è®¾è¾“å‡ºä¸º$Y_{pred}=[y_1,y_2,â€¦,y_K]$,åˆ™$P_{y_i}$ä¸º P_{y_i}=\\frac{e_{y_i}}{\\sum_{j=0}^Ke^{y_j}}å…¶ä¸­$y_i$çš„ç»´åº¦ä¸º$d$ï¼Œä»å…¬å¼å¯ä»¥çœ‹å‡ºè®¡ç®—æ•ˆç‡ä¸º$O(Kd)$ 1.3.2 åˆ†å±‚softmaxéœå¤«æ›¼æ ‘å¯ä»¥å‚è€ƒ https://zhuanlan.zhihu.com/p/154356949 ä¸ºä»€ä¹ˆè¦éœå¤«æ›¼ï¼Œæ™®é€šçš„ä¸è¡Œï¼Ÿ åˆ†å±‚softmaxæ ¸å¿ƒæ€æƒ³ä¸ºåˆ©ç”¨è®­ç»ƒæ ·æœ¬æ„å»ºéœå¤«æ›¼æ ‘ï¼Œå¦‚ä¸‹ æ ‘çš„ç»“æ„æ˜¯æ ¹æ®ä¸åŒç±»åœ¨æ ·æœ¬ä¸­å‡ºç°çš„é¢‘æ¬¡æ„é€ çš„ï¼Œå³é¢‘æ¬¡è¶Šå¤§çš„èŠ‚ç‚¹è·ç¦»æ ¹èŠ‚ç‚¹è¶Šè¿‘ã€‚$K$ä¸ªä¸åŒçš„ç±»ç»„æˆæ‰€æœ‰çš„å¶å­èŠ‚ç‚¹ï¼Œ$K-1ä¸ª$å†…éƒ¨èŠ‚ç‚¹ä½œä¸ºå‚æ•°ã€‚ä»æ ¹èŠ‚ç‚¹åˆ°æŸä¸ªå¶å­èŠ‚ç‚¹$y_i$ç»è¿‡çš„èŠ‚ç‚¹å’Œè¾¹å½¢æˆä¸€æ¡è·¯å¾„ï¼Œè·¯å¾„é•¿åº¦è¡¨ç¤ºä¸º $L_{y_i}$,$n_{(y_i,j)}$è¡¨ç¤ºè·¯å¾„ä¸Šçš„èŠ‚ç‚¹ï¼Œé‚£ä¹ˆ P_{y_i}=\\prod \\limits_{j=1}^{L_{y_i}}P_{(n(y_{i},j),left\\ or\\ right)} \\\\=\\prod \\limits_{j=0}^{L_{y_i}-1}\\sigma(f(n(y_i,j+1)==LC(n(y_i,j))){\\theta_{n(y_i,j)}^T} Y) \\\\å…¶ä¸­LC(n(y_i,j)è¡¨ç¤ºn(y_i,j)çš„å·¦å­©å­ï¼Œ\\sigma ä¸ºSIGMODå‡½æ•°ï¼Œf(m)=\\begin{equation}\\left\\{ \\begin{aligned} 1 && if \\ m==true \\\\ -1 & & \\ else \\\\ \\end{aligned} \\right. \\end{equation}ä»å…¬å¼å¯ä»¥çœ‹å‡ºæ—¶é—´å¤æ‚åº¦é™ä½è‡³$dlogK$ã€‚ ä»¥å›¾ä¸­$y_2$ä¸ºä¾‹ï¼š P_{y_2}=P_{(n(y_{2},1),left)}\\cdot P_{(n(y_{2},2),left)}\\cdot P_{(n(y_{2},3),right)} \\\\=\\sigma({\\theta_{n(y_2,1)}^T} Y)\\cdot \\sigma({\\theta_{n(y_2,2)}^T} Y) \\cdot \\sigma({-\\theta_{n(y_2,3)}^T} Y)ä»æ ¹èŠ‚ç‚¹èµ°åˆ°å¶å­èŠ‚ç‚¹ $y_2$ ï¼Œå®é™…ä¸Šæ˜¯åœ¨åšäº†3æ¬¡é€»è¾‘å›å½’ã€‚ 2.è®­ç»ƒè¯å‘é‡https://arxiv.org/abs/1607.04606 å‚è€ƒhttps://arxiv.org/abs/1607.01759 https://zhuanlan.zhihu.com/p/32965521 https://blog.csdn.net/qq_27009517/article/details/80676022 http://alex.smola.org/papers/2009/Weinbergeretal09.pdf https://arxiv.org/abs/1607.04606 fasttextå·¥å…· https://github.com/facebookresearch/fastText","link":"/2021/07/19/fasttext/"},{"title":"å®¹é”™æœºåˆ¶","text":"åœ¨åˆ†å¸ƒå¼æ¶æ„ä¸­ï¼Œå½“æŸä¸ªèŠ‚ç‚¹å‡ºç°æ•…éšœï¼Œå…¶ä»–èŠ‚ç‚¹åŸºæœ¬ä¸å—å½±å“ã€‚è¿™æ—¶åªéœ€è¦é‡å¯åº”ç”¨ï¼Œæ¢å¤ä¹‹å‰æŸä¸ªæ—¶é—´ç‚¹çš„çŠ¶æ€ç»§ç»­å¤„ç†å°±å¯ä»¥äº†ã€‚è¿™ä¸€åˆ‡çœ‹ä¼¼ç®€å•ï¼Œå¯æ˜¯åœ¨å®æ—¶æµå¤„ç†ä¸­ï¼Œæˆ‘ä»¬ä¸ä»…éœ€è¦ä¿è¯æ•…éšœåèƒ½å¤Ÿé‡å¯ç»§ç»­è¿è¡Œï¼Œè¿˜è¦ä¿è¯ç»“æœçš„æ­£ç¡®æ€§ã€æ•…éšœæ¢å¤çš„é€Ÿåº¦ã€å¯¹å¤„ç†æ€§èƒ½çš„å½±å“ï¼Œè¿™å°±éœ€è¦åœ¨æ¶æ„ä¸Šåšå‡ºæ›´åŠ ç²¾å·§çš„è®¾è®¡ã€‚åœ¨Flinkä¸­ï¼Œæœ‰ä¸€å¥—å®Œæ•´çš„å®¹é”™æœºåˆ¶ï¼ˆ fault toleranceï¼‰æ¥ä¿è¯æ•…éšœåçš„æ¢å¤ï¼Œå…¶ä¸­æœ€é‡è¦çš„å°±æ˜¯æ£€æŸ¥ç‚¹ï¼ˆ checkpointï¼‰ã€‚åœ¨ç¬¬ä¹ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»è¿‡æ£€æŸ¥ç‚¹çš„åŸºæœ¬æ¦‚å¿µå’Œç”¨é€”ï¼Œæ¥ä¸‹æ¥æˆ‘ ä»¬å°±æ·±å…¥æ¢è®¨ä¸€ä¸‹æ£€æŸ¥ç‚¹çš„åŸç†å’Œ Flinkçš„å®¹é”™æœºåˆ¶ã€‚","link":"/2022/03/27/fault-tolerance/"},{"title":"ç‰¹å¾å·¥ç¨‹","text":"https://zhuanlan.zhihu.com/p/111296130","link":"/2021/10/21/feature-en/"},{"title":"ç‰¹å¾æå–å™¨","text":"å¤§è‡´åˆ†ä¸ºä¸‰ç±»ï¼šCNNï¼ŒLSTMï¼Œtransformer block 1.CNN æ»‘åŠ¨éƒ¨åˆ†ä¸ºå·ç§¯æ ¸ 2.LSTM 3.transformer block å‚è€ƒhttps://www.cnblogs.com/sandwichnlp/p/11612596.html#transformer","link":"/2021/07/24/feature-extractor/"},{"title":"feature scale","text":"","link":"/2022/08/04/feature-scale/"},{"title":"Felix Flexible Text Editing Through Tagging and Insertion","text":"googleç»§lasertaggerä¹‹åçš„åˆä¸€ç¯‡text edit paper In contrast to conventional sequence-to-sequence (seq2seq) models, FELIX is efficient in low-resource settings and fast at inference time, while being capable of modeling flexible input-output transformations. We achieve this by decomposing the text-editing task into two sub-tasks: tagging to decide on the subset of input tokens and their order in the output text and insertion to in-fill the missing tokens in the output not present in the input. 1 Introduction In particular, we have designed FELIX with the following requirements in mind: Sample efficiency, Fast inference time, Flexible text editing 2 Model descriptionFELIX decomposes the conditional probability of generating an output sequence $y$ from an input$x$ as follows: p(\\textbf{y}|\\textbf{x})=p_{ins}(\\textbf{y}|\\textbf{y}^m)p_{tag}(\\textbf{y}^t,\\pi|\\textbf{x})2.1 Tagging Modeltrained to optimize both the tagging and pointing loss: \\mathcal{L}=\\mathcal{L}_{pointing }+\\lambda\\mathcal{L}_{tagging }Tagging : tag sequence $\\textbf{y}^t$ç”±3ç§tagç»„æˆï¼š$KEEP$ï¼Œ$DELETE$ï¼Œ$INSERT (INS)$ Tags are predicted by applying a single feedforward layer $f$ to the output of the encoder $\\textbf{h}^L$ (the source sentence is first encoded using a 12-layer BERT-base model). $\\textbf{y}^t_i=argmax(f(\\textbf{h}^L_i))$ Pointing: Given a sequence $\\textbf{x}$ and the predicted tags $\\textbf{y}^t$ , the re-ordering model generates a permutation $\\pi$ so that from $\\pi$and $\\textbf{y}^t$ we can reconstruct the insertion model input $\\textbf{y}^m$. Thus we have: p(\\textbf{y}^m|\\textbf{x}) \\approx \\prod \\limits_{i}p(\\pi(i)|\\textbf{x},\\textbf{y}^t,i)p(\\textbf{y}_i^t|\\textbf{x})Our implementation is based on a pointer network. The output of this model is a series of predicted pointers (source token â†’ next target token) The input to the Pointer layer at position $i$: \\textbf{h}^{L+1}_{i}=f([\\textbf{h}^{L}_{i};e(\\textbf{y}_i^t);e(\\textbf{p}_i)])å…¶ä¸­$e(\\textbf{y}_i^t)$is the embedding of the predicted tagï¼Œ$e(\\textbf{p}_i)$ is the positional embedding The pointer network attends over all hidden states, as such: p(\\pi(i)|\\textbf{h}_i^{L+1})=attention(\\textbf{h}_i^{L+1},\\textbf{h}_{\\pi(i)}^{L+1})å…¶ä¸­$\\textbf{h}_i^{L+1}$ as $Q $, $\\textbf{h}_{\\pi(i)}^{L+1}$ as $K$ When realizing the pointers, we use a constrained beam search 2.2 Insertion Model To represent masked token spans we consider two options: masking and infilling. In the former case the tagging model predicts how many tokens need to be inserted by specializing the $INSERT$ tag into $INS_k$, where $k$ translates the span into $ k$ $MASK$ tokens. For the infilling case the tagging model predicts a generic $INS$ tag. Note that we preserve the deletedâ€‹ span in the input to the insertion model by enclosing it between $[REPL]$ and $[/REPL]$ tags. our insertion model is also based on a 12-layer BERT-base and we can directly take advantage of the BERT-style pretrained checkpoints. å‚è€ƒhttps://aclanthology.org/2020.findings-emnlp.111.pdf","link":"/2021/09/30/felix/"},{"title":"Generalizing from a Few Examples A Survey on Few-Shot Learning","text":"paperï¼š https://arxiv.org/abs/1904.05046 git: https://github.com/tata1661/FSL-Mate/tree/master/FewShotPapers#Applications åŸæ–‡æŒ‰åº”ç”¨å¯¹FSLåšäº†æ€»ç»“ï¼Œä¸NLPç›¸å…³çš„æœ‰ï¼š High-risk learning: Acquiring new word vectors from tiny data, in EMNLP, 2017. A. Herbelot and M. Baroni. paper MetaEXP: Interactive explanation and exploration of large knowledge graphs, in TheWebConf, 2018. F. Behrens, S. Bischoff, P. Ladenburger, J. RÃ¼ckin, L. Seidel, F. Stolp, M. Vaichenker, A. Ziegler, D. Mottin, F. Aghaei, E. MÃ¼ller, M. Preusse, N. MÃ¼ller, and M. Hunger. paper code Few-shot representation learning for out-of-vocabulary words, in ACL, 2019. Z. Hu, T. Chen, K.-W. Chang, and Y. Sun. paper Learning to customize model structures for few-shot dialogue generation tasks, in ACL, 2020. Y. Song, Z. Liu, W. Bi, R. Yan, and M. Zhang. paper Few-shot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network, in ACL, 2020. Y. Hou, W. Che, Y. Lai, Z. Zhou, Y. Liu, H. Liu, and T. Liu. paper Meta-reinforced multi-domain state generator for dialogue systems, in ACL, 2020. Y. Huang, J. Feng, M. Hu, X. Wu, X. Du, and S. Ma. paper Few-shot knowledge graph completion, in AAAI, 2020. C. Zhang, H. Yao, C. Huang, M. Jiang, Z. Li, and N. V. Chawla. paper Universal natural language processing with limited annotations: Try few-shot textual entailment as a start, in EMNLP, 2020. W. Yin, N. F. Rajani, D. Radev, R. Socher, and C. Xiong. paper code Simple and effective few-shot named entity recognition with structured nearest neighbor learning, in EMNLP, 2020. Y. Yang, and A. Katiyar. paper code Discriminative nearest neighbor few-shot intent detection by transferring natural language inference, in EMNLP, 2020. J. Zhang, K. Hashimoto, W. Liu, C. Wu, Y. Wan, P. Yu, R. Socher, and C. Xiong. paper code Few-shot learning for opinion summarization, in EMNLP, 2020. A. BraÅ¾inskas, M. Lapata, and I. Titov. paper code Adaptive attentional network for few-shot knowledge graph completion, in EMNLP, 2020. J. Sheng, S. Guo, Z. Chen, J. Yue, L. Wang, T. Liu, and H. Xu. paper code Few-shot complex knowledge base question answering via meta reinforcement learning, in EMNLP, 2020. Y. Hua, Y. Li, G. Haffari, G. Qi, and T. Wu. paper code Self-supervised meta-learning for few-shot natural language classification tasks, in EMNLP, 2020. T. Bansal, R. Jha, T. Munkhdalai, and A. McCallum. paper code Uncertainty-aware self-training for few-shot text classification, in NeurIPS, 2020. S. Mukherjee, and A. Awadallah. paper code Learning to extrapolate knowledge: Transductive few-shot out-of-graph link prediction, in NeurIPS, 2020:. J. Baek, D. B. Lee, and S. J. Hwang. paper code MetaNER: Named entity recognition with meta-learning, in TheWebConf, 2020. J. Li, S. Shang, and L. Shao. paper Conditionally adaptive multi-task learning: Improving transfer learning in NLP using fewer parameters &amp; less data, in ICLR, 2021. J. Pilault, A. E. hattami, and C. Pal. paper code Revisiting few-sample BERT fine-tuning, in ICLR, 2021. T. Zhang, F. Wu, A. Katiyar, K. Q. Weinberger, and Y. Artzi. paper code Few-shot conversational dense retrieval, in SIGIR, 2021. S. Yu, Z. Liu, C. Xiong, T. Feng, and Z. Liu. paper code Relational learning with gated and attentive neighbor aggregator for few-shot knowledge graph completion, in SIGIR, 2021. G. Niu, Y. Li, C. Tang, R. Geng, J. Dai, Q. Liu, H. Wang, J. Sun, F. Huang, and L. Si. paper Few-shot language coordination by modeling theory of mind, in ICML, 2021. H. Zhu, G. Neubig, and Y. Bisk. paper code Graph-evolving meta-learning for low-resource medical dialogue generation, in AAAI, 2021. S. Lin, P. Zhou, X. Liang, J. Tang, R. Zhao, Z. Chen, and L. Lin. paper KEML: A knowledge-enriched meta-learning framework for lexical relation classification, in AAAI, 2021. C. Wang, M. Qiu, J. Huang, and X. He. paper Few-shot learning for multi-label intent detection, in AAAI, 2021. Y. Hou, Y. Lai, Y. Wu, W. Che, and T. Liu. paper code SALNet: Semi-supervised few-shot text classification with attention-based lexicon construction, in AAAI, 2021. J.-H. Lee, S.-K. Ko, and Y.-S. Han. paper Learning from my friends: Few-shot personalized conversation systems via social networks, in AAAI, 2021. Z. Tian, W. Bi, Z. Zhang, D. Lee, Y. Song, and N. L. Zhang. paper code Relative and absolute location embedding for few-shot node classification on graph, in AAAI, 2021. Z. Liu, Y. Fang, C. Liu, and S. C.H. Hoi. paper Few-shot question answering by pretraining span selection, in ACL-IJCNLP, 2021. O. Ram, Y. Kirstain, J. Berant, A. Globerson, and O. Levy. paper code A closer look at few-shot crosslingual transfer: The choice of shots matters, in ACL-IJCNLP, 2021. M. Zhao, Y. Zhu, E. Shareghi, I. Vulic, R. Reichart, A. Korhonen, and H. SchÃ¼tze. paper code Learning from miscellaneous other-classwords for few-shot named entity recognition, in ACL-IJCNLP, 2021. M. Tong, S. Wang, B. Xu, Y. Cao, M. Liu, L. Hou, and J. Li. paper code Distinct label representations for few-shot text classification, in ACL-IJCNLP, 2021. S. Ohashi, J. Takayama, T. Kajiwara, and Y. Arase. paper code Entity concept-enhanced few-shot relation extraction, in ACL-IJCNLP, 2021. S. Yang, Y. Zhang, G. Niu, Q. Zhao, and S. Pu. paper code On training instance selection for few-shot neural text generation, in ACL-IJCNLP, 2021. E. Chang, X. Shen, H.-S. Yeh, and V. Demberg. paper code Unsupervised neural machine translation for low-resource domains via meta-learning, in ACL-IJCNLP, 2021. C. Park, Y. Tae, T. Kim, S. Yang, M. A. Khan, L. Park, and J. Choo. paper code Meta-learning with variational semantic memory for word sense disambiguation, in ACL-IJCNLP, 2021. Y. Du, N. Holla, X. Zhen, C. Snoek, and E. Shutova. paper code Multi-label few-shot learning for aspect category detection, in ACL-IJCNLP, 2021. M. Hu, S. Z. H. Guo, C. Xue, H. Gao, T. Gao, R. Cheng, and Z. Su. paper TextSETTR: Few-shot text style extraction and tunable targeted restyling, in ACL-IJCNLP, 2021. P. Rileya, N. Constantb, M. Guob, G. Kumarc, D. Uthusb, and Z. Parekh. paper Few-shot text ranking with meta adapted synthetic weak supervision, in ACL-IJCNLP, 2021. S. Sun, Y. Qian, Z. Liu, C. Xiong, K. Zhang, J. Bao, Z. Liu, and P. Bennett. paper code PROTAUGMENT: Intent detection meta-learning through unsupervised diverse paraphrasing, in ACL-IJCNLP, 2021. T. Dopierre, C. Gravier, and W. Logerais. paper code AUGNLG: Few-shot natural language generation using self-trained data augmentation, in ACL-IJCNLP, 2021. X. Xu, G. Wang, Y.-B. Kim, and S. Lee. paper code Meta self-training for few-shot neural sequence labeling, in KDD, 2021. Y. Wang, S. Mukherjee, H. Chu, Y. Tu, M. Wu, J. Gao, and A. H. Awadallah. paper code Knowledge-enhanced domain adaptation in few-shot relation classification, in KDD, 2021. J. Zhang, J. Zhu, Y. Yang, W. Shi, C. Zhang, and H. Wang. paper code Few-shot text classification with triplet networks, data augmentation, and curriculum learning, in NAACL-HLT, 2021. J. Wei, C. Huang, S. Vosoughi, Y. Cheng, and S. Xu. paper code Few-shot intent classification and slot filling with retrieved examples, in NAACL-HLT, 2021. D. Yu, L. He, Y. Zhang, X. Du, P. Pasupat, and Q. Li. paper Non-parametric few-shot learning for word sense disambiguation, in NAACL-HLT, 2021. H. Chen, M. Xia, and D. Chen. paper code Towards few-shot fact-checking via perplexity, in NAACL-HLT, 2021. N. Lee, Y. Bang, A. Madotto, and P. Fung. paper ConVEx: Data-efficient and few-shot slot labeling, in NAACL-HLT, 2021. M. Henderson, and I. Vulic. paper Few-shot text generation with natural language instructions, in EMNLP, 2021. T. Schick, and H. SchÃ¼tze. paper Towards realistic few-shot relation extraction, in EMNLP, 2021. S. Brody, S. Wu, and A. Benton. paper code Few-shot emotion recognition in conversation with sequential prototypical networks, in EMNLP, 2021. G. Guibon, M. Labeau, H. Flamein, L. Lefeuvre, and C. Clavel. paper code Learning prototype representations across few-shot tasks for event detection, in EMNLP, 2021. V. Lai, F. Dernoncourt, and T. H. Nguyen. paper Exploring task difficulty for few-shot relation extraction, in EMNLP, 2021. J. Han, B. Cheng, and W. Lu. paper code Honey or poison? Solving the trigger curse in few-shot event detection via causal intervention, in EMNLP, 2021. J. Chen, H. Lin, X. Han, and L. Sun. paper code Nearest neighbour few-shot learning for cross-lingual classification, in EMNLP, 2021. M. S. Bari, B. Haider, and S. Mansour. paper Knowledge-aware meta-learning for low-resource text classification, in EMNLP, 2021. H. Yao, Y. Wu, M. Al-Shedivat, and E. P. Xing. paper code Few-shot named entity recognition: An empirical baseline study, in EMNLP, 2021. J. Huang, C. Li, K. Subudhi, D. Jose, S. Balakrishnan, W. Chen, B. Peng, J. Gao, and J. Han. paper MetaTS: Meta teacher-student network for multilingual sequence labeling with minimal supervision, in EMNLP, 2021. Z. Li, D. Zhang, T. Cao, Y. Wei, Y. Song, and B. Yin. paper Meta-LMTC: Meta-learning for large-scale multi-label text classification, in EMNLP, 2021. R. Wang, X. Su, S. Long, X. Dai, S. Huang, and J. Chen. paper","link":"/2021/12/12/few-shot/"},{"title":"å‰é¦ˆç¥ç»ç½‘ç»œ","text":"Feedforward neural networkï¼ŒFNN å’Œå…¨è¿æ¥ç¥ç»ç½‘ç»œçš„åŒºåˆ«ï¼Ÿï¼Ÿï¼Ÿ","link":"/2022/08/20/ffn/"},{"title":"finetune","text":"1 ä½¿ç”¨å“ªäº›å±‚å‚ä¸ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨å“ªäº›å±‚å‚ä¸ä¸‹æ¸¸ä»»åŠ¡ é€‰æ‹©çš„å±‚model1+ä¸‹æ¸¸ä»»åŠ¡model2 å¯¹äºæ·±åº¦æ¨¡å‹çš„ä¸åŒå±‚ï¼Œæ•è·çš„çŸ¥è¯†æ˜¯ä¸åŒçš„ï¼Œæ¯”å¦‚è¯´è¯æ€§æ ‡æ³¨ï¼Œå¥æ³•åˆ†æï¼Œé•¿æœŸä¾èµ–ï¼Œè¯­ä¹‰è§’è‰²ï¼ŒååŒå¼•ç”¨ã€‚å¯¹äºRNN basedçš„æ¨¡å‹ï¼Œç ”ç©¶è¡¨æ˜å¤šå±‚çš„LSTMç¼–ç å™¨çš„ä¸åŒå±‚å¯¹äºä¸åŒä»»åŠ¡çš„è¡¨ç°ä¸ä¸€æ ·ã€‚å¯¹äºtransformer based çš„æ¨¡å‹ï¼ŒåŸºæœ¬çš„å¥æ³•ç†è§£åœ¨ç½‘ç»œçš„æµ…å±‚å‡ºç°ï¼Œç„¶è€Œé«˜çº§çš„è¯­ä¹‰ç†è§£åœ¨æ·±å±‚å‡ºç°ã€‚ ç”¨$\\textbf{H}^{l}(1&lt;=l&lt;=L)$è¡¨ç¤ºPTMçš„ç¬¬$l$å±‚çš„representationï¼Œ$g(\\cdot)$ä¸ºç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ã€‚æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•é€‰æ‹©representation: a) Embedding Only choose only the pre-trained static embeddingsï¼Œå³$g(\\textbf{H}^{1})$ b) Top Layer é€‰æ‹©é¡¶å±‚çš„representationï¼Œç„¶åæ¥å…¥ç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ï¼Œå³$g(\\textbf{H}^{L})$ c) All Layers è¾“å…¥å…¨éƒ¨å±‚çš„representationï¼Œè®©æ¨¡å‹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„å±‚æ¬¡ï¼Œç„¶åæ¥å…¥ç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ï¼Œæ¯”å¦‚ELMoï¼Œå¼å­å¦‚ä¸‹ g(\\textbf{r}_t)=g(\\gamma \\sum_{l=1}^{L}\\alpha_l\\textbf{H}^{(l)})å…¶ä¸­$\\alpha$ is the softmax-normalized weight for layer $l$ and $\\gamma$ is a scalar to scale the vectors output by pre-trained model 2 å‚æ•°æ˜¯å¦å›ºå®šæ€»å…±æœ‰ä¸¤ç§å¸¸ç”¨çš„æ¨¡å‹è¿ç§»æ–¹å¼ï¼šfeature extraction (where the pre-trained parameters are frozen), and fine-tuning (where the pre-trained parameters are unfrozen and fine-tuned). 3 Fine-Tuning StrategiesTwo-stage fine-tuning ç¬¬ä¸€é˜¶æ®µä¸ºä¸­é—´ä»»åŠ¡ï¼Œç¬¬äºŒé˜¶æ®µä¸ºç›®æ ‡ä»»åŠ¡ Multi-task fine-tuning multi-task learning and pre-training are complementary technologies. Fine-tuning with extra adaptation modules The main drawback of fine-tuning is its parameter ineffciency: every downstream task has its own fine-tuned parameters. Therefore, a better solution is to inject some fine-tunable adaptation modules into PTMs while the original parameters are fixed. Others self-ensemble ï¼Œself-distillationï¼Œgradual unfreezingï¼Œsequential unfreezing å‚è€ƒhttps://arxiv.org/pdf/2003.08271v4.pdf","link":"/2022/06/11/finetune/"},{"title":"flask","text":"python webåº”ç”¨æ¡†æ¶ï¼Œåç«¯ ç¼–å†™é€»è¾‘ 123456789101112from flask import Flask, request, jsonify##åˆ›å»ºåº”ç”¨app1 = Flask(__name__)###ç»‘å®šå‡½æ•°@app1.route('URL rule', methods=['post'])def process_element_data(): return##å¯åŠ¨åº”ç”¨app1.run(....) æ‰§è¡Œé€»è¾‘1 å¯åŠ¨åº”ç”¨2 å‰ç«¯å‘é€è¯·æ±‚3 æ ¹æ®URL ruleæ‰¾å‡½æ•°ï¼Œè¿”å›ç»“æœç»™å‰ç«¯","link":"/2022/06/08/flask/"},{"title":"flinkåˆ†å±‚api","text":"Flink æ ¹æ®æŠ½è±¡ç¨‹åº¦åˆ†å±‚ï¼Œæä¾›äº†ä¸‰ç§ä¸åŒçš„ APIã€‚æ¯ä¸€ç§ API åœ¨ç®€æ´æ€§å’Œè¡¨è¾¾åŠ›ä¸Šæœ‰ç€ä¸åŒçš„ä¾§é‡ï¼Œå¹¶ä¸”é’ˆå¯¹ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚","link":"/2022/03/20/flink-api/"},{"title":"æµæ‰¹é€‰æ‹©","text":"ä¹‹å‰ç‰ˆæœ¬ 1234//æµStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();//æ‰¹ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); ç°åœ¨ç‰ˆæœ¬ é€šè¿‡æ‰§è¡Œæ¨¡å¼ execution modeé€‰æ‹© 1 æµå¤„ç† streaming é»˜è®¤ 2 æ‰¹å¤„ç† batch 3 è‡ªåŠ¨ automatic ï¼ˆ1ï¼‰ é€šè¿‡å‘½ä»¤è¡Œ 1flink run -Dexecution.runtime-mode=BATCH/../.. ï¼ˆ2ï¼‰ä»£ç  123env.setRuntimeMode(RuntimeExecutionMode.STREAMING); env.setRuntimeMode(RuntimeExecutionMode.BATCH); env.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC);","link":"/2022/05/07/flink-batch-stream/"},{"title":"flink cdc","text":"CDCæ˜¯ Change Data Capture(å˜æ›´æ•°æ®è·å– )çš„ç®€ç§°ã€‚ æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œç›‘æµ‹å¹¶æ•è·æ•°æ®åº“çš„å˜åŠ¨ï¼ˆåŒ…æ‹¬æ•°æ®æˆ–æ•°æ®è¡¨çš„æ’å…¥ ã€ æ›´æ–° ä»¥åŠ åˆ é™¤ç­‰ï¼‰ï¼Œå°†è¿™äº›å˜æ›´æŒ‰å‘ç”Ÿçš„é¡ºåºå®Œæ•´è®°å½•ä¸‹æ¥ï¼Œå†™å…¥åˆ°æ¶ˆæ¯ä¸­é—´ä»¶ä¸­ä»¥ä¾›å…¶ä»–æœåŠ¡è¿›è¡Œè®¢é˜…åŠæ¶ˆè´¹ã€‚ Flinkç¤¾åŒºå¼€å‘äº† flink-cdc-connectors ç»„ä»¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥ä» MySQLã€ PostgreSQL ç­‰æ•°æ®åº“ç›´æ¥ è¯»å–å…¨é‡æ•°æ® å’Œ å¢é‡å˜æ›´æ•°æ® çš„ source ç»„ä»¶ã€‚ è¯´ç™½äº†å°±æ˜¯è¿æ¥æ•°æ®åº“ï¼Œç„¶åå®æ—¶ç›‘æ§å˜åŒ–","link":"/2022/05/15/flink-cdc/"},{"title":"flink cep","text":"0 ç®€ä»‹ç±»ä¼¼çš„å¤šä¸ªäº‹ä»¶çš„ç»„åˆï¼Œæˆ‘ä»¬æŠŠå®ƒå«ä½œâ€œå¤æ‚äº‹ä»¶â€ã€‚å¯¹äºå¤æ‚æ—¶é—´çš„å¤„ç†ï¼Œç”±äºæ¶‰åŠåˆ°äº‹ä»¶çš„ä¸¥æ ¼é¡ºåºï¼Œæœ‰æ—¶è¿˜æœ‰æ—¶é—´çº¦æŸï¼Œæˆ‘ä»¬å¾ˆéš¾ç›´æ¥ç”¨ SQLæˆ–DataStream APIæ¥å®Œæˆã€‚äºæ˜¯åªå¥½æ”¾å¤§æ‹› æ´¾åº•å±‚çš„å¤„ç†å‡½æ•°ï¼ˆ process functionï¼‰ä¸Šé˜µäº†ã€‚å¤„ç†å‡½æ•°ç¡®å®å¯ä»¥æå®šè¿™äº›éœ€æ±‚ï¼Œä¸è¿‡å¯¹äºéå¸¸å¤æ‚çš„ç»„åˆäº‹ä»¶ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦è®¾ç½®å¾ˆå¤šçŠ¶æ€ã€å®šæ—¶å™¨ï¼Œå¹¶åœ¨ä»£ç ä¸­å®šä¹‰å„ç§æ¡ä»¶åˆ†æ”¯ï¼ˆ if elseï¼‰é€»è¾‘æ¥å¤„ç†ï¼Œå¤æ‚åº¦ä¼šéå¸¸é«˜ï¼Œå¾ˆå¯èƒ½ä¼šä½¿ä»£ç å¤±å»å¯è¯»æ€§ã€‚æ€ æ ·å¤„ç†è¿™ç±»å¤æ‚äº‹ä»¶å‘¢ï¼Ÿ Flinkä¸ºæˆ‘ä»¬æä¾›äº†ä¸“é—¨ç”¨äºå¤„ç†å¤æ‚äº‹ä»¶çš„åº“ CEPï¼Œå¯ä»¥è®©æˆ‘ä»¬æ›´åŠ è½»æ¾åœ°è§£å†³è¿™ç±»æ£˜æ‰‹çš„é—®é¢˜ã€‚è¿™åœ¨ä¼ä¸šçš„å®æ—¶é£é™©æ§åˆ¶ä¸­æœ‰éå¸¸é‡è¦çš„ä½œç”¨ã€‚ Complex Event Processingï¼Œflink ä¸“é—¨ç”¨æ¥å¤„ç†å¤æ‚äº‹ä»¶çš„åº“ 1 åŸç†cepåº•å±‚æ˜¯çŠ¶æ€æœº å¤æ‚äº‹ä»¶å¯ä»¥é€šè¿‡è®¾è®¡çŠ¶æ€æœºæ¥å¤„ç†ï¼Œç”¨æˆ·è‡ªå·±å†™å®¹æ˜“å‡ºé”™ï¼Œcepå¸®æˆ‘ä»¬å°è£…å¥½ï¼Œç”¨æˆ·å†™é¡¶å±‚é€»è¾‘å°±å¯ä»¥äº† 2 æ ¸å¿ƒæ­¥éª¤ æ€»ç»“èµ·æ¥ï¼Œå¤æ‚äº‹ä»¶å¤„ç†ï¼ˆCEPï¼‰çš„æµç¨‹å¯ä»¥åˆ†æˆä¸‰ä¸ªæ­¥éª¤ï¼ˆ1ï¼‰å®šä¹‰ä¸€ä¸ªåŒ¹é…è§„åˆ™ï¼ˆ2ï¼‰å°†åŒ¹é…è§„åˆ™åº”ç”¨åˆ°äº‹ä»¶æµä¸Šï¼Œæ£€æµ‹æ»¡è¶³è§„åˆ™çš„å¤æ‚äº‹ä»¶ï¼ˆ3ï¼‰å¯¹æ£€æµ‹åˆ°çš„ å¤æ‚äº‹ä»¶è¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°ç»“æœè¿›è¡Œè¾“å‡º","link":"/2022/03/27/flink-cep/"},{"title":"flinkéƒ¨ç½²","text":"Flinkçš„éƒ¨ç½²æ–¹å¼æ˜¯çµæ´»çš„ï¼Œè·ŸSparkä¸€æ ·ï¼Œæ”¯æŒLocalï¼ŒStandaloneï¼ŒYarnï¼ŒMesosï¼ŒKubernetes ä»£ç ä¸­å¥½åƒä¸èƒ½æŒ‡å®šéƒ¨ç½²æ–¹å¼ï¼Œå’Œsparkä¸åŒ https://blog.csdn.net/qq_33689414/article/details/90671685 1 Localæœ€ç®€å•çš„å¯åŠ¨æ–¹å¼ï¼Œå…¶å®æ˜¯ä¸æ­å»ºé›†ç¾¤ï¼Œç›´æ¥æœ¬åœ°å¯åŠ¨ã€‚æœ¬åœ°éƒ¨ç½²éå¸¸ç®€å•ï¼Œç›´æ¥è§£å‹å®‰è£…åŒ…å°±å¯ä»¥ä½¿ç”¨ï¼Œä¸ç”¨è¿›è¡Œä»»ä½•é…ç½®ï¼›ä¸€èˆ¬ç”¨æ¥åšä¸€äº›ç®€å•çš„æµ‹è¯•ã€‚ 2 Standalone ä¼šè¯æ¨¡å¼ï¼Œåº”ç”¨æ¨¡å¼ åŒºåˆ«åœ¨äºjobmasterçš„å¯åŠ¨æ—¶é—´ç‚¹ï¼Œä¼šè¯é¢„å…ˆå¯åŠ¨ï¼Œåº”ç”¨åœ¨ä½œä¸šæäº¤å¯åŠ¨ 3 Yarn1 ä¼šè¯ session åœ¨ä¼šè¯æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå¯åŠ¨ä¸€ä¸ªYARN sessionï¼Œè¿™ä¸ªä¼šè¯ä¼šåˆ›å»ºä¸€ä¸ª Flinké›†ç¾¤ã€‚ 2 å•ä½œä¸š per-job flinkä¸ä¼šé¢„å…ˆå¯åŠ¨ï¼Œåœ¨æäº¤ä½œä¸šï¼Œæ‰å¯åŠ¨æ–°çš„jobmanager 3 åº”ç”¨application ä¸å•ä½œä¸šå¾ˆç›¸ä¼¼ åŒºåˆ«åœ¨äºæäº¤ç»™yarnèµ„æºç®¡ç†å™¨çš„ä¸æ˜¯å…·ä½“ä½œä¸šï¼Œè€Œæ˜¯æ•´ä¸ªåº”ç”¨ï¼ˆåŒ…å«äº†å¤šä¸ªä½œä¸šï¼‰ 4 Mesos5 Kubernetes","link":"/2022/03/12/flink-deploy/"},{"title":"ç®—å­é“¾","text":"å¤šä¸ªç®—å­åˆå¹¶ åˆå¹¶æ¡ä»¶ï¼š1 å¹¶è¡Œåº¦ç›¸åŒçš„ç®—å­ 2 ä¸€å¯¹ä¸€ one to one å¥½å¤„ï¼š1. å‡å°‘çº¿ç¨‹ä¹‹é—´çš„åˆ‡æ¢å’Œç¼“å­˜åŒºçš„æ•°æ®äº¤æ¢ 2 å‡å°‘æ—¶å»¶ 3 æé«˜ååé‡","link":"/2022/04/25/flink-operator-chain/"},{"title":"flinkä¼˜åŒ–","text":"https://shopify.engineering/optimizing-apache-flink-applications-tips https://cloud.tencent.com/developer/article/1897249 1 å¹¿æ’­ https://blog.csdn.net/weixin_44318830/article/details/107678101 å¹¿æ’­æ˜¯ä¸€ç§æ“ä½œ å¦‚æœä¸ä½¿ç”¨å¹¿æ’­ï¼Œæ¯ä¸€ä¸ª Task éƒ½ä¼šæ‹·è´ä¸€ä»½æ•°æ®é›†ï¼Œé€ æˆå†…å­˜èµ„æºæµªè´¹ ; å¹¿æ’­åï¼Œæ¯ä¸ªèŠ‚ç‚¹å­˜ä¸€ä»½,ä¸åŒçš„Task éƒ½å¯ä»¥åœ¨èŠ‚ç‚¹ä¸Šè·å–åˆ° 1 å¹¿æ’­å˜é‡ https://blog.csdn.net/yang_shibiao/article/details/118662134 2 å¹¿æ’­æµ BroadcastStream 3 å¹¿æ’­çŠ¶æ€ BroadcastState","link":"/2022/04/23/flink-optimization/"},{"title":"å¹¶è¡Œåº¦è®¾ç½®","text":"https://blog.csdn.net/hongzhen91/article/details/90812686 ä¸€ä¸ªä»»åŠ¡çš„å¹¶è¡Œå®ä¾‹(çº¿ç¨‹)æ•°ç›®å°±è¢«ç§°ä¸ºè¯¥ä»»åŠ¡çš„å¹¶è¡Œåº¦ å¹¶è¡Œåº¦è®¾ç½®å±‚æ¬¡ 1 Operator Levelï¼ˆç®—å­å±‚æ¬¡ï¼‰ 12345678910111213141516171819202122232425262728293031323334353637383940setParallelismreduce(new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() { @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; value1, Tuple2&lt;String, Long&gt; value2) throws Exception { // å°†ç´¯åŠ å™¨æ›´æ–°ä¸ºå½“å‰æœ€å¤§çš„pvç»Ÿè®¡å€¼ï¼Œç„¶åå‘ä¸‹æ¸¸å‘é€ç´¯åŠ å™¨çš„å€¼ return value1.f1 &gt; value2.f1 ? value1 : value2; } }).setParallelism(5) .print(); (Mary,1)(Bob,1)(Mary,2)(Bob,2)(Mary,3)(Bob,3)(Mary,4)(Bob,4)keyBy(r -&gt; true) // ä¸ºæ¯ä¸€æ¡æ•°æ®åˆ†é…åŒä¸€ä¸ªkeyï¼Œå°†èšåˆç»“æœå‘é€åˆ°ä¸€æ¡æµä¸­å» .reduce(new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() { @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; value1, Tuple2&lt;String, Long&gt; value2) throws Exception { // å°†ç´¯åŠ å™¨æ›´æ–°ä¸ºå½“å‰æœ€å¤§çš„pvç»Ÿè®¡å€¼ï¼Œç„¶åå‘ä¸‹æ¸¸å‘é€ç´¯åŠ å™¨çš„å€¼ return value1.f1 &gt; value2.f1 ? value1 : value2; } }) .print().setParallelism(5); 2&gt; (Bob,2)1&gt; (Mary,2)1&gt; (Bob,4)3&gt; (Mary,3)5&gt; (Bob,1)5&gt; (Mary,4)4&gt; (Mary,1)4&gt; (Bob,3) 2Execution Environment Levelï¼ˆæ‰§è¡Œç¯å¢ƒå±‚æ¬¡ï¼‰ 3Client Levelï¼ˆå®¢æˆ·ç«¯å±‚æ¬¡ï¼‰ 4System Levelï¼ˆç³»ç»Ÿå±‚æ¬¡ï¼‰ ä¼˜å…ˆçº§1&gt;2&gt;3&gt;4","link":"/2022/05/11/flink-parallel/"},{"title":"å¤„ç†å‡½æ•°(process funtion)","text":"å¤„ç†å‡½æ•°ä½äºåº•å±‚ï¼Œæ“ä½œéº»çƒ¦ï¼Œä½†æ˜¯ä½¿ç”¨æ›´åŠ çµæ´»ï¼Œæ˜¯flinkçš„â€œæ ¸æ­¦å™¨â€ï¼Œè½»æ˜“ä¸ç”¨ï¼Œä½†æ˜¯ä¸€å®šè¡Œã€‚ åœ¨å¤„ç†å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬ç›´é¢çš„å°±æ˜¯æ•°æ®æµä¸­æœ€åŸºæœ¬çš„å…ƒç´ ï¼šæ•°æ®äº‹ä»¶ï¼ˆeventï¼‰ã€çŠ¶æ€ stateä»¥åŠæ—¶é—´ï¼ˆ timeï¼‰ã€‚ https://blog.51cto.com/u_15349018/3698518 1 åˆ†ç±»8ç§ä¸åŒçš„å¤„ç†å‡½æ•° æ¯ä¸ªå¤„ç†å‡½æ•°ä½¿å¾—çš„æ—¶å€™æ³¨æ„ä¸¤ä¸ªå…³é”®å‡½æ•° 1 processElement å¿…é¡» å…ƒç´ åŸºæœ¬å¤„ç† 2 onTimer() éå¿…é¡» å°±æ˜¯è®¾ç½®å®šæ—¶å™¨ï¼Œç„¶åè§¦å‘æ“ä½œ 2 ä¾§è¾“å‡ºæµï¼ˆ Side Outputï¼‰1 ä¸»æµ collect 2 åˆ†æµ å¤„ç†å‡½æ•°çš„processElementæˆ–è€…onTimerä¸­ä½¿ç”¨.output ï¼ˆoutputTagï¼Œæ•°æ®ï¼‰ è·å–ä¾§è¾“å‡ºæµ 1Stream.getSideOutput(outputTag)","link":"/2022/03/22/flink-processfunction/"},{"title":"Flinkç¨‹åºæ„æˆéƒ¨åˆ†","text":"âš« è·å–æ‰§è¡Œç¯å¢ƒï¼ˆ execution environmentï¼‰âš« è¯»å–æ•°æ®æºï¼ˆ sourceï¼‰âš« å®šä¹‰åŸºäºæ•°æ®çš„è½¬æ¢æ“ä½œï¼ˆ transformationsï¼‰âš« å®šä¹‰è®¡ç®—ç»“æœçš„è¾“å‡ºä½ç½®ï¼ˆ sinkï¼‰ 1 source1 ä»é›†åˆä¸­è¯»å–æ•°æ®æœ€ç®€å•çš„è¯»å–æ•°æ®çš„æ–¹å¼ï¼Œå°±æ˜¯åœ¨ä»£ç ä¸­ç›´æ¥åˆ›å»ºä¸€ä¸ªJavaé›†åˆï¼Œç„¶åè°ƒç”¨æ‰§è¡Œç¯å¢ƒfromCollectionæ–¹æ³•è¿›è¡Œè¯»å–ã€‚è¿™ç›¸å½“äºå°†æ•°æ®ä¸´æ—¶å­˜å‚¨åˆ°å†…å­˜ä¸­ï¼Œå½¢æˆç‰¹æ®Šçš„æ•°æ®ç»“æ„åï¼Œä½œä¸ºæ•°æ®æºä½¿ç”¨ï¼Œä¸€èˆ¬ç”¨äºæµ‹è¯•ã€‚ 2 ä»æ–‡ä»¶è¯»å–æ•°æ®çœŸæ­£çš„å®é™…åº”ç”¨ä¸­ï¼Œè‡ªç„¶ä¸ä¼šç›´æ¥å°†æ•°æ®å†™åœ¨ä»£ç ä¸­ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šä»å­˜å‚¨ä»‹è´¨ä¸­è·å–æ•°æ®ï¼Œä¸€ä¸ªæ¯”è¾ƒå¸¸è§çš„æ–¹å¼å°±æ˜¯è¯»å–æ—¥å¿—æ–‡ä»¶ã€‚è¿™ä¹Ÿæ˜¯æ‰¹å¤„ç†ä¸­æœ€å¸¸è§çš„è¯»å–æ–¹å¼ã€‚ 1DataStream&lt;String&gt; stream = env.readTextFile(&quot;clicks .csvâ€œ); 3 sockethttps://www.jianshu.com/p/cb26a0f6c622 socketæ–‡æœ¬æµçš„è¯»å–éœ€è¦é…ç½®ä¸¤ä¸ªå‚æ•°ï¼šå‘é€ç«¯ä¸»æœºåå’Œç«¯å£ æ–‡æœ¬æµæ•°æ®çš„å‘é€ï¼Œå¯ä»¥é€šè¿‡ Linuxç³»ç»Ÿè‡ªå¸¦çš„ netcatå·¥å…·è¿›è¡Œæ¨¡æ‹Ÿã€‚ 1nc -lk 7777 4 kafka5 è‡ªå®šä¹‰ Source3 sink1 è¾“å‡ºåˆ°æ–‡ä»¶2 è¾“å‡ºåˆ° Kafka3 è¾“å‡ºåˆ° Redis4 è¾“å‡ºåˆ° Elasticsearch5 è¾“å‡ºåˆ° MySQL (JDBC)6 è‡ªå®šä¹‰ Sinkè¾“å‡º","link":"/2022/03/20/flink-program-struct/"},{"title":"flink vs spark","text":"æ•°æ®æ¨¡å‹1 spark é‡‡ç”¨ RDD æ¨¡å‹ï¼Œ spark streaming çš„ DStream å®é™…ä¸Šä¹Ÿå°±æ˜¯ä¸€ç»„ ç»„å°æ‰¹æ•°æ® RDD çš„é›†åˆ2 flink åŸºæœ¬æ•°æ®æ¨¡å‹æ˜¯æ•°æ®æµï¼Œä»¥åŠäº‹ä»¶ï¼ˆ Event ï¼‰åºåˆ—è¿è¡Œæ—¶æ¶æ„1 spark æ˜¯æ‰¹è®¡ç®—ï¼Œå°† DAG åˆ’åˆ†ä¸ºä¸åŒçš„ stage ï¼Œä¸€ä¸ªå®Œæˆåæ‰å¯ä»¥è®¡ç®—ä¸‹ä¸€ä¸ª2 flink æ˜¯æ ‡å‡†çš„æµæ‰§è¡Œæ¨¡å¼ï¼Œä¸€ä¸ªäº‹ä»¶åœ¨ä¸€ä¸ªèŠ‚ç‚¹å¤„ç†å®Œåå¯ä»¥ç›´æ¥å‘å¾€ä¸‹ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œå¤„ç†","link":"/2022/03/12/flink-spark/"},{"title":"Flinkæ¶æ„åŸç†","text":"1.Flinkç»„ä»¶ 1 JobManager 2 ä»»åŠ¡ç®¡ç†å™¨ï¼ˆ TaskManagerï¼‰ 2.ä»»åŠ¡è°ƒåº¦æµç¨‹","link":"/2022/03/12/flink-srtuct/"},{"title":"çŠ¶æ€ç¼–ç¨‹","text":"0 çŠ¶æ€ç®¡ç†æœºåˆ¶1 ç®—å­ä»»åŠ¡åˆ†ç±»1 æ— çŠ¶æ€ 2 æœ‰çŠ¶æ€ 2 çŠ¶æ€åˆ†ç±»Flink æœ‰ä¸¤ç§çŠ¶æ€ï¼šæ‰˜ç®¡çŠ¶æ€ï¼ˆManaged Stateï¼‰å’ŒåŸå§‹çŠ¶æ€ï¼ˆRaw Stateï¼‰ã€‚ä¸€èˆ¬æƒ…å†µä½¿ç”¨æ‰˜ç®¡çŠ¶æ€ï¼Œåªæœ‰åœ¨æ‰˜ç®¡çŠ¶æ€æ— æ³•å®ç°ç‰¹æ®Šéœ€æ±‚ï¼Œæ‰ä¼šä½¿ç”¨åŸå§‹è½¬æ€ï¼Œä¸€èˆ¬æƒ…å†µä¸ä½¿ç”¨ã€‚ æ‰˜ç®¡çŠ¶æ€åˆ†ç±»ï¼šç®—å­çŠ¶æ€ï¼ˆOperator Stateï¼‰å’ŒæŒ‰é”®åˆ†åŒºçŠ¶æ€ï¼ˆKeyed Stateï¼‰ 1 æŒ‰é”®åˆ†åŒºçŠ¶æ€ 2 ç®—å­çŠ¶æ€ 3 å¹¿æ’­çŠ¶æ€ Broadcast State ç‰¹æ®Šçš„ç®—å­çŠ¶æ€ 3 çŠ¶æ€æŒä¹…åŒ– å¯¹çŠ¶æ€è¿›è¡ŒæŒä¹…åŒ–ï¼ˆ persistenceï¼‰ä¿å­˜ï¼Œè¿™æ ·å°±å¯ä»¥åœ¨å‘ç”Ÿæ•…éšœåè¿›è¡Œé‡å¯æ¢å¤ã€‚ flinkçŠ¶æ€æŒä¹…åŒ–æ–¹å¼ï¼šå†™å…¥ä¸€ä¸ªâ€œæ£€æŸ¥ç‚¹â€ï¼ˆ checkpointï¼‰æˆ–è€…ä¿å­˜ç‚¹ savepointä¿å­˜åˆ°å¤–éƒ¨å­˜å‚¨ç³»ç»Ÿä¸­ã€‚å…·ä½“çš„å­˜å‚¨ä»‹è´¨ï¼Œä¸€èˆ¬æ˜¯åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼ˆ distributed file systemï¼‰ã€‚ 4 çŠ¶æ€åç«¯ State Backendsåœ¨Flinkä¸­ï¼ŒçŠ¶æ€çš„å­˜å‚¨ã€è®¿é—®ä»¥åŠç»´æŠ¤ï¼Œéƒ½æ˜¯ç”±ä¸€ä¸ªå¯æ’æ‹”çš„ç»„ä»¶å†³å®šçš„ï¼Œè¿™ä¸ªç»„ä»¶å°±å«ä½œçŠ¶æ€åç«¯ï¼ˆ state backendï¼‰ã€‚çŠ¶æ€åç«¯ä¸»è¦è´Ÿè´£ä¸¤ä»¶äº‹ï¼šä¸€æ˜¯æœ¬åœ°çš„çŠ¶æ€ç®¡ç†ï¼ŒäºŒæ˜¯å°†æ£€æŸ¥ç‚¹ï¼ˆ checkpointï¼‰å†™å…¥è¿œç¨‹çš„ æŒä¹…åŒ–å­˜å‚¨ã€‚","link":"/2022/03/27/flink-state-program/"},{"title":"Table APIå’ŒSQL","text":"https://blog.csdn.net/weixin_45366499/article/details/115449175 0 åŸç†1 åŠ¨æ€è¡¨ flinkä¸­çš„è¡¨æ˜¯åŠ¨æ€è¡¨ é™æ€è¡¨ï¼šhiveï¼Œmysqlç­‰ åŠ¨æ€è¡¨ï¼šä¸æ–­æ›´æ–° 2 æŒç»­æŸ¥è¯¢ 1 ç®€ä»‹Apache Flink æœ‰ä¸¤ç§å…³ç³»å‹ API æ¥åšæµæ‰¹ç»Ÿä¸€å¤„ç†ï¼šTable API å’Œ SQLã€‚ Table API æ˜¯ç”¨äº Scala å’Œ Java è¯­è¨€çš„æŸ¥è¯¢ APIï¼Œå®ƒå¯ä»¥ç”¨ä¸€ç§éå¸¸ç›´è§‚çš„æ–¹å¼æ¥ ç»„åˆä½¿ç”¨é€‰å–ã€è¿‡æ»¤ã€join ç­‰å…³ç³»å‹ç®—å­ã€‚ 123Table maryClickTable = eventTable.where($(&quot;user&quot;).isEqual(&quot;alice&quot;)).select($(&quot;url&quot;), $(&quot;user&quot;)); SQL æ˜¯åŸºäº Apache Calcite æ¥å®ç°çš„æ ‡å‡† SQL 123Table urlCountTable = tableEnv.sqlQuery(&quot;SELECT user, COUNT(url) FROM EventTable GROUP BY user&quot;); 2 æ¡†æ¶è¡¨ç¯å¢ƒå’Œæµæ‰§è¡Œç¯å¢ƒä¸åŒ 3 æµè¡¨ç›¸äº’è½¬åŒ–stream ã€Šâ€”â€”ã€‹table 123456tableEnvè¡¨ç¯å¢ƒ// å°†æ•°æ®æµeventstreamè½¬æ¢æˆè¡¨eventTableTable eventTable = tableEnv.fromDataStream(eventstream);// å°†è¡¨visitTableè½¬æ¢æˆæ•°æ®æµï¼Œæ‰“å°è¾“å‡ºtableEnv.toDataStream(visitTable).print(); 4 è¿æ¥å¤–éƒ¨ç³»ç»Ÿå¯ä»¥åœ¨åˆ›å»ºè¡¨çš„æ—¶å€™ç”¨ WITHå­å¥æŒ‡å®šè¿æ¥å™¨connector 5 å®¢æˆ·ç«¯./bin/sql client.sh 6 æ—¶é—´å±æ€§ äº‹ä»¶äº‹ä»¶ã€å¤„ç†äº‹ä»¶ åœ¨åˆ›å»ºè¡¨çš„ DDLä¸­å®šä¹‰ åœ¨æ•°æ®æµè½¬æ¢ä¸ºè¡¨æ—¶å®šä¹‰ 7 çª—å£","link":"/2022/03/27/flink-tableapi-sql/"},{"title":"ä»»åŠ¡ç”Ÿæˆå’Œåˆ†é…","text":"mainä»£ç  -ã€‹ æ•°æ®æµå›¾ï¼ˆdataflow graphï¼Œlogical streamgraphï¼‰ -ã€‹ ä½œä¸šå›¾ï¼ˆjobgraphï¼‰-ã€‹æ‰§è¡Œå›¾ï¼ˆexecutiongraphï¼‰-&gt; ç‰©ç†å›¾ï¼ˆphysical graphï¼‰","link":"/2022/04/25/flink-task-assign/"},{"title":"ä»»åŠ¡æ§½ task slots","text":"slotå…±äº« å¹¶è¡Œåº¦ï¼šç®—å­çš„å­ä»»åŠ¡ä¸ªæ•° ç¨‹åºçš„å¹¶è¡Œåº¦ï¼šæœ€å¤§ç®—å­å¹¶è¡Œåº¦ å‡è®¾ï¼š è®¾ç½®å…¨å±€å¹¶è¡Œåº¦ä¸º6ï¼Œä¿æŒsinkä¸º1 sourceï¼Œmap(6) -ã€‹keybyã€‚ã€‚ã€‚(6) -ã€‹sink(1) æ€»å…±æœ‰13ä¸ªå­ä»»åŠ¡ 2 ä¸ªtaskmanger , æ¯ä¸ªtaskmanger 3ä¸ªslot","link":"/2022/04/25/flink-task-slot/"},{"title":"flinkæäº¤ä»»åŠ¡","text":"https://codeantenna.com/a/Y6wpSYwfRL 1.web ui https://blog.csdn.net/godelgnis/article/details/106051751 2.å‘½ä»¤è¡Œ å¯ä»¥æŒ‡å®šéƒ¨ç½²æ–¹å¼ https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/deployment/cli/ https://blog.csdn.net/weixin_42993799/article/details/106566037 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051 å‚æ•°å¿…é€‰ ï¼š -n,--container &lt;arg&gt; åˆ†é…å¤šå°‘ä¸ªyarnå®¹å™¨ (=taskmanagerçš„æ•°é‡) 2 å‚æ•°å¯é€‰ ï¼š -D &lt;arg&gt; åŠ¨æ€å±æ€§ -d,--detached ç‹¬ç«‹è¿è¡Œ -jm,--jobManagerMemory &lt;arg&gt; JobManagerçš„å†…å­˜ [in MB] -nm,--name åœ¨YARNä¸Šä¸ºä¸€ä¸ªè‡ªå®šä¹‰çš„åº”ç”¨è®¾ç½®ä¸€ä¸ªåå­— -q,--query æ˜¾ç¤ºyarnä¸­å¯ç”¨çš„èµ„æº (å†…å­˜, cpuæ ¸æ•°) -qu,--queue &lt;arg&gt; æŒ‡å®šYARNé˜Ÿåˆ—. -s,--slots &lt;arg&gt; æ¯ä¸ªTaskManagerä½¿ç”¨çš„slotsæ•°é‡ -tm,--taskManagerMemory &lt;arg&gt; æ¯ä¸ªTaskManagerçš„å†…å­˜ [in MB] -z,--zookeeperNamespace &lt;arg&gt; é’ˆå¯¹HAæ¨¡å¼åœ¨zookeeperä¸Šåˆ›å»ºNameSpace -id,--applicationId &lt;yarnAppId&gt; YARNé›†ç¾¤ä¸Šçš„ä»»åŠ¡idï¼Œé™„ç€åˆ°ä¸€ä¸ªåå°è¿è¡Œçš„yarn sessionä¸­ 3 run [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt; runæ“ä½œå‚æ•°: -c,--class &lt;classname&gt; å¦‚æœæ²¡æœ‰åœ¨jaråŒ…ä¸­æŒ‡å®šå…¥å£ç±»ï¼Œåˆ™éœ€è¦åœ¨è¿™é‡Œé€šè¿‡è¿™ä¸ªå‚æ•°æŒ‡å®š -m,--jobmanager &lt;host:port&gt; æŒ‡å®šéœ€è¦è¿æ¥çš„jobmanager(ä¸»èŠ‚ç‚¹)åœ°å€ï¼Œä½¿ç”¨è¿™ä¸ªå‚æ•°å¯ä»¥æŒ‡å®šä¸€ä¸ªä¸åŒäºé…ç½®æ–‡ä»¶ä¸­çš„jobmanager -p,--parallelism &lt;parallelism&gt; æŒ‡å®šç¨‹åºçš„å¹¶è¡Œåº¦ã€‚å¯ä»¥è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ã€‚ 4 å¯åŠ¨ä¸€ä¸ªæ–°çš„yarn-session,å®ƒä»¬éƒ½æœ‰ä¸€ä¸ªyæˆ–è€…yarnçš„å‰ç¼€ ä¾‹å¦‚ï¼š./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar è¿æ¥æŒ‡å®šhostå’Œportçš„jobmanagerï¼š ./bin/flink run -m SparkMaster:1234 ./examples/batch/WordCount.jar -input hdfs://hostname:port/hello.txt -output hdfs://hostname:port/result1 å¯åŠ¨ä¸€ä¸ªæ–°çš„yarn-sessionï¼š ./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar -input hdfs://hostname:port/hello.txt -output hdfs://hostname:port/result1 5 æ³¨æ„ï¼šå‘½ä»¤è¡Œçš„é€‰é¡¹ä¹Ÿå¯ä»¥ä½¿ç”¨./bin/flink å·¥å…·è·å¾—ã€‚ 6 Action &quot;run&quot; compiles and runs a program. Syntax: run [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt; &quot;run&quot; action options: -c,--class &lt;classname&gt; Class with the program entry point (&quot;main&quot; method or &quot;getPlan()&quot; method. Only needed if the JAR file does not specify the class in its manifest. -C,--classpath &lt;url&gt; Adds a URL to each user code classloader on all nodes in the cluster. The paths must specify a protocol (e.g. file://) and be accessible on all nodes (e.g. by means of a NFS share). You can use this option multiple times for specifying more than one URL. The protocol must be supported by the {@link java.net.URLClassLoader}. -d,--detached If present, runs the job in detached mode -n,--allowNonRestoredState Allow to skip savepoint state that cannot be restored. You need to allow this if you removed an operator from your program that was part of the program when the savepoint was triggered. -p,--parallelism &lt;parallelism&gt; The parallelism with which to run the program. Optional flag to override the default value specified in the configuration. -q,--sysoutLogging If present, suppress logging output to standard out. -s,--fromSavepoint &lt;savepointPath&gt; Path to a savepoint to restore the job from (for example hdfs:///flink/savepoint-1537). 7 Options for yarn-cluster mode: -d,--detached If present, runs the job in detached mode -m,--jobmanager &lt;arg&gt; Address of the JobManager (master) to which to connect. Use this flag to connect to a different JobManager than the one specified in the configuration. -yD &lt;property=value&gt; use value for given property -yd,--yarndetached If present, runs the job in detached mode (deprecated; use non-YARN specific option instead) -yh,--yarnhelp Help for the Yarn session CLI. -yid,--yarnapplicationId &lt;arg&gt; Attach to running YARN session -yj,--yarnjar &lt;arg&gt; Path to Flink jar file -yjm,--yarnjobManagerMemory &lt;arg&gt; Memory for JobManager Container with optional unit (default: MB) -yn,--yarncontainer &lt;arg&gt; Number of YARN container to allocate (=Number of Task Managers) -ynl,--yarnnodeLabel &lt;arg&gt; Specify YARN node label for the YARN application -ynm,--yarnname &lt;arg&gt; Set a custom name for the application on YARN -yq,--yarnquery Display available YARN resources (memory, cores) -yqu,--yarnqueue &lt;arg&gt; Specify YARN queue. -ys,--yarnslots &lt;arg&gt; Number of slots per TaskManager -yst,--yarnstreaming Start Flink in streaming mode -yt,--yarnship &lt;arg&gt; Ship files in the specified directory (t for transfer) -ytm,--yarntaskManagerMemory &lt;arg&gt; Memory per TaskManager Container with optional unit (default: MB) -yz,--yarnzookeeperNamespace &lt;arg&gt; Namespace to create the Zookeeper sub-paths for high availability mode -z,--zookeeperNamespace &lt;arg&gt; Namespace to create the Zookeeper sub-paths for high availability mode","link":"/2022/03/14/flink-task/"},{"title":"æ—¶é—´è¯­ä¹‰(Notions of Time)","text":"https://blog.csdn.net/lomodays207/article/details/109642581 åœ¨Flinkä¸­ï¼Œç”±äºå¤„ç†æ—¶é—´æ¯”è¾ƒç®€å•ï¼Œæ—©æœŸç‰ˆæœ¬é»˜è®¤çš„æ—¶é—´è¯­ä¹‰æ˜¯å¤„ç†æ—¶é—´ï¼›è€Œè€ƒè™‘åˆ°äº‹ä»¶æ—¶é—´åœ¨å®é™…åº”ç”¨ä¸­æ›´ä¸ºå¹¿æ³›ï¼Œä» 1.12ç‰ˆæœ¬ å¼€å§‹ Flinkå·²ç»å°† äº‹ä»¶æ—¶é—´ä½œä¸ºäº†é»˜è®¤çš„æ—¶é—´è¯­ä¹‰ã€‚ 1.å¤„ç†æ—¶é—´ï¼ˆ Processing Time)å¤„ç†æ—¶é—´çš„æ¦‚å¿µéå¸¸ç®€å•ï¼Œå°±æ˜¯æŒ‡æ‰§è¡Œå¤„ç†æ“ä½œçš„æœºå™¨çš„ç³»ç»Ÿæ—¶é—´ã€‚ 2.äº‹ä»¶æ—¶é—´ï¼ˆ Event Time)äº‹ä»¶æ—¶é—´ï¼Œæ˜¯æŒ‡æ¯ä¸ªäº‹ä»¶åœ¨å¯¹åº”çš„è®¾å¤‡ä¸Šå‘ç”Ÿçš„æ—¶é—´ï¼Œä¹Ÿå°±æ˜¯æ•°æ®ç”Ÿæˆçš„æ—¶é—´ã€‚ 3 æ‘„å…¥æ—¶é—´ï¼ˆ Ingestion Timeï¼‰å®ƒæ˜¯æŒ‡æ•°æ®è¿›å…¥ Flinkæ•°æ®æµçš„æ—¶é—´ï¼Œä¹Ÿå°±æ˜¯ Sourceç®—å­è¯»å…¥æ•°æ®çš„æ—¶é—´ã€‚","link":"/2022/03/21/flink-time/"},{"title":"watermark(æ°´ä½çº¿)","text":"https://blog.csdn.net/lmalds/article/details/52704170 https://blog.csdn.net/lightupworld/article/details/116697831 1 ä»‹ç»åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸€èˆ¬ä¼šé‡‡ç”¨äº‹ä»¶æ—¶é—´è¯­ä¹‰ æ°´ä½çº¿å¯ä»¥çœ‹ä½œåœ¨æ•°æ®æµä¸­åŠ å…¥ä¸€ä¸ªæ—¶é’Ÿæ ‡è®°ï¼Œè®°å½•å½“å‰çš„äº‹ä»¶æ—¶é—´ï¼›è¿™ä¸ªæ ‡è®°å¯ä»¥ç›´æ¥å¹¿æ’­åˆ°ä¸‹æ¸¸ï¼Œå½“ä¸‹æ¸¸ä»»åŠ¡æ”¶åˆ°è¿™ä¸ªæ ‡è®°ï¼Œå°±å¯ä»¥æ›´æ–°è‡ªå·±çš„æ—¶é’Ÿäº†ã€‚ 2 åˆ†ç±»1 æœ‰åºæµçš„æ°´ä½çº¿ æ–¹æ¡†æ˜¯äº‹ä»¶æ—¶é—´ï¼Œè™šçº¿æ˜¯æ°´ä½çº¿ï¼Œç®­å¤´è¡¨ç¤ºæ•°æ®åˆ°è¾¾çš„é¡ºåºï¼Œæ¯”å¦‚äº‹ä»¶æ—¶é—´ä¸º2çš„æ•°æ®ç¬¬ä¸€ä¸ªåˆ°ï¼Œäº‹ä»¶æ—¶é—´ä¸º5çš„æ•°æ®ç¬¬äºŒä¸ªåˆ° 2 ä¹±åºæµçš„æ°´ä½çº¿ æ¯”æ°´ä½çº¿å°çš„æ•°æ®åœ¨åé¢å‡ºç°ï¼Œä¹Ÿå°±æ˜¯è¯´æœ¬åº”è¯¥åœ¨æ°´ä½çº¿ä¹‹å‰å‡ºç°çš„æ•°æ®æ™šåˆ°äº†ï¼Œå°±æ˜¯è¿Ÿåˆ°æ•°æ®ï¼Œè¿Ÿåˆ°æ•°æ®æ˜¯ä¸¢å¼ƒçš„ï¼Œæ¯”å¦‚wï¼ˆ9ï¼‰åé¢çš„8ï¼Œ9 3 å¦‚ä½•ç”Ÿæˆæ°´ä½çº¿1 åŸåˆ™ æˆ‘ä»¬çŸ¥é“ï¼Œå®Œç¾çš„æ°´ä½çº¿æ˜¯â€œç»å¯¹æ­£ç¡®â€çš„ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªæ°´ä½çº¿ä¸€æ—¦å‡ºç°ï¼Œå°±è¡¨ç¤ºè¿™ä¸ªæ—¶é—´ä¹‹å‰çš„æ•°æ®å·²ç»å…¨éƒ¨åˆ°é½ã€ä¹‹åå†ä¹Ÿä¸ä¼šå‡ºç°äº†ã€‚è€Œå®Œç¾çš„ä¸œè¥¿æ€»æ˜¯å¯æœ›ä¸å¯å³ï¼Œæˆ‘ä»¬åªèƒ½å°½é‡å»ä¿è¯æ°´ä½çº¿çš„æ­£ç¡®ã€‚ â€œç­‰â€ æˆ–è€…è¯´â€œå»¶è¿Ÿâ€ ä¸ºäº†å‡è¡¡å®æ—¶æ€§ï¼ˆå°‘ç­‰ï¼Œä¼šå¼•å…¥å¤§é‡è¿Ÿåˆ°æ•°æ®ï¼‰å’Œå‡†ç¡®æ€§ï¼ˆå‡å°‘è¿Ÿåˆ°æ•°æ®ï¼Œå¤šç­‰ï¼‰ 2 æ€ä¹ˆå†™ https://nightlies.apache.org/flink/flink-docs-release-1.14/zh/docs/dev/datastream/event-time/generating_watermarks/ 1 assignTimestampsAndWatermarks 1Datastream &lt;event&gt; withTimestampsAndWatermarks = stream.assignTimestampsAndWatermarks(WatermarkStrategy) WatermarkStrategy å†…ç½® 12WatermarkStrategy.forMonotonousTimestampsWatermarkStrategy.forBoundedOutOfOrderness è‡ªå®šä¹‰ å…ˆå®ç°æ¥å£WatermarkGeneratorï¼Œç„¶åæ”¹å†™ä¸€äº›ä¸œè¥¿ 2 è‡ªå®šä¹‰æ•°æ®æºä¸­å‘é€æ°´ä½çº¿ æ³¨æ„ï¼šè‡ªå®šä¹‰æ•°æ®æºä¹Ÿå¯ä»¥ç”¨assignTimestampsAndWatermarksï¼Œè¿™é‡Œæ˜¯æŒ‡åœ¨è‡ªå®šä¹‰æ•°æ®æºä¸­å®ç°è‡ªå·±çš„æ°´ä½çº¿å‘é€ï¼Œä¸ç”¨assignTimestampsAndWatermarks 4 æ°´ä½çº¿ä¼ é€’ ä¸Šæ¸¸å¹¶è¡Œåº¦ä¸º4ï¼Œä¸‹æ¸¸å¹¶è¡Œåº¦ä¸º3 ç­–ç•¥ï¼šæœ¨æ¡¶åŸç†ï¼Œå–å¾—æ˜¯æœ€å°çš„ ä¸ºä»€ä¹ˆæœ¨æ¡¶åŸåˆ™ï¼Œä»¥å‡†ä¸ºç¬¬ä¸€è¦ä¹‰ï¼Œä¸¾ä¸ªä¾‹å­å›¾2ï¼Œå¦‚æœä¸æ˜¯3ï¼Œæ˜¯4ï¼Œé‚£ä¹ˆ3ä¸å°±è¿Ÿåˆ°äº†å—","link":"/2022/03/21/flink-watermark/"},{"title":"flume","text":"1.ä½œç”¨æ—¥å¿—é‡‡é›† Flumeæ˜¯æµå¼æ—¥å¿—é‡‡é›†å·¥å…·ï¼ŒFLumeæä¾›å¯¹æ•°æ®è¿›è¡Œç®€å•å¤„ç†å¹¶ä¸”å†™åˆ°å„ç§æ•°æ®æ¥æ”¶æ–¹ï¼ˆå¯å®šåˆ¶ï¼‰çš„èƒ½åŠ›ï¼ŒFlumeæä¾›ä»æœ¬åœ°æ–‡ä»¶ï¼ˆspooling directory sourceï¼‰ã€å®æ—¶æ—¥å¿—ï¼ˆtaildirã€execï¼‰ã€RESTæ¶ˆæ¯ã€Thiftã€Avroã€Syslogã€Kafkaç­‰æ•°æ®æºä¸Šæ”¶é›†æ•°æ®çš„èƒ½åŠ›ã€‚ 2.Flumeæ¶æ„https://jiandansuifeng.blog.csdn.net/article/details/118926483 https://www.jianshu.com/p/9a5c682b0551 ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š Source:æ•°æ®æº Channel:ä¸´æ—¶å­˜å‚¨æ•°æ®çš„ç®¡é“ Sink: ç›®çš„åœ° 3.æ‹¦æˆªå™¨(interceptor)https://blog.51cto.com/u_15241496/2869403 æ‹¦æˆªå™¨æ˜¯ç®€å•çš„æ’ä»¶å¼ç»„ä»¶ï¼Œè®¾ç½®åœ¨sourceå’Œchannelä¹‹é—´ã€‚sourceæ¥æ”¶åˆ°çš„äº‹ä»¶eventï¼Œåœ¨å†™å…¥channelä¹‹å‰ï¼Œæ‹¦æˆªå™¨éƒ½å¯ä»¥è¿›è¡Œè½¬æ¢æˆ–è€…åˆ é™¤è¿™äº›äº‹ä»¶ã€‚æ¯ä¸ªæ‹¦æˆªå™¨åªå¤„ç†åŒä¸€ä¸ªsourceæ¥æ”¶åˆ°çš„äº‹ä»¶ã€‚å¯ä»¥è‡ªå®šä¹‰æ‹¦æˆªå™¨ã€‚ 1 jaråŒ… 2 å°†æ‰“åŒ…çš„jaræ”¾åˆ°XXX/flume/lib 3 é…ç½®æ–‡ä»¶ /opt/module/flume/conf vim file-flume-kafka.conf 123a1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type =com.atguigu.flume.interceptor.ETLInterceptor$Builder 4.ä¸ºä»€ä¹ˆè¦é›†æˆFlumeå’ŒKafkahttps://blog.csdn.net/qq_37466640/article/details/103425555 5.ä¾‹å­ 4.1 é‡‡é›†æ—¥å¿— 1ï¼‰Source ï¼ˆ1ï¼‰Taildir Sourceç›¸æ¯”Exec Sourceã€Spooling Directory Sourceçš„ä¼˜åŠ¿ TailDir Sourceï¼šæ–­ç‚¹ç»­ä¼ ã€å¤šç›®å½•ã€‚Flume1.6ä»¥å‰éœ€è¦è‡ªå·±è‡ªå®šä¹‰Sourceè®°å½•æ¯æ¬¡è¯»å–æ–‡ä»¶ä½ç½®ï¼Œå®ç°æ–­ç‚¹ç»­ä¼ ã€‚ä¸ä¼šä¸¢æ•°æ®ï¼Œä½†æ˜¯æœ‰å¯èƒ½ä¼šå¯¼è‡´æ•°æ®é‡å¤ã€‚ Exec Sourceå¯ä»¥å®æ—¶æœé›†æ•°æ®ï¼Œä½†æ˜¯åœ¨Flumeä¸è¿è¡Œæˆ–è€…Shellå‘½ä»¤å‡ºé”™çš„æƒ…å†µä¸‹ï¼Œæ•°æ®å°†ä¼šä¸¢å¤±ã€‚ Spooling Directory Sourceç›‘æ§ç›®å½•ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚ ï¼ˆ2ï¼‰batchSizeå¤§å°å¦‚ä½•è®¾ç½®ï¼Ÿ ç­”ï¼šEvent 1Kå·¦å³æ—¶ï¼Œ500-1000åˆé€‚ï¼ˆé»˜è®¤ä¸º100ï¼‰ 2ï¼‰Channel é‡‡ç”¨Kafka Channelï¼Œçœå»äº†Sinkï¼Œæé«˜äº†æ•ˆç‡ã€‚KafkaChannelæ•°æ®å­˜å‚¨åœ¨Kafkaé‡Œé¢ï¼Œæ‰€ä»¥æ•°æ®æ˜¯å­˜å‚¨åœ¨ç£ç›˜ä¸­ã€‚ æ³¨æ„åœ¨Flume1.7ä»¥å‰ï¼ŒKafka Channelå¾ˆå°‘æœ‰äººä½¿ç”¨ï¼Œå› ä¸ºå‘ç°parseAsFlumeEventè¿™ä¸ªé…ç½®èµ·ä¸äº†ä½œç”¨ã€‚ä¹Ÿå°±æ˜¯æ— è®ºparseAsFlumeEventé…ç½®ä¸ºtrueè¿˜æ˜¯falseï¼Œéƒ½ä¼šè½¬ä¸ºFlume Eventã€‚è¿™æ ·çš„è¯ï¼Œé€ æˆçš„ç»“æœæ˜¯ï¼Œä¼šå§‹ç»ˆéƒ½æŠŠFlumeçš„headersä¸­çš„ä¿¡æ¯æ··åˆç€å†…å®¹ä¸€èµ·å†™å…¥Kafkaçš„æ¶ˆæ¯ä¸­ï¼Œè¿™æ˜¾ç„¶ä¸æ˜¯æˆ‘æ‰€éœ€è¦çš„ï¼Œæˆ‘åªæ˜¯éœ€è¦æŠŠå†…å®¹å†™å…¥å³å¯ã€‚ 3ï¼‰Sink çœå»äº†Sinkï¼Œæé«˜äº†æ•ˆç‡ 4ï¼‰Interceptor ETLInterceptor 4.2 æ¶ˆè´¹æ•°æ® 1ï¼‰Source 2ï¼‰Channel MemoryChannelä¼ è¾“æ•°æ®é€Ÿåº¦æ›´å¿«ï¼Œä½†å› ä¸ºæ•°æ®ä¿å­˜åœ¨JVMçš„å †å†…å­˜ä¸­ï¼ŒAgentè¿›ç¨‹æŒ‚æ‰ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±ï¼Œé€‚ç”¨äºå¯¹æ•°æ®è´¨é‡è¦æ±‚ä¸é«˜çš„éœ€æ±‚ã€‚FileChannelä¼ è¾“é€Ÿåº¦ç›¸å¯¹äºMemoryæ…¢ï¼Œä½†æ•°æ®å®‰å…¨ä¿éšœé«˜ï¼ŒAgentè¿›ç¨‹æŒ‚æ‰ä¹Ÿå¯ä»¥ä»å¤±è´¥ä¸­æ¢å¤æ•°æ®ã€‚ é‡‘èç±»å…¬å¸ã€å¯¹é’±è¦æ±‚éå¸¸å‡†ç¡®çš„å…¬å¸é€šå¸¸ä¼šé€‰æ‹©FileChannel ä¼ è¾“çš„æ˜¯æ™®é€šæ—¥å¿—ä¿¡æ¯ï¼ˆäº¬ä¸œå†…éƒ¨ä¸€å¤©ä¸¢100ä¸‡-200ä¸‡æ¡ï¼Œè¿™æ˜¯éå¸¸æ­£å¸¸çš„ï¼‰ï¼Œé€šå¸¸é€‰æ‹©MemoryChannelã€‚ 3ï¼‰Sink HDFS Sink 4ï¼‰Interceptor TimeStampInterceptor flumeæ—¶é—´æ‹¦æˆªå™¨ è·å–æ—¥å¿—ä¸­çš„å®é™…æ—¶é—´","link":"/2022/01/30/flume/"},{"title":"pytorchä¸­æ¨¡å‹çš„forwardæ–¹æ³•æ˜¯å¦‚ä½•è¢«è‡ªåŠ¨è°ƒç”¨çš„","text":"https://blog.csdn.net/weixin_41912543/article/details/108147378","link":"/2021/12/07/forward/"},{"title":"GBDT","text":"GBDT ï¼ˆGradient Boosting Decison Treeï¼‰=Gradient Boosting+cartå›å½’æ ‘ æ³¨æ„æ˜¯cartå›å½’æ ‘ï¼Œä¸æ˜¯cartåˆ†ç±»æ ‘ è¯´ç™½äº†å°±æ˜¯gradient boostingåŸºå­¦ä¹ å™¨ä¸ºcartå›å½’æ ‘ gradient boostingç®—æ³•æµç¨‹:1.åˆå§‹åŒ–ï¼š$f_0(x) = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{i=1}^N L(y_i, \\gamma)$ 2.for m=1 to M: (a). è®¡ç®—è´Ÿæ¢¯åº¦ï¼š $\\tilde{y}_i = -\\frac{\\partial L(y_i,f_{m-1}(x_i))}{\\partial f_{m-1}(x_i)}, \\quad i = 1,2 \\cdots N$ (b). é€šè¿‡æœ€å°åŒ–å¹³æ–¹è¯¯å·®ï¼Œç”¨åŸºå­¦ä¹ å™¨$h_m(x)$æ‹Ÿåˆ$\\tilde{y_i}$ï¼Œ$w_m = \\mathop{\\arg\\min}\\limits_w \\sum\\limits_{i=1}^{N} \\left[\\tilde{y}_i - h_m(x_i\\,;\\,w) \\right]^2$ (c). ä½¿ç”¨line searchç¡®å®šæ­¥é•¿$Ï_m$ï¼Œä½¿$L$æœ€å°ï¼Œ$\\rho_m = \\mathop{\\arg\\min}\\limits_{\\rho} \\sum\\limits_{i=1}^{N} L(y_i,f_{m-1}(x_i) + \\rho h_m(x_i\\,;\\,w_m))$ (d). $f_m(x) = f_{m-1}(x) + \\rho_m h_m(x\\,;\\,w_m)$ 3.è¾“å‡º$f_M(x)$ GBDTç®—æ³•æµç¨‹ï¼š åˆå§‹åŒ–ï¼š $f_0(x) = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{i=1}^N L(y_i, \\gamma)$ for m=1 to M:(a). è®¡ç®—è´Ÿæ¢¯åº¦ï¼š $\\tilde{y}_i = -\\frac{\\partial L(y_i,f_{m-1}(x_i))}{\\partial f_{m-1}(x_i)}, \\qquad i = 1,2 \\cdots N$(b). $\\left \\{ R_{jm} \\right\\}_1^J = \\mathop{\\arg\\min}\\limits_{\\left \\{ R_{jm} \\right\\}_1^J}\\sum\\limits_{i=1}^N \\left [\\tilde{y}_i - h_m(x_i\\,;\\,\\left \\{R_{jm},b_{jm} \\right\\}_1^J) \\right]^2$(c). $\\gamma_{jm} = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{x_i \\in R_{jm}}L(y_i,f_{m-1}(x_i)+\\gamma)$(d). $f_m(x) = f_{m-1}(x) + \\sum\\limits_{j=1}^J \\gamma_{jm}I(x \\in R_{jm})$ è¾“å‡º$f_M(x)$ å‚è€ƒhttps://blog.csdn.net/zpalyq110/article/details/79527653 https://zhuanlan.zhihu.com/p/86354141","link":"/2021/09/24/gbdt/"},{"title":"å›¾ç¥ç»å·¥å…·","text":"PyGï¼Œ DGLå¯¹æ¯” https://www.zhihu.com/question/399802947","link":"/2021/12/16/gnn-trick/"},{"title":"gpt","text":"GPTä¸‰éƒ¨æ›²å®£å‘ŠNLPçš„â€œé¢„è®­ç»ƒ+å¾®è°ƒâ€æ—¶ä»£çš„å´›èµ·å’Œèµ°å‘è¾‰ç…Œã€‚ åŸæ–‡åˆ†åˆ«ä¸ºï¼š ã€ŠImproving Language Understanding by Generative Pre-Trainingã€‹ ã€ŠLanguage Models are Unsupervised Multitask Learnersã€‹ ã€ŠLanguage Models are Few-Shot Learnersã€‹ 1.GPT1 æ¨¡å‹çš„æ•´ä½“ç»“æ„å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚ä½¿ç”¨è¿‡ç¨‹è¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼šç¬¬ä¸€æ­¥é¢„è®­ç»ƒï¼Œåˆ©ç”¨å¤§é‡è¯­æ–™å­¦ä¹ å¾—åˆ°high-capacityçš„è¯­è¨€æ¨¡å‹ï¼›ç¬¬äºŒæ­¥æ˜¯fine_tuningï¼Œåˆ©ç”¨æ ‡ç­¾æ•°æ®ä½¿å…¶æ‹Ÿåˆåˆ°ç‰¹å®šä»»åŠ¡ã€‚ 1.1 Unsupervised pre-trainingä½œè€…å°†transformer decoderä¸­Encoder-Decoder Attentionå±‚å»æ‰åä½œä¸ºåŸºæœ¬å•å…ƒï¼Œç„¶åå¤šå±‚å †å ä½œä¸ºè¯­è¨€æ¨¡å‹çš„ä¸»ä½“ï¼Œç„¶åå°†è¾“å‡ºç»è¿‡ä¸€ä¸ªsoftmaxå±‚ï¼Œæ¥å¾—åˆ°ç›®æ ‡è¯çš„è¾“å‡ºåˆ†å¸ƒï¼š h_0=UW_e+W_p \\\\h_l=transformer\\_block(h_{l-1}),\\ \\forall l \\in [1,n] \\\\P(u|u_{-k},...,u_{-1}) =softmax(h_nW_e^T)\\å…¶ä¸­$U=\\{u_{-k},â€¦,u_{-1}\\}$ æ˜¯é¢„æµ‹è¯$u $å‰$k$ä¸ªtokençš„ç‹¬çƒ­ç¼–ç åºåˆ—ï¼Œ$n$æ˜¯æ¨¡å‹çš„å±‚æ•°ï¼Œ$W_e$æ˜¯token embedding matrixï¼Œ$W_p$æ˜¯position embedding matrixã€‚ ç»™å®šä¸€ä¸ªæ— ç›‘ç£çš„è¯­æ–™åº“$\\mathcal{U}$ï¼Œuse a standard language modeling objective to maximize the following likelihood L_1(\\mathcal{U})=\\sum_ilog P(u_i|u_{i-k},...,u_{i-1})å…¶ä¸­$k$ æ˜¯ä¸Šä¸‹æ–‡çª—å£å¤§å°ã€‚ 1.2 Supervised fine-tuningå¯¹äºæ•°æ®é›†$\\mathcal{C}$ï¼Œæœ‰æ•°æ®$(x^1,x^2,â€¦,x^m,y)$ P(y|x^1,x^2,...,x^m)=softmax(h_l^mW_y) \\\\L_2(\\mathcal{C})=\\sum_{(x,y)}log P(y|x^1,x^2,...,x^m)å…¶ä¸­$W_y$ä¸ºå…¨è¿æ¥å±‚çš„å‚æ•° ä½œè€…å‘ç°ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥è¾…åŠ©ç›‘ç£å­¦ä¹ è¿›è¡Œå¾®è°ƒï¼Œæœ‰ä¸¤ä¸ªå¥½å¤„ï¼š æé«˜ç›‘ç£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼› åŠ é€Ÿæ”¶æ•›ã€‚ æ‰€ä»¥ï¼Œæœ€ç»ˆä¸‹æ¸¸ä½¿ç”¨çš„ç›‘ç£æ¨¡å‹æŸå¤±å‡½æ•°ä¸ºï¼š L_3(\\mathcal{C})=L_2(\\mathcal{C})+\\lambda*L_1(\\mathcal{C})1.3 Task-specific input transformations æ‰€æœ‰çš„è¾“å…¥æ–‡æœ¬éƒ½ä¼šåŠ ä¸Šå¼€å§‹å’Œç»“åˆtoken$(s),(e)$ åˆ†ç±» åˆ†ç±»è¿‡ç¨‹å¯å¦‚ä¸Š1.2ï¼Œè¾“å…¥è¡¨ç¤ºä¸º$[(s);Context;(e)]$ æ–‡æœ¬è•´å« å°†è¾“å…¥æ‹¼æ¥æˆ$[(s); premise; ($) ; hypothesis ; (e)]$ ç›¸ä¼¼åº¦ ç”±äºæ–‡æœ¬ç›¸ä¼¼åº¦ä¸ä¸¤ä¸ªæ¯”è¾ƒæ–‡æœ¬çš„å‰åé¡ºåºæ²¡æœ‰å…³ç³»ï¼Œå› æ­¤å°†ä¸¤ç§æ–‡æœ¬é¡ºåºéƒ½è€ƒè™‘è¿›æ¥ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤º é—®ç­”ä¸å¸¸è¯†æ¨ç† å‡è®¾æ–‡æ¡£ä¸º$z$ï¼Œé—®é¢˜ä¸º$q$ï¼Œä¸€ç³»åˆ—ç­”æ¡ˆä¸º$\\{a_k\\}$ï¼Œå°†å…¶è¾“å…¥è¡¨ç¤ºä¸º$[(s); z; q; ($); a_k;(e)]$ï¼Œç„¶åå¤šä¸ªå›ç­”ç»„åˆçš„å½¢å¼ï¼Œå¦‚ä¸Šå›¾ã€‚ 2.GPT2æ€»ç»“å°±æ˜¯ï¼šå¤šä»»åŠ¡é¢„è®­ç»ƒ+è¶…å¤§æ•°æ®é›†+è¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚é€šè¿‡ä¸€ä¸ªè¶…å¤§æ•°æ®é›†æ¶µç›–NLPçš„å¤§å¤šä»»åŠ¡ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªè¶…å¤§è§„æ¨¡æ¨¡å‹è¿›è¡Œå¤šä»»åŠ¡é¢„è®­ç»ƒï¼Œä½¿å…¶æ— éœ€ä»»ä½•ä¸‹æ¸¸ä»»åŠ¡çš„finetuneå°±å¯ä»¥åšåˆ°å¤šä¸ªNLPä»»åŠ¡çš„SOTAã€‚ä¸¾ä¸ªä¾‹å­ï¼Œæ‹¿é«˜è€ƒä¸ºä¾‹ï¼Œäººçš„æ™ºåŠ›å’Œè„‘å®¹é‡å¯ä»¥ç†è§£ä¸ºå‚æ•°å¤§å°ï¼Œç”±äºä¸ªä½“å·®å¼‚ï¼Œå¯ä»¥å°†ä¸åŒçš„å­¦ç”Ÿç†è§£ä¸ºä¸åŒå‚æ•°é‡çš„æ¨¡å‹ï¼Œå·å­å¯ä»¥ç†è§£ä¸ºæ•°æ®é›†ï¼Œä¸åŒçš„å­¦ç§‘å¯ä»¥ç†è§£ä¸ºä¸åŒä»»åŠ¡ã€‚GPT2æœ‰ç‚¹ç±»ä¼¼å­¦éœ¸ï¼Œå°±æ˜¯æœ‰è¶…é«˜çš„æ™ºåŠ›å’Œè„‘å®¹é‡ï¼Œç„¶ååˆ·å¤§é‡ä¸åŒå­¦ç§‘çš„é¢˜ç›®ï¼Œå› æ­¤å¯¹é«˜è€ƒè¿™ä¸ªå¤šä»»åŠ¡çš„ä¸‹æ¸¸ä»»åŠ¡å°±å¯ä»¥å–å¾—å¥½æˆç»©ã€‚ GPT2ç›¸å¯¹äºGPT1æœ‰å“ªäº›ä¸åŒå‘¢ï¼Ÿ GPT2å»æ‰äº†fine-tuningï¼šä¸å†é’ˆå¯¹ä¸åŒä»»åŠ¡åˆ†åˆ«è¿›è¡Œå¾®è°ƒå»ºæ¨¡ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è¯†åˆ«å‡ºæ¥éœ€è¦åšä»€ä¹ˆä»»åŠ¡ã€‚è¿™å°±å¥½æ¯”ä¸€ä¸ªäººåšè§ˆç¾¤ä¹¦ï¼Œä½ é—®ä»–ä»€ä¹ˆç±»å‹çš„é—®é¢˜ï¼Œä»–éƒ½å¯ä»¥é¡ºæ‰‹æ‹ˆæ¥ï¼ŒGPT2å°±æ˜¯è¿™æ ·ä¸€ä¸ªåšè§ˆç¾¤ä¹¦çš„æ¨¡å‹ã€‚ è¶…å¤§æ•°æ®é›†ï¼šWebTextï¼Œè¯¥æ•°æ®é›†åšäº†ä¸€äº›ç®€å•çš„æ•°æ®æ¸…ç†ï¼Œå¹¶ä¸”å®éªŒç»“æœè¡¨æ˜ç›®å‰æ¨¡å‹ä»ç„¶å¤„äºä¸€ä¸ªæ¬ æ‹Ÿåˆçš„æƒ…å†µã€‚ å¢åŠ ç½‘ç»œå‚æ•°ï¼šGPT2å°†Transformerå †å çš„å±‚æ•°å¢åŠ åˆ°48å±‚ï¼Œéšå±‚çš„ç»´åº¦ä¸º1600ï¼Œå‚æ•°é‡æ›´æ˜¯è¾¾åˆ°äº†15äº¿ã€‚15äº¿ä»€ä¹ˆæ¦‚å¿µå‘¢ï¼ŒBertçš„å‚æ•°é‡ä¹Ÿæ‰åªæœ‰3äº¿å“¦~å½“ç„¶ï¼Œè¿™æ ·çš„å‚æ•°é‡ä¹Ÿä¸æ˜¯è¯´è°éƒ½èƒ½è¾¾åˆ°çš„ï¼Œè¿™ä¹Ÿå¾—å–å†³äºmoneyçš„å¤šå°‘å•Š~ è°ƒæ•´transformerï¼šå°†layer normalizationæ”¾åˆ°æ¯ä¸ªsub-blockä¹‹å‰ï¼Œå¹¶åœ¨æœ€åä¸€ä¸ªtransformeråå†å¢åŠ ä¸€ä¸ªlayer normalizationï¼Œå¦‚ä¸‹å›¾ã€‚ è¾“å…¥è¡¨ç¤ºï¼šGPT2é‡‡ç”¨äº†BPEè¿™ç§subwordçš„ç»“æ„ä½œä¸ºè¾“å…¥ å…¶ä»–ï¼šGPT2å°†è¯æ±‡è¡¨æ•°é‡å¢åŠ åˆ°50257ä¸ªï¼›æœ€å¤§çš„ä¸Šä¸‹æ–‡å¤§å° (context size) ä»GPTçš„512æå‡åˆ°äº†1024 tokensï¼›batchsizeå¢åŠ åˆ°512ã€‚ GPT2çš„è¾“å…¥æ˜¯å®Œå…¨çš„æ–‡æœ¬ï¼Œä»€ä¹ˆæç¤ºéƒ½ä¸åŠ å—ï¼Ÿ å½“ç„¶ä¸æ˜¯ï¼Œå®ƒä¹Ÿä¼šåŠ å…¥æç¤ºè¯ï¼Œæ¯”å¦‚ï¼š$TL;DR:$ï¼ŒGPT2æ¨¡å‹å°±ä¼šçŸ¥é“æ˜¯åšæ‘˜è¦å·¥ä½œäº†ï¼Œè¾“å…¥çš„æ ¼å¼å°±æ˜¯ $æ–‡æœ¬+TL;DR:$ï¼Œç„¶åå°±ç­‰å¾…è¾“å‡ºå°±è¡Œäº†~ 3.GPT3GPT3ï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰1750äº¿ä¸ªå‚æ•°çš„è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼Œæ¯”GPT2å¤§100å€ï¼Œæ„Ÿè§‰çœŸæ˜¯è¿›å…¥ç®—åŠ›æ—¶ä»£äº†ã€‚è·ç¦»ä¸ªäººç”¨æˆ·å¤ªè¿œäº†ï¼Œå°±ä¸æ·±æŒ–äº†ã€‚ å‚è€ƒhttps://zhuanlan.zhihu.com/p/146719974 https://zhuanlan.zhihu.com/p/125139937 https://www.cnblogs.com/yifanrensheng/p/13167796.html#_label1_0 https://www.jianshu.com/p/96c5d5d5c468 https://blog.csdn.net/qq_35128926/article/details/111399679 https://zhuanlan.zhihu.com/p/96791725 https://terrifyzhao.github.io/2019/02/18/GPT2.0%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB.html https://zhuanlan.zhihu.com/p/56865533","link":"/2021/08/26/gpt/"},{"title":"Gradient Accumulation","text":"https://blog.csdn.net/u013546508/article/details/121157559 https://blog.csdn.net/Princeicon/article/details/108058822","link":"/2021/11/10/gradient-accumulate-steps/"},{"title":"æ¢¯åº¦çˆ†ç‚¸ã€æ¢¯åº¦æ¶ˆå¤±å’Œè§£å†³æ–¹æ³•","text":"1.æ¢¯åº¦è®¾äºŒå…ƒå‡½æ•°$z=f(x,y)$ åœ¨å¹³é¢åŒºåŸŸ$D$ä¸Šå…·æœ‰ä¸€é˜¶è¿ç»­åå¯¼æ•°ï¼Œåˆ™å¯¹äºæ¯ä¸€ä¸ªç‚¹$P(xï¼Œy)$çš„æ¢¯åº¦ä¸º grad \\ f(x,y)=\\nabla f(x,y)=f_x(x,y)\\vec{j}+ f_y(x,y)\\vec{j}2.BPç®—æ³•å›¾ç¤º 3.æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜éƒ½æ˜¯å› ä¸ºç½‘ç»œå¤ªæ·±ï¼Œç½‘ç»œæƒå€¼æ›´æ–°ä¸ç¨³å®šé€ æˆçš„ï¼Œæœ¬è´¨ä¸Šæ˜¯å› ä¸ºæ¢¯åº¦åå‘ä¼ æ’­ä¸­çš„è¿ä¹˜æ•ˆåº”ã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œç°æœ‰å¦‚ä¸Šé“¾å¼è¿æ¥çš„ç½‘ç»œ$(x\\rightarrow z \\rightarrow y)$ \\frac{\\partial C }{\\partial b_1}=\\frac{\\partial C }{\\partial y_4}\\frac{\\partial y_4 }{\\partial z_4}\\frac{\\partial z_4 }{\\partial x_4}\\frac{\\partial x_4 }{\\partial z_3}\\frac{\\partial z_3 }{\\partial x_3}\\frac{\\partial x_3 }{\\partial z_2}\\frac{\\partial z_2 }{\\partial x_2}\\frac{\\partial x_2 }{\\partial z_1}\\frac{\\partial z_1 }{\\partial b_1}=\\frac{\\partial C }{\\partial y_4}g^{'}(z_4)w_4g^{'}(z_3)w_3g^{'}(z_2)w_2g^{'}(z_1)w_1å‡è®¾$g$ä¸ºsigmoidï¼Œé‚£ä¹ˆ$g^{â€˜}(z)$æœ€å¤§å€¼ä¸º$\\frac{1}{4}$ï¼Œè€Œæˆ‘ä»¬åˆå§‹åŒ–çš„ç½‘ç»œæƒå€¼é€šå¸¸éƒ½å°äº1ï¼Œæ‰€ä»¥$g^{â€˜}(z)w \\le \\frac{1}{4}$ï¼Œå› æ­¤å¯¹äºä¸Šé¢çš„é“¾å¼æ±‚å¯¼ï¼Œå±‚æ•°è¶Šå¤šï¼Œæ±‚å¯¼ç»“æœ$\\frac{\\partial C }{\\partial b_1}$è¶Šå°ï¼Œå› è€Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µå‡ºç°ã€‚ è¿™æ ·ï¼Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜çš„å‡ºç°åŸå› å°±æ˜¾è€Œæ˜“è§äº†ï¼Œå½“$w$æ¯”è¾ƒå¤§çš„æ—¶å€™æˆ–è€…æ¿€æ´»å‡½æ•°çš„æ¢¯åº¦è¾ƒå¤§ï¼Œå³$g^{â€˜}(z)w &gt; 1$ï¼Œå±‚æ•°è¶Šå¤šï¼Œæ±‚å¯¼ç»“æœ$\\frac{\\partial C }{\\partial b_1}$è¶Šå¤§ï¼Œç›´åˆ°çˆ†ç‚¸ã€‚ 4.æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸è§£å†³æ–¹æ³•4.1 è§£å†³æ¢¯åº¦æ¶ˆå¤±1.ç”¨ReLUã€Leaky-ReLUã€P-ReLUã€R-ReLUã€Maxoutç­‰æ›¿ä»£sigmoidå‡½æ•°ã€‚ 2.ç”¨Batch Normalizationã€‚ 3.LSTMçš„ç»“æ„è®¾è®¡ä¹Ÿå¯ä»¥æ”¹å–„RNNä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚ 4.æ®‹å·®ç½‘ç»œ 5.åˆé€‚çš„åˆå§‹åŒ–æƒé‡ 4.2è§£å†³æ¢¯åº¦çˆ†ç‚¸1.æ¢¯åº¦å‰ªåˆ‡ï¼šå¯¹æ¢¯åº¦è®¾å®šé˜ˆå€¼ 2.æƒé‡æ­£åˆ™åŒ–(L1 å’Œ L2 ) 3.åˆé€‚çš„åˆå§‹åŒ–æƒé‡ å‚è€ƒhttps://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/ https://zhuanlan.zhihu.com/p/25631496 https://aijishu.com/a/1060000000100195","link":"/2021/09/02/gradient/"},{"title":"gradient boosting","text":"æ¨å¯¼è¿‡ç¨‹Gradient Boostingä¸ºboostingç®—æ³•çš„ä¸€ç§ï¼Œé‡‡ç”¨å’ŒAdaBooståŒæ ·çš„åŠ æ³•æ¨¡å‹ï¼Œåœ¨ç¬¬mæ¬¡è¿­ä»£ä¸­ï¼Œå‰m-1ä¸ªåŸºå­¦ä¹ å™¨éƒ½æ˜¯å›ºå®šçš„ï¼Œå³ f_m(x) = f_{m-1}(x) + \\rho_m h_m(x) \\tag{1}æ ¸å¿ƒæ€æƒ³æ˜¯å¾—åˆ°åŸºå­¦ä¹ å™¨$h_m(x)$å’Œæƒé‡$p_m$ å‚æ•°ç©ºé—´çš„æ¢¯åº¦ä¸‹é™å¾ˆå¸¸è§ï¼Œå³ \\theta = \\theta - \\alpha \\cdot \\frac{\\partial}{\\partial \\theta}L(\\theta)è‹¥å°†$f(x)$å½“æˆå‚æ•°ï¼Œåˆ™åŒæ ·å¯ä»¥ä½¿ç”¨å‡½æ•°ç©ºé—´çš„æ¢¯åº¦ä¸‹é™æ³•ï¼š f_m(x) = f_{m-1}(x) - \\rho_m \\cdot \\frac{\\partial}{\\partial f_{m-1}(x)}L(y,f_{m-1}(x)) \\tag{2}å¯¹æ¯”ï¼ˆ1ï¼‰ï¼ˆ2ï¼‰ï¼Œæˆ‘ä»¬å‘ç°$h_m(x) \\approx -\\frac{\\partial L(y,f_{m-1}(x))}{\\partial f_{m-1}(x)}$ ç®—æ³•æµç¨‹:1.åˆå§‹åŒ–ï¼š$f_0(x) = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{i=1}^N L(y_i, \\gamma)$ 2.for m=1 to M: (a). è®¡ç®—è´Ÿæ¢¯åº¦ï¼š $\\tilde{y}_i = -\\frac{\\partial L(y_i,f_{m-1}(x_i))}{\\partial f_{m-1}(x_i)}, \\quad i = 1,2 \\cdots N$ (b). é€šè¿‡æœ€å°åŒ–å¹³æ–¹è¯¯å·®ï¼Œç”¨åŸºå­¦ä¹ å™¨$h_m(x)$æ‹Ÿåˆ$\\tilde{y_i}$ï¼Œ$w_m = \\mathop{\\arg\\min}\\limits_w \\sum\\limits_{i=1}^{N} \\left[\\tilde{y}_i - h_m(x_i\\,;\\,w) \\right]^2$ (c). ä½¿ç”¨line searchç¡®å®šæ­¥é•¿$Ï_m$ï¼Œä½¿$L$æœ€å°ï¼Œ$\\rho_m = \\mathop{\\arg\\min}\\limits_{\\rho} \\sum\\limits_{i=1}^{N} L(y_i,f_{m-1}(x_i) + \\rho h_m(x_i\\,;\\,w_m))$ (d). $f_m(x) = f_{m-1}(x) + \\rho_m h_m(x\\,;\\,w_m)$ 3.è¾“å‡º$f_M(x)$ å‚è€ƒhttps://www.cnblogs.com/zhubinwang/p/5170087.html https://www.cnblogs.com/massquantity/p/9174746.html","link":"/2021/09/23/gradient_boosting/"},{"title":"A Comprehensive Survey on Graph Neural Networks","text":"there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. 1.ä»‹ç»è™½ç„¶æ·±åº¦å­¦ä¹ æŠ€æœ¯å¯ä»¥æ•è·æ¬§å¼ç©ºé—´æ•°æ®çš„éšè—æ¨¡å¼ï¼Œä½†æ˜¯ç›®å‰å¾ˆå¤šåº”ç”¨æ˜¯åŸºäºå›¾çš„ï¼Œè¿™æ˜¯éæ¬§ç©ºé—´çš„æ•°æ®ã€‚å›¾æ•°æ®çš„å¤æ‚æ€§ç»™ç°æœ‰çš„æŠ€æœ¯å¸¦æ¥äº†å¾ˆå¤§çš„æŒ‘æˆ˜ã€‚è¿™æ˜¯å› ä¸ºå›¾æ•°æ®å¯ä»¥æ˜¯ä¸è§„åˆ™çš„ï¼Œä¸€ä¸ªå›¾å¯èƒ½æœ‰ä¸åŒæ•°é‡çš„æ— åºç»“ç‚¹ï¼Œä¸€ä¸ªç»“ç‚¹å¯èƒ½æœ‰ä¸åŒæ•°é‡çš„é‚»æ¥ç»“ç‚¹ã€‚è¿™ä¼šä½¿å¾—ä¸€äº›åŸºæœ¬æ“ä½œï¼Œæ¯”å¦‚å·ç§¯ï¼Œåœ¨å›¾é¢†åŸŸæ— æ³•å¾ˆå¥½çš„æ•è·ç‰¹å¾ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œç›®å‰æœºå™¨å­¦ä¹ ç®—æ³•æœ‰ä¸€ä¸ªé‡è¦çš„å‡è®¾ï¼Œå°±æ˜¯å‡è®¾å„ä¸ªç»“ç‚¹æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œç„¶è€Œï¼Œå›¾ä¸­å­˜åœ¨å¾ˆå¤šå¤æ‚çš„è¿æ¥ä¿¡æ¯ï¼Œä¸»è¦ç”¨æ¥è¡¨å¾ç»“ç‚¹é—´çš„äº’ç›¸å…³æ€§ã€‚ä¸ºäº†è§£å†³ä»¥ä¸Šé—®é¢˜ï¼Œè¡ç”Ÿäº†å¾ˆå¤šå›¾ç¥ç»ç½‘ç»œæŠ€æœ¯ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚ï¼Œå›¾å·ç§¯ã€‚ä¸‹å›¾å¯¹æ¯”äº†ä¼ ç»Ÿçš„2Då·ç§¯å’Œå›¾å·ç§¯ã€‚äºŒè€…æœ€å¤§çš„åŒºåˆ«åœ¨äºé‚»æ¥ç»“ç‚¹ï¼Œä¸€ä¸ªæœ‰åºä¸€ä¸ªæ— åºï¼Œä¸€ä¸ªå°ºå¯¸å›ºå®šä¸€ä¸ªå°ºå¯¸å¯å˜ã€‚ 2.èƒŒæ™¯å’Œå®šä¹‰A. èƒŒæ™¯Graph neural networks vs network embedding The main distinction between GNNs and network embedding is that GNNs are a group of neural network models which are designed for various tasks while network embedding covers various kinds of methods targeting the same task. Graph neural networks vs graph kernel methods The difference is that this mapping function of graph kernel methods is deterministic rather than learnable. GNNs are much more efficient than graph kernel methods. B. å®šä¹‰ ä¸Šè¡¨ä¸ºæœ¬æ–‡çš„notationã€‚ 1.å›¾ $ {G}=(V,E) $è¡¨ç¤ºä¸€ä¸ªå›¾ã€‚$N(v)=\\{u\\in V|(v,u)\\in E\\}$è¡¨ç¤ºç»“ç‚¹$v$çš„é‚»æ¥ç»“ç‚¹ã€‚$\\textbf{A}$æ˜¯é‚»æ¥çŸ©é˜µï¼Œå¦‚æœ$A_{ij}=1$,é‚£ä¹ˆè¡¨ç¤º$e_{ij}\\in E$ï¼›å¦‚æœ$A_{ij}=0$,é‚£ä¹ˆè¡¨ç¤º$e_{ij} \\notin E$ã€‚$\\textbf{X} \\in \\mathbb{R}^{n \\times d} $æ˜¯ç»“ç‚¹ç‰¹å¾çŸ©é˜µï¼Œ$\\textbf{X}^{e} \\in \\mathbb{R}^{m \\times c}$æ˜¯è¾¹ç‰¹å¾çŸ©é˜µã€‚ 2.æœ‰å‘å›¾ A graph is undirected if and only if the adjacency matrix is symmetric. 3.æ—¶ç©ºå›¾ A spatial-temporal graph is an attributed graph where the node attributes change dynamically over time. $G^{(t)}=(V,E,\\textbf{X}^{(t)})ï¼Œ\\textbf{X}^{(t)} \\in \\mathbb{R}^{n \\times d}$ 3.åˆ†ç±»å’Œæ¡†æ¶3.1 GNNåˆ†ç±»ä½œè€…æŠŠGNNåˆ†æˆä»¥ä¸‹4ç±»ï¼Œåˆ†åˆ«ä¸ºRecGNNsï¼ŒConvGNNs , GAEs, STGNNsã€‚ RecGNNsï¼ˆRecurrent graph neural networksï¼‰ RecGNNs aim to learn node representations with recurrent neural architectures. They assume a node in a graph constantly exchanges information message with its neighbors until a stable equilibrium is reached. ConvGNNsï¼ˆConvolutional graph neural networks ï¼‰ The main idea is to generate a node $v$â€™s representation by aggregating its own features $\\textbf{x}_v$ and neighborsâ€™ features $\\textbf{x}_u,u\\in N(v)$ã€‚Different from RecGNNs, ConvGNNs stack multiple graph convolutional layers to extract high-level node representations. GAEsï¼ˆGraph autoencodersï¼‰ are unsupervised learning frameworks which encode nodes/graphs into a latent vector space and reconstruct graph data from the encoded information. GAEs are used to learn network embeddings andgraph generative distributions. STGNNsï¼ˆSpatial-temporal graph neural networksï¼‰ aim to learn hidden patterns from spatial-temporal graphs. The key idea of STGNNs is to consider spatial dependency and temporal dependency at the same time. 3.2 æ¡†æ¶With the graph structure and node content information as inputs, the outputs of GNNs can focus on different graph analytics tasks with one of the following mechanisms: Node-level outputs relate to node regression and node classification tasks. Edge-level outputs relate to the edge classification and link prediction tasks. Graph-level outputs relate to the graph classification task. Training Frameworksï¼š 1.Semi-supervised learning for node-level classification 2.Supervised learning for graph-level classification 3.Unsupervised learning for graph embedding 4.RecGNNsRecGNNs apply the same set of parameters recurrently over nodes in a graph to extract high-level node representations. æ¥ä¸‹æ¥ä»‹ç»å‡ ç§RecGNNs ç»“æ„ã€‚ GNN* Based on an information diffusion mechanism, GNN* updates nodesâ€™ states by exchanging neighborhood information recurrently until a stable equilibrium is reached. ç»“ç‚¹çš„hidden state is recurrently updated by \\textbf{h}_v^{(t)}=\\sum_{u\\in N(v)}f(\\textbf{x}_v,\\textbf{x}^e_{(v,u)},\\textbf{x}_{u},\\textbf{h}_{u}^{(t-1)})$\\textbf{h}_v^0$éšæœºåˆå§‹åŒ–ã€‚$f(\\cdot)$æ˜¯ parametric functionï¼Œmust be a contraction mapping, which shrinks the distance between two points after projecting them into a latent space. è®­ç»ƒè¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼Œæ›´æ–°ç»“ç‚¹è¡¨ç¤ºå’Œæ›´æ–°å‚æ•°ï¼Œäº¤æ›¿è¿›è¡Œä½¿å¾—lossæ”¶æ•›ã€‚When a convergence criterion is satisfied, the last step node hidden states are forwarded to a readout layer. GraphESN GraphESNä½¿ç”¨ESNæé«˜GNN*çš„è®­ç»ƒæ•ˆç‡ã€‚GraphESNåŒ…å«encoderå’Œoutput outputã€‚encoderéšæœºåˆå§‹åŒ–å¹¶ä¸”ä¸éœ€è¦è®­ç»ƒã€‚It implements a contractive state transition function to recurrently update node states until the global graph state reaches convergence. Afterward, the output layer is trained by taking the fixed node states as inputs. Gated Graph Neural Networks (GGNNs) \\textbf{h}_{v}^t=GRU(\\textbf{h}_{v}^{t-1},\\sum_{u\\in N(v)}\\textbf{W}h_{u}^t)The adavantage is that it no longer needs to constrain parameters to ensure convergence. However, the downside of training by BPTT is that it sacrifices efficiency both in time and memory. GGNN RecGNNs åˆ©ç”¨GRUä½œä¸ºå¾ªç¯å‡½æ•° \\textbf{h}_v^{(t)}=GRU(\\textbf{h}_v^{(t-1)},\\sum_{u\\in N(v)}\\textbf{W}\\textbf{h}_u^{(t-1)})å…¶ä¸­$\\textbf{h}_v^{(0)}=\\textbf{x}_v$ã€‚ GGNN uses the back-propagation through time (BPTT) algorithm to learn the model parameters. å¯¹äºå¤§çš„å›¾ä¸é€‚ç”¨ã€‚ SSE proposes a learning algorithm that is more scalable to large graphs \\textbf{h}_{v}^{(t)}=(1-\\alpha)\\textbf{h}_{v}^{ï¼ˆt-1ï¼‰}+\\alpha \\textbf{W}_1 \\sigma(\\textbf{W}_2[\\textbf{x}_v,\\sum_{u\\in N(v)}[\\textbf{h}_u^{t-1},\\textbf{x}_u]])å…¶ä¸­$\\alpha$ä¸ºè¶…å‚æ•°ï¼Œ$\\sigma(\\cdot)$ä¸ºsigmoidå‡½æ•°ã€‚ 5.ConvGNNs ConvGNNsä¸RecGNNs ä¸»è¦åŒºåˆ«åœ¨äºä¸Šå›¾ã€‚ ConvGNNs fall into two categories, spectral-based and spatial-based. Spectral based approaches define graph convolutions by introducing filters from the perspective of graph signal processing [82] where the graph convolutional operation is interpreted as removing noises from graph signals. Spatial-based approaches inherit ideas from RecGNNs to define graph convolutions by information propagation. spatial-based methods have developed rapidly recently due to its attractive efficiency, flexibility, and generality. 5.1 Spectral-based ConvGNNs5.2 Spatial-based ConvGNNsç½—åˆ—å‡ ä¸ªåŸºæœ¬çš„ç»“æ„ã€‚ NN4G \\textbf{h}_{v}^{(k)}=f(\\textbf{W}^{(k)^T}\\textbf{x}_v+\\sum_{i=1}^{k-1}\\sum_{u\\in N(v) }\\Theta^{(k)^{T}}\\textbf{h}_{u}^{(k-1)})å…¶ä¸­$f(\\cdot)$æ˜¯æ¿€æ´»å‡½æ•°ï¼Œ$\\textbf{h}_{v}^{(0)}=0$ï¼Œå¯ä»¥ä½¿ç”¨çŸ©é˜µå½¢å¼è¡¨è¾¾ä¸ºï¼š \\textbf{H}^{(k)}=f(\\textbf{X}\\textbf{W}^{(k)}+\\sum_{i=1}^{k-1}\\textbf{A}\\textbf{H}^{k-1}\\Theta^{(k)})DCNN regards graph convolutions as a diffusion process. \\textbf{H}^{(k)}=f(\\textbf{W}^{(k)}\\odot\\textbf{P}^k\\textbf{X} )å…¶ä¸­$f(\\cdot)$æ˜¯æ¿€æ´»å‡½æ•°ã€‚probability transition matrix $\\textbf{P}\\in\\mathbb{R}^{n\\times n},\\textbf{P} = \\textbf{D}^{-1}\\textbf{A}$ã€‚ DCNN concatenates $\\textbf{H}^{(1)},\\textbf{H}^{(2)},â€¦,\\textbf{H}^{(K)}$together as the final model outputs. PGC-DGCNN MPNN 5.3 Graph Pooling ModulesAfter a GNN generates node features, we can use them for the final task. But using all these features directly can be computationally challenging, thus, a down-sampling strategy is needed. Depending on the objective and the role it plays in the network, different names are given to this strategy: (1) the pooling operation aims to reduce the size of parameters by down-sampling the nodes to generate smaller representations and thus avoid overfitting, permutation invariance, and computational complexity issues; (2) the readout operation is mainly used to generate graph-level representation based on node representations. Their mechanism is very similar. In this chapter, we use pooling to refer to all kinds of down-sampling strategies applied to GNNs. mean/max/sum pooling is the most primitive and effective way ï¼š \\textbf{h}_G=mean/max/sum(\\textbf{h}_1^{(K)},\\textbf{h}_2^{(K)},...,\\textbf{h}_n^{(K)})$K$ is the index of the last graph convolutional layer. some works [17], [27], [46] also use attention mechanisms to enhance the mean/sum pooling. [101] propose the Set2Set method to generate a memory that increases with the size of the input. è¿˜æœ‰SortPoolingï¼ŒDiffPoolç­‰ 6.GAEs7.STGNNs8.APPLICATIONSå‚è€ƒhttps://arxiv.org/abs/1901.00596v4","link":"/2021/08/10/graph-nn-survey/"},{"title":"Graphå’ŒSession","text":"graphå®šä¹‰äº†è®¡ç®—æ–¹å¼ï¼ˆè®¡ç®—æµç¨‹ï¼‰ï¼Œæœ¬èº«ä¸ä¼šè¿›è¡Œä»»ä½•è®¡ç®— sessionå¸®åŠ©graphè®¡ç®— å¯ä»¥å®šä¹‰å¤šä¸ªgraphï¼Œä¾‹å¦‚ä¸€ä¸ªgraphå®ç°z = x + yï¼Œå¦ä¸€ä¸ªgraphå®ç°u = 2 * v å‚è€ƒhttps://www.jianshu.com/p/b636de7c251a https://blog.csdn.net/qq_40242197/article/details/105315219","link":"/2022/06/02/graph-session/"},{"title":"hadoopæ¶æ„","text":"1 æ€»è§ˆhttps://blog.csdn.net/wangxudongx/article/details/104079998 2 MapReducehttps://zhuanlan.zhihu.com/p/377204048 3 hdfs0 è¯»å†™åŸç†https://blog.csdn.net/whdxjbw/article/details/81072207 1 æ–‡ä»¶æ ¼å¼https://www.cnblogs.com/wqbin/p/14635480.html Hadoopä¸­çš„æ–‡ä»¶æ ¼å¼å¤§è‡´ä¸Šåˆ†ä¸ºé¢å‘è¡Œå’Œé¢å‘åˆ—ä¸¤ç±» é¢å‘è¡Œï¼šåŒä¸€è¡Œçš„æ•°æ®å­˜å‚¨åœ¨ä¸€èµ·ï¼Œå³è¿ç»­å­˜å‚¨ã€‚SequenceFile,MapFile,Avro Datafileã€‚é‡‡ç”¨è¿™ç§æ–¹å¼ï¼Œå¦‚æœåªéœ€è¦è®¿é—®è¡Œçš„ä¸€å°éƒ¨åˆ†æ•°æ®ï¼Œäº¦éœ€è¦å°†æ•´è¡Œè¯»å…¥å†…å­˜ï¼Œæ¨è¿Ÿåºåˆ—åŒ–ä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯ä»ç£ç›˜è¯»å–æ•´è¡Œæ•°æ®çš„å¼€é”€å´æ— æ³•é¿å…ã€‚é¢å‘è¡Œçš„å­˜å‚¨é€‚åˆäºæ•´è¡Œæ•°æ®éœ€è¦åŒæ—¶å¤„ç†çš„æƒ…å†µã€‚ é¢å‘åˆ—ï¼šæ•´ä¸ªæ–‡ä»¶è¢«åˆ‡å‰²ä¸ºè‹¥å¹²åˆ—æ•°æ®ï¼Œæ¯ä¸€åˆ—æ•°æ®ä¸€èµ·å­˜å‚¨ã€‚Parquet , RCFile,ORCFileã€‚é¢å‘åˆ—çš„æ ¼å¼ä½¿å¾—è¯»å–æ•°æ®æ—¶ï¼Œå¯ä»¥è·³è¿‡ä¸éœ€è¦çš„åˆ—ï¼Œé€‚åˆäºåªå¤„äºè¡Œçš„ä¸€å°éƒ¨åˆ†å­—æ®µçš„æƒ…å†µã€‚ä½†æ˜¯è¿™ç§æ ¼å¼çš„è¯»å†™éœ€è¦æ›´å¤šçš„å†…å­˜ç©ºé—´ï¼Œå› ä¸ºéœ€è¦ç¼“å­˜è¡Œåœ¨å†…å­˜ä¸­ï¼ˆä¸ºäº†è·å–å¤šè¡Œä¸­çš„æŸä¸€åˆ—ï¼‰ã€‚åŒæ—¶ä¸é€‚åˆæµå¼å†™å…¥ï¼Œå› ä¸ºä¸€æ—¦å†™å…¥å¤±è´¥ï¼Œå½“å‰æ–‡ä»¶æ— æ³•æ¢å¤ï¼Œè€Œé¢å‘è¡Œçš„æ•°æ®åœ¨å†™å…¥å¤±è´¥æ—¶å¯ä»¥é‡æ–°åŒæ­¥åˆ°æœ€åä¸€ä¸ªåŒæ­¥ç‚¹ï¼Œæ‰€ä»¥Flumeé‡‡ç”¨çš„æ˜¯é¢å‘è¡Œçš„å­˜å‚¨æ ¼å¼ã€‚ 2 ä¸Šä¼ æ–‡ä»¶1.é¡µé¢ 2.å‘½ä»¤è¡Œ https://blog.csdn.net/tandelin/article/details/89514784 4 RPCRemote Procdure Callï¼Œä¸­æ–‡åï¼šè¿œç¨‹è¿‡ç¨‹è°ƒç”¨ å®ƒå…è®¸ä¸€å°è®¡ç®—æœºç¨‹åºè¿œç¨‹è°ƒç”¨å¦å¤–ä¸€å°è®¡ç®—æœºçš„å­ç¨‹åºï¼Œè€Œä¸ç”¨å»å…³å¿ƒåº•å±‚çš„ç½‘ç»œé€šä¿¡ç»†èŠ‚ Hadoopçš„è¿›ç¨‹é—´äº¤äº’éƒ½æ˜¯é€šè¿‡RPCæ¥è¿›è¡Œçš„ï¼Œæ¯”å¦‚Namenodeä¸Datanode https://www.cnblogs.com/SmallBird-Nest/p/11430330.html","link":"/2022/01/28/hadoop-framewowk/"},{"title":"Hadoopéƒ¨ç½²æ–¹å¼","text":"https://blog.csdn.net/aohun0743/article/details/101702331 https://cloud.tencent.com/developer/article/1924241?from=article.detail.1336692 æœ¬åœ°æ¨¡å¼ å•æœºè¿è¡Œï¼Œåªæ˜¯ç”¨æ¥æ¼”ç¤ºä¸€ä¸‹å®˜æ–¹æ¡ˆä¾‹ã€‚ç”Ÿäº§ç¯å¢ƒä¸ç”¨ã€‚ ä¼ªåˆ†å¸ƒå¼æ¨¡å¼ ä¹Ÿæ˜¯å•æœºè¿è¡Œï¼Œä½†æ˜¯å…·å¤‡Hadoopé›†ç¾¤çš„æ‰€æœ‰åŠŸèƒ½ï¼Œä¸€å°æœåŠ¡å™¨æ¨¡æ‹Ÿä¸€ä¸ªåˆ†å¸ƒå¼çš„ç¯å¢ƒã€‚ä¸ªåˆ«ç¼ºé’±çš„å…¬å¸ç”¨æ¥æµ‹è¯•ï¼Œç”Ÿäº§ç¯å¢ƒä¸ç”¨ã€‚ å®Œå…¨åˆ†å¸ƒå¼æ¨¡å¼ å¤šå°æœåŠ¡å™¨ç»„æˆåˆ†å¸ƒå¼ç¯å¢ƒã€‚ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚ æ­å»ºï¼š https://blog.csdn.net/a1786742005/article/details/104104983 é«˜å¯ç”¨å®Œå…¨åˆ†å¸ƒå¼æ¨¡å¼ HAé«˜å¯ç”¨æ˜¯Hadoop2.xæ‰å¼€å§‹å¼•å…¥çš„æœºåˆ¶ï¼Œæ˜¯ä¸ºäº†è§£å†³Hadoopçš„å•ç‚¹æ•…éšœé—®é¢˜ã€‚ä¸»è¦æœ‰ä¸¤ç§éƒ¨ç½²æ–¹å¼ï¼Œä¸€ç§æ˜¯NFSï¼ˆNetwork File Systemï¼‰æ–¹å¼ï¼Œå¦å¤–ä¸€ç§æ˜¯QJMï¼ˆQuorum Journal Managerï¼‰æ–¹å¼ã€‚ç”¨å¾—è¾ƒå¤šçš„æ˜¯QJMæ–¹å¼ï¼Œç¨³å®šæ€§æ›´å¥½ã€‚å®é™…æ“ä½œä¸­ï¼Œç”Ÿäº§ç¯å¢ƒçš„Hadoopé›†ç¾¤æ­å»ºä¸€èˆ¬éƒ½ä¼šåšHAéƒ¨ç½²ã€‚","link":"/2022/01/26/hadoop-persudo/"},{"title":"hadoop SafeMode","text":"https://blog.csdn.net/bingduanlbd/article/details/51900512 https://developer.aliyun.com/article/566059# https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Safemode During start up the NameNode loads the file system state from the fsimage and the edits log file. It then waits for DataNodes to report their blocks so that it does not prematurely start replicating the blocks though enough replicas already exist in the cluster. During this time NameNode stays in Safemode. Safemode for the NameNode is essentially a read-only mode for the HDFS cluster, where it does not allow any modifications to file system or blocks. Normally the NameNode leaves Safemode automatically after the DataNodes have reported that most file system blocks are available. If required, HDFS could be placed in Safemode explicitly using bin/hadoop dfsadmin -safemode command. NameNode front page shows whether Safemode is on or off. A more detailed description and configuration is maintained as JavaDoc for setSafeMode(). å®‰å…¨æ¨¡å¼æ˜¯HDFSæ‰€å¤„çš„ä¸€ç§ç‰¹æ®ŠçŠ¶æ€ï¼Œåœ¨è¿™ç§çŠ¶æ€ä¸‹ï¼Œæ–‡ä»¶ç³»ç»Ÿåªæ¥å—è¯»æ•°æ®è¯·æ±‚ï¼Œè€Œä¸æ¥å—åˆ é™¤ã€ä¿®æ”¹ç­‰å˜æ›´è¯·æ±‚ã€‚åœ¨NameNodeä¸»èŠ‚ç‚¹å¯åŠ¨æ—¶ï¼ŒHDFSé¦–å…ˆè¿›å…¥å®‰å…¨æ¨¡å¼ï¼ŒDataNodeåœ¨å¯åŠ¨çš„æ—¶å€™ä¼šå‘namenodeæ±‡æŠ¥å¯ç”¨çš„blockç­‰çŠ¶æ€ï¼Œå½“æ•´ä¸ªç³»ç»Ÿè¾¾åˆ°å®‰å…¨æ ‡å‡†æ—¶ï¼ŒHDFSè‡ªåŠ¨ç¦»å¼€å®‰å…¨æ¨¡å¼ã€‚å¦‚æœHDFSå‡ºäºå®‰å…¨æ¨¡å¼ä¸‹ï¼Œåˆ™æ–‡ä»¶blockä¸èƒ½è¿›è¡Œä»»ä½•çš„å‰¯æœ¬å¤åˆ¶æ“ä½œï¼Œå› æ­¤è¾¾åˆ°æœ€å°çš„å‰¯æœ¬æ•°é‡è¦æ±‚æ˜¯åŸºäºdatanodeå¯åŠ¨æ—¶çš„çŠ¶æ€æ¥åˆ¤å®šçš„ï¼Œå¯åŠ¨æ—¶ä¸ä¼šå†åšä»»ä½•å¤åˆ¶ï¼ˆä»è€Œè¾¾åˆ°æœ€å°å‰¯æœ¬æ•°é‡è¦æ±‚ï¼‰","link":"/2022/02/06/hadoop-safe-mode/"},{"title":"Hadoop in Secure Mode","text":"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html#:~:text=When%20Hadoop%20is%20configured%20to,or%20%2Fetc%2Fhosts%20files. This document describes how to configure authentication for Hadoop in secure mode. By default Hadoop runs in non-secure mode in which no actual authentication is required.By configuring Hadoop runs in secure mode, each user and service needs to be authenticated by Kerberos in order to use Hadoop services.","link":"/2022/02/06/hadoop-security/"},{"title":"hadoop trick","text":"1 é›†ç¾¤æ•°æ®å‡è¡¡1 èŠ‚ç‚¹é—´æ•°æ®å‡è¡¡ ï¼ˆ1ï¼‰å¼€å¯æ•°æ®å‡è¡¡å‘½ä»¤ start-balancer.sh -threshold 10 ï¼ˆ2ï¼‰åœæ­¢æ•°æ®å‡è¡¡å‘½ä»¤ stop-balancer.sh 2 ç£ç›˜é—´æ•°æ®å‡è¡¡ ï¼ˆ1ï¼‰ç”Ÿæˆå‡è¡¡è®¡åˆ’ï¼ˆæˆ‘ä»¬åªæœ‰ä¸€å—ç£ç›˜ï¼Œä¸ä¼šç”Ÿæˆè®¡åˆ’ï¼‰ hdfs diskbalancer -plan hadoop103 ï¼ˆ2ï¼‰æ‰§è¡Œå‡è¡¡è®¡åˆ’ hdfs diskbalancer -execute hadoop103.plan.json ï¼ˆ3ï¼‰æŸ¥çœ‹å½“å‰å‡è¡¡ä»»åŠ¡çš„æ‰§è¡Œæƒ…å†µ hdfs diskbalancer -query hadoop103 ï¼ˆ4ï¼‰å–æ¶ˆå‡è¡¡ä»»åŠ¡ hdfs diskbalancer -cancel hadoop103.plan.json 2 æ•°æ®å‹ç¼©https://cloud.tencent.com/developer/article/1417401 1 LZOå‹ç¼© LZOå‹ç¼©æ–‡ä»¶çš„å¯åˆ‡ç‰‡ç‰¹æ€§ä¾èµ–äºå…¶ç´¢å¼•ï¼Œæ•…æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ä¸ºLZOå‹ç¼©æ–‡ä»¶åˆ›å»ºç´¢å¼•ã€‚è‹¥æ— ç´¢å¼•ï¼Œåˆ™LZOæ–‡ä»¶çš„åˆ‡ç‰‡åªæœ‰ä¸€ä¸ªã€‚ 1[atguigu@hadoop102 bin]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_log/dt=2020-06-14 3 Hadoopå‚æ•°è°ƒä¼˜https://developer.aliyun.com/article/566013 1ï¼‰HDFSå‚æ•°è°ƒä¼˜ 2ï¼‰YARNå‚æ•°è°ƒä¼˜","link":"/2022/01/28/hadoop-trick/"},{"title":"å“ˆå¸Œè¡¨","text":"1 å“ˆå¸Œå‡½æ•° 2 å“ˆå¸Œå†²çªhttps://blog.51cto.com/u_15077556/3984082 https://www.jianshu.com/p/585f8882bbfb 3 æ•ˆç‡æ’å…¥å’ŒæŸ¥æ‰¾çš„æ—¶é—´å¤æ‚åº¦éƒ½æ˜¯ä¸ºO(1) å‚è€ƒhttps://zhuanlan.zhihu.com/p/144296454","link":"/2022/06/16/hashtable/"},{"title":"HBase","text":"0 ç®€ä»‹Apache HBase is the Hadoop database, a distributed, scalable, big data store. HBase is a type of â€œNoSQLâ€ database. HBaseæ˜¯ä¸€ç§æ„å»ºåœ¨HDFSä¹‹ä¸Šçš„åˆ†å¸ƒå¼ã€é¢å‘åˆ—çš„å­˜å‚¨ç³»ç»Ÿã€‚ Hadoopå·²ç»æœ‰äº†HDFSå’ŒMapReduceï¼Œä¸ºä»€ä¹ˆéœ€è¦HBase 1 Hadoopå¯ä»¥å¾ˆå¥½åœ°è§£å†³å¤§è§„æ¨¡æ•°æ®çš„ç¦»çº¿æ‰¹é‡å¤„ç†é—®é¢˜ï¼Œä½†æ˜¯ï¼Œå—é™äºHadoopMapReduceç¼–ç¨‹æ¡†æ¶çš„é«˜å»¶è¿Ÿæ•°æ®å¤„ç†æœºåˆ¶ï¼Œä½¿å¾—Hadoopæ— æ³•æ»¡è¶³å¤§è§„æ¨¡æ•°æ®å®æ—¶å¤„ç†åº”ç”¨çš„éœ€æ±‚ã€‚ 2 ä¼ ç»Ÿçš„é€šç”¨å…³ç³»å‹æ•°æ®åº“æ— æ³•åº”å¯¹åœ¨æ•°æ®è§„æ¨¡å‰§å¢æ—¶å¯¼è‡´çš„ç³»ç»Ÿæ‰©å±•æ€§å’Œæ€§èƒ½é—®é¢˜ï¼ˆåˆ†åº“åˆ†è¡¨ä¹Ÿä¸èƒ½å¾ˆå¥½è§£å†³ï¼‰ã€‚ä¼ ç»Ÿå…³ç³»æ•°æ®åº“åœ¨æ•°æ®ç»“æ„å˜åŒ–æ—¶ä¸€èˆ¬éœ€è¦åœæœºç»´æŠ¤ï¼›ç©ºåˆ—æµªè´¹å­˜å‚¨ç©ºé—´ã€‚ HBaseä¸ä¼ ç»Ÿçš„å…³ç³»æ•°æ®åº“çš„åŒºåˆ« 1ã€æ•°æ®ç±»å‹ï¼šå…³ç³»æ•°æ®åº“é‡‡ç”¨å…³ç³»æ¨¡å‹ï¼Œå…·æœ‰ä¸°å¯Œçš„æ•°æ®ç±»å‹å’Œå­˜å‚¨æ–¹å¼ï¼ŒHBaseåˆ™é‡‡ç”¨äº†æ›´åŠ ç®€å•çš„æ•°æ®æ¨¡å‹ï¼Œå®ƒæŠŠæ•°æ®å­˜å‚¨ä¸ºæœªç»è§£é‡Šçš„å­—ç¬¦ä¸²ã€‚ 2ã€æ•°æ®æ“ä½œï¼šå…³ç³»æ•°æ®åº“ä¸­åŒ…å«äº†ä¸°å¯Œçš„æ“ä½œï¼Œå…¶ä¸­ä¼šæ¶‰åŠå¤æ‚çš„å¤šè¡¨è¿æ¥ã€‚HBaseæ“ä½œåˆ™ä¸å­˜åœ¨å¤æ‚çš„è¡¨ä¸è¡¨ä¹‹é—´çš„å…³ç³»ï¼Œåªæœ‰ç®€å•çš„æ’å…¥ã€æŸ¥è¯¢ã€åˆ é™¤ã€æ¸…ç©ºç­‰ï¼Œå› ä¸ºHBaseåœ¨è®¾è®¡ä¸Šå°±é¿å…äº†å¤æ‚çš„è¡¨å’Œè¡¨ä¹‹é—´çš„å…³ç³»ã€‚ 3ã€å­˜å‚¨æ¨¡å¼ï¼šå…³ç³»æ•°æ®åº“æ˜¯åŸºäºè¡Œæ¨¡å¼å­˜å‚¨çš„ã€‚HBaseæ˜¯åŸºäºåˆ—å­˜å‚¨çš„ï¼Œæ¯ä¸ªåˆ—æ—éƒ½ç”±å‡ ä¸ªæ–‡ä»¶ä¿å­˜ï¼Œä¸åŒåˆ—æ—çš„æ–‡ä»¶æ˜¯åˆ†ç¦»çš„ã€‚ 4ã€æ•°æ®ç´¢å¼•ï¼šå…³ç³»æ•°æ®åº“é€šå¸¸å¯ä»¥é’ˆå¯¹ä¸åŒåˆ—æ„å»ºå¤æ‚çš„å¤šä¸ªç´¢å¼•ï¼Œä»¥æé«˜æ•°æ®è®¿é—®æ€§èƒ½ã€‚HBaseåªæœ‰ä¸€ä¸ªç´¢å¼•â€”â€”è¡Œé”®ï¼Œé€šè¿‡å·§å¦™çš„è®¾è®¡ï¼ŒHBaseä¸­çš„æ‰€æœ‰è®¿é—®æ–¹æ³•ï¼Œæˆ–è€…é€šè¿‡è¡Œé”®è®¿é—®ï¼Œæˆ–è€…é€šè¿‡è¡Œé”®æ‰«æï¼Œä»è€Œä½¿å¾—æ•´ä¸ªç³»ç»Ÿä¸ä¼šæ…¢ä¸‹æ¥ã€‚ 5ã€æ•°æ®ç»´æŠ¤ï¼šåœ¨å…³ç³»æ•°æ®åº“ä¸­ï¼Œæ›´æ–°æ“ä½œä¼šç”¨æœ€æ–°çš„å½“å‰å€¼å»æ›¿æ¢è®°å½•ä¸­åŸæ¥çš„æ—§å€¼ï¼Œæ—§å€¼è¢«è¦†ç›–åå°±ä¸ä¼šå­˜åœ¨ã€‚è€Œåœ¨HBaseä¸­æ‰§è¡Œæ›´æ–°æ“ä½œæ—¶ï¼Œå¹¶ä¸ä¼šåˆ é™¤æ•°æ®æ—§çš„ç‰ˆæœ¬ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ä¸ªæ–°çš„ç‰ˆæœ¬ï¼Œæ—§æœ‰çš„ç‰ˆæœ¬ä»ç„¶ä¿ç•™ã€‚ 6ã€å¯ä¼¸ç¼©æ€§ï¼šå…³ç³»æ•°æ®åº“å¾ˆéš¾å®ç°æ¨ªå‘æ‰©å±•ï¼Œçºµå‘æ‰©å±•çš„ç©ºé—´ä¹Ÿæ¯”è¾ƒæœ‰é™ã€‚ç›¸åï¼ŒHBaseå’ŒBigTableè¿™äº›åˆ†å¸ƒå¼æ•°æ®åº“å°±æ˜¯ä¸ºäº†å®ç°çµæ´»çš„æ°´å¹³æ‰©å±•è€Œå¼€å‘çš„ï¼Œèƒ½å¤Ÿè½»æ˜“åœ°é€šè¿‡åœ¨é›†ç¾¤ä¸­å¢åŠ æˆ–è€…å‡å°‘ç¡¬ä»¶æ•°é‡æ¥å®ç°æ€§èƒ½çš„ä¼¸ç¼©ã€‚ 1 é…ç½®https://www.cnblogs.com/frankdeng/p/9310191.html å¯åŠ¨æˆåŠŸjpsåå¯ä»¥çœ‹åˆ°hmaster ï¼Œhregionservice 2 hbase shellä¸æ”¯æŒsqlï¼Œå¯¹è¡¨æ“ä½œéœ€è¦ä½¿ç”¨hbase shellå‘½ä»¤æˆ–è€…hbase api 3 Phoenixåœ¨hbaseä¸Šæ„å»ºSQLå±‚ï¼Œä½¿å¾—hbase èƒ½å¤Ÿä½¿ç”¨æ ‡å‡†SQLç®¡ç†æ•°æ®ï¼ŒPhoenixä¸­çš„sqlè¯­å¥è¿˜æ˜¯æœ‰äº›ä¸åŒçš„ 4 é—®é¢˜1 org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet https://cloud.tencent.com/developer/article/1812290 2 stop-hbase.shå…³é—­ä¸äº†ï¼Œä¸€ç›´å¤„äºç­‰å¾…çŠ¶æ€ https://blog.csdn.net/weixin_45462732/article/details/106909501 3 hregionserviceå¯åŠ¨å°±æŒ‚äº† çœ‹æ—¥å¿— å‚è€ƒhttps://www.cnblogs.com/wendyw/p/12691971.html#_label3 https://juejin.cn/post/6844903777347043336 https://www.jianshu.com/p/53864dc3f7b4 https://www.cnblogs.com/frankdeng/p/9310191.html https://blog.csdn.net/weixin_45462732/article/details/106909501 ä¸­æ–‡æ–‡æ¡£ http://hbase.org.cn/docs/166.html#regionserver.arch","link":"/2022/02/05/hbase/"},{"title":"Bridging the Gap Between Relevance Matching and Semantic Matching for Short Text Similarity Modeling","text":"https://cs.uwaterloo.ca/~jimmylin/publications/Rao_etal_EMNLP2019.pdf 2 HCAN: Hybrid Co-Attention Network three major components: (1) a hybrid encoder (2) a relevance matching module (3) a semantic matching module 2.1 Hybrid Encodershybrid encoder module that explores three types of encoders: deep, wide, and contextual query and context words :$\\{w_1^q,w_2^q,â€¦,w_n^q\\},\\{w_1^c,w_2^c,â€¦,w_m^c\\}$, embedding representations $\\textbf{Q}\\in \\mathbb{R}^{n\\times L},\\textbf{C}\\in \\mathbb{R}^{m\\times L}$ Deep Encoder $\\textbf{U}$è¡¨ç¤º$\\textbf{Q},\\textbf{C}$ Wide Encoder Unlike the deep encoder that stacks multiple convolutional layers hierarchically, the wide encoder organizes convolutional layers in parallel, with each convolutional layer having a different window size k Contextual Encoder 2.2 Relevance Matching 2.3 Semantic Matching 2.4 Final Classification","link":"/2021/12/02/hcan/"},{"title":"å †ï¼Œä¼˜å…ˆé˜Ÿåˆ—","text":"å † https://blog.csdn.net/weixin_45697774/article/details/104481087 ä¼˜å…ˆé˜Ÿåˆ— https://www.cnblogs.com/xzxl/p/7266404.html https://www.jianshu.com/p/b51ab28ca8dd å †å’Œä¼˜å…ˆé˜Ÿåˆ—çš„å…³ç³» https://blog.csdn.net/weixin_44337445/article/details/110508591","link":"/2021/11/30/heap/"},{"title":"hiveæ•°æ®å¯¼å…¥å¯¼å‡º","text":"https://www.cnblogs.com/xing901022/p/5801061.html","link":"/2022/03/17/hive-data/"},{"title":"hexo_intro","text":"1.éƒ¨ç½²123hexo clean hexo g hexo d 2.åˆ›å»ºæ–‡ç« 1hexo new &quot;XXX&quot; 3.å¸¸è§é—®é¢˜Error: pandoc exited with code 7: pandoc: Unknown extension: smart è§£å†³ï¼šå¸è½½pandoc 1npm un hexo-renderer-pandoc â€”save errorï¼šspawn failed 1.åˆ é™¤.deploy_gitæ–‡ä»¶å¤¹ 2.æ‰§è¡Œ 1git config --global core.autocrlf false hexo å›¾ç‰‡æ˜¾ç¤ºé—®é¢˜ 1ã€åœ¨_config.ymlè®¾ç½®post_asset_folderä¸ºtrue hexo new â€œpaper_nameâ€æ—¶ä¼šåˆ›å»ºpaper_name.mdå’Œpaper_nameçš„æ–‡ä»¶å¤¹ï¼Œå°†å›¾ç‰‡æ”¾åœ¨paper_nameçš„æ–‡ä»¶å¤¹ 2ã€å®‰è£…æ’ä»¶asset-imagenpm install https://github.com/CodeFalling/hexo-asset-image3ã€è®¾ç½®å›¾ç‰‡ä¸ºç›¸å¯¹è·¯å¾„ æ³¨æ„ä¿®æ”¹å›¾ç‰‡è·¯å¾„ä¸­çš„ \\ ä¸º / ,å¹¶ä¸”ä¸å¸¦ . æˆ–è€… . /","link":"/2021/07/18/hexo-intro/"},{"title":"hiveæ¶æ„","text":"https://cwiki.apache.org/confluence/display/hive/design#Design-HiveArchitecture https://zhuanlan.zhihu.com/p/87545980 https://blog.csdn.net/oTengYue/article/details/91129850 https://jiamaoxiang.top/2020/06/27/Hive%E7%9A%84%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90/ https://www.javatpoint.com/hive-architecture Hive ClientHive allows writing applications in various languages, including Java, Python, and C++. It supports different types of clients such as:- Thrift Server - It is a cross-language service provider platform that serves the request from all those programming languages that supports Thrift. JDBC Driver - It is used to establish a connection between hive and Java applications. The JDBC Driver is present in the class org.apache.hadoop.hive.jdbc.HiveDriver. ODBC Driver - It allows the applications that support the ODBC protocol to connect to Hive. Hive ServicesThe following are the services provided by Hive:- Hive CLI - The Hive CLI (Command Line Interface) is a shell where we can execute Hive queries and commands. Hive Web User Interface - The Hive Web UI is just an alternative of Hive CLI. It provides a web-based GUI for executing Hive queries and commands. Hive MetaStore - It is a central repository that stores all the structure information of various tables and partitions in the warehouse. It also includes metadata of column and its type information, the serializers and deserializers which is used to read and write data and the corresponding HDFS files where the data is stored. Hive Server - It is referred to as Apache Thrift Server. It accepts the request from different clients and provides it to Hive Driver. Hive Driver - It receives queries from different sources like web UI, CLI, Thrift, and JDBC/ODBC driver. It transfers the queries to the compiler. Hive Compiler - The purpose of the compiler is to parse the query and perform semantic analysis on the different query blocks and expressions. It converts HiveQL statements into MapReduce jobs. Hive Execution Engine - Optimizer generates the logical plan in the form of DAG of map-reduce tasks and HDFS tasks. In the end, the execution engine executes the incoming tasks in the order of their dependencies. è®¡ç®—å¼•æ“Hiveæ”¯æŒMapReduceã€Tezã€Spark https://cloud.tencent.com/developer/article/1893808 https://blog.csdn.net/kwu_ganymede/article/details/52223133 æ•°æ®å­˜å‚¨https://cloud.tencent.com/developer/article/1411821 Hiveæ˜¯åŸºäºhdfsçš„ï¼Œå®ƒçš„æ•°æ®å­˜å‚¨åœ¨Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚Hiveæœ¬èº«æ˜¯æ²¡æœ‰ä¸“é—¨çš„æ•°æ®å­˜å‚¨æ ¼å¼ï¼Œä¹Ÿæ²¡æœ‰ä¸ºæ•°æ®å»ºç«‹ç´¢å¼•ï¼Œåªéœ€è¦åœ¨åˆ›å»ºè¡¨çš„æ—¶å€™å‘Šè¯‰Hiveæ•°æ®ä¸­çš„åˆ—åˆ†éš”ç¬¦å’Œè¡Œåˆ†éš”ç¬¦ï¼ŒHiveå°±å¯ä»¥è§£ææ•°æ®ã€‚ defaultæ•°æ®åº“ä¸­çš„è¡¨çš„å­˜å‚¨ä½ç½® /user/hive/warehouseå…¶ä»–æ•°æ®åº“çš„è¡¨è‡ªå·±æŒ‡å®š","link":"/2022/02/09/hive-framework/"},{"title":"Hive MetaStore","text":"1 æè¿°Hive MetaStore - It is a central repository that stores all the structure information of various tables and partitions in the warehouse. It also includes metadata of column and its type information, the serializers and deserializers which is used to read and write data and the corresponding HDFS files where the data is stored. 2 Hiveçš„å…ƒæ•°æ®å­˜å‚¨(Metastoreä¸‰ç§é…ç½®æ–¹å¼)Embeddedï¼ŒLocalï¼ŒRemote https://blog.csdn.net/epitomizelu/article/details/117091656 https://zhuanlan.zhihu.com/p/473378621 https://blog.csdn.net/qq_40990732/article/details/80914873 3 Hiveå…ƒæ•°æ®åº“ä»‹ç»https://blog.csdn.net/victorzzzz/article/details/81874674","link":"/2022/03/30/hive-metadatastore/"},{"title":"Hiveä¸ä¼ ç»Ÿæ•°æ®åº“å¯¹æ¯”","text":"Hive ä¼ ç»Ÿæ•°æ®åº“ æŸ¥è¯¢è¯­è¨€ HQL SQL æ•°æ®å­˜å‚¨ HDFS Raw Deviceæˆ–è€… Local FS æ•°æ®æ ¼å¼ ç”¨æˆ·è‡ªå®šä¹‰ ç³»ç»Ÿå†³å®š æ•°æ®æ›´æ–° ä¸æ”¯æŒ æ”¯æŒ æ‰§è¡Œ MapReduce Excutor æ‰§è¡Œå»¶è¿Ÿ é«˜ ä½ å¤„ç†æ•°æ®è§„æ¨¡ å¤§ å° ç´¢å¼• 0.8ç‰ˆæœ¬ååŠ å…¥ä½å›¾ç´¢å¼• æœ‰å¤æ‚çš„ç´¢å¼• å¯æ‰©å±•æ€§ é«˜ ä½ https://cloud.tencent.com/developer/article/1785857","link":"/2022/03/01/hive-vs-database/"},{"title":"hiveä¼˜åŒ–","text":"https://blog.csdn.net/yu0_zhang0/article/details/81776459 1 ç´¢å¼•https://www.jianshu.com/p/28b825367ba1 https://www.jianshu.com/p/d53f528daca7 Hiveç´¢å¼•çš„ç›®æ ‡æ˜¯æé«˜å¯¹è¡¨çš„æŸäº›åˆ—è¿›è¡ŒæŸ¥è¯¢æŸ¥æ‰¾çš„é€Ÿåº¦ã€‚ ç´¢å¼•æ‰€èƒ½æä¾›çš„æŸ¥è¯¢é€Ÿåº¦çš„æé«˜æ˜¯ä»¥å­˜å‚¨ç´¢å¼•çš„ç£ç›˜ç©ºé—´ä¸ºä»£ä»·çš„ã€‚ Hive 3.0å¼€å§‹å°† ç§»é™¤indexçš„åŠŸèƒ½ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯Hive 2.3ç‰ˆæœ¬å¼€å§‹çš„ç‰©åŒ–è§†å›¾ï¼Œè‡ªåŠ¨é‡å†™çš„ç‰©åŒ–è§†å›¾æ›¿ä»£äº†indexçš„åŠŸèƒ½ã€‚ 2 ç‰©åŒ–è§†å›¾https://blog.csdn.net/u011447164/article/details/105790713 åŒºåˆ«äºæ™®é€šè§†å›¾ 12345create materialized view view2asselect dept.deptno,dept.dname,emp.enamefrom emp,deptwhere emp.deptno=dept.deptno;","link":"/2022/04/06/hive-optimazation/"},{"title":"hive","text":"å¸¸è§é—®é¢˜1.FAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create Spark client for Spark session https://blog.csdn.net/qq_41504585/article/details/108064512 å¯åŠ¨metastorehttps://blog.csdn.net/u010670689/article/details/41576647 hive â€”service metastore 2&gt;&amp;1 &gt;&gt; /var/log.log &amp; å¯åŠ¨hiveserver2hiveserver2 è¿æ¥æ–¹å¼https://blog.csdn.net/qq_41851454/article/details/79833306 https://www.shuzhiduo.com/A/RnJW4Z2r5q/ 1.cli hive 2.beeline https://www.jianshu.com/p/97bbe79d88d2","link":"/2022/01/31/hive/"},{"title":"å»ºè¡¨","text":"https://www.jianshu.com/p/4f60f3c923fe 0 CREATE TABLEhttps://blog.csdn.net/Thomson617/article/details/86153924 123456789101112131415161718192021CREATE EXTERNAL TABLE dim_sku_info ( `id` STRING COMMENT 'å•†å“id', `price` DECIMAL(16,2) COMMENT 'å•†å“ä»·æ ¼', `sku_name` STRING COMMENT 'å•†å“åç§°', `sku_desc` STRING COMMENT 'å•†å“æè¿°', `weight` DECIMAL(16,2) COMMENT 'é‡é‡', `is_sale` BOOLEAN COMMENT 'æ˜¯å¦åœ¨å”®', `spu_id` STRING COMMENT 'spuç¼–å·', `spu_name` STRING COMMENT 'spuåç§°', `category3_id` STRING COMMENT 'ä¸‰çº§åˆ†ç±»id', `category3_name` STRING COMMENT 'ä¸‰çº§åˆ†ç±»åç§°', `category2_id` STRING COMMENT 'äºŒçº§åˆ†ç±»id', `category2_name` STRING COMMENT 'äºŒçº§åˆ†ç±»åç§°', `category1_id` STRING COMMENT 'ä¸€çº§åˆ†ç±»id', `category1_name` STRING COMMENT 'ä¸€çº§åˆ†ç±»åç§°', `tm_id` STRING COMMENT 'å“ç‰Œid', `tm_name` STRING COMMENT 'å“ç‰Œåç§°', `sku_attr_values` ARRAY&lt;STRUCT&lt;attr_id:STRING,value_id:STRING,attr_name:STRING,value_name:STRING&gt;&gt; COMMENT 'å¹³å°å±æ€§', `sku_sale_attr_values` ARRAY&lt;STRUCT&lt;sale_attr_id:STRING,sale_attr_value_id:STRING,sale_attr_name:STRING,sale_attr_value_name:STRING&gt;&gt; COMMENT 'é”€å”®å±æ€§', `create_time` STRING COMMENT 'åˆ›å»ºæ—¶é—´') COMMENT 'å•†å“ç»´åº¦è¡¨' 1 EXTERNAL å…³é”®å­—å¯ä»¥è®©ç”¨æˆ·åˆ›å»ºä¸€ä¸ªå¤–éƒ¨è¡¨ï¼Œé»˜è®¤æ˜¯å†…éƒ¨è¡¨ 2 å­—æ®µçš„æ•°æ®ç±»å‹ https://blog.csdn.net/weixin_46941961/article/details/108551512 https://blog.csdn.net/weixin_43215250/article/details/90034169 é›†åˆæ•°æ®ç±»å‹ï¼šArrayã€Mapå’ŒStruct 1.åˆ†åŒºhttps://www.jianshu.com/p/5dbbaea8ff41 PARTITIONED BY (dt string) 0 åˆ†ç±» é™æ€åˆ†åŒºSPï¼ˆstatic partitionï¼‰åŠ¨æ€åˆ†åŒºDPï¼ˆdynamic partitionï¼‰ é™æ€åˆ†åŒºä¸åŠ¨æ€åˆ†åŒºçš„ä¸»è¦åŒºåˆ«åœ¨äºé™æ€åˆ†åŒºæ˜¯æ‰‹åŠ¨æŒ‡å®šï¼Œè€ŒåŠ¨æ€åˆ†åŒºæ˜¯é€šè¿‡æ•°æ®æ¥è¿›è¡Œåˆ¤æ–­ã€‚ 1 é™æ€åˆ†åŒº 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556--å»ºè¡¨DROP TABLE IF EXISTS dwd_display_log;CREATE EXTERNAL TABLE dwd_display_log( `area_code` STRING COMMENT 'åœ°åŒºç¼–ç ', `brand` STRING COMMENT 'æ‰‹æœºå“ç‰Œ', `channel` STRING COMMENT 'æ¸ é“', `is_new` STRING COMMENT 'æ˜¯å¦é¦–æ¬¡å¯åŠ¨', `model` STRING COMMENT 'æ‰‹æœºå‹å·', `mid_id` STRING COMMENT 'è®¾å¤‡id', `os` STRING COMMENT 'æ“ä½œç³»ç»Ÿ', `user_id` STRING COMMENT 'ä¼šå‘˜id', `version_code` STRING COMMENT 'appç‰ˆæœ¬å·', `during_time` BIGINT COMMENT 'appç‰ˆæœ¬å·', `page_item` STRING COMMENT 'ç›®æ ‡id ', `page_item_type` STRING COMMENT 'ç›®æ ‡ç±»å‹', `last_page_id` STRING COMMENT 'ä¸Šé¡µç±»å‹', `page_id` STRING COMMENT 'é¡µé¢ID ', `source_type` STRING COMMENT 'æ¥æºç±»å‹', `ts` BIGINT COMMENT 'appç‰ˆæœ¬å·', `display_type` STRING COMMENT 'æ›å…‰ç±»å‹', `item` STRING COMMENT 'æ›å…‰å¯¹è±¡id ', `item_type` STRING COMMENT 'appç‰ˆæœ¬å·', `order` BIGINT COMMENT 'æ›å…‰é¡ºåº', `pos_id` BIGINT COMMENT 'æ›å…‰ä½ç½®') COMMENT 'æ›å…‰æ—¥å¿—è¡¨'PARTITIONED BY (`dt` STRING)STORED AS PARQUETLOCATION '/warehouse/gmall/dwd/dwd_display_log'TBLPROPERTIES('parquet.compression'='lzo');--åŠ è½½æ•°æ®insert overwrite table dwd_display_log partition(dt='2020-06-14')select get_json_object(line,'$.common.ar'), get_json_object(line,'$.common.ba'), get_json_object(line,'$.common.ch'), get_json_object(line,'$.common.is_new'), get_json_object(line,'$.common.md'), get_json_object(line,'$.common.mid'), get_json_object(line,'$.common.os'), get_json_object(line,'$.common.uid'), get_json_object(line,'$.common.vc'), get_json_object(line,'$.page.during_time'), get_json_object(line,'$.page.item'), get_json_object(line,'$.page.item_type'), get_json_object(line,'$.page.last_page_id'), get_json_object(line,'$.page.page_id'), get_json_object(line,'$.page.source_type'), get_json_object(line,'$.ts'), get_json_object(display,'$.display_type'), get_json_object(display,'$.item'), get_json_object(display,'$.item_type'), get_json_object(display,'$.order'), get_json_object(display,'$.pos_id')from ods_log lateral view explode_json_array(get_json_object(line,'$.displays')) tmp as displaywhere dt='2020-06-14'and get_json_object(line,'$.displays') is not null; 2 åŠ¨æ€åˆ†åŒº æ³¨æ„åˆ†åŒºå­—æ®µdtæ•°æ®æ¥æºäºdate_format(create_time,â€™yyyy-MM-ddâ€™) å’Œé™æ€åˆ†åŒºæ¯”è¾ƒï¼Œå»ºè¡¨çš„æ—¶å€™æ²¡åŒºåˆ«ï¼ŒåŠ è½½æ•°æ®æœ‰åŒºåˆ« 12345678910111213141516171819202122232425262728--å»ºè¡¨DROP TABLE IF EXISTS dwd_comment_info;CREATE EXTERNAL TABLE dwd_comment_info( `id` STRING COMMENT 'ç¼–å·', `user_id` STRING COMMENT 'ç”¨æˆ·ID', `sku_id` STRING COMMENT 'å•†å“sku', `spu_id` STRING COMMENT 'å•†å“spu', `order_id` STRING COMMENT 'è®¢å•ID', `appraise` STRING COMMENT 'è¯„ä»·(å¥½è¯„ã€ä¸­è¯„ã€å·®è¯„ã€é»˜è®¤è¯„ä»·)', `create_time` STRING COMMENT 'è¯„ä»·æ—¶é—´') COMMENT 'è¯„ä»·äº‹å®è¡¨'PARTITIONED BY (`dt` STRING)STORED AS PARQUETLOCATION '/warehouse/gmall/dwd/dwd_comment_info/'TBLPROPERTIES (&quot;parquet.compression&quot;=&quot;lzo&quot;);--åŠ è½½æ•°æ®insert overwrite table dwd_comment_info partition (dt)select id, user_id, sku_id, spu_id, order_id, appraise, create_time, date_format(create_time,'yyyy-MM-dd')from ods_comment_infowhere dt='2020-0 2 LOCATIONLOCATION â€˜/warehouse/gmall/ods/ods_logâ€™ æŒ‡å®šæ•°æ®åœ¨hdfsä¸Šçš„å­˜å‚¨ä½ç½® 3 ROW FORMAThttps://www.imooc.com/article/12213 https://blog.csdn.net/S_Running_snail/article/details/84258162 æŒ‡å®šæ•°æ®åˆ‡åˆ†æ ¼å¼ ROW FORMAT DELIMITED FIELDS TERMINATED BY â€˜\\tâ€™ 4 STORED AShttps://blog.csdn.net/ZZQHELLO2018/article/details/106175887 æŒ‡å®šå­˜å‚¨æ–¹å¼ è¡Œå¼å­˜å‚¨ï¼šTEXTFILE ã€SEQUENCEFILE åˆ—å¼å­˜å‚¨ï¼š ORCã€PARQUET 5 TBLPROPERTIEShttps://blog.csdn.net/yangguosb/article/details/83651073 https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTableCreate/Drop/TruncateTable TBLPROPERTIESæ˜¯è¡¨çš„ä¸€äº›å±æ€§ï¼ŒHIVEå†…ç½®äº†ä¸€éƒ¨åˆ†å±æ€§ï¼Œä½¿ç”¨è€…ä¹Ÿå¯ä»¥åœ¨åˆ›å»ºè¡¨æ—¶è¿›è¡Œè‡ªå®šä¹‰ï¼› TBLPROPERTIES (â€œparquet.compressionâ€=â€lzoâ€);","link":"/2022/04/02/hql-build/"},{"title":"hqlå¸¸è§æ“ä½œ","text":"1 withâ€¦asâ€¦https://www.jianshu.com/p/d518e9f5d5f9 1 å¥½å¤„ â€‹ a. æé«˜ä»£ç å¯è¯»æ€§ â€‹ ç»“æ„æ¸…æ™° â€‹ b. ä¼˜åŒ–æ‰§è¡Œé€Ÿåº¦ â€‹ å­æŸ¥è¯¢ç»“æœå­˜åœ¨å†…å­˜ä¸­ï¼Œä¸éœ€è¦é‡å¤è®¡ç®— 2 ç”¨æ³• 1with table_name as(å­æŸ¥è¯¢è¯­å¥) å…¶ä»–sql; 1234with temp as ( select * from xxx)select * from temp; 2 è§†å›¾ä¸åŸºæœ¬è¡¨ä¸åŒï¼Œå®ƒæ˜¯ä¸€ä¸ªè™šè¡¨ã€‚åœ¨æ•°æ®åº“ä¸­ï¼Œå­˜æ”¾çš„åªæ˜¯è§†å›¾çš„å®šä¹‰ï¼Œè€Œä¸å­˜æ”¾è§†å›¾åŒ…å«çš„æ•°æ®é¡¹ï¼Œè¿™äº›é¡¹ç›®ä»ç„¶å­˜æ”¾åœ¨åŸæ¥çš„åŸºæœ¬è¡¨ç»“æ„ä¸­ã€‚ è§†å›¾æ˜¯åªè¯»çš„ï¼Œä¸èƒ½å‘è§†å›¾ä¸­æ’å…¥æˆ–åŠ è½½æˆ–æ”¹å˜æ•°æ® ä½œç”¨ï¼š 1 ä¾¿æ· é€šè¿‡å¼•å…¥è§†å›¾æœºåˆ¶ï¼Œç”¨æˆ·å¯ä»¥å°†æ³¨æ„åŠ›é›†ä¸­åœ¨å…¶å…³å¿ƒçš„æ•°æ®ä¸Šï¼ˆè€Œéå…¨éƒ¨æ•°æ®ï¼‰ï¼Œè¿™æ ·å°±å¤§å¤§æé«˜äº†ç”¨æˆ·æ•ˆç‡ä¸ç”¨æˆ·æ»¡æ„åº¦ï¼Œè€Œä¸”å¦‚æœè¿™äº›æ•°æ®æ¥æºäºå¤šä¸ªåŸºæœ¬è¡¨ç»“æ„ï¼Œæˆ–è€…æ•°æ®ä¸ä»…æ¥è‡ªäºåŸºæœ¬è¡¨ç»“æ„ï¼Œè¿˜æœ‰ä¸€éƒ¨åˆ†æ•°æ®æ¥æºäºå…¶ä»–è§†å›¾ï¼Œå¹¶ä¸”æœç´¢æ¡ä»¶åˆæ¯”è¾ƒå¤æ‚æ—¶ï¼Œéœ€è¦ç¼–å†™çš„æŸ¥è¯¢è¯­å¥å°±ä¼šæ¯”è¾ƒçƒ¦çï¼Œæ­¤æ—¶å®šä¹‰è§†å›¾å°±å¯ä»¥ä½¿æ•°æ®çš„æŸ¥è¯¢è¯­å¥å˜å¾—ç®€å•å¯è¡Œã€‚ 2 å®‰å…¨ å®šä¹‰è§†å›¾å¯ä»¥å°†è¡¨ä¸è¡¨ä¹‹é—´çš„å¤æ‚çš„æ“ä½œè¿æ¥å’Œæœç´¢æ¡ä»¶å¯¹ç”¨æˆ·ä¸å¯è§ï¼Œç”¨æˆ·åªéœ€è¦ç®€å•åœ°å¯¹ä¸€ä¸ªè§†å›¾è¿›è¡ŒæŸ¥è¯¢å³å¯ï¼Œæ•…å¢åŠ äº†æ•°æ®çš„å®‰å…¨æ€§ï¼Œä½†ä¸èƒ½æé«˜æŸ¥è¯¢æ•ˆç‡ã€‚ åˆ›å»º 12345678CREATE VIEW [IF NOT EXISTS] view_name [(column_name [COMMENT column_comment], ...) ][COMMENT table_comment]AS SELECT ...hive&gt; CREATE VIEW emp_30000 AS &gt; SELECT * FROM employee &gt; WHERE salary&gt;30000; åˆ é™¤ 1DROP VIEW view_name","link":"/2022/04/02/hql-common-operation/"},{"title":"hqlå¢åˆ æ”¹æŸ¥","text":"1å¢insert load 2åˆ 1 è¡¨ Drop è¡¨ç»“æ„éƒ½æ²¡æœ‰äº† 1DROP TABLE IF EXISTS employee; 2 è®°å½• æ²¡æœ‰DELETE TRUNCATE æ‰€æœ‰è®°å½• truncate table employees; INSERT OVERWRITE 12INSERT OVERWRITE TABLE dpc_test SELECT * FROM dpc_test WHERE age is not null; 3æ”¹1 update é’ˆå¯¹è®°å½• 1update student set id='444' where name='tom'; 2 Alter è¡¨ç»“æ„ 4æŸ¥select","link":"/2022/05/06/hql-crud/"},{"title":"å‡½æ•°","text":"1 ç³»ç»Ÿå‡½æ•°https://www.studytime.xin/article/hive-knowledge-function.html 1 get_json_object https://blog.csdn.net/weixin_43412569/article/details/105290637 2 nvl ç©ºå€¼åˆ¤æ–­è½¬æ¢å‡½æ•° https://blog.csdn.net/a850661962/article/details/101209028 3 coalesce https://blog.csdn.net/yilulvxing/article/details/86595725 1select coalesce(success_cnt,period,1) from tableA å½“success_cntä¸ä¸ºnullï¼Œé‚£ä¹ˆæ— è®ºperiodæ˜¯å¦ä¸ºnullï¼Œéƒ½å°†è¿”å›success_cntçš„çœŸå®å€¼ï¼ˆå› ä¸ºsuccess_cntæ˜¯ç¬¬ä¸€ä¸ªå‚æ•°ï¼‰ï¼Œå½“success_cntä¸ºnullï¼Œè€Œperiodä¸ä¸ºnullçš„æ—¶å€™ï¼Œè¿”å›periodçš„çœŸå®å€¼ã€‚åªæœ‰å½“success_cntå’Œperiodå‡ä¸ºnullçš„æ—¶å€™ï¼Œå°†è¿”å›1ã€‚ 4 collect_listå’Œcollect_set https://blog.csdn.net/weixin_30230059/article/details/113324945 https://blog.csdn.net/qq_44104303/article/details/117551807 å®ƒä»¬éƒ½æ˜¯å°†åˆ†ç»„ä¸­çš„æŸåˆ—è½¬ä¸ºä¸€ä¸ªæ•°ç»„è¿”å›ï¼Œä¸åŒçš„æ˜¯collect_listä¸å»é‡è€Œcollect_setå»é‡ã€‚ 5 named_struct https://blog.csdn.net/weixin_43597208/article/details/117554838 åšå­—æ®µæ‹¼æ¥ åŒºåˆ«äºstructï¼Œstruct æ˜¯é›†åˆæ•°æ®ç±»å‹ï¼Œä¸€èˆ¬ç”¨äºå»ºè¡¨ï¼Œnamed_structæ˜¯å­—æ®µæ‹¼æ¥å‡½æ•°ï¼Œä¸€èˆ¬ç”¨äºæŸ¥è¯¢ 6 array_contains() 1array_contains(arrayï¼Œå€¼) åˆ¤æ–­arrayä¸­æ˜¯å¦åŒ…å«æŸä¸ªå€¼ï¼ŒåŒ…å«è¿”å›trueï¼Œä¸åŒ…å«è¿”å›false 7 cast https://www.jianshu.com/p/999176fa2730 æ˜¾å¼çš„å°†ä¸€ä¸ªç±»å‹çš„æ•°æ®è½¬æ¢æˆå¦ä¸€ä¸ªæ•°æ®ç±»å‹ 1Cast(å­—æ®µå as è½¬æ¢çš„ç±»å‹ ) 2 ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°UDF(User-Defined-Function)ï¼šå•å…¥å•å‡ºUDTF(User-Defined Table-Generating Functions)ï¼šå•å…¥å¤šå‡ºUDAF(User Defined Aggregation Function)ï¼šå¤šå…¥å•å‡ºhttps://blog.csdn.net/qq_40579464/article/details/105903405 1.ç¼–å†™ä»£ç  jarä¸èƒ½éšæ„ç¼–å†™ï¼Œéœ€è¦å’Œhiveå¯¹é½æ¥å£ï¼Œå¯ä»¥å€ŸåŠ©å·¥å…·import org.apache.hadoop.hive.ql.exec.UDF; 121 public class classname extends UDF2 ç¼–å†™evalute https://blog.csdn.net/eyeofeagle/article/details/83904147 2.æ‰“åŒ…3.å¯¼å…¥hiveå¤åˆ¶åˆ°hdfsä¸ŠHiveå®‰è£…ç›®å½•çš„libç›®å½•ä¸‹4.åˆ›å»ºå…³è”add jar hdfs://localhost:9000/user/root/hiveudf.jarcreate temporary function my_lower as â€˜com.example.hive.udf.LowerCaseâ€™;5.ä½¿ç”¨ hql udfçš„ä½¿ç”¨å’Œæ™®é€šå†…ç½®å‡½æ•°ä¸€æ ·ï¼Œæ¯”å¦‚æœ‰udf1 1select udf1ï¼ˆcol1ï¼‰ from table1","link":"/2022/04/02/hql-function/"},{"title":"sql,hqlåŒºåˆ«","text":"https://www.geeksforgeeks.org/difference-between-sql-and-hiveql/","link":"/2022/03/18/hql-sql/"},{"title":"åŠ è½½æ•°æ®","text":"https://www.cnblogs.com/bjlhx/p/6946422.html https://blog.csdn.net/m0_49092046/article/details/109251015 1 load1load data [local] inpath â€˜/opt/module/datas/student.txtâ€™ [overwrite] | into table tabName [partition (partcol1=val1,â€¦)]; ï¼ˆ1ï¼‰load data:è¡¨ç¤ºåŠ è½½æ•°æ®ï¼ˆ2ï¼‰local:è¡¨ç¤ºä»æœ¬åœ°åŠ è½½æ•°æ®åˆ° hive è¡¨ï¼›å¦åˆ™ä» HDFS åŠ è½½æ•°æ®åˆ° hive è¡¨ï¼ˆ3ï¼‰inpath:è¡¨ç¤ºåŠ è½½æ•°æ®çš„è·¯å¾„ï¼ˆ4ï¼‰overwrite:è¡¨ç¤ºè¦†ç›–è¡¨ä¸­å·²æœ‰æ•°æ®ï¼Œå¦åˆ™è¡¨ç¤ºè¿½åŠ ï¼ˆ5ï¼‰into table:è¡¨ç¤ºåŠ è½½åˆ°å“ªå¼ è¡¨ï¼ˆ6ï¼‰tabName:è¡¨ç¤ºå…·ä½“çš„è¡¨ï¼ˆ7ï¼‰partition:è¡¨ç¤ºä¸Šä¼ åˆ°æŒ‡å®šåˆ†åŒº ä¾‹å­ï¼š 1load data inpath '/origin_data/gmall/log/topic_log/2020-06-14' into table ods_log partition(dt='2020-06-14') 2 INSERThttps://help.aliyun.com/document_detail/73775.html insert into å’Œinsert overwrite 1234561insert into table student partition(month='20201022') values(1,'zhangsan');2 insert overwrite table student partition(month='20201023')select id, name from student where month='20201023';","link":"/2022/04/02/hql-loaddata/"},{"title":"huggingface","text":"NLPå°å¸®æ‰‹ï¼Œhuggingfaceçš„transformer gitï¼š https://github.com/huggingface/transformers paperï¼š https://arxiv.org/abs/1910.03771v5 æ•´ä½“ç»“æ„ ç®€å•æ•™ç¨‹ï¼š https://blog.csdn.net/weixin_44614687/article/details/106800244 from_pretrained åº•å±‚ä¸ºload_state_dict 12345678910Some weights of the model checkpoint at ../../../../test/data/chinese-roberta-wwm-ext were not used when initializing listnet_bert: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']- This IS expected if you are initializing listnet_bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).- This IS NOT expected if you are initializing listnet_bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).Some weights of listnet_bert were not initialized from the model checkpoint at ../../../../test/data/chinese-roberta-wwm-ext and are newly initialized: ['Linear2.weight', 'Linear1.weight', 'Linear1.bias', 'Linear2.bias']You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.ä¸¤éƒ¨åˆ†ï¼š1 åŠ è½½çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­æœ‰å‚æ•°æ²¡æœ‰ç”¨åˆ° 2 è‡ªå·±çš„æ¨¡å‹æœ‰å‚æ•°æ²¡æœ‰åˆå§‹åŒ–finetuneçš„æ—¶å€™æŠ¥è¿™ä¸ª å¾ˆæ­£å¸¸predictçš„æ—¶å€™åº”è¯¥ä¸ä¼šæœ‰ å…³äºmodelBertModel -&gt; our model 1 åŠ è½½transformersä¸­çš„æ¨¡å‹ 1from transformers import BertPreTrainedModel, BertModel,AutoTokenizer,AutoConfig 2 åŸºäº1ä¸­çš„æ¨¡å‹æ­å»ºè‡ªå·±çš„ç»“æ„","link":"/2021/12/07/huggingface/"},{"title":"IDEA","text":"æ¿€æ´»https://www.heiz123.com/2022/02/242/#di_liu_bu_da_kai_IDEA_tian_ru_zhi_ding_ji_huo_ma_wan_cheng_ji_huo IDEAä¿®æ”¹å˜é‡çš„å€¼https://blog.csdn.net/qq_36925114/article/details/102484525 debughttps://www.cnblogs.com/chiangchou/p/idea-debug.html language levelhttps://blog.csdn.net/glpghz/article/details/107509987 å½“æˆ‘ä»¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯ JDK 8ï¼Œä½†æ˜¯ä»£ç å´æ²¡æœ‰ä½¿ç”¨ JDK 8 çš„æ–°ç‰¹æ€§ï¼Œåªéœ€ä½¿ç”¨ JDK 7 çš„æ—¶å€™æˆ‘ä»¬å¯ä»¥é€‰æ‹© 7 - Diamondsï¼ŒARMï¼Œmulti-catch etc","link":"/2022/03/08/idea/"},{"title":"å…‹éš†è™šæ‹Ÿæœºä¿®æ”¹é™æ€IPä¸æˆåŠŸè§£å†³åŠæ³•","text":"https://blog.csdn.net/nullnullago/article/details/122343454 https://blog.csdn.net/xiaozizai2015/article/details/88855915 https://blog.csdn.net/Panda_813/article/details/104606990?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;utm_relevant_index=2 https://blog.csdn.net/qq_38616559/article/details/104949693 æ³¨æ„ä¸€ä¸ªå‘ï¼šä¿®æ”¹ipçš„æ—¶å€™ï¼Œvim ens33æ–‡ä»¶äº§ç”Ÿå†²çªï¼Œä»¥ä¸ºä¿®æ”¹æˆåŠŸï¼Œå…¶å®æ²¡æœ‰","link":"/2022/01/29/ifconfig/"},{"title":"å€’æ’ç´¢å¼•","text":"","link":"/2022/07/15/indexing/"},{"title":"ä¿¡æ¯æŠ½å– Information Extraction","text":"ç®€ä»‹ä¿¡æ¯æŠ½å–æ˜¯åŸºäºå·²æœ‰ä¿¡æ¯ç­›é€‰å‡ºç›®æ ‡ä¿¡æ¯ï¼Œä¸æ˜¯æ— ä¸­ç”Ÿæœ‰ï¼Œç”Ÿæˆæ˜¯æœ‰æ— ä¸­ç”Ÿæœ‰çš„èƒ½åŠ› ä¿¡æ¯æŠ½å–ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªå­ä»»åŠ¡ï¼šå‘½åå®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€äº‹ä»¶æŠ½å–ã€‚ å®ä½“æŠ½å–åˆç§°å‘½åå®ä½“è¯†åˆ«ï¼Œå…¶ç›®çš„æ˜¯ä»æ–‡æœ¬ä¸­æŠ½å–å®ä½“ä¿¡æ¯å…ƒç´ ã€‚æƒ³è¦ä»æ–‡æœ¬ä¸­è¿›è¡Œå®ä½“æŠ½å–ï¼Œé¦–å…ˆéœ€è¦ä»æ–‡æœ¬ä¸­è¯†åˆ«å’Œå®šä½å®ä½“ï¼Œç„¶åå†å°†è¯†åˆ«çš„å®ä½“åˆ†ç±»åˆ°é¢„å®šä¹‰çš„ç±»åˆ«ä¸­å»ã€‚ å…³ç³»æŠ½å–æ˜¯çŸ¥è¯†æŠ½å–çš„é‡è¦å­ä»»åŠ¡ä¹‹ä¸€ï¼Œé¢å‘éç»“æ„åŒ–æ–‡æœ¬æ•°æ®ï¼Œ å…³ç³»æŠ½å–æ˜¯ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºä¸¤ä¸ªæˆ–è€…å¤šä¸ªå®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ã€‚å…³ç³»æŠ½å–ä¸å®ä½“æŠ½å–å¯†åˆ‡ç›¸å…³ï¼Œä¸€èˆ¬åœ¨è¯†åˆ«å‡ºæ–‡æœ¬ä¸­çš„å®ä½“åï¼Œå†æŠ½å–å®ä½“ä¹‹é—´å¯èƒ½å­˜åœ¨çš„å…³ç³»ï¼Œä¹Ÿæœ‰å¾ˆå¤šè”åˆæ¨¡å‹åŒæ—¶å°†è¿™ä¸¤ä¸ªä»»åŠ¡ä¸€èµ·åšäº†çš„ï¼› äº‹ä»¶æŠ½å–æ˜¯æŒ‡ ä»è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­æŠ½å–å‡ºç”¨æˆ·æ„Ÿå…´è¶£çš„äº‹ä»¶ä¿¡æ¯ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„å½¢å¼å‘ˆ ç°å‡ºæ¥ï¼Œä¾‹å¦‚äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ã€åœ°ç‚¹ã€å‘ç”ŸåŸå› ã€å‚ä¸è€…ç­‰ã€‚è·Ÿå…³ç³»æŠ½å–æœ‰é‡å çš„åœ°æ–¹ï¼ŒåŒæ ·ä¹Ÿå¯ä»¥åˆ†ä¸ºæµæ°´çº¿æ–¹æ³•å’Œè”åˆæŠ½å–æ–¹æ³•ã€‚ ä¾‹å­ï¼š 1.NERå‘½åå®ä½“è¯†åˆ« ï¼ˆå®ä½“æŠ½å–ï¼‰ï¼šä»æ–‡æœ¬ä¸­æ£€æµ‹å‡ºå‘½åå®ä½“ï¼Œå¹¶å°†å…¶åˆ†ç±»åˆ°é¢„å®šä¹‰çš„ç±»åˆ«ä¸­ï¼Œä¾‹å¦‚äººç‰©ã€ç»„ç»‡ã€åœ°ç‚¹ã€æ—¶é—´ç­‰ã€‚å›¾ä¸­é«˜ç°è‰²è®°çš„æ–‡å­—å°±æ˜¯å‘½åå®ä½“ï¼Œåœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå‘½åå®ä½“è¯†åˆ«æ˜¯çŸ¥è¯†æŠ½å–å…¶ä»–ä»»åŠ¡çš„åŸºç¡€ã€‚2.å…³ç³»æŠ½å– ï¼šä»æ–‡æœ¬ä¸­è¯†åˆ«æŠ½å–å®ä½“åŠå®ä½“ä¹‹é—´çš„å…³ç³»ã€‚ä¾‹å¦‚ï¼Œä»å¥å­â€œ[ç‹æ€èª] æ˜¯ä¸‡è¾¾é›†å›¢è‘£äº‹é•¿[ç‹å¥æ—]çš„ç‹¬å­â€ä¸­è¯†åˆ«å‡ºå®ä½“â€œ[ç‹å¥æ—]â€å’Œâ€œ[ç‹æ€ èª]â€ä¹‹é—´å…·æœ‰â€œçˆ¶å­â€å…³ç³»ã€‚3.äº‹ä»¶æŠ½å–ï¼šè¯†åˆ«æ–‡æœ¬ä¸­å…³äºäº‹ä»¶çš„ä¿¡æ¯ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„å½¢å¼å‘ˆç°ã€‚ä¾‹å¦‚ï¼Œä»ææ€–è¢­å‡»äº‹ä»¶çš„æ–°é—»æŠ¥é“ä¸­è¯†åˆ«è¢­å‡»å‘ç”Ÿçš„åœ°ç‚¹ã€æ—¶é—´ã€è¢­å‡»ç›®æ ‡å’Œå—å®³äººç­‰ä¿¡æ¯ã€‚ å‚è€ƒhttps://zhuanlan.zhihu.com/p/183966841 https://zhuanlan.zhihu.com/p/376898772 https://zhuanlan.zhihu.com/p/352513650","link":"/2022/04/07/information-extract/"},{"title":"Informer Beyond Efficient Transformer for Long Sequence Time-Series Forecasting","text":"paperï¼š https://arxiv.org/abs/2012.07436 code github ï¼š https://github.com/zhouhaoyi/Informer2020 https://zhuanlan.zhihu.com/p/363084133 https://blog.csdn.net/fluentn/article/details/115392229 https://blog.csdn.net/weixin_42838061/article/details/117361871 æ‘˜è¦there are several severe issues with Transformer that prevent it from being directly applicable to LSTFï¼ˆLong sequence time-series forecastingï¼‰, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture Informer, with three distinctive characteristicsï¼š1. ProbSparse self-attention mechanism 2. the self-attention distilling 3.the generative style decoder 2 Preliminary 3 Methodology 3.1 The Uniform Input Representation 3.2 Efficient Self-attention MechanismQuery Sparsity Measurement Some previous attempts have revealed that the distribution of self-attention probability has potential sparsity. The â€œsparsityâ€ self-attention score forms a long tail distribution,è§ä¸Šå›¾,æ¥ä¸‹æ¥å°±æ˜¯è¦æŠŠä¸ç¬¦åˆsparsityçš„queryæ‰¾å‡ºæ¥,ä¹Ÿå°±æ˜¯uniform distributionï¼Œç„¶åç”¨KLæ•£åº¦è¡¡é‡ä¸¤ç§åˆ†å¸ƒçš„è·ç¦»ï¼Œå¾—å‡ºthe i-th queryâ€™s sparsity measurement ä½†æ˜¯ç›´æ¥ç”¨ä¸Šé¢çš„å¼å­å­˜åœ¨å‡ ä¸ªé—®é¢˜ï¼š1. requires calculating each dot-product pairs 2.LogSumExp operation has the potential numerical stability issue å› æ­¤æå‡ºè¿‘ä¼¼çš„è®¡ç®— ProbSparse Self-attention The masked version can be achieved by applying positional mask on step 6 and using cmusum() in mean(\u0001) of step 7. In the practice, we can use sum() as the simpler implement of mean(). 3.3 Encoder: Allowing for Processing Longer Sequential Inputs under the Memory Usage Limitation To enhance the robustness of the distilling operation, we build replicas of the main stack with halving inputs, and progressively decrease the number of self-attention distilling layers by dropping one layer at a time, like a pyramid in Fig.(2) æ³¨æ„:encoderéƒ¨åˆ†æœ‰ä¸¤ä¸ªstackï¼Œä¸€ä¸ªæ˜¯ä¸»stackï¼Œä¸€ä¸ªæ˜¯ä»stackï¼Œå¦‚å›¾2ï¼Œä»stackçš„è¾“å…¥ä¸ºä¸»stackçš„ä¸€åŠï¼Œ Self-attention Distilling 3.4 Decoder: Generating Long Sequential Outputs Through One Forward Procedureâ€˜å’ŒåŸæ¥transformerçš„åŒºåˆ«ï¼šä¸»è¦åœ¨äºpredictionï¼ŒåŸæ¥æ˜¯step by stepï¼Œç°åœ¨æ˜¯one forward procedureï¼Œæ€ä¹ˆå®ç°çš„å‘¢ï¼Ÿå…³é”®åœ¨äºdecoderçš„è¾“å…¥çš„æ„é€  A fully connected layer acquires the final output, and its outsize dy depends on whether we are performing a univariate forecasting or a multivariate one. dy=1 uniï¼Œdy&gt;1 multi","link":"/2021/11/21/informer/"},{"title":"æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……(Intent Detection and Slot Filling)","text":"1.ç®€ä»‹å‡ºè‡ª https://zhuanlan.zhihu.com/p/75228411# åœ¨å¯¹è¯ç³»ç»Ÿçš„NLUä¸­ï¼Œæ„å›¾è¯†åˆ«ï¼ˆIntent Detectionï¼Œç®€å†™ä¸ºIDï¼‰å’Œæ§½ä½å¡«å……ï¼ˆSlot Fillingï¼Œç®€å†™ä¸ºSFï¼‰æ˜¯ä¸¤ä¸ªé‡è¦çš„å­ä»»åŠ¡ã€‚å…¶ä¸­ï¼Œæ„å›¾è¯†åˆ«å¯ä»¥çœ‹åšæ˜¯NLPä¸­çš„ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œè€Œæ§½ä½å¡«å……å¯ä»¥çœ‹åšæ˜¯ä¸€ä¸ªåºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼Œåœ¨æ—©æœŸçš„ç³»ç»Ÿä¸­ï¼Œé€šå¸¸çš„åšæ³•æ˜¯å°†ä¸¤è€…æ‹†åˆ†æˆä¸¤ä¸ªç‹¬ç«‹çš„å­ä»»åŠ¡ã€‚ä½†è¿™ç§åšæ³•è·Ÿäººç±»çš„è¯­è¨€ç†è§£æ–¹å¼æ˜¯ä¸ä¸€è‡´çš„ï¼Œäº‹å®ä¸Šæˆ‘ä»¬åœ¨å®è·µä¸­å‘ç°ï¼Œä¸¤è€…å¾ˆå¤šæ—¶å€™æ˜¯å…·æœ‰è¾ƒå¼ºç›¸å…³æ€§çš„ï¼Œæ¯”å¦‚ä¸‹è¾¹çš„ä¾‹å­ï¼š 1.æˆ‘è¦å¬[åŒ—äº¬å¤©å®‰é—¨, song] â€” Intentï¼šæ’­æ”¾æ­Œæ›²2.å¸®æˆ‘å«ä¸ªè½¦ï¼Œåˆ°[åŒ—äº¬å¤©å®‰é—¨, location] â€” Inentï¼šæ‰“è½¦3.æ’­æ”¾[å¿˜æƒ…æ°´, song] â€” Intentï¼šæ’­æ”¾æ­Œæ›²4.æ’­æ”¾[å¤ä»‡è€…è”ç›Ÿ, movie] â€” Intentï¼šæ’­æ”¾è§†é¢‘ 1å’Œ2ä¸­ï¼Œå¯ä»¥çœ‹åˆ°åŒæ ·æ˜¯â€œåŒ—äº¬å¤©å®‰é—¨â€ï¼Œç”±äºæ„å›¾çš„ä¸åŒï¼Œè¯¥å®ä½“å…·å¤‡å®Œå…¨ä¸åŒçš„æ§½ä½ç±»å‹ã€‚3å’Œ4ä¸­ï¼Œç”±äºæ§½ä½ç±»å‹çš„ä¸åŒï¼Œå¯¼è‡´äº†æœ€ç»ˆæ„å›¾çš„ä¸åŒï¼Œè¿™å¾€å¾€æ„å‘³ç€ï¼Œåœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„åç»§æµç¨‹ä¸­å°†å±•ç°å‡ºå®Œå…¨ä¸åŒçš„è¡Œä¸ºâ€”â€”-æ‰“å¼€ç½‘æ˜“éŸ³ä¹æ’­æ”¾æ­Œæ›² or æ‰“å¼€çˆ±å¥‡è‰ºæ’­æ”¾ç”µå½±ã€‚ éšç€å¯¹è¯ç³»ç»Ÿçš„çƒ­åº¦é€æ¸ä¸Šå‡ï¼Œç ”ç©¶çš„é‡ç‚¹ä¹Ÿé€æ¸å€¾å‘äºå°†ä¸¤ä¸ªä»»åŠ¡è¿›è¡Œè”åˆï¼Œä»¥å……åˆ†åˆ©ç”¨æ„å›¾å’Œæ§½ä½ä¸­çš„è¯­ä¹‰å…³è”ã€‚é‚£ä¹ˆï¼Œé—®é¢˜æ¥äº†ï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•è¿›è¡Œè”åˆå‘¢ï¼Ÿä»ç›®å‰çš„è¶‹åŠ¿æ¥çœ‹ï¼Œå¤§ä½“ä¸Šæœ‰ä¸¤å¤§ç±»æ–¹æ³•ï¼š å¤šä»»åŠ¡å­¦ä¹ ï¼šæŒ‰Multi-Task Learningçš„å¥—è·¯ï¼Œåœ¨å­¦ä¹ æ—¶æœ€ç»ˆçš„lossç­‰äºä¸¤ä¸ªä»»åŠ¡çš„lossçš„weight sumï¼Œä¸¤è€…åœ¨æ¨¡å‹æ¶æ„ä¸Šä»ç„¶å®Œå…¨ç‹¬ç«‹ï¼Œæˆ–è€…ä»…å…±äº«ç‰¹å¾ç¼–ç å™¨ã€‚ äº¤äº’å¼æ¨¡å‹ï¼šå°†æ¨¡å‹ä¸­Slotå’ŒIntentçš„éšå±‚è¡¨ç¤ºè¿›è¡Œäº¤äº’ï¼Œå¼•å…¥æ›´å¼ºçš„å½’çº³åç½®ï¼Œæœ€è¿‘çš„ç ”ç©¶æ˜¾ç¤ºï¼Œè¿™ç§æ–¹æ³•çš„è”åˆNLUå‡†ç¡®ç‡æ›´é«˜ã€‚ å‚è€ƒ[1] https://zhuanlan.zhihu.com/p/165963264 [2] https://zhuanlan.zhihu.com/p/75228411#","link":"/2021/10/09/intent-detect-slot-fill/"},{"title":"æ„å›¾è¯†åˆ«","text":"æœ¬è´¨æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œå¤šç”¨åœ¨æœç´¢å¼•æ“å’Œæ™ºèƒ½é—®ç­”ä¸­ã€‚ è§£å†³æ–¹æ³• 1ã€åŸºäºè§„åˆ™æ¨¡æ¿æ„å›¾è¯†åˆ« https://blog.csdn.net/qq_16555103/article/details/100767984 2ã€åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹æ¥å¯¹ç”¨æˆ·çš„æ„å›¾è¿›è¡Œåˆ¤åˆ« æ¯”å¦‚fasttextï¼ŒLSTM+attentionï¼ŒBERT å‚è€ƒhttps://blog.csdn.net/qq_37228811/article/details/104307144?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.no_search_link&amp;spm=1001.2101.3001.4242 https://blog.csdn.net/qq_16555103/article/details/100767984","link":"/2021/10/09/intent-detect/"},{"title":"javaåº”ç”¨åœºæ™¯","text":"å‰ç«¯ åç«¯ å¤§æ•°æ® https://www.cnblogs.com/zlt9/p/7206238.html","link":"/2022/03/06/java-application/"},{"title":"javaæ¡†æ¶","text":"https://segmentfault.com/a/1190000016917114","link":"/2022/03/06/java-framework/"},{"title":"å¤šçº¿ç¨‹ç¼–ç¨‹","text":"è¿›ç¨‹ &gt; çº¿ç¨‹","link":"/2022/05/03/java-multi-thread/"},{"title":"ç½‘ç»œç¼–ç¨‹","text":"","link":"/2022/05/03/java-net-program/"},{"title":"javaå¸¸è§é—®é¢˜","text":"Could not find or load main classhttps://blog.csdn.net/gao_zhennan/article/details/112749742 https://www.html.cn/softprog/java/142271.html https://blog.csdn.net/qq_43189115/article/details/99856659 https://blog.csdn.net/zdash21/article/details/101310736 https://www.jianshu.com/p/bd5d07982699 java.lang.NoClassDefFoundErrorhttps://www.jianshu.com/p/8dcdb02f97f7 https://blog.csdn.net/jamesjxin/article/details/46606307 Warning: Class â€˜com.xxx.xxxâ€˜ not found in module â€˜xxxxâ€˜https://blog.csdn.net/diligent_jianhao/article/details/111515183 java: Compilation failed: internal java compiler errorhttps://blog.csdn.net/ximaiyao1984/article/details/114782006","link":"/2022/03/08/java-problem/"},{"title":"javaå­¦ä¹ ç½‘ç«™","text":"https://www.pdai.tech/","link":"/2022/05/16/java-tech/"},{"title":"jdbc","text":"https://zhuanlan.zhihu.com/p/140885502 JDBCçš„å…¨ç§°æ˜¯Javaæ•°æ®åº“è¿æ¥(Java Database connect)ï¼Œå®ƒæ˜¯ä¸€å¥—ç”¨äºæ‰§è¡ŒSQLè¯­å¥çš„Java APIã€‚åº”ç”¨ç¨‹åºå¯é€šè¿‡è¿™å¥—APIè¿æ¥åˆ°å…³ç³»æ•°æ®åº“ï¼Œå¹¶ä½¿ç”¨SQLè¯­å¥æ¥å®Œæˆå¯¹æ•°æ®åº“ä¸­æ•°æ®çš„æŸ¥è¯¢ã€æ›´æ–°å’Œåˆ é™¤ç­‰æ“ä½œã€‚åº”ç”¨ç¨‹åºä½¿ç”¨JDBCè®¿é—®æ•°æ®åº“çš„æ–¹å¼å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚","link":"/2022/03/19/jdbc/"},{"title":"java","text":"1.Javaå¹³å°https://www.cnblogs.com/HeavenZhi/p/14075331.html#jrejava-runtime-environment https://blog.csdn.net/ZGL_cyy/article/details/104081834 javaæ˜¯è¯­è¨€ï¼Œè¿™ä¸ªæ˜¯å¹³å°ã€‚Java å¹³å°ç”± Java è™šæ‹Ÿæœºï¼ˆJava Virtual Machineï¼ŒJVMï¼‰å’Œ Java åº”ç”¨ç¼–ç¨‹æ¥å£ï¼ˆApplication Programming Interfaceï¼ŒAPIï¼‰ï¼‰æ„æˆã€‚ java SE Java SEï¼ˆJava Platform Standard Editionï¼ŒJava å¹³å°æ ‡å‡†ç‰ˆï¼‰ä»¥å‰ç§°ä¸º J2SEï¼Œå®ƒå…è®¸å¼€å‘å’Œéƒ¨ç½²åœ¨æ¡Œé¢ã€æœåŠ¡å™¨ã€åµŒå…¥å¼ç¯å¢ƒå’Œå®æ—¶ç¯å¢ƒä¸­ä½¿ç”¨çš„ Java åº”ç”¨ç¨‹åºã€‚Java SE åŒ…å«äº†æ”¯æŒ Java Web æœåŠ¡å¼€å‘çš„ç±»ï¼Œå¹¶ä¸º Java EE æä¾›åŸºç¡€ï¼Œå¦‚ Java è¯­è¨€åŸºç¡€ã€JDBC æ“ä½œã€I/O æ“ä½œã€ç½‘ç»œé€šä¿¡ä»¥åŠå¤šçº¿ç¨‹ç­‰æŠ€æœ¯ã€‚ Java EE Java EEï¼ˆJava Platform Enterprise Editionï¼ŒJava å¹³å°ä¼ä¸šç‰ˆï¼‰ä»¥å‰ç§°ä¸º J2EEã€‚ä¼ä¸šç‰ˆæœ¬å¸®åŠ©å¼€å‘å’Œéƒ¨ç½²å¯ç§»æ¤ã€å¥å£®ã€å¯ä¼¸ç¼©ä¸”å®‰å…¨çš„æœåŠ¡å™¨ç«¯ Java åº”ç”¨ç¨‹åºã€‚Java EE æ˜¯åœ¨ Java SE åŸºç¡€ä¸Šæ„å»ºçš„ï¼Œå®ƒæä¾› Web æœåŠ¡ã€ç»„ä»¶æ¨¡å‹ã€ç®¡ç†å’Œé€šä¿¡ APIï¼Œå¯ä»¥ç”¨æ¥å®ç°ä¼ä¸šçº§çš„é¢å‘æœåŠ¡ä½“ç³»ç»“æ„ï¼ˆService Oriented Architectureï¼ŒSOAï¼‰å’Œ Web 2.0 åº”ç”¨ç¨‹åºã€‚ Java ME Java MEï¼ˆJava Platform Micro Editionï¼ŒJava å¹³å°å¾®å‹ç‰ˆï¼‰ä»¥å‰ç§°ä¸º J2MEï¼Œä¹Ÿå« K-JAVAã€‚ Java ME ä¸ºåœ¨ç§»åŠ¨è®¾å¤‡å’ŒåµŒå…¥å¼è®¾å¤‡ï¼ˆæ¯”å¦‚æ‰‹æœºã€PDAã€ç”µè§†æœºé¡¶ç›’å’Œæ‰“å°æœºï¼‰ä¸Šè¿è¡Œçš„åº”ç”¨ç¨‹åºæä¾›ä¸€ä¸ªå¥å£®ä¸”çµæ´»çš„ç¯å¢ƒã€‚ Java ME åŒ…æ‹¬çµæ´»çš„ç”¨æˆ·ç•Œé¢ã€å¥å£®çš„å®‰å…¨æ¨¡å‹ã€ä¸°å¯Œçš„å†…ç½®ç½‘ç»œåè®®ä»¥åŠå¯¹å¯ä»¥åŠ¨æ€ä¸‹è½½çš„è”ç½‘å’Œç¦»çº¿åº”ç”¨ç¨‹åºã€‚åŸºäº Java ME è§„èŒƒçš„åº”ç”¨ç¨‹åº åªéœ€ç¼–å†™ä¸€æ¬¡å°±å¯ä»¥ç”¨äºè®¸å¤šè®¾å¤‡ï¼Œè€Œä¸”å¯ä»¥åˆ©ç”¨æ¯ä¸ªè®¾å¤‡çš„æœ¬æœºåŠŸèƒ½ã€‚ 2 run command123456789101112131415//he_test// lib// src// HelloWorld.java// binpackage com.hlw.test;public class HelloWorld { /* ç¬¬ä¸€ä¸ªJavaç¨‹åº * * å®ƒå°†è¾“å‡ºå­—ç¬¦ä¸² Hello World * */ public static void main(String[] args) { System.out.println(&quot;Hello World&quot;); // è¾“å‡º Hello World }} he_testä¸‹ 1.ç¼–è¯‘ä»£ç  javac -d bin/ ./src/HelloWorld.java bin/ä¸‹ç”Ÿæˆcom/hlw/test/HelloWorld.class 2.è¿è¡Œç¨‹åº java -classpath/-cp ./bin/ com/hlw/test/HelloWorld 3 Java æºæ–‡ä»¶çš„å‘½åè§„åˆ™ é€šå¸¸æƒ…å†µä¸‹ï¼ŒJava ç¨‹åºæºæ–‡ä»¶çš„ä¸»æ–‡ä»¶åå¯ä»¥ä»»æ„ã€‚ ä½†å¦‚æœå…¶ä¸­å®šä¹‰äº†ä¸€ä¸ª public ç±»ï¼Œåˆ™è¯¥æºæ–‡ä»¶çš„æ–‡ä»¶åå¿…é¡»ä¸è¯¥ public ç±»çš„ç±»åç›¸åŒã€‚ ä¸€ä¸ªJava æºæ–‡ä»¶å¯åŒ…å«å¤šä¸ªç±»å®šä¹‰ï¼Œä½†æœ€å¤šåªèƒ½åŒ…å«ä¸€ä¸ªpublicç±»å®šä¹‰ã€‚ 4 jaråŒ…0.ä¸‹è½½jaråŒ…https://www.cnblogs.com/Marydon20170307/p/9149256.html 1.ç¯å¢ƒå¯¼å…¥jaråŒ…ide https://www.jianshu.com/p/9762b7098b76 https://www.cnblogs.com/mracale/p/10493823.html ubuntu https://blog.csdn.net/weixin_30681615/article/details/99745369 https://blog.csdn.net/chencaw/article/details/78884107 https://blog.csdn.net/j_bean/article/details/75095337 ä¾‹å­: ####ç›®å½•ç»“æ„test â€‹ lib â€‹ spark-assembly_2.10-1.6.0-cdh5.16.1.jar â€‹ src â€‹ demo.java â€‹ bin #åœ¨testè·¯å¾„ä¸‹ 1.ç¼–è¯‘ javac -cp ./lib/spark-assembly_2.10-1.6.0-cdh5.16.1.jar -d ./bin/ ./src/demo.java 2.è¿è¡Œ java -cp ./lib/spark-assembly_2.10-1.6.0-cdh5.16.1.jar:./bin/ com/yzy/spark/demo æ³¨æ„ï¼š1 -cp éœ€è¦åˆ—å‡ºæ‰€æœ‰jaråŒ…ï¼Œideä¹Ÿæ˜¯å…¨éƒ¨åˆ—å‡ºäº† 2 windowä¸Šï¼Œç”¨;åˆ†éš”ï¼›linuxä¸Šæ˜¯:åˆ†éš” 2.ä»£ç å¼•ç”¨jaråŒ…import 3.æ€ä¹ˆç”Ÿæˆjarhttps://www.cnblogs.com/swordfall/p/11359370.html https://blog.csdn.net/smgsn01/article/details/108038046 mavenï¼Œideè‡ªå¸¦ï¼Œjarå‘½ä»¤ 4.æ‰§è¡Œjava -jar XXX.jar 5 packagehttps://blog.csdn.net/qq_41297896/article/details/90056534 https://www.runoob.com/java/java-package.html https://www.runoob.com/w3cnote/java-compile-with-package.html ä¸ºäº†æ›´å¥½åœ°ç»„ç»‡ç±»ï¼Œç”¨äºåŒºåˆ«ç±»åçš„å‘½åç©ºé—´ åŒ…çš„å‘½åè§„èŒƒ https://blog.csdn.net/shi779276212/article/details/92795085 ä½¿ç”¨ï¼š 6 é‡å†™(Override)ä¸é‡è½½(Overload)https://www.runoob.com/java/java-override-overload.html é‡å†™ï¼šæ˜¯å­ç±»å¯¹çˆ¶ç±»åŒåå‡½æ•°çš„äºŒæ¬¡å®ç° é‡è½½ï¼šä¸€ä¸ªç±»å†…å­˜åœ¨å¤šä¸ªé‡åå‡½æ•°ï¼Œè€Œå‚æ•°ä¸åŒ 7 å¤šæ€http://c.biancheng.net/view/1001.html# https://www.runoob.com/java/java-polymorphism.html å¤šæ€æ˜¯åŒä¸€ä¸ªè¡Œä¸ºå…·æœ‰å¤šä¸ªä¸åŒè¡¨ç°å½¢å¼æˆ–å½¢æ€çš„èƒ½åŠ›ã€‚ å¤šæ€å­˜åœ¨çš„ä¸‰ä¸ªå¿…è¦æ¡ä»¶ ç»§æ‰¿ é‡å†™ çˆ¶ç±»å¼•ç”¨æŒ‡å‘å­ç±»å¯¹è±¡ï¼šParent p = new Child(); åˆ†ç±»ï¼š https://blog.csdn.net/zhao_miao/article/details/83750898 1 å‘ä¸Šè½¬å‹ çˆ¶ç±» çˆ¶ç±»å¯¹è±¡ = å­ç±»å®ä¾‹ åªèƒ½è°ƒç”¨çˆ¶ç‰¹æœ‰ï¼Œå­è¦†ç›–ï¼Œä¸èƒ½å­ç‰¹æœ‰ 2 å‘ä¸‹è½¬å‹ å‘ä¸‹è½¬å‹ä¹‹å‰ä¸€å®šè¦è¿›è¡Œå‘ä¸Šè½¬å‹ï¼ï¼ å­ç±» å­ç±»å¯¹è±¡ = ï¼ˆå­ç±»ï¼‰çˆ¶ç±»å®ä¾‹ å¯ä»¥çˆ¶ç‰¹æœ‰ï¼Œå­è¦†ç›–ï¼Œå­ç‰¹æœ‰ 8 å‡½æ•°å…¥å£https://blog.csdn.net/weixin_29740921/article/details/114249667 å‡½æ•°å…¥å£ä¸ºmainï¼Œå°±å’Œc++çš„mainå‡½æ•°ä¸€æ ·ï¼Œmainæ–¹æ³•çš„å†™æ³•æ˜¯å›ºå®šçš„ 12public static void main(String[] args) {}public static void main(String args[]) {} ä¸€ä¸ªjavaæ–‡ä»¶å¯ä»¥ä¸åªæœ‰ä¸€ä¸ªmainï¼Œä¸åŒç±»éƒ½å¯ä»¥æœ‰è‡ªå·±çš„mainï¼Œç„¶åé€‰å“ªä¸ªmainå‘¢ï¼Œä¹Ÿå°±æ˜¯é€‰å“ªä¸ªç±»å‘¢ï¼Ÿ é€‰å…¬å…±ç±»ï¼ˆè‡³å¤šåŒ…å«ä¸€ä¸ªï¼‰ï¼›è‹¥æ˜¯æ²¡æœ‰å°±é€‰ç”¨åŒåç±»ï¼Œå’Œæ–‡ä»¶åŒå 9 å¼•ç”¨javaæ²¡æœ‰æŒ‡é’ˆ å’ŒC++çš„å¼•ç”¨ä¸ä¸€æ ·ï¼Œå’ŒC++æŒ‡é’ˆæœ‰ç‚¹åƒ java 4ç§å¼•ç”¨ https://blog.csdn.net/linzhiqiang0316/article/details/88591907 10 æ•°æ®ç±»å‹å’Œå˜é‡ç±»å‹çš„åŒºåˆ«https://blog.csdn.net/qq_61411852/article/details/123130531 1.æ•°æ®ç±»å‹ å®šä¹‰ä¸€ä¸ªå˜é‡ï¼Œæ¯ä¸€ç§æ•°æ®ç±»å‹éœ€è¦ç”¨åˆ°çš„å­˜å‚¨ç©ºé—´éƒ½ä¸åŒï¼Œè¿™æ—¶éœ€è¦ç”¨ä¸åŒçš„æ•°æ®ç±»å‹æ¥å®šä¹‰å˜é‡ï¼›ä¾‹å¦‚ï¼šint float doubleç­‰ç­‰ 2.å˜é‡ç±»å‹ å±€éƒ¨å˜é‡ï¼šç±»çš„æ–¹æ³•ä¸­çš„å˜é‡ã€‚ å®ä¾‹å˜é‡ï¼šç‹¬ç«‹äºæ–¹æ³•ä¹‹å¤–çš„å˜é‡ï¼Œä¸è¿‡æ²¡æœ‰ static ä¿®é¥°ã€‚ ç±»å˜é‡ï¼šç‹¬ç«‹äºæ–¹æ³•ä¹‹å¤–çš„å˜é‡ï¼Œç”¨ static ä¿®é¥°ã€‚ 12 æ•°æ®ç±»å‹åŸºæœ¬ç±»å‹ï¼šbooleanï¼Œ charï¼Œ intï¼Œ byteï¼Œshortï¼Œlongï¼Œ floatï¼Œdoubleï¼ˆæœ‰å€¼åŸŸèŒƒå›´ï¼‰ ä¸ºä»€ä¹ˆå­˜åœ¨åŸºæœ¬ç±»å‹è¿˜è¦åŒ…è£…ç±»ï¼Ÿ åŸºæœ¬ç±»å‹ä¸æ˜¯å¯¹è±¡ï¼ŒåŒ…è£…ç±»æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œå¢åŠ é¢å‘å¯¹è±¡ç‰¹æ€§ åŒ…è£…ç±»ï¼šBooleanï¼ŒCharacterï¼ŒIntegerï¼ŒByteï¼ŒShortï¼ŒLongï¼ŒFloatï¼ŒDouble è‡ªåŠ¨è£…ç®± 123456Integer i = 100;ç­‰ä»·äºInteger i = Integer.valueOf(100);ArrayList intList = new ArrayList();intList.add(1); è‡ªåŠ¨æ‹†ç®± 1234int t = i; ç­‰ä»·äºint t = i.intValue(); 13 æ•°ç»„å£°æ˜ 12345dataType[] arrayRefVar; // é¦–é€‰çš„æ–¹æ³• æˆ– dataType arrayRefVar[]; // æ•ˆæœç›¸åŒï¼Œä½†ä¸æ˜¯é¦–é€‰æ–¹æ³• åˆ›å»º 123arrayRefVar=new dataType[arraySize];æˆ–è€…arrayRefVar = {value0, value1, ..., valuek}; å¤šç»´æ•°ç»„ 1type[][] typeName = new type[typeLength1][typeLength2]; 14 foreachå’Œæ™®é€šforå¾ªç¯æ¯”è¾ƒï¼Œåœ¨éå†æ•°ç»„ã€é›†åˆæ–¹é¢ï¼Œforeachä¸ºå¼€å‘äººå‘˜æä¾›äº†æå¤§çš„æ–¹ä¾¿ 123456for(å…ƒç´ ç±»å‹t å…ƒç´ å˜é‡x : éå†å¯¹è±¡obj){ å¼•ç”¨äº†xçš„javaè¯­å¥; } 12345678910public class TestArray { public static void main(String[] args) { double[] myList = {1.9, 2.9, 3.4, 3.5}; // æ‰“å°æ‰€æœ‰æ•°ç»„å…ƒç´  for (double element: myList) { System.out.println(element); } }} 15 ä»æ§åˆ¶å°è¯»å–æ•°æ®1 BufferedReader 12341 throws IOException2 BufferedReader br = new BufferedReader(new InputStreamReader(System.in));3 c = (char) br.read();æˆ–è€…str = br.readLine(); 2 Scanner 16 ç±»å‹è½¬åŒ–http://c.biancheng.net/view/796.html 1è‡ªåŠ¨ç±»å‹è½¬æ¢ ä¸¤ç§æ•°æ®ç±»å‹å½¼æ­¤å…¼å®¹ ç›®æ ‡ç±»å‹çš„å–å€¼èŒƒå›´å¤§äºæºæ•°æ®ç±»å‹ï¼ˆä½çº§ç±»å‹æ•°æ®è½¬æ¢æˆé«˜çº§ç±»å‹æ•°æ®ï¼‰ 2 å¼ºåˆ¶ç±»å‹è½¬æ¢ æ‰€ä»¥å½“ä¸¤ç§æ•°æ®ç±»å‹ä¸å…¼å®¹ï¼Œæˆ–ç›®æ ‡ç±»å‹çš„å–å€¼èŒƒå›´å°äºæºç±»å‹æ—¶ï¼Œè‡ªåŠ¨è½¬æ¢å°†æ— æ³•è¿›è¡Œï¼Œè¿™æ—¶å°±éœ€è¦è¿›è¡Œå¼ºåˆ¶ç±»å‹è½¬æ¢ã€‚ 123int a = 3;double b = 5.0;a = (int)b; 17 å¼‚å¸¸å¤„ç†http://c.biancheng.net/view/6751.html Exception æ˜¯å¼‚å¸¸çš„åŸºç±» 1 è¯­å¥æŠ›å‡ºå¼‚å¸¸ try 123456789try{ // ç¨‹åºä»£ç }catch(å¼‚å¸¸ç±»å‹1 å¼‚å¸¸çš„å˜é‡å1){ // ç¨‹åºä»£ç }catch(å¼‚å¸¸ç±»å‹2 å¼‚å¸¸çš„å˜é‡å2){ // ç¨‹åºä»£ç }finally{ // ç¨‹åºä»£ç } throw å½“ throw è¯­å¥æ‰§è¡Œæ—¶ï¼Œå®ƒåé¢çš„è¯­å¥å°†ä¸æ‰§è¡Œï¼Œæ­¤æ—¶ç¨‹åºè½¬å‘è°ƒç”¨è€…ç¨‹åºï¼Œå¯»æ‰¾ä¸ä¹‹ç›¸åŒ¹é…çš„ catch è¯­å¥ï¼Œæ‰§è¡Œç›¸åº”çš„å¼‚å¸¸å¤„ç†ç¨‹åºã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸åŒ¹é…çš„ catch è¯­å¥ï¼Œåˆ™å†è½¬å‘ä¸Šä¸€å±‚çš„è°ƒç”¨ç¨‹åºã€‚è¿™æ ·é€å±‚å‘ä¸Šï¼Œç›´åˆ°æœ€å¤–å±‚çš„å¼‚å¸¸å¤„ç†ç¨‹åºç»ˆæ­¢ç¨‹åºå¹¶æ‰“å°å‡ºè°ƒç”¨æ ˆæƒ…å†µã€‚ 1throw ExceptionObject; 2 æ–¹æ³•æŠ›å‡ºå¼‚å¸¸ throws å‡½æ•°å£°æ˜å¼‚å¸¸ï¼Œä½†æ˜¯æœ¬èº«ä¸å¤„ç†å¼‚å¸¸ï¼Œäº¤ç»™è°ƒç”¨è€…å¤„ç† 1returnType method_name(paramList) throws Exception 1,Exception2,â€¦{â€¦} 1234567891011121314151617181920212223import java.io.FileInputStream;import java.io.IOException;public class Test04 { public void readFile() throws IOException { // å®šä¹‰æ–¹æ³•æ—¶å£°æ˜å¼‚å¸¸ FileInputStream file = new FileInputStream(&quot;read.txt&quot;); // åˆ›å»º FileInputStream å®ä¾‹å¯¹è±¡ int f; while ((f = file.read()) != -1) { System.out.println((char) f); f = file.read(); } file.close(); } public static void main(String[] args) { Throws t = new Test04(); try { t.readFile(); // è°ƒç”¨ readFHe()æ–¹æ³• } catch (IOException e) { // æ•è·å¼‚å¸¸ System.out.println(e); } }} 12public static void main(String[] args) throws Exceptionå¼‚å¸¸è°å¤„ç†ï¼ŒJVMå¤„ç† 20 finalï¼Œstaticï¼Œstaticå’Œfinalä¸€èµ·ä½¿ç”¨https://blog.csdn.net/hust_yfang/article/details/79585696 1 final ç±» å˜é‡ æ–¹æ³• 2 static å˜é‡ æ–¹æ³• è€çœ‹è§å‡½æ•°å‰é¢æœ‰staticï¼Œå¯ä»¥æ²¡æœ‰ï¼ŒäºŒè€…åŒºåˆ«ï¼š åŠ äº†staticï¼Œå¯ä»¥ä¸ç”¨å®ä¾‹åŒ–ç±»å°±èƒ½è°ƒç”¨æ–¹æ³•ï¼›æ²¡æœ‰åŠ staticï¼Œå¿…é¡»å®ä¾‹åŒ–ç±»æ‰å¯ä»¥ç”¨ 3 staticå’Œfinalä¸€èµ·ä½¿ç”¨ å˜é‡ æ–¹æ³• 22 æ³›å‹ç›®çš„ï¼šä¸ºäº†å…¼å®¹å¤šç§æ•°æ®ç±»å‹ æ³›å‹æ ‡è®°ç¬¦ 12345678E - Element (åœ¨é›†åˆä¸­ä½¿ç”¨ï¼Œå› ä¸ºé›†åˆä¸­å­˜æ”¾çš„æ˜¯å…ƒç´ )ï¼›T - Typeï¼ˆJava ç±»ï¼‰ï¼›K - Keyï¼ˆé”®ï¼‰ï¼›V - Valueï¼ˆå€¼ï¼‰ï¼›N - Numberï¼ˆæ•°å€¼ç±»å‹ï¼‰ï¼›R - Result ï¼ˆè¿”å›ç»“æœï¼Œå¤šç”¨äºå‡½æ•°å¼ç¼–ç¨‹ï¼‰ï¼›? - è¡¨ç¤ºä¸ç¡®å®šçš„javaç±»å‹ã€‚O 1 æ³›å‹æ–¹æ³• 12public void printArray( int [] inputArray ) -ã€‹public &lt; E &gt; void printArray( E[] inputArray )public &lt;T extends Comparable&lt;T&gt;&gt; T maximum(T x, T y, T z) //Comparableæ˜¯ä¸€ä¸ªç±» 2 æ³›å‹ç±» 1public class Box -ã€‹ public class Box&lt;T&gt; 23 å¯¹è±¡ä½œä¸ºè¿”å›å€¼123456789101112131415161718192021222324252627282930313233 class Phone { String brand;//å“ç‰Œ double price; String color; public void call(String who){ System.out.println(&quot;ç»™&quot;+who+&quot;æ‰“ç”µè¯&quot;); } public void sendMessage(){ System.out.println(&quot;ç¾¤å‘çŸ­ä¿¡&quot;); }}public class test { public static void main(String[] args) { Phone two=getPhone(); System.out.println(two.price); System.out.println(two.brand); System.out.println(two.color); } public static Phone getPhone(){ Phone one=new Phone(); one.brand=&quot;è‹¹æœ&quot;; one.price=8388.0; one.color=&quot;ç«ç‘°é‡‘&quot;; return one; }} 24 æ­£åˆ™javaå’Œpythonæ­£åˆ™å¾ˆåƒï¼Œä½†ä¸æ˜¯å®Œå…¨ä¸€æ · https://blog.csdn.net/weixin_39574708/article/details/114958384 https://blog.csdn.net/henu_xiaohei/article/details/84765678 1 | æˆ–è€… 2 å›ºå®šåŒ¹é…ä½æ•° 12\\d{7,8} //7ä¸ºæˆ–è€…8ä¸º[A-Z]{1}[0-9]{8} æ³¨æ„matches()ï¼Œfindï¼ˆï¼‰ matchæ˜¯å…¨éƒ¨åŒ¹é…ï¼Œfindæ˜¯éƒ¨åˆ†åŒ¹é… 3 è½¬ä¹‰å­—ç¬¦ è½¬ä¹‰å­—ç¬¦\\ *ï¼šä¸åŒäºåŸæ¥çš„å­—æ¯å«ä¹‰ï¼Œæ¯”å¦‚\\nè¡¨ç¤ºæ¢è¡Œ javaæ­£åˆ™ä¸ºä»€ä¹ˆè¦ä¸¤ä¸ªæ–œæ†è¡¨ç¤ºè½¬ä¹‰ https://blog.csdn.net/qq_37325947/article/details/107819945 25 javaå¦‚ä½•å…¼å®¹ä¸åŒç±»å‹çš„è¾“å…¥ å‡½æ•°é‡è½½ æ³›å‹ 26 è£…é¥°å™¨@Override éœ€è¦ä½ é‡å†™ 28 ç±»this å’Œpython selfä¸€æ ·ï¼ŒæŒ‡çš„æ˜¯å¯¹è±¡ #ç±»ç›´æ¥è°ƒç”¨æ–¹æ³• https://blog.csdn.net/qq_40136594/article/details/83996659 éœ€è¦æ˜¯é™æ€æ–¹æ³• 1 åˆ›å»ºå¯¹è±¡new 12345678910public class Puppy{ public Puppy(String name){ //è¿™ä¸ªæ„é€ å™¨ä»…æœ‰ä¸€ä¸ªå‚æ•°ï¼šname System.out.println(&quot;å°ç‹—çš„åå­—æ˜¯ : &quot; + name ); } public static void main(String[] args){ // ä¸‹é¢çš„è¯­å¥å°†åˆ›å»ºä¸€ä¸ªPuppyå¯¹è±¡ Puppy myPuppy = new Puppy( &quot;tommy&quot; ); }} 2 ç±»ç»§æ‰¿1 extends 123class å­ç±» extends çˆ¶ç±» {}//åªå¯ä»¥å•ç»§æ‰¿ 2 implements ä¸€èˆ¬ç”¨äºç±»ç»§æ‰¿æ¥å£ 1234567891011public interface A { public void eat(); public void sleep();} public interface B { public void show();} public class C implements A,B {} superå…³é”®å­—ï¼šå½“å‰å¯¹è±¡ï¼Œä½†æ˜¯ç”¨æ¥è°ƒç”¨çˆ¶ç±»æˆå‘˜ thiså…³é”®å­—ï¼šå½“å‰å¯¹è±¡ï¼Œç”¨æ¥è°ƒç”¨å­ç±»æˆå‘˜ å…³äºæ„é€ å‡½æ•°ï¼š 1 è¿›å…¥å­ç±»å¯¹åº”çš„æ„é€ å‡½æ•° 2 è‹¥æ˜¯æ²¡æœ‰æ˜¾ç¤ºè°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°ï¼Œåˆ™è‡ªåŠ¨è°ƒç”¨ï¼›è‹¥æ˜¯æ˜¾ç¤ºçš„è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°ï¼ˆsuper()ï¼Œå¿…é¡»å†™ç¬¬ä¸€å¥ï¼Œsuper.SuperClassï¼ˆï¼‰ é”™è¯¯ï¼‰ï¼Œåˆ™æ˜¾ç¤ºè°ƒç”¨ 3 å…ˆè°ƒç”¨çˆ¶ç±»ï¼Œç„¶åè°ƒç”¨å­ç±» 3 åŒ¿åç±»https://www.runoob.com/java/java-anonymous-class.html 4 æŠ½è±¡ç±»ï¼ŒæŠ½è±¡æ–¹æ³•ä½œç”¨ï¼šæŠ½è±¡ç±»ä¸ºæ‰€æœ‰å­ç±»æä¾›äº†ä¸€ä¸ªé€šç”¨æ¨¡æ¿ï¼Œå­ç±»å¯ä»¥åœ¨è¿™ä¸ªæ¨¡æ¿åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ï¼Œå¯ä»¥é¿å…å­ç±»è®¾è®¡çš„éšæ„æ€§ 1 æŠ½è±¡ç±» ç‰¹æ®Šçš„ç±»ï¼šæŠ½è±¡ç±»ä¸èƒ½å®ä¾‹åŒ–å¯¹è±¡ï¼Œä¼šæŠ¥é”™ 12public abstract class Employee1 åœ¨æ™®é€šç±»çš„åŸºç¡€ä¸ŠåŠ abstract æ€ä¹ˆä½¿ç”¨æŠ½è±¡ç±»ï¼Ÿ é€šè¿‡ç±»ç»§æ‰¿çš„æ–¹å¼ä½¿ç”¨ 2 æŠ½è±¡æ–¹æ³• æ™®é€šç±»ä¸èƒ½æœ‰æŠ½è±¡æ–¹æ³•ï¼Œåªæœ‰æŠ½è±¡ç±»ï¼Œæˆ–è€…æ¥å£ 1234public abstract double computePay();1. abstract2. åªæœ‰å‡½æ•°å£°æ˜ï¼Œæ²¡æœ‰å‡½æ•°å…·ä½“å®ç°3 å­ç±»ä¸æ˜¯æŠ½è±¡ç±»ï¼Œéœ€è¦ç»™å‡ºæŠ½è±¡ç±»ä¸­çš„æŠ½è±¡æ–¹æ³•çš„å…·ä½“å®ç°ï¼›å­ç±»ä¹Ÿæ˜¯æŠ½è±¡ç±»ï¼Œé‚£ä¹ˆå¯ä»¥ä¸éœ€è¦ 5 æ¥å£æ¥å£å¹¶ä¸æ˜¯ç±»ï¼Œæ˜¯æŠ½è±¡æ–¹æ³•çš„é›†åˆ 12345[å¯è§åº¦] interface æ¥å£åç§° [extends å…¶ä»–çš„æ¥å£åï¼Œ å…¶ä»–çš„æ¥å£åï¼Œ å…¶ä»–çš„æ¥å£å] { // å£°æ˜å˜é‡,åªèƒ½æ˜¯ public static final ç±»å‹çš„ // æŠ½è±¡æ–¹æ³•}//æ¥å£åªèƒ½ç»§æ‰¿æ¥å£ï¼Œextendsï¼Œå¯ä»¥æ˜¯å¤šç»§æ‰¿ æ€ä¹ˆä½¿ç”¨æ¥å£ï¼Ÿé€šè¿‡ç±»æ¥å®ç° 123...implements æ¥å£åç§°[, å…¶ä»–æ¥å£åç§°, å…¶ä»–æ¥å£åç§°..., ...] ...public class MammalInt implements Animal // Animalæ˜¯æ¥å£ å…³ç³»ï¼š ç±»å’Œç±»ï¼Œç»§æ‰¿ï¼Œåªèƒ½å•ç»§æ‰¿ ç±»å’Œæ¥å£ï¼Œå®ç°ï¼Œå¯ä»¥å¤šå®ç° æ¥å£å’Œæ¥å£ï¼Œç»§æ‰¿ï¼Œå¯ä»¥å¤šç»§æ‰¿ default https://blog.csdn.net/qq_35835624/article/details/80196932 é…åˆæ¥å£ä½¿ç”¨ ä½¿å¾—æ¥å£å†…çš„å‡½æ•°å¯ä»¥å†™æ–¹æ³•ä½“ï¼ŒåŸæ¥å…¨æ˜¯æŠ½è±¡æ–¹æ³•ï¼Œä¸èƒ½æœ‰æ–¹æ³•ä½“ 29 Lambdaè¡¨è¾¾å¼å£°æ˜çš„æ—¶å€™éœ€è¦ -&gt; https://www.runoob.com/java/java8-lambda-expressions.html 12345MathOperation subtraction = (a, b) -&gt; a - b; //å£°æ˜System.out.println(&quot;10 - 5 = &quot; + tester.operate(10, 5, subtraction));//è°ƒç”¨ä¸€èµ· System.out.println(&quot;10 - 5 = &quot; + tester.operate(10, 5, (a, b) -&gt; a - b));","link":"/2022/01/05/java/"},{"title":"jupyter notebook","text":"é…ç½®https://blog.csdn.net/weixin_41149572/article/details/114640624 ä¼ å‚å’Œ.pyå”¯ä¸€åŒºåˆ« jupyterï¼šargs=parser.pars_args(argew=[ä¼ å…¥å‚æ•°]) pyï¼šargs=parser.pars_args() å‚è€ƒhttps://blog.csdn.net/weixin_41149572/article/details/114640624","link":"/2022/06/22/jupyter-notebook/"},{"title":"jvm","text":"1. JDKã€JREã€JVM0 æ±‡æ€»https://github.com/doocs/jvm 1 JDKã€JREã€JVMhttps://its401.com/article/weixin_45797022/104963478 ä¸‰è€…çš„åŒºåˆ«ä¸è”ç³» JDKç”¨äºå¼€å‘ï¼Œæ˜¯ç»™å¼€å‘äººå‘˜ç”¨çš„ JRE ç”¨äºè¿è¡Œjavaç¨‹åºï¼Œæ™®é€šç”¨æˆ·ç”¨ JVMæ˜¯javaå®ç°è·¨å¹³å°çš„æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œæ™®é€šç”¨æˆ·ç”¨ 2 javaå†…å­˜åŒºåŸŸï¼Œjava memory modeläºŒè€…ä¸åŒ https://blog.csdn.net/javazejian/article/details/72772461 1 å†…å­˜åŒºåŸŸ https://cloud.tencent.com/developer/article/1748395 string çš„ å†…å­˜åˆ†é… https://blog.csdn.net/liufangbaishi2014/article/details/52238881 2 jmm","link":"/2022/05/01/jvm/"},{"title":"k-fold","text":"","link":"/2021/10/13/k-fold/"},{"title":"kafkaå¸¸è§è®¡ç®—","text":"Kafkaæœºå™¨æ•°é‡è®¡ç®—ç»éªŒå…¬å¼ï¼šKafkaæœºå™¨æ•°é‡= 2 ï¼ˆå³°å€¼ç”Ÿäº§é€Ÿåº¦ å‰¯æœ¬æ•° / 100ï¼‰+ 1 1ï¼‰å³°å€¼ç”Ÿäº§é€Ÿåº¦ å³°å€¼ç”Ÿäº§é€Ÿåº¦å¯ä»¥å‹æµ‹å¾—åˆ°ã€‚ 2ï¼‰å‰¯æœ¬æ•° å‰¯æœ¬æ•°é»˜è®¤æ˜¯1ä¸ªï¼Œåœ¨ä¼ä¸šé‡Œé¢2-3ä¸ªéƒ½æœ‰ï¼Œ2ä¸ªå±…å¤šã€‚ å‰¯æœ¬å¤šå¯ä»¥æé«˜å¯é æ€§ï¼Œä½†æ˜¯ä¼šé™ä½ç½‘ç»œä¼ è¾“æ•ˆç‡ã€‚ ä¾‹å­ï¼š å…ˆæ‹¿åˆ°å³°å€¼ç”Ÿäº§é€Ÿåº¦ï¼Œå†æ ¹æ®è®¾å®šçš„å‰¯æœ¬æ•°ï¼Œå°±èƒ½é¢„ä¼°å‡ºéœ€è¦éƒ¨ç½²Kafkaçš„æ•°é‡ã€‚ æ¯”å¦‚æˆ‘ä»¬çš„å³°å€¼ç”Ÿäº§é€Ÿåº¦æ˜¯50M/sã€‚å‰¯æœ¬æ•°ä¸º2ã€‚ Kafkaæœºå™¨æ•°é‡ = 2 ï¼ˆ50 2 / 100ï¼‰+ 1 = 3å° Kafkaåˆ†åŒºæ•°è®¡ç®—ï¼ˆ1ï¼‰åˆ›å»ºä¸€ä¸ªåªæœ‰1ä¸ªåˆ†åŒºçš„topic ï¼ˆ2ï¼‰æµ‹è¯•è¿™ä¸ªtopicçš„producerååé‡å’Œconsumerååé‡ã€‚ ï¼ˆ3ï¼‰å‡è®¾ä»–ä»¬çš„å€¼åˆ†åˆ«æ˜¯Tpå’ŒTcï¼Œå•ä½å¯ä»¥æ˜¯MB/sã€‚ ï¼ˆ4ï¼‰ç„¶åå‡è®¾æ€»çš„ç›®æ ‡ååé‡æ˜¯Ttï¼Œé‚£ä¹ˆåˆ†åŒºæ•° = Tt / minï¼ˆTpï¼ŒTcï¼‰ ä¾‹å¦‚ï¼šproducerååé‡ = 20m/sï¼›consumerååé‡ = 50m/sï¼ŒæœŸæœ›ååé‡100m/sï¼›åˆ†åŒºæ•° = 100 / 20 = 5åˆ†åŒº https://blog.csdn.net/weixin_42641909/article/details/89294698 åˆ†åŒºæ•°ä¸€èˆ¬è®¾ç½®ä¸ºï¼š3-10ä¸ª","link":"/2022/03/12/kafka-cal/"},{"title":"kafkaå¸¸è§é—®é¢˜","text":"1 kafkaå¯åŠ¨åä¸€æ®µæ—¶é—´è‡ªåŠ¨é€€å‡ºçš„è§£å†³æ–¹æ¡ˆhttps://blog.csdn.net/weixin_46303867/article/details/115256466 2 ERROR Shutdown broker because all log dirs in â€¦ have failedhttps://blog.csdn.net/szxiaohe/article/details/103639127 3 è¿æ¥zookeeperè¶…æ—¶https://www.jianshu.com/p/ce215e6ef203","link":"/2022/03/12/kafka-problem/"},{"title":"kafkaå¸¸è§å‘½ä»¤","text":"å¯åŠ¨å‘½ä»¤ 1/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties å…³é—­å‘½ä»¤ 1/opt/module/kafka/bin/kafka-server-stop.sh stop","link":"/2022/04/11/kafka-command/"},{"title":"kafkaä¸Zookeeperçš„å…³ç³»","text":"https://www.lilinchao.com/archives/1548.html https://developer.51cto.com/article/658581.html è¿‡å» Apache Kafkaçš„ä¸€ä¸ªå…³é”®ä¾èµ–æ˜¯Apache Zookeeperï¼Œå®ƒæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼é…ç½®å’ŒåŒæ­¥æœåŠ¡ã€‚ Zookeeperæ˜¯Kafkaä»£ç†å’Œæ¶ˆè´¹è€…ä¹‹é—´çš„åè°ƒæ¥å£ã€‚ KafkaæœåŠ¡å™¨é€šè¿‡Zookeeperé›†ç¾¤å…±äº«ä¿¡æ¯ã€‚ Kafkaåœ¨Zookeeperä¸­å­˜å‚¨åŸºæœ¬å…ƒæ•°æ®ï¼Œä¾‹å¦‚å…³äºä¸»é¢˜ï¼Œä»£ç†ï¼Œæ¶ˆè´¹è€…åç§»(é˜Ÿåˆ—è¯»å–å™¨)ç­‰çš„ä¿¡æ¯ã€‚ ç”±äºæ‰€æœ‰å…³é”®ä¿¡æ¯å­˜å‚¨åœ¨Zookeeperä¸­ï¼Œå¹¶ä¸”å®ƒé€šå¸¸åœ¨å…¶æ•´ä½“ä¸Šå¤åˆ¶æ­¤æ•°æ®ï¼Œå› æ­¤Kafkaä»£ç†/ Zookeeperçš„æ•…éšœä¸ä¼šå½±å“Kafkaé›†ç¾¤çš„çŠ¶æ€ã€‚ Kafkaå°†æ¢å¤çŠ¶æ€ï¼Œä¸€æ—¦Zookeeperé‡æ–°å¯åŠ¨ã€‚ è¿™ä¸ºKafkaå¸¦æ¥äº†é›¶åœæœºæ—¶é—´ã€‚ Kafkaä»£ç†ä¹‹é—´çš„é¢†å¯¼è€…é€‰ä¸¾ä¹Ÿé€šè¿‡ä½¿ç”¨Zookeeperåœ¨é¢†å¯¼è€…å¤±è´¥çš„æƒ…å†µä¸‹å®Œæˆã€‚ æœªæ¥ Kafka 2.8.0ï¼Œç§»é™¤äº†å¯¹Zookeeperçš„ä¾èµ–ï¼Œé€šè¿‡KRaftè¿›è¡Œè‡ªå·±çš„é›†ç¾¤ç®¡ç†","link":"/2022/03/12/kafka-zoo/"},{"title":"KafkaåŸç†ç»“æ„","text":"Apache KafkaÂ® is an event streaming platform. What does that mean? Kafka combines three key capabilities so you can implement your use cases for event streaming end-to-end with a single battle-tested solution: To publish (write) and subscribe to (read) streams of events, including continuous import/export of your data from other systems. To store streams of events durably and reliably for as long as you want. To process streams of events as they occur or retrospectively. And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner. Kafka can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud. You can choose between self-managing your Kafka environments and using fully managed services offered by a variety of vendors. è¯¦ç»†åŸç†è§ï¼šhttps://blog.csdn.net/weixin_45366499/article/details/106943229","link":"/2022/01/30/kafka/"},{"title":"ä¸»å¤–é”®","text":"ä¸»é”®ã€å¤–é”® https://blog.csdn.net/weixin_31642161/article/details/113113942 æœ‰å¯èƒ½æ²¡æœ‰ä¸»é”® è”åˆä¸»é”®ï¼Œå¤åˆä¸»é”® è”åˆä¸»é”®ï¼šæ•°æ®åº“è¡¨çš„ä¸»é”®ç”±ä¸¤ä¸ªåŠä»¥ä¸Šçš„å­—æ®µç»„æˆã€‚ å¤åˆä¸»é”®ï¼šæœ‰äº‰è®®","link":"/2022/02/15/key-id/"},{"title":"key&#x2F;value","text":"æŸä¸ªå­—æ®µä¸ºkeyï¼ŒæŸä¸ªå­—æ®µä¸ºvalue","link":"/2022/03/02/key-value/"},{"title":"KG-BERT BERT for Knowledge Graph Completion","text":"åŸæ–‡ https://arxiv.org/pdf/1909.03193.pdf ä¸€.èƒŒæ™¯è¡¥å…… çŸ¥è¯†å›¾è°±æ™®éå­˜åœ¨ä¸å®Œå¤‡çš„é—®é¢˜ã€‚ä»¥ä¸Šå›¾ä¸ºä¾‹ï¼Œé»‘è‰²çš„ç®­å¤´è¡¨ç¤ºå·²ç»å­˜åœ¨çš„å…³ç³»ï¼Œçº¢è‰²çš„è™šçº¿åˆ™æ˜¯ç¼ºå¤±çš„å…³ç³»ã€‚çŸ¥è¯†å›¾è°±è¡¥å…¨æ˜¯åŸºäºå›¾è°±é‡Œå·²æœ‰çš„å…³ç³»å»æ¨ç†å‡ºç¼ºå¤±çš„å…³ç³»ã€‚ç”±äºBERTåœ¨NLPå–å¾—çš„æˆç»©ï¼Œä½œè€…å°†å…¶è¿ç§»åˆ°çŸ¥è¯†å›¾è°±è¡¥å…¨çš„åº”ç”¨ä¸Šã€‚ äºŒ.ç»“æ„ä½œè€…è®¾è®¡äº†ä¸¤ç§è®­ç»ƒæ–¹å¼çš„KG - BERT, å¯ä»¥è¿ç”¨åˆ°ä¸åŒçš„çŸ¥è¯†å›¾è°±è¡¥å…¨ä»»åŠ¡å½“ä¸­ã€‚ 2.1 Illustrations of fine-tuning KG-BERT for predicting the plausibility of a triple è¾“å…¥ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼Œ$Head$ï¼Œ$Relation$ï¼Œ$Tail$ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ$Head$å¯ä»¥æ˜¯â€œSteven Paul Jobs was an American business magnate,entrepreneur and investor.â€ æˆ–è€…â€œSteve Jobsâ€ï¼Œ$Relation$å¯ä»¥æ˜¯â€œfoundedâ€ï¼Œ$Tail$å¯ä»¥æ˜¯â€œApple Inc. is an American multinational technology company headquartered in Cupertino, California.â€æˆ–è€…â€œApple Inc.â€ã€‚ç”¨$[SEP]$åˆ†éš”å®ä½“å’Œå…³ç³»ã€‚è¾“å…¥ä¸º3ä¸ªå‘é‡çš„sumï¼Œå³token, segment å’Œposition embeddingsã€‚å¯¹äºsegmentï¼Œå®ä½“çš„segment Embeddingä¸º$e_A$ï¼Œè€Œå…³ç³»çš„segment Embeddingä¸º$e_B$ã€‚å¯¹äºposition ï¼Œç›¸åŒpositionçš„ä¸åŒtokenä½¿ç”¨ç›¸åŒçš„position embeddingã€‚ å¯¹äºè¾“å…¥çš„ä¸‰å…ƒç»„$\\tau=(h,r,t)$ï¼Œç›®æ ‡å‡½æ•°ä¸ºï¼š S_{\\tau}=f(h,r,t)=sigmoid(CW^T)ï¼ŒS_{\\tau} \\in \\mathbb{R}^2,S_{\\tau 0}, S_{\\tau 1} \\in [0,1]æŸå¤±å‡½æ•°æ˜¯$S$å’Œ$y$çš„äº¤å‰ç†µï¼š L=-\\sum_{\\tau \\in D^{+}\\cup D^{-}}(y_{\\tau}log(S_{\\tau0})+(1-y_{\\tau}log(S_{\\tau1})))å…¶ä¸­$y_{\\tau}\\in \\{0,1\\}$æ˜¯æ ‡ç­¾ã€‚ å…³äºè´Ÿæ ·æœ¬çš„æ„é€ ï¼Œä½œè€…æ˜¯å°†æ­£æ ·æœ¬çš„$Head$æˆ–è€…$Tail$å˜æˆéšæœºæ›¿æ¢æˆåˆ«çš„ï¼Œå¦‚ä¸‹ D^{-}=\\{(h^{'},r,t)|h^{'}\\in E\\cap h^{'}\\neq h \\cap(h^{'},r,t)\\notin D^{+} \\}\\\\\\cup\\{(h,r,t^{'})|t^{'}\\in E\\cap t^{'}\\neq t \\cap(h,r,t^{'})\\notin D^{+}\\}å…¶ä¸­$E$ä¸ºå®ä½“çš„é›†åˆã€‚ 2.2 Illustrations of fine-tuning KG-BERT for predicting the relation between two entities ä½œè€…å‘ç°ç›´æ¥ä½¿ç”¨ä¸¤ä¸ªå®ä½“å»é¢„æµ‹å…³ç³»ï¼Œæ•ˆæœä¼˜äºä½¿ç”¨ä¸¤ä¸ªå®ä½“å’Œä¸€ä¸ªéšæœºå…³ç³»ï¼ˆè¿™é‡Œæœ¬äººè®¤ä¸ºä¸€ä¸ªéšæœºçš„å…³ç³»æœ¬æ¥å°±æ˜¯é”™è¯¯ç‰¹å¾ï¼Œæ„Ÿè§‰è‚¯å®šä¼šå½±å“é¢„æµ‹ç»“æœï¼‰ã€‚è¿™é‡Œå’Œ2.1ç»“æ„çš„å·®å¼‚åœ¨äºï¼š1.è¾“å…¥ä»å®ä½“åŠ å…³ç³»çš„ä¸‰è¾“å…¥å˜æˆåŸºäºå®ä½“çš„åŒè¾“å…¥2.è¾“å‡ºä»äºŒåˆ†ç±»å˜æˆå¤šåˆ†ç±» ç›®æ ‡å‡½æ•°ä¸ºï¼š S_{\\tau}^{'}=f(h,r,t)=softmax(CW^{'T})æŸå¤±å‡½æ•°ä¸º$S^{â€˜}$å’Œ$y^{â€˜}$çš„äº¤å‰ç†µï¼š L^{'}=-\\sum_{\\tau \\in D^{+}}\\sum_{i=1}^{R}y_{\\tau i}^{'}log(s^{'}_{\\tau i})ä¸‰.å®éªŒsettingï¼š We choose pre-trained BERT-Base model with 12 layers, 12 self-attention heads and H = 768 as the initialization of KG-BERT, then fine tune KG-BERT with Adam implemented in BERT. å‚è€ƒhttps://github.com/yao8839836/kg-bert https://zhuanlan.zhihu.com/p/355391327","link":"/2021/08/06/kg-bert/"},{"title":"KNN","text":"KNNå¯ä»¥ç”¨æ¥åˆ†ç±»å’Œå›å½’ï¼Œä»¥åˆ†ç±»ä¸ºä¾‹ã€‚ ä¸€.ç®—æ³•æµç¨‹ KNNåˆ†ç±»ç®—æ³•çš„è®¡ç®—è¿‡ç¨‹ï¼š 1ï¼‰è®¡ç®—å¾…åˆ†ç±»ç‚¹ä¸å·²çŸ¥ç±»åˆ«çš„ç‚¹ä¹‹é—´çš„è·ç¦» 2ï¼‰æŒ‰ç…§è·ç¦»é€’å¢æ¬¡åºæ’åº 3ï¼‰é€‰å–ä¸å¾…åˆ†ç±»ç‚¹è·ç¦»æœ€å°çš„Kä¸ªç‚¹ 4ï¼‰ç¡®å®šå‰Kä¸ªç‚¹æ‰€åœ¨ç±»åˆ«çš„å‡ºç°æ¬¡æ•° 5ï¼‰è¿”å›å‰Kä¸ªç‚¹å‡ºç°æ¬¡æ•°æœ€é«˜çš„ç±»åˆ«ä½œä¸ºå¾…åˆ†ç±»ç‚¹çš„é¢„æµ‹åˆ†ç±» å¦‚ä¸Šå›¾ï¼Œä¸¾ä¸ªä¾‹å­ï¼š å¦‚æœK=3ï¼Œç»¿è‰²åœ†ç‚¹çš„æœ€é‚»è¿‘çš„3ä¸ªç‚¹æ˜¯2ä¸ªçº¢è‰²å°ä¸‰è§’å½¢å’Œ1ä¸ªè“è‰²å°æ­£æ–¹å½¢ï¼Œå°‘æ•°ä»å±äºå¤šæ•°ï¼ŒåŸºäºç»Ÿè®¡çš„æ–¹æ³•ï¼Œåˆ¤å®šç»¿è‰²çš„è¿™ä¸ªå¾…åˆ†ç±»ç‚¹å±äºçº¢è‰²çš„ä¸‰è§’å½¢ä¸€ç±»ã€‚ å¦‚æœK=5ï¼Œç»¿è‰²åœ†ç‚¹çš„æœ€é‚»è¿‘çš„5ä¸ªé‚»å±…æ˜¯2ä¸ªçº¢è‰²ä¸‰è§’å½¢å’Œ3ä¸ªè“è‰²çš„æ­£æ–¹å½¢ï¼Œè¿˜æ˜¯å°‘æ•°ä»å±äºå¤šæ•°ï¼ŒåŸºäºç»Ÿè®¡çš„æ–¹æ³•ï¼Œåˆ¤å®šç»¿è‰²çš„è¿™ä¸ªå¾…åˆ†ç±»ç‚¹å±äºè“è‰²çš„æ­£æ–¹å½¢ä¸€ç±»ã€‚ äºŒ.è·ç¦»åº¦é‡é€‰æ‹©1.é—µå¯å¤«æ–¯åŸºè·ç¦» 2.æ¬§å¼è·ç¦» 3.æ›¼å“ˆé¡¿è·ç¦» ä¸‰.Kå€¼çš„é€‰æ‹©é€‰æ‹©è¾ƒå°çš„Kå€¼ï¼Œå®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆï¼›é€‰æ‹©è¾ƒå¤§çš„Kå€¼ï¼Œåˆ™å®¹æ˜“æ¬ æ‹Ÿåˆã€‚åœ¨åº”ç”¨ä¸­ï¼Œé€šå¸¸é‡‡ç”¨äº¤å‰éªŒè¯æ³•æ¥é€‰æ‹©æœ€ä¼˜Kå€¼ã€‚ å››.ä¼˜ç¼ºç‚¹ä¼˜ç‚¹: 1ï¼‰ç®—æ³•ç®€å•ï¼Œç†è®ºæˆç†Ÿï¼Œæ—¢å¯ä»¥ç”¨æ¥åšåˆ†ç±»ä¹Ÿå¯ä»¥ç”¨æ¥åšå›å½’ã€‚ 2ï¼‰å¯ç”¨äºéçº¿æ€§åˆ†ç±»ã€‚ ç¼ºç‚¹ï¼š 1ï¼‰éœ€è¦ç®—æ¯ä¸ªæµ‹è¯•ç‚¹ä¸è®­ç»ƒé›†çš„è·ç¦»ï¼Œå½“è®­ç»ƒé›†è¾ƒå¤§æ—¶ï¼Œè®¡ç®—é‡ç›¸å½“å¤§ï¼Œæ—¶é—´å¤æ‚åº¦é«˜ï¼Œç‰¹åˆ«æ˜¯ç‰¹å¾æ•°é‡æ¯”è¾ƒå¤§çš„æ—¶å€™ã€‚ 2ï¼‰æ ·æœ¬ä¸å¹³è¡¡é—®é¢˜ï¼ˆå³æœ‰äº›ç±»åˆ«çš„æ ·æœ¬æ•°é‡å¾ˆå¤šï¼Œè€Œå…¶å®ƒæ ·æœ¬çš„æ•°é‡å¾ˆå°‘ï¼‰ï¼Œå¯¹ç¨€æœ‰ç±»åˆ«çš„é¢„æµ‹å‡†ç¡®åº¦ä½ã€‚","link":"/2021/10/10/knn/"},{"title":"çŸ¥è¯†å›¾è°±","text":"ä¸œå—çš„è¯¾ç¨‹ï¼š https://github.com/npubird/KnowledgeGraphCourse","link":"/2021/12/12/knowledgegraph/"},{"title":"From RankNet to LambdaRank to LambdaMART","text":"1.RankNetRankNeté‡‡ç”¨pairwiseçš„æ–¹æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚ lossæ¨å¯¼ ç»™å®šç‰¹å®š$query$ä¸‹çš„ä¸¤ä¸ªæ–‡æ¡£$U_i$å’Œ$U_j$ï¼Œå…¶ç‰¹å¾å‘é‡åˆ†åˆ«ä¸º$x_i$å’Œ$x_j$ï¼Œç»è¿‡RankNetè¿›è¡Œå‰å‘è®¡ç®—å¾—åˆ°å¯¹åº”çš„åˆ†æ•°ä¸º$s_i=f(x_i)$å’Œ$s_j=f(x_j)$ã€‚ç”¨$U_i \\rhd U_j$è¡¨ç¤º$U_i$æ¯”$U_j$æ’åºæ›´é å‰ã€‚ç»§è€Œå¯ä»¥ç”¨ä¸‹é¢çš„å…¬å¼æ¥è¡¨ç¤º$U_i$åº”è¯¥æ¯”$U_j$æ’åºæ›´é å‰çš„æ¦‚ç‡ï¼š P_{ij} \\equiv P(U_i \\rhd U_j) \\equiv \\frac{1}{1+e^{-\\sigma(s_i-s_j)}}å®šä¹‰$S_{ij} \\in \\{0,\\pm1\\}$ä¸ºæ–‡æ¡£$i$å’Œæ–‡æ¡£$j$è¢«æ ‡è®°çš„æ ‡ç­¾ä¹‹é—´çš„å…³è”ï¼Œå³ S_{ij}=\\left\\{ \\begin{aligned} 1&& æ–‡æ¡£iæ¯”æ–‡æ¡£jæ›´ç›¸å…³\\\\ 0&& æ–‡æ¡£iå’Œæ–‡æ¡£jç›¸å…³æ€§ä¸€è‡´\\\\ -1&& æ–‡æ¡£jæ¯”æ–‡æ¡£iæ›´ç›¸å…³ \\end{aligned} \\right.å®šä¹‰$\\overline{P}_{ij}=\\frac{1}{2}(1+S_{ij})$è¡¨ç¤º$U_i$åº”è¯¥æ¯”$U_j$æ’åºæ›´é å‰çš„å·²çŸ¥æ¦‚ç‡ï¼Œåˆ™å¯ä»¥ç”¨äº¤å‰ç†µå®šä¹‰ä¼˜åŒ–ç›®æ ‡çš„æŸå¤±å‡½æ•°ï¼š \\begin{align*} C&=-\\overline{P}_{ij}log{P_{ij}}-(1-\\overline{P}_{ij})log(1-P_{ij}) \\\\&=\\frac{1}{2}(1-S_{ij})\\sigma(s_i-s_j)+log(1+e^{-\\sigma(s_i-s_j)}) \\end{align*}æ³¨æ„ï¼š$\\sigma$æ˜¯è¶…å‚æ•° ranknet åŠ é€Ÿ 2.LambdaRankranketç¼ºé™·ä¸ºåªè€ƒè™‘pairçš„ç›¸å¯¹ä½ç½®æ²¡æœ‰è€ƒè™‘äºŒè€…åœ¨åˆ—è¡¨çš„æ•´ä½“ä½ç½® LambdaRankæœ¬è´¨ä¸ºranknetåŸºç¡€ä¸ŠåŠ å…¥Listwiseçš„æŒ‡æ ‡ï¼Œå› æ­¤æœ‰äººå°†LambdaRankå½’ä¸ºlistwiseæ–¹æ³•ï¼Œä¹Ÿæœ‰å½’åˆ°pairwiseæ–¹æ³• 2.1 RankNetçš„å±€é™ 2.2 LambdaRankå®šä¹‰ \\begin{align*} \\frac{\\partial{C}}{\\partial{w_k}}&=\\frac{\\partial{C}}{\\partial{s_i}}\\frac{\\partial{s_i}}{\\partial{w_k}}+\\frac{\\partial{C}}{\\partial{s_j}}\\frac{\\partial{s_j}}{\\partial{w_k}} \\\\&=\\sigma\\left(\\frac{1}{2}(1-S_{ij})-\\frac{1}{1+e^{\\sigma(s_i-s_j)}}\\right)\\left(\\frac{\\partial{s_i}}{\\partial{w_k}}-\\frac{\\partial{s_j}}{\\partial{w_k}}\\right) \\\\&=\\lambda_{ij}\\left(\\frac{\\partial{s_i}}{\\partial{w_k}}-\\frac{\\partial{s_j}}{\\partial{w_k}}\\right) \\end{align*} \\\\å…¶ä¸­\\lambda_{ij}=\\frac{\\partial{C}}{\\partial{s_i}}=-\\frac{\\partial{C}}{\\partial{s_j}}=\\sigma\\left(\\frac{1}{2}(1-S_{ij})-\\frac{1}{1+e^{\\sigma(s_i-s_j)}}\\right)ä¸Šè¿°å…¬å¼å¯ä»¥è¿›ä¸€æ­¥ç®€åŒ–ï¼Œå³åªè€ƒè™‘$S_{ij}=1$ ï¼ˆä¸ºä»€ä¹ˆå¯ä»¥ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼‰ é‚£ä¹ˆLambdaï¼Œ$\\lambda$ï¼Œå°±æ˜¯æ¢¯åº¦ \\lambda_{ij}=\\frac{-\\sigma}{1+e^{\\sigma(s_i-s_j)}}ä¸ºäº†åŠ å¼ºæ’åºä¸­å‰åé¡ºåºçš„é‡è¦æ€§ï¼ŒLambdaåœ¨åŸåŸºç¡€ä¸Šå¼•å…¥è¯„ä»·æŒ‡æ ‡Zï¼ˆå¦‚NDCGï¼‰ï¼ŒæŠŠäº¤æ¢ä¸¤ä¸ªæ–‡æ¡£çš„ä½ç½®å¼•èµ·çš„è¯„ä»·æŒ‡æ ‡çš„å˜åŒ–$|\\Delta Z_{ij}|$ä½œä¸ºå…¶ä¸­ä¸€ä¸ªå› å­ï¼š \\lambda_{ij}=\\frac{\\partial{C}}{\\partial{s_i}}=\\frac{-\\sigma}{1+e^{\\sigma(s_i-s_j)}}|\\Delta Z_{ij}|åæ¨å‡º LambdaRank çš„æŸå¤±å‡½æ•°ï¼š C=log(1+e^{\\sigma (s_i-s_j)})|\\Delta Z_{ij}|3.LambdaMARTå±äºlistwiseï¼Œä¹Ÿæœ‰è¯´pairwiseã€‚ LambdaMART=lambda($\\lambda$)+mart(gbdt) $\\lambda$å°±æ˜¯æ¢¯åº¦ï¼Œlambdarankå°±æ˜¯ä¸€ç§lossï¼Œgbdtå°±æ˜¯æ¨¡å‹ lambdamartè¯´ç™½äº†å°±æ˜¯åˆ©ç”¨gbdtè®¡ç®—lambdarankä¸­sï¼Œæˆ–è€…è¯´å°†lambdarankä½œä¸ºgbdtçš„loss gbdtï¼Œlambdamartç®—æ³•æµç¨‹å·®å¼‚åœ¨äºstep1 GBDTï¼š åˆå§‹åŒ–ï¼š $f_0(x) = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{i=1}^N L(y_i, \\gamma)$ for m=1 to M:(a). è®¡ç®—è´Ÿæ¢¯åº¦ï¼š $\\tilde{y}_i = -\\frac{\\partial L(y_i,f_{m-1}(x_i))}{\\partial f_{m-1}(x_i)}, \\qquad i = 1,2 \\cdots N$(b). $\\left \\{ R_{jm} \\right\\}_1^J = \\mathop{\\arg\\min}\\limits_{\\left \\{ R_{jm} \\right\\}_1^J}\\sum\\limits_{i=1}^N \\left [\\tilde{y}_i - h_m(x_i\\,;\\,\\left \\{R_{jm},b_{jm} \\right\\}_1^J) \\right]^2$(c). $\\gamma_{jm} = \\mathop{\\arg\\min}\\limits_\\gamma \\sum\\limits_{x_i \\in R_{jm}}L(y_i,f_{m-1}(x_i)+\\gamma)$(d). $f_m(x) = f_{m-1}(x) + \\sum\\limits_{j=1}^J \\gamma_{jm}I(x \\in R_{jm})$ è¾“å‡º$f_M(x)$ LambdaMART: å‚è€ƒhttps://blog.csdn.net/laolu1573/article/details/87372514 https://liam.page/uploads/slides/lambdamart.pdf https://blog.csdn.net/zpalyq110/article/details/79527653 https://zhuanlan.zhihu.com/p/86354141 https://www.cnblogs.com/genyuan/p/9788294.html https://blog.csdn.net/huagong_adu/article/details/40710305 https://zhuanlan.zhihu.com/p/270608987 https://www.cnblogs.com/bentuwuying/p/6690836.html paperåŸæ–‡ï¼š https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf https://www.jianshu.com/p/a78b3f52c221 https://blog.csdn.net/zhoujialin/article/details/46697409 https://blog.csdn.net/w28971023/article/details/45849659 https://zhuanlan.zhihu.com/p/270608987","link":"/2021/09/27/lambdamart/"},{"title":"lambda","text":"12345678def test01(a,b,c,d): return a*b*c*dprint(test01(1,2,3,4))#ç›¸å½“äºä¸‹é¢è¿™ä¸ªå‡½æ•°f=lambda a,b,c,d:a*b*c*dprint(f(1,2,3,4)) 1234567891011121314151617181920211.f=[lambda x: i*x for i in range(1,5)]print(f)print(f[0](2))print([m(2) for m in f])[&lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x0000028503A613A0&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x0000028503A61430&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x0000028503A614C0&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x0000028503A61550&gt;]4[4, 4, 4, 4]2.f=[lambda x,i=i: i*x for i in range(1,5)]print(f)print(f[0](2))print([m(2) for m in f])[&lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x000001B4039813A0&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x000001B403981430&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x000001B4039814C0&gt;, &lt;function &lt;listcomp&gt;.&lt;lambda&gt; at 0x000001B403981550&gt;]2[2, 4, 6, 8]","link":"/2022/09/12/lamdba/"},{"title":"åˆ·é¢˜æŒ‡å—","text":"https://github.com/halfrost/LeetCode-Go","link":"/2021/11/30/leet-coding/"},{"title":"LASERTAGGER","text":"ä¸€. æ‘˜è¦å¯¹äºæŸä¸€äº›æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„æ–‡æœ¬æœ‰å¾ˆå¤šçš„é‡å éƒ¨åˆ†ï¼Œå¦‚æœè¿˜æ˜¯é‡‡ç”¨encoder-decoderçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹å»ä»é›¶å¼€å§‹ç”Ÿæˆï¼Œå…¶å®æ˜¯å¾ˆæµªè´¹å’Œæ²¡å¿…è¦çš„ï¼Œå¹¶ä¸”ä¼šå¯¼è‡´ä¸¤ä¸ªé—®é¢˜ï¼š1ï¼šç”Ÿæˆæ¨¡å‹çš„å¹»è§‰é—®é¢˜(å°±æ˜¯æ¨¡å‹èƒ¡è¯´å…«é“) ï¼›2ï¼šå‡ºç°å è¯(éƒ¨åˆ†ç‰‡æ®µä¸€è‡´)ã€‚ åŸºäºä¸Šé¢çš„è€ƒè™‘ï¼Œä½œè€…æå‡ºäº†lasertaggeræ¨¡å‹ï¼Œé€šè¿‡å‡ ä¸ªå¸¸ç”¨çš„æ“ä½œï¼škeep tokenã€delete tokenã€ add tokenï¼Œç»™è¾“å…¥åºåˆ—çš„æ¯ä¸ªtokenæ‰“ä¸Šæ ‡ç­¾ï¼Œä½¿å¾—æ–‡æœ¬ç”Ÿæˆä»»åŠ¡è½¬åŒ–ä¸ºäº†åºåˆ—æ ‡æ³¨ä»»åŠ¡ã€‚ é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç›¸è¾ƒäºencoder-decoderæ¨¡å‹çš„ä¼˜åŠ¿æœ‰å¦‚ä¸‹ï¼š1ã€æ¨ç†çš„é€Ÿåº¦æ›´å¿« 2ã€åœ¨è¾ƒå°çš„æ•°æ®é›†ä¸Šæ€§èƒ½ä¼˜äºseq2seq baselineï¼Œåœ¨å¤§æ•°æ®é›†ä¸Šå’ŒbaselineæŒå¹³ï¼ˆå› ä¸ºè¾“å…¥å’Œè¾“å‡ºçš„æ–‡æœ¬æœ‰å¾ˆå¤šçš„é‡å éƒ¨åˆ†ï¼Œå¯¹äºè¿™ç§æƒ…å†µï¼Œlasertaggerçš„å€™é€‰è¯åº“æ¯”è¾ƒå°ï¼Œå› ä¸ºå¯¹äºé‡å éƒ¨åˆ†çš„è¯ï¼Œè¯åº“åªéœ€è¦æ·»åŠ keepï¼Œè€Œä¼ ç»Ÿencoder-decoderçš„å€™é€‰è¯åº“ä¾ç„¶å¾ˆå¤§ï¼Œå› ä¸ºå¯¹äºé‡å éƒ¨åˆ†çš„è¯ï¼Œè¯åº“éœ€è¦æ·»åŠ å¯¹åº”çš„è¯ï¼‰ äºŒ.ä¸»è¦è´¡çŒ®1ã€é€šè¿‡è¾“å…¥å’Œè¾“å‡ºæ–‡æœ¬ï¼Œè‡ªåŠ¨å»æå–éœ€è¦addçš„token 2ã€é€šè¿‡è¾“å…¥æ–‡æœ¬ï¼Œè¾“å‡ºæ–‡æœ¬å’Œtagé›†ï¼Œç»™è®­ç»ƒçš„è¾“å…¥åºåˆ—æ‰“ä¸Šæ ‡ç­¾ 3ã€æå‡ºäº†ä¸¤ä¸ªç‰ˆæœ¬ï¼Œ$LASERTAGGER_{AR}$( bert+transformer decoder )å’Œ$LASERTAGGER_{FF}$( bert+desen+softmax ) ä¸‰. æ•´ä½“æµç¨‹ å…¶å®å°±æ˜¯ä¸¤ä¸ªè¿‡ç¨‹ï¼Œä¸€.å°†è¾“å…¥æ–‡æœ¬å˜ç¼–ç æˆç‰¹æ®Šæ ‡æ³¨ï¼ŒäºŒ.å°†æ ‡æ³¨è§£ç æˆæ–‡æœ¬ å››. æ–‡æœ¬æ ‡æ³¨4.1 Tagé›†æ„å»ºï¼ˆä¹Ÿå°±æ˜¯labelé›†æ„å»ºï¼‰ä¸€èˆ¬æƒ…å†µï¼Œtagåˆ†ä¸ºä¸¤ä¸ªå¤§ç±»ï¼š base tag $B$å’Œ add tag $P$ã€‚å¯¹äºbase tagï¼Œå°±æ˜¯$KEEP$æˆ–è€…$DELETE$å½“å‰tokenï¼›å¯¹äºadd tagï¼Œå°±æ˜¯è¦æ·»åŠ ä¸€ä¸ªè¯åˆ°tokenå‰é¢ï¼Œæ·»åŠ çš„è¯æ¥æºäºè¯è¡¨$V$ã€‚å®é™…åœ¨å·¥ç¨‹ä¸­ï¼Œå°†$B$å’Œ$P$ç»“åˆæ¥è¡¨ç¤ºï¼Œå³$^{P}B$ï¼Œæ€»çš„tagæ•°é‡å¤§çº¦ç­‰äº$B$çš„æ•°é‡ä¹˜ä»¥$P$çš„æ•°é‡ï¼Œå³$2|V|$ã€‚å¯¹äºæŸäº›ä»»åŠ¡å¯ä»¥å¼•å…¥ç‰¹å®šçš„tagï¼Œæ¯”å¦‚å¯¹äºå¥å­èåˆï¼Œå¯ä»¥å¼•å…¥$SWAP$,å¦‚ä¸‹å›¾ã€‚ 4.1.1 è¯è¡¨Vçš„æ„å»ºæ„å»ºç›®æ ‡ï¼š æœ€å°åŒ–è¯æ±‡è¡¨è§„æ¨¡ï¼› æœ€å¤§åŒ–ç›®æ ‡è¯è¯­çš„æ¯”ä¾‹ é™åˆ¶è¯æ±‡è¡¨çš„è¯ç»„æ•°é‡å¯ä»¥å‡å°‘ç›¸åº”è¾“å‡ºçš„å†³ç­–é‡ï¼›æœ€å¤§åŒ–ç›®æ ‡è¯è¯­çš„æ¯”ä¾‹å¯ä»¥é˜²æ­¢æ¨¡å‹æ·»åŠ æ— æ•ˆè¯ã€‚ æ„å»ºè¿‡ç¨‹ï¼š é€šè¿‡$LCS$ç®—æ³•ï¼ˆlongest common sequenceï¼Œæœ€é•¿å…¬å…±å­åºåˆ—ï¼Œæ³¨æ„å’Œæœ€é•¿å…¬å…±å­ä¸²ä¸æ˜¯ä¸€å›äº‹ï¼‰ï¼Œæ‰¾å‡ºè¾“å…¥å’Œè¾“å‡ºåºåˆ—çš„æœ€é•¿å…¬å…±å­åºåˆ—ï¼Œè¾“å‡ºå‰©ä¸‹çš„åºåˆ—ï¼Œå°±æ˜¯éœ€è¦$add$çš„tokenï¼Œæ·»åŠ åˆ°è¯è¡¨$V$ï¼Œè¯è¡¨ä¸­çš„è¯åŸºäºè¯é¢‘æ’åº,ç„¶åé€‰æ‹©$l$ä¸ªå¸¸ç”¨çš„ã€‚ ä¸¾ä¸ªä¾‹å­ï¼šsoruceä¸ºâ€œ12345678â€ï¼Œtargetä¸ºâ€1264591â€ â€‹ æœ€é•¿å…¬å…±å­åºåˆ—ä¸º[â€˜1â€™, â€˜2â€™, â€˜4â€™, â€˜5â€™] â€‹ éœ€è¦$add$çš„tokenä¸º [â€˜6â€™, â€˜91â€™] æºç ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667def _lcs_table(source, target): &quot;&quot;&quot;Returns the Longest Common Subsequence dynamic programming table.&quot;&quot;&quot; rows = len(source) cols = len(target) lcs_table = [[0] * (cols + 1) for _ in range(rows + 1)] for i in range(1, rows + 1): for j in range(1, cols + 1): if source[i - 1] == target[j - 1]: lcs_table[i][j] = lcs_table[i - 1][j - 1] + 1 else: lcs_table[i][j] = max(lcs_table[i - 1][j], lcs_table[i][j - 1]) return lcs_tabledef _backtrack(table, source, target, i, j): &quot;&quot;&quot;Backtracks the Longest Common Subsequence table to reconstruct the LCS. Args: table: Precomputed LCS table. source: List of source tokens. target: List of target tokens. i: Current row index. j: Current column index. Returns: List of tokens corresponding to LCS. &quot;&quot;&quot; if i == 0 or j == 0: return [] if source[i - 1] == target[j - 1]: # Append the aligned token to output. return _backtrack(table, source, target, i - 1, j - 1) + [target[j - 1]] if table[i][j - 1] &gt; table[i - 1][j]: return _backtrack(table, source, target, i, j - 1) else: return _backtrack(table, source, target, i - 1, j)def _compute_lcs(source, target): # s1={1,3,4,5,6,7,7,8},s2={3,5,7,4,8,6,7,8,2} return 35778 table = _lcs_table(source, target) return _backtrack(table, source, target, len(source), len(target)) def _get_added_phrases(source: Text, target: Text) -&gt; Sequence[Text]: &quot;&quot;&quot; Computes the phrases that need to be added to the source to get the target. &quot;&quot;&quot; sep = '' source_tokens = utils.get_token_list(source.lower()) target_tokens = utils.get_token_list(target.lower()) #compute Longest Common Subsequence kept_tokens = _compute_lcs(source_tokens, target_tokens) added_phrases = [] kept_idx = 0 phrase = [] for token in target_tokens: if kept_idx &lt; len(kept_tokens) and token == kept_tokens[kept_idx]: kept_idx += 1 if phrase: added_phrases.append(sep.join(phrase)) phrase = [] else: phrase.append(token) if phrase: added_phrases.append(sep.join(phrase)) return added_phrases è¯è¡¨ä½äºæ–‡ä»¶label_map.txt.logï¼Œæœ¬äººåŸºäºè‡ªå·±çš„æ•°æ®é›†ï¼Œå†…å®¹å¦‚ä¸‹æ‰€ç¤º 12345Idx Frequency Coverage (%) Phrase1 19 94.22 å€2 15 95.27 å•ä½3 8 95.76 åœ°4 6 96.17 æ‰§å‹¤ 4.1.2 tagé›†æœ¬äººåŸºäºè‡ªå·±çš„æ•°æ®é›†ï¼Œå¾—åˆ°çš„å€™é€‰tagå¦‚ä¸‹ï¼š 12345678910KEEPDELETEKEEP|å€DELETE|å€KEEP|å•ä½DELETE|å•ä½KEEP|åœ°DELETE|åœ°KEEP|æ‰§å‹¤DELETE|æ‰§å‹¤ 4.2 Converting Training Targets into Tagspaperä¸Šçš„ä¼ªä»£ç ï¼š é‡‡ç”¨è´ªå¿ƒç­–ç•¥ï¼Œæ ¸å¿ƒæ€æƒ³å°±æ˜¯éå†$t$ï¼Œå…ˆå’Œ$s$åŒ¹é…ï¼ŒåŒ¹é…ä¸Šå°±$keep$ï¼Œç„¶å$i_t+j$ï¼Œå¾—åˆ°æ½œåœ¨çš„$add \\ phrase \\ p=t(i_t:i_t+j-1) $ï¼Œç„¶ååˆ¤æ–­$t(i_t+j)==s(i_s)\\ and \\ p\\in V $ æºç ï¼š å’Œä¼ªä»£ç æœ‰ä¸€ç‚¹ä¸åŒï¼Œå·®å¼‚åœ¨äº#####ä¹‹é—´ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586def _compute_single_tag( self, source_token, target_token_idx, target_tokens): &quot;&quot;&quot;Computes a single tag. The tag may match multiple target tokens (via tag.added_phrase) so we return the next unmatched target token. Args: source_token: The token to be tagged. target_token_idx: Index of the current target tag. target_tokens: List of all target tokens. Returns: A tuple with (1) the computed tag and (2) the next target_token_idx. &quot;&quot;&quot; source_token = source_token.lower() target_token = target_tokens[target_token_idx].lower() if source_token == target_token: return tagging.Tag('KEEP'), target_token_idx + 1 # source_token!=target_token added_phrase = '' for num_added_tokens in range(1, self._max_added_phrase_length + 1): if target_token not in self._token_vocabulary: break added_phrase += (' ' if added_phrase else '') + target_token next_target_token_idx = target_token_idx + num_added_tokens if next_target_token_idx &gt;= len(target_tokens): break target_token = target_tokens[next_target_token_idx].lower() if (source_token == target_token and added_phrase in self._phrase_vocabulary): return tagging.Tag('KEEP|' + added_phrase), next_target_token_idx + 1 return tagging.Tag('DELETE'), target_token_idxdef _compute_tags_fixed_order(self, source_tokens, target_tokens): &quot;&quot;&quot;Computes tags when the order of sources is fixed. Args: source_tokens: List of source tokens. target_tokens: List of tokens to be obtained via edit operations. Returns: List of tagging.Tag objects. If the source couldn't be converted into the target via tagging, returns an empty list. &quot;&quot;&quot; tags = [tagging.Tag('DELETE') for _ in source_tokens] # Indices of the tokens currently being processed. source_token_idx = 0 target_token_idx = 0 while target_token_idx &lt; len(target_tokens): tags[source_token_idx], target_token_idx = self._compute_single_tag( source_tokens[source_token_idx], target_token_idx, target_tokens) #################################################################################### # If we're adding a phrase and the previous source token(s) were deleted, # we could add the phrase before a previously deleted token and still get # the same realized output. For example: # [DELETE, DELETE, KEEP|&quot;what is&quot;] # and # [DELETE|&quot;what is&quot;, DELETE, KEEP] # Would yield the same realized output. Experimentally, we noticed that # the model works better / the learning task becomes easier when phrases # are always added before the first deleted token. Also note that in the # current implementation, this way of moving the added phrase backward is # the only way a DELETE tag can have an added phrase, so sequences like # [DELETE|&quot;What&quot;, DELETE|&quot;is&quot;] will never be created. if tags[source_token_idx].added_phrase: # # the learning task becomes easier when phrases are always added before the first deleted token first_deletion_idx = self._find_first_deletion_idx( source_token_idx, tags) if first_deletion_idx != source_token_idx: tags[first_deletion_idx].added_phrase = ( tags[source_token_idx].added_phrase) tags[source_token_idx].added_phrase = '' ######################################################################################## source_token_idx += 1 if source_token_idx &gt;= len(tags): break # If all target tokens have been consumed, we have found a conversion and # can return the tags. Note that if there are remaining source tokens, they # are already marked deleted when initializing the tag list. if target_token_idx &gt;= len(target_tokens): # all target tokens have been consumed return tags return [] # TODO ç¼ºé™·ï¼š å¯¹äºä¸€äº›æƒ…å†µï¼Œæ— æ³•è¿˜åŸï¼Œä¸¾ä¸ªä¾‹å­ï¼š â€‹ sourceï¼šè¯ä»¶æœ‰æ•ˆæœŸæˆªæ­¢æ—¥æœŸ targetï¼šè¯ä»¶æ—¥æœŸæ ¼å¼ â€‹ å¾—ä¸åˆ°tagç»“æœ å¯ä»¥è¡¥å……ç­–ç•¥æ¥ä¿®å¤bug 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364def _compute_tags_fixed_order(self, source_tokens, target_tokens): &quot;&quot;&quot;Computes tags when the order of sources is fixed. Args: source_tokens: List of source tokens. target_tokens: List of tokens to be obtained via edit operations. Returns: List of tagging.Tag objects. If the source couldn't be converted into the target via tagging, returns an empty list. &quot;&quot;&quot; tags = [tagging.Tag('DELETE') for _ in source_tokens] # Indices of the tokens currently being processed. source_token_idx = 0 target_token_idx = 0 while target_token_idx &lt; len(target_tokens): tags[source_token_idx], target_token_idx = self._compute_single_tag( source_tokens[source_token_idx], target_token_idx, target_tokens) ######################################################################################### # If we're adding a phrase and the previous source token(s) were deleted, # we could add the phrase before a previously deleted token and still get # the same realized output. For example: # [DELETE, DELETE, KEEP|&quot;what is&quot;] # and # [DELETE|&quot;what is&quot;, DELETE, KEEP] # Would yield the same realized output. Experimentally, we noticed that # the model works better / the learning task becomes easier when phrases # are always added before the first deleted token. Also note that in the # current implementation, this way of moving the added phrase backward is # the only way a DELETE tag can have an added phrase, so sequences like # [DELETE|&quot;What&quot;, DELETE|&quot;is&quot;] will never be created. if tags[source_token_idx].added_phrase: # # the learning task becomes easier when phrases are always added before the first deleted token first_deletion_idx = self._find_first_deletion_idx( source_token_idx, tags) if first_deletion_idx != source_token_idx: tags[first_deletion_idx].added_phrase = ( tags[source_token_idx].added_phrase) tags[source_token_idx].added_phrase = '' ####################################################################################### source_token_idx += 1 if source_token_idx &gt;= len(tags): break # If all target tokens have been consumed, we have found a conversion and # can return the tags. Note that if there are remaining source tokens, they # are already marked deleted when initializing the tag list. if target_token_idx &gt;= len(target_tokens): # all target tokens have been consumed return tags ####fix bug by lavine ###strategy1 added_phrase = &quot;&quot;.join(target_tokens[target_token_idx:]) if added_phrase in self._phrase_vocabulary: tags[-1] = tagging.Tag('DELETE|' + added_phrase) print(''.join(source_tokens)) print(''.join(target_tokens)) print(str([str(tag) for tag in tags] if tags != None else None)) return tags ###strategy2 return [] # TODO 4.3 æ¨¡å‹ç»“æ„ æ¨¡å‹ä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š1.encoder:generates activation vectors for each element in the input sequence 2.decoderï¼šconverts encoder activations into tag labels 4.3.1 encoderç”±äº$BERT$åœ¨sentence encoding tasksä¸Šåšåˆ°state-of-the-artï¼Œæ‰€ä»¥ä½¿ç”¨$BERT$ ä½œä¸ºencoderéƒ¨åˆ†ã€‚ä½œè€…é€‰æ‹©äº†$BERT_{base}$,åŒ…å«12ä¸ªself-attentionå±‚ 4.3.2 decoderåœ¨$BERT$åŸæ–‡ä¸­ï¼Œå¯¹äºæ ‡æ³¨ä»»åŠ¡é‡‡å–äº†éå¸¸ç®€å•çš„decoderç»“æ„ï¼Œå³é‡‡ç”¨ä¸€å±‚feed-forwardä½œä¸ºdecoderï¼ŒæŠŠè¿™ç§ç»„åˆå«åš$LASERTAGGER_{FF}$ï¼Œè¿™ç§ç»“æ„çš„ç¼ºç‚¹åœ¨äºé¢„æµ‹çš„æ ‡æ³¨è¯ç›¸äº’ç‹¬ç«‹ï¼Œæ²¡æœ‰è€ƒè™‘æ ‡æ³¨è¯çš„å…³è”æ€§ã€‚ ä¸ºäº†è€ƒè™‘æ ‡æ³¨è¯çš„å…³è”æ€§ï¼Œdecodeä½¿ç”¨äº†Transformer decoderï¼Œå•å‘è¿æ¥ï¼Œè®°ä½œ$LASERTAGGER_{AR}$ï¼Œè¿™ç§encoderå’Œdecoderçš„ç»„åˆçš„æœ‰ç‚¹åƒBERTç»“åˆGPTçš„æ„Ÿè§‰decoder å’Œencoderåœ¨ä»¥ä¸‹æ–¹é¢äº¤æµï¼š(i) through a full attention over the sequence of encoder activations (ii) by directly consuming the encoder activation at the current step äº”.realizeå¯¹äºåŸºæœ¬çš„tagï¼Œæ¯”å¦‚$KEEP$ï¼Œ$DELETE$ï¼Œ$ADD$ï¼Œ$realize$å°±æ˜¯æ ¹æ®è¾“å…¥å’Œtagç›´æ¥è½¬æ¢å°±è¡Œï¼›å¯¹äºç‰¹æ®Šçš„tagï¼Œéœ€è¦ä¸€äº›ç‰¹å®šæ“ä½œï¼Œçœ‹æƒ…å†µç»´æŠ¤è§„åˆ™ã€‚ å…­ losså‡è®¾å¥å­é•¿åº¦ä¸ºnï¼Œtagæ•°é‡ä¸ºm, lossä¸ºnä¸ªmåˆ†ç±»ä»»åŠ¡çš„å’Œ ä¸ƒ.è¯„ä»·æŒ‡æ ‡è¯„ä»·æŒ‡æ ‡ï¼Œä¸åŒä»»åŠ¡ä¸åŒè¯„ä»·æŒ‡æ ‡ 1 Sentence Fusion Exact score ï¼špercentage of exactly correctly predicted fusionsï¼ˆç±»ä¼¼accuracyï¼‰ SARI ï¼šaverage F1 scores of the added, kept, and deleted n-grams 2 Split and Rephrase SARI 3 Abstractive Summarization ROUGE-L 4 Grammatical Error Correction (GEC) precision and recall, F0:5 å…«.å®éªŒç»“æœbaselineï¼š based on Transformer where both the encoder and decoder replicate the $BERT_{base}$ architecture é€Ÿåº¦ï¼š1.$LASERTAGGER_{AR} $is already 10x faster than comparable-in-accuracy $SEQ2SEQ_{BERT}$ baseline. This difference is due to the former model using a 1-layer decoder (instead of 12 layers) and no encoder-decoder cross attention. 2.$LASERTAGGER_{FF}$ is more than 100x faster å…¶ä½™ç»“æœå‚è€ƒpaper å‚è€ƒhttps://arxiv.org/pdf/1909.01187.pdf https://github.com/google-research/lasertagger https://zhuanlan.zhihu.com/p/348109034","link":"/2021/07/27/lasertagger/"},{"title":"å¸¸è§é¢˜ç›®","text":"1 topkå¿«æ’ O(n) æ¯æ’ä¸€æ¬¡ï¼Œå°±çŸ¥é“åŸºå‡†çš„ä½ç½®ï¼Œå°±å¯ä»¥å¾—å‡ºTopKæ˜¯åœ¨åŸºå‡†å·¦è¾¹éƒ¨åˆ†è¿˜æ˜¯å³è¾¹éƒ¨åˆ†ï¼Œå› æ­¤ä¸éœ€è¦å…¨éƒ¨æ’åº å †æ’ O(k+nlog(k)) 21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# ç»™å®šä¸€ä¸ªå­—ç¬¦ä¸²så’Œä¸€ä¸ªå­—ç¬¦ä¸²pï¼Œè¯·é—®æœ€å°‘å»æ‰sä¸­çš„å¤šå°‘ä¸ªå­—ç¬¦ï¼Œæ‰èƒ½ä½¿å¾—pæ˜¯sçš„å­ä¸²å‘¢ï¼Ÿ# è§£ç­”è¦æ±‚æ—¶é—´é™åˆ¶ï¼š1000ms, å†…å­˜é™åˆ¶ï¼š100MB# è¾“å…¥# ä¸¤è¡Œï¼Œç¬¬ä¸€è¡Œä¸ºå­—ç¬¦ä¸²sï¼Œç¬¬äºŒè¡Œä¸ºå­—ç¬¦ä¸²pã€‚(så’ŒpåªåŒ…å«å°å†™è‹±æ–‡å­—æ¯,sçš„é•¿åº¦ä¸è¶…è¿‡2000,pçš„é•¿åº¦ä¸è¶…è¿‡10,ä¸”ä¿è¯æœ‰è§£ï¼‰# è¾“å‡º# æœ€å°‘å»æ‰çš„å­—ç¬¦ä¸ªæ•°ã€‚# æ ·ä¾‹# è¾“å…¥æ ·ä¾‹ 1# axb# ab# è¾“å‡º# 1# è¾“å…¥æ ·ä¾‹ 2# axabc# abc# è¾“å‡º# 0# è¾“å…¥æ ·ä¾‹ 3# axbacxbc# abc# è¾“å‡º# 2#dp[i][j] è¡¨ç¤º s[:i]æœ€å°‘éœ€è¦åˆ å‡ ä¸ªp[:j]æ˜¯å®ƒçš„å­ä¸² O(mn) O(mn)###def minedit(str1,str2): m=len(str1) n=len(str2) # max_num=9999 dp=[[None for i in range(n+1)]for j in range(m+1)] dp[0][0]=0 for i in range(m): dp[i][0]=0 for i in range(1,m+1): for j in range(1,n+1): if str1[i-1]==str2[j-1]: dp[i][j]=dp[i-1][j-1] else: ## if dp[i-1][j]!=None: dp[i][j]=dp[i-1][j]+1 result=None for i in range(n,m+1): if result==None: result=dp[i][n] else: result=min(result,dp[i][n]) return result print(minedit(&quot;axbacxbc&quot;,&quot;abc&quot;))","link":"/2022/05/19/leet-normal/"},{"title":"lightgbm","text":"Light gradient boosting machine ç”¨äºæ’åº12import lightgbm as lgblgb.LGBMRanker åŸç† LGBMRankeræ¨¡å‹å’Œè¿™ä¸ªLambdaMARTçš„åŸç†å¾ˆåƒ https://blog.csdn.net/wuzhongqiang/article/details/110521519 å‚è€ƒhttps://zhuanlan.zhihu.com/p/99069186 https://mp.weixin.qq.com/s/XxFHmxV4_iDq8ksFuZM02w https://www.jianshu.com/p/765efe2b951a https://blog.csdn.net/wuzhongqiang/article/details/110521519","link":"/2022/06/09/lightgbm/"},{"title":"leetcodeå¸¸è§å¥—è·¯","text":"ä¸€.å¸¸è§ç®—æ³•åˆ†æ²»ç­–ç•¥ï¼ŒåŠ¨æ€è§„åˆ’ï¼Œå›æº¯ï¼Œåˆ†æ”¯é™ç•Œï¼Œè´ªå¿ƒç­–ç•¥ äºŒ.å·§ç”¨æ•°æ®ç»“æ„æ™®é€šæ ˆã€å•è°ƒæ ˆ é˜Ÿåˆ— å † å­—å…¸æ ‘ ä¸‰.æŠ€å·§åŒæŒ‡é’ˆ/æ»‘çª—ï¼ŒäºŒåˆ†æŸ¥æ‰¾ï¼Œæ’åºï¼Œå¿«æ…¢æŒ‡é’ˆï¼Œå–ä½™ï¼Œä½è¿ç®—ï¼Œå€å¢ï¼ˆ29. ä¸¤æ•°ç›¸é™¤ï¼‰ã€é€’å½’ æ—¶ç©ºè½¬åŒ–ï¼ˆhashtableï¼‰ å›› å¥—è·¯é€‰æ‹©https://zhuanlan.zhihu.com/p/358653377 https://zhuanlan.zhihu.com/p/341176507 å‚è€ƒhttps://zhuanlan.zhihu.com/p/358653377 https://zhuanlan.zhihu.com/p/341176507","link":"/2021/08/10/leetcode_algorith-tech/"},{"title":"å¸¸è§æ“ä½œ","text":"1 è½¯è¿æ¥https://www.cnblogs.com/sueyyyy/p/10985443.html# å½“æˆ‘ä»¬éœ€è¦åœ¨ä¸åŒçš„ç›®å½•ï¼Œç”¨åˆ°ç›¸åŒçš„æ–‡ä»¶æ—¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦åœ¨æ¯ä¸€ä¸ªéœ€è¦çš„ç›®å½•ä¸‹éƒ½æ”¾ä¸€ä¸ªå¿…é¡»ç›¸åŒçš„æ–‡ä»¶ï¼Œæˆ‘ä»¬åªè¦åœ¨å…¶å®ƒçš„ ç›®å½•ä¸‹ç”¨lnå‘½ä»¤é“¾æ¥ï¼ˆlinkï¼‰å°±å¯ä»¥ï¼Œä¸å¿…é‡å¤çš„å ç”¨ç£ç›˜ç©ºé—´ã€‚ ln -s source_path target_path ä¾‹å­ï¼šln -s /home/atguigu/bin/ ~/bin 2 SSHæ— å¯†ç™»å½•é…ç½®http://www.yaowenming.com/A/gAJG0mvg5Z/ ï¼ˆ1ï¼‰hadoop102ä¸Šç”Ÿæˆå…¬é’¥å’Œç§é’¥ï¼š [atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa ç„¶åæ•²ï¼ˆä¸‰ä¸ªå›è½¦ï¼‰ï¼Œå°±ä¼šç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶id_rsaï¼ˆç§é’¥ï¼‰ã€id_rsa.pubï¼ˆå…¬é’¥ï¼‰ ï¼ˆ2ï¼‰å°†hadoop102å…¬é’¥æ‹·è´åˆ°è¦å…å¯†ç™»å½•çš„ç›®æ ‡æœºå™¨ä¸Š [atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102 [atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103 [atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104 ï¼ˆ3ï¼‰hadoop103ä¸Šç”Ÿæˆå…¬é’¥å’Œç§é’¥ï¼š [atguigu@hadoop103 .ssh]$ ssh-keygen -t rsa ç„¶åæ•²ï¼ˆä¸‰ä¸ªå›è½¦ï¼‰ï¼Œå°±ä¼šç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶id_rsaï¼ˆç§é’¥ï¼‰ã€id_rsa.pubï¼ˆå…¬é’¥ï¼‰ ï¼ˆ4ï¼‰å°†hadoop103å…¬é’¥æ‹·è´åˆ°è¦å…å¯†ç™»å½•çš„ç›®æ ‡æœºå™¨ä¸Š [atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop102 [atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop103 [atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop104 3 å°†textå†…å®¹åŠ å…¥åˆ°fileæ–‡ä»¶çš„ç¬¬1è¡Œä¹‹åsed -i â€˜1 a textâ€™ file ä¾‹å­ï¼šsed -i â€˜1 a kinit -kt /etc/security/keytab/hive.keytab hiveâ€™ hdfs_to_ods_log.sh 4 ä¿®æ”¹è„šæœ¬æ‰§è¡Œæƒé™chmod chmod u+x lg .sh https://blog.csdn.net/u013197629/article/details/73608613 5 é›†ç¾¤åˆ†å‘è„šæœ¬åŸºäºrsyncå‘½ä»¤ 1rsync -av /opt/module root@hadoop103:/opt/ 1.ç¼–å†™è„šæœ¬ 12345678910111213141516171819202122232425262728#!/bin/bash#1. åˆ¤æ–­å‚æ•°ä¸ªæ•°if [ $# -lt 1 ]then echo Not Enough Arguement! exit;fi#2. éå†é›†ç¾¤æ‰€æœ‰æœºå™¨for host in hadoop102 hadoop103 hadoop104do echo ==================== $host ==================== #3. éå†æ‰€æœ‰ç›®å½•ï¼ŒæŒ¨ä¸ªå‘é€ for file in $@ do #4 åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨ if [ -e $file ] then #5. è·å–çˆ¶ç›®å½• pdir=$(cd -P $(dirname $file); pwd) #6. è·å–å½“å‰æ–‡ä»¶çš„åç§° fname=$(basename $file) ssh $host &quot;mkdir -p $pdir&quot; rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi donedone 2.ä¿®æ”¹è„šæœ¬xsyncå…·æœ‰æ‰§è¡Œæƒé™ 1chmod +x xsync 6 ç¯å¢ƒå˜é‡https://blog.csdn.net/white_idiot/article/details/78253004 7 linuxæ ¹ç›®å½•ä¸‹å„ä¸ªæ–‡ä»¶å¤¹çš„ä½œç”¨https://blog.51cto.com/u_14233078/2443062 8 å¦‚ä½•è®©ä½ çš„è„šæœ¬å¯ä»¥åœ¨ä»»æ„åœ°æ–¹éƒ½å¯æ‰§è¡Œï¼Ÿhttps://www.cnblogs.com/yychuyu/p/12918957.html 9 LinuxæœåŠ¡å™¨jpsæŠ¥process information unavailablehttps://blog.csdn.net/weixin_44803002/article/details/103332889 cd /tmp rm -rf /tmp/hsperfdata_* 10 sudoå‘½ä»¤ ä½¿ç”¨hiveç”¨æˆ·å¯åŠ¨hiveserver2 1[root@hadoop102 ~]# sudo -i -u hive hiveserver2 11 jpshttps://blog.csdn.net/wangzhongshun/article/details/112546027 ä¸è¿‡jpsæœ‰ä¸ªç¼ºç‚¹æ˜¯åªèƒ½æ˜¾ç¤ºå½“å‰ç”¨æˆ·çš„è¿›ç¨‹idï¼Œè¦æ˜¾ç¤ºå…¶ä»–ç”¨æˆ·çš„è¿˜åªèƒ½ç”¨linuxçš„pså‘½ä»¤ 12 scp scp -r root@hosts : addr ./ 13 tarhttps://www.cnblogs.com/w54255787/p/10175202.html tar -cvf models.tar models 14 kill -9 sparksubmit æ— æ•ˆhttps://www.codetd.com/article/4229439 é‡å¯ 15 åˆ›å»ºç”¨æˆ·å’Œç”¨æˆ·ç»„https://www.jianshu.com/p/1e3fcfc8e3ef","link":"/2022/02/07/linun-common-command/"},{"title":"linux","text":"rootç”¨æˆ·ä¹Ÿæ˜¯ç”¨æˆ·ï¼Œå°±æ˜¯æƒé™é«˜äºæ™®é€šç”¨æˆ· cd ~ ï¼šå›åˆ°å½“å‰ç”¨æˆ·ç›®å½• cd /ï¼šå›åˆ°æ ¹ç›®å½•","link":"/2022/01/27/linux-comm/"},{"title":"listwise","text":"åšå®¢ https://zhuanlan.zhihu.com/p/66514492 Listwise Approach to Learning to Rank - Theory and Algorithmï¼ˆListMLEï¼‰ http://icml2008.cs.helsinki.fi/papers/167.pdf Learning to Rank: From Pairwise Approach to Listwise Approachï¼ˆListNetï¼‰ https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf","link":"/2021/12/20/listwise/"},{"title":"Learning to Rank From Pairwise Approach to Listwise Approach(listnet)","text":"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf https://blog.csdn.net/Mr_tyting/article/details/80554849 æ ¸å¿ƒæ€æƒ³ä¸ºï¼š Given two lists of scoresï¼ˆæ¨¡å‹å’Œäººï¼‰ we can first calculate two permutation probability distributions from themï¼ˆç®€åŒ–åˆ°ç”¨top1ï¼‰ and then calculate the distance between the two distributions as the listwise loss function.ï¼ˆäº¤å‰ç†µï¼‰ 4. Probability Models4.1. Permutation Probability $\\pi=(2,3,1) $æŒ‡çš„æ˜¯å¯¹è±¡2æ’åœ¨ç¬¬ä¸€ä½ ä¸Šé¢æ˜¯topnçš„å½¢å¼ å› ä¸ºæ€»å…±æœ‰nï¼æ¬¡æ’åºç»„åˆ 4.2. Top One Probabilitytopkï¼š P_s(\\pi)=\\prod \\limits_{j=1}^K\\frac{\\phi(S_{\\pi(j)})}{\\sum_{k=j}^n\\phi(S_{\\pi(k)})}æ€»å…±æœ‰N ! / ( N âˆ’ k ) ! ç§ä¸åŒæ’åˆ—ï¼Œå¤§å¤§å‡å°‘äº†è®¡ç®—å¤æ‚åº¦ top1ï¼š æ­¤æ—¶æœ‰nç§ä¸åŒæ’åˆ—æƒ…å†µ æ¦‚ç‡åˆ†å¸ƒçš„å«ä¹‰ï¼šå¯¹äºæ¯ä¸ªjï¼Œåˆ†åˆ«éƒ½å¤„äºç¬¬ä¸€çš„æ¦‚ç‡æ˜¯å¤šå°‘ 5.Learning Method: ListNetWe employ a new learning method for optimizing the listwise loss function based on top one probability, with Neural Network as model and Gradient Descent as optimization algorithm. We refer to the method as ListNet. $y^{(i)}$æ˜¯çœŸå®çš„score listï¼Œæœ‰ä¸ªç–‘é—®å°±æ˜¯$y^{(i)}$æ€ä¹ˆå¾—åˆ°ï¼Ÿå…³äºè¿™ä¸ªï¼Œåº”è¯¥æ˜¯å…ˆæœ‰çœŸå®çš„score listï¼ˆäººæ‰“ï¼‰ï¼Œç„¶ååŸºäºscore listå¾—åˆ°æ’åºï¼Œå‚è€ƒ https://zhuanlan.zhihu.com/p/66514492 æ ¸å¿ƒæ­¥éª¤1.æ‰“æ ‡å¾—åˆ°çœŸå®çš„score listï¼Œæ¨¡å‹å¾—åˆ°é¢„æµ‹çš„score list 2.ç„¶åç”¨softmaxå¾—åˆ°çœŸå®çš„å’Œé¢„æµ‹çš„score listçš„æ¦‚ç‡åˆ†å¸ƒ 3.ç„¶åç”¨äº¤å‰ç†µè®¡ç®—ä¸¤ç§æ¦‚ç‡åˆ†å¸ƒçš„å·®è·","link":"/2021/12/21/listnet/"},{"title":"æŸå¤±å‡½æ•°","text":"æŸå¤±å‡½æ•°ä¸€èˆ¬éƒ½è¦ç”¨å¯å¯¼å‡½æ•°ï¼Œå› ä¸ºå¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼Œæ¯”å¦‚æ¢¯åº¦ä¸‹é™ï¼Œç‰›é¡¿æ³•ï¼Œéƒ½éœ€è¦å¯¼æ•°ã€‚ 1.å›å½’æŸå¤±1.1 Mean Squared Error L=\\frac{1}{N}\\sum_{i=1}^{N}(y_i-\\hat{y}_i)^21.2 Mean Absolute Error L=\\frac{1}{N}\\sum_{i=1}^{N}|y_i-\\hat{y}_i|1.3 Huber Loss ( Smooth Mean Absolute Error Loss ) L=\\frac{1}{N}\\sum_{i=1}^{N}[\\mathbb{1}_{|y_i-\\hat{y_i}|\\le \\delta}\\frac{(y_i-\\hat{y_i})^2}{2}+\\mathbb{1}_{|y_i-\\hat{y_i}|> \\delta} \\ (\\delta \\cdot |y_i-\\hat{y_i}|-\\frac{1}{2}\\delta^{2})]2.åˆ†ç±»æŸå¤±2.1 Cross-entropy losshttps://zhuanlan.zhihu.com/p/100921909 Kæ˜¯ç§ç±»æ•°é‡ yæ˜¯æ ‡ç­¾ pæ˜¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯æŒ‡ç±»åˆ«æ˜¯içš„æ¦‚ç‡ 2.2 Hinge loss L=max(0,1-y\\cdot \\hat{y})SVMæ¨¡å‹çš„æŸå¤±å‡½æ•°æœ¬è´¨ä¸Šå°±æ˜¯ Hinge Loss + L2 æ­£åˆ™åŒ– å‚è€ƒhttps://blog.csdn.net/m0_38007695/article/details/114983574","link":"/2021/09/07/loss-func/"},{"title":"é€»è¾‘å›å½’","text":"é€»è¾‘å›å½’ï¼ˆlrï¼‰= çº¿æ€§å›å½’+sigmoid","link":"/2022/08/20/logistic-reg/"},{"title":"è¶…é•¿æ–‡æœ¬å¤„ç†","text":"bertæœ€å¤§é•¿åº¦å›ºå®šï¼Œé»˜è®¤ä¸º512 æ•°æ®å±‚é¢ï¼š 1 ç›´æ¥æˆªæ–­ï¼šå¤ªç²—æš´ï¼Œå¯èƒ½æŠŠé‡è¦çš„ä¸¢äº† 2 æŠ½å–é‡è¦éƒ¨åˆ† 3 åˆ†æ®µ+æ‹¼æ¥ â€‹ é—®é¢˜å¾ˆå¤šï¼Œæ€ä¹ˆè®­ç»ƒï¼Ÿï¼Ÿæ€ä¹ˆé¢„æµ‹ï¼Ÿï¼Ÿï¼Ÿ æ¨¡å‹å±‚é¢ï¼š transformer-xl basedçš„ptmï¼Œæ¯”å¦‚xlnet ä¼ ç»Ÿrnn basedçš„seq2seq å‚è€ƒhttps://www.zhihu.com/question/395903256","link":"/2022/05/31/long-text/"},{"title":"è°ƒèŠ‚å­¦ä¹ ç‡","text":"å½“å­¦ä¹ ç‡è¿‡å¤§çš„æ—¶å€™ä¼šå¯¼è‡´æ¨¡å‹éš¾ä»¥æ”¶æ•›ï¼Œè¿‡å°çš„æ—¶å€™ä¼šæ”¶æ•›é€Ÿåº¦è¿‡æ…¢ï¼Œåˆç†çš„å­¦ä¹ ç‡æ‰èƒ½è®©æ¨¡å‹æ”¶æ•›åˆ°æœ€å°ç‚¹è€Œéå±€éƒ¨æœ€ä¼˜ç‚¹æˆ–éç‚¹ ç»éªŒå€¼ï¼š 0.01 ~ 0.001 å­¦ä¹ ç‡è¡°å‡åŸå› ï¼šèµ·åˆè·ç¦»ç›®æ ‡åç¦»å¤§ï¼Œå¯ä»¥è®¾ç½®è¾ƒå¤§ï¼Œä¸ºäº†å¿«é€Ÿæ”¶æ•›ï¼Œåç»­é€æ¸é è¿‘ç›®æ ‡ï¼Œéœ€è¦ç²¾ç»†åŒ–ä¸€ç‚¹ï¼Œæ‰€ä»¥å¸Œæœ›å€¼å°ä¸€ç‚¹ åˆ†ç±» 1.è½®æ•°è¡°å‡ æ¯ç»è¿‡kä¸ªepochsåå­¦ä¹ ç‡å‡åŠ 2.æŒ‡æ•°è¡°å‡ \\alpha_t=decay\\_rate^{epoch}*\\alpha_{t-1}3.åˆ†æ•°è¡°å‡ \\alpha_t=\\frac{\\alpha_{t-1}}{1+decay\\_rate*epoch}å‚è€ƒhttps://blog.csdn.net/LiuPeiP_VIPL/article/details/119581343","link":"/2021/12/18/lr/"},{"title":"æ¶ˆæ¯ä¼ é€’","text":"1.ä½¿ç”¨å†…ç½®çš„æ¶ˆæ¯ä¼ é€’apiæ¯”å¦‚GraphConv 2.å®ç°è‡ªå·±çš„æ¶ˆæ¯ä¼ é€’ç­–ç•¥Write your own GNN module https://docs.dgl.ai/tutorials/blitz/3_message_passing.html Message Passing APIs https://docs.dgl.ai/guide/message-api.html#guide-message-passing-api https://docs.dgl.ai/guide/message-heterograph.html Apply Message Passing On Part Of The Graph https://docs.dgl.ai/guide/message-part.html message function,Reduce function https://docs.dgl.ai/api/python/dgl.function.html","link":"/2021/12/31/make-own-gnn-module/"},{"title":"Spark vs MapReduce","text":"å¯¹æ¯”https://www.educba.com/mapreduce-vs-spark/ MapReduce Spark Productâ€™s Category From the introduction, we understood that MapReduce enables the processing of data and hence is majorly a data processing engine. Spark, on the other hand, is a framework that drives complete analytical solutions or applications and hence making it an obvious choice for data scientists to use this as a data analytics engine. Frameworkâ€™s Performance and Data Processing In the case of MapReduce, reading and writing operations are performed from and to a disk thus leading to slowness in the processing speed. In Spark, the number of read/write cycles is minimized along with storing data in memory allowing it to be 10 times faster. But spark may suffer a major degradation if data doesnâ€™t fit in memory. Latency As a result of lesser performance than Spark, MapReduce has a higher latency in computing. Since Spark is faster, it enables developers with low latency computing. Manageability of framework MapReduce being only a batch engine, other components must be handled separately yet synchronously thus making it difficult to manage. Spark is a complete data analytics engine, has the capability to perform batch, interactive streaming, and similar component all under the same cluster umbrella and thus easier to manage! Real-time Analysis MapReduce was built mainly for batch processing and hence fails when used for real-time analytics use cases. Data coming from real-time live streams like Facebook, Twitter, etc. can be efficiently managed and processed in Spark. Interactive Mode MapReduce doesnâ€™t provide the gamut of having interactive mode. In spark it is possible to process the data interactively Security MapReduce has accessibility to all features of Hadoop security and as a result of this, it is can be easily integrated with other projects of Hadoop Security. MapReduce also supports ASLs. In Spark, the security is by default set to OFF which might lead to a major security fallback. In the case of authentication, only the shared secret password method is possible in Spark. Tolerance to Failure In case of crash of MapReduce process, the process is capable of starting from the place where it was left off earlier as it relies on Hard Drives rather than RAMs In case of crash of Spark process, the processing should start from the beginning and hence becomes less fault-tolerant than MapReduce as it relies of RAM usage. sparkä¸ºä»€ä¹ˆæ¯”MapReduceå¿«https://blog.csdn.net/JENREY/article/details/84873874 1 sparkåŸºäºå†…å­˜ ï¼ŒmapreduceåŸºäºç£ç›˜ æŒ‡çš„æ˜¯ä¸­é—´ç»“æœ MapReduceï¼šé€šå¸¸éœ€è¦å°†è®¡ç®—çš„ä¸­é—´ç»“æœå†™å…¥ç£ç›˜ï¼Œç„¶åè¿˜è¦è¯»å–ç£ç›˜ï¼Œä»è€Œå¯¼è‡´äº†é¢‘ç¹çš„ç£ç›˜IO Sparkï¼šä¸éœ€è¦æ¯æ¬¡å°†è®¡ç®—çš„ä¸­é—´ç»“æœå†™å…¥ç£ç›˜ 2 sparkç²—ç²’åº¦èµ„æºç”³è¯·ï¼ŒMapReduceç»†ç²’åº¦èµ„æºç”³è¯· spark æ‰§è¡Œtaskä¸éœ€è¦è‡ªå·±ç”³è¯·èµ„æºï¼Œæäº¤ä»»åŠ¡çš„æ—¶å€™ç»Ÿä¸€ç”³è¯·äº† MapReduce æ‰§è¡Œtaskä»»åŠ¡çš„æ—¶å€™ï¼Œtaskè‡ªå·±ç”³è¯· 3 sparkåŸºäºå¤šçº¿ç¨‹ï¼ŒmapreduceåŸºäºå¤šè¿›ç¨‹","link":"/2022/02/25/mapreduce-spark/"},{"title":"maven","text":"1 ç®€ä»‹Maven æ˜¯ä¸€ä¸ªé¡¹ç›®ç®¡ç†å·¥å…·ï¼Œå¯ä»¥å¯¹ Java é¡¹ç›®è¿›è¡Œæ„å»ºã€ä¾èµ–ç®¡ç†ã€‚ 2 å®‰è£…é…ç½®https://blog.csdn.net/qq_19734597/article/details/120996418 https://blog.csdn.net/weixin_34234829/article/details/89686175 https://blog.csdn.net/idomyway/article/details/81974677 1 æ›´æ¢é•œåƒ conf/settings.xml https://www.cnblogs.com/digdeep/p/5026066.html https://blog.csdn.net/qq_42931492/article/details/107283590 2 ç½‘ç»œé…ç½® conf/settings.xml https://blog.csdn.net/zongf0504/article/details/88797831 3 é—®é¢˜ (org.apache.maven.wagon.providers.http.httpclient.NoHttpResponseException) caught when processing request to {}-&gt;http://XXXXXX-&gt;http://maven.aliyun.com:80: The target server failed to respond 3 ç®¡ç†åŒ…https://blog.51cto.com/u_15119353/3303815 1 è®¾ç½®setting.xml 2 ç¼–å†™pom 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.11_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch6_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.44&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-statebackend-rocksdb_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-planner_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-planner-blink_2.12&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-csv&lt;/artifactId&gt; &lt;version&gt;1.10.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3 ç”Ÿæˆæœ¬åœ°åŒ…çš„repository é»˜è®¤ä½ç½®åœ¨/user/.m2/repositoryï¼Œåœ¨settingå¯ä»¥ä¿®æ”¹ 4 ç¯å¢ƒä½¿ç”¨æœ¬åœ°repository https://blog.csdn.net/weixin_42476601/article/details/87884514 4 é—®é¢˜1.com/atguigu/gmall/hive/udtf/ExplodeJSONArray has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0 è§£å†³ï¼šä¸¤è¾¹jdkç‰ˆæœ¬å¯¹é½å°±å¥½ æ‰“åŒ…æ—¶å€™æ³¨æ„è¦ï¼šmaven clean,maven compile class file versionså¯¹åº”jdkç‰ˆæœ¬ï¼š 1234567891049 = Java 550 = Java 651 = Java 752 = Java 853 = Java 954 = Java 1055 = Java 1156 = Java 1257 = Java 1358 = Java 14 2.Unknown host maven.aliyun.com","link":"/2022/03/06/maven/"},{"title":"BERTåœ¨ç¾å›¢æœç´¢æ ¸å¿ƒæ’åºçš„æ¢ç´¢å’Œå®è·µ","text":"å¾ˆæœ‰å¯å‘ï¼ŒæŠ±ç€å­¦ä¹ æ€åº¦ï¼Œmarkä¸€ä¸‹ æ¨¡å‹å±‚é¢æ•´ä½“ç»“æ„å¦‚ä¸‹ 1 BERTé¢„è®­ç»ƒ 2 å¤šä»»åŠ¡å­¦ä¹  â€‹ åœºæ™¯å±‚ï¼šæ ¹æ®ä¸šåŠ¡åœºæ™¯è¿›è¡Œåˆ’åˆ†ï¼Œæ¯ä¸ªä¸šåŠ¡åœºæ™¯å•ç‹¬è®¾è®¡ç½‘ç»œç»“æ„ 3 è”åˆè®­ç»ƒ ä¸¤ä¸ªä»»åŠ¡åˆ†åˆ«ä¸ºï¼š â€‹ 1 ç›¸å…³æ€§ä»»åŠ¡ï¼šç›¸å…³æ€§+NERï¼ˆå¤šä»»åŠ¡å¢å¼ºç›¸å…³æ€§ï¼‰ â€‹ 2 æ’åºä»»åŠ¡ æ€ä¹ˆè”åˆæ²¡çœ‹å‡ºæ¥ ä¹‹å‰æ˜¯ä¸¤é˜¶æ®µfinetuneï¼š 1. å…ˆç›¸å…³æ€§ä»»åŠ¡ 2 ç„¶åæ’åºä»»åŠ¡ å‚è€ƒhttps://tech.meituan.com/2020/07/09/bert-in-meituan-search.html","link":"/2021/08/21/meituan/"},{"title":"å…ƒæ•°æ®ç®¡ç†","text":"å…ƒæ•°æ®https://www.ruanyifeng.com/blog/2007/03/metadata.html# https://dataedo.com/kb/data-glossary/what-is-metadata https://www.cnblogs.com/alight/p/3982086.html Metadata is simply data about data. It means it is a description and context of the data. It helps to organize, find and understand data. Here are a few real world examples of metadata: Those are some typical metadata elements: Title and description Tags and categories Who created and when Who last modified and when Who can access or update å…ƒæ•°æ®ç®¡ç†https://zhuanlan.zhihu.com/p/336504407 å…ƒæ•°æ®ç®¡ç†å·¥å…·atlas hive","link":"/2022/02/07/meta-data-management/"},{"title":"ç»†ç²’åº¦NLPä»»åŠ¡","text":"AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization ï¼ˆByteDance AI Labï¼‰ https://arxiv.org/pdf/2008.11869.pdf å‚è€ƒ","link":"/2022/06/30/micro-Grained/"},{"title":"è¿­ä»£åˆ†æ","text":"","link":"/2022/07/26/ml-iteration-analyze/"},{"title":"æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²","text":"0 OONXOpen Neural Network Exchange è·¨æ¡†æ¶çš„æ¨¡å‹ä¸­é—´è¡¨è¾¾ï¼Œæ¨¡å‹çš„ç»Ÿä¸€å­˜å‚¨å½¢å¼,ONNX æ¨¡å‹ä¸€èˆ¬ç”¨äºä¸­é—´éƒ¨ç½²é˜¶æ®µ 1 pytorchlibtorch 2 TensorFlowTensorflow Serving TensorFlow Lite 3 TensorRTåŠ é€Ÿç”¨çš„ NVIDIAÂ® TensorRTâ„¢ is an SDK for optimizing trained deep learning models to enable high-performance inference. https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html 4 NCNNncnn is a high-performance neural network inference computing framework optimized for mobile platforms. 5 TVMåŠ é€Ÿ ApacheTVMæ˜¯ä¸€ä¸ªé¢å‘CPUã€GPUå’Œæœºå™¨å­¦ä¹ åŠ é€Ÿå™¨çš„å¼€æºæœºå™¨å­¦ä¹ ç¼–è¯‘å™¨æ¡†æ¶ã€‚å®ƒæ—¨åœ¨ä½¿æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆèƒ½å¤Ÿåœ¨ä»»ä½•åç«¯è®¾å¤‡é«˜æ•ˆåœ°ä¼˜åŒ–å¹¶è¿è¡Œè®¡ç®— https://chinese.tvm.wiki/tutorial/introduction.html#an-overview-of-tvm-and-model-optimization 6 onnxruntime åŠ é€Ÿç”¨çš„ 7 ç»„åˆä½¿ç”¨ 1 TensorFlow -&gt; oonx-&gt;onnxruntime https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html å‚è€ƒhttps://zhuanlan.zhihu.com/p/346511883 https://zhuanlan.zhihu.com/p/423551635 https://hub.fastgit.org/onnx/tutorials https://blog.csdn.net/zxgmlcj/article/details/103279869 https://hub.fastgit.org/microsoft/onnxruntime https://hub.fastgit.org/onnx/onnx https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html https://chinese.tvm.","link":"/2022/05/23/model-deploy/"},{"title":"é›†ç¾¤ç›‘æ§","text":"å¸¸ç”¨è¿ç»´ç›‘æ§å·¥å…·è¯¦ç»†å¯¹æ¯” https://www.leoheng.com/2021/08/10/%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E8%AF%A6%E7%BB%86%E5%AF%B9%E6%AF%94/ Zabbix+Grafana https://www.cnblogs.com/wushuaishuai/p/10852355.html","link":"/2022/02/05/monitor-pcs/"},{"title":"å•è°ƒæ ˆ","text":"åˆ†ç±»ï¼š å•è°ƒæ ˆä¹Ÿåˆ†ä¸ºå•è°ƒé€’å¢æ ˆå’Œå•è°ƒé€’å‡æ ˆ å•è°ƒé€’å¢æ ˆï¼šå•è°ƒé€’å¢æ ˆå°±æ˜¯ä»æ ˆåº•åˆ°æ ˆé¡¶æ•°æ®æ˜¯ä»å¤§åˆ°å° å•è°ƒé€’å‡æ ˆï¼šå•è°ƒé€’å‡æ ˆå°±æ˜¯ä»æ ˆåº•åˆ°æ ˆé¡¶æ•°æ®æ˜¯ä»å°åˆ°å¤§ ä¸¾ä¾‹ï¼šå•è°ƒé€’å¢æ ˆ ç°åœ¨æœ‰ä¸€ç»„æ•°10ï¼Œ3ï¼Œ7ï¼Œ4ï¼Œ12ã€‚ä»å·¦åˆ°å³ä¾æ¬¡å…¥æ ˆï¼Œåˆ™å¦‚æœæ ˆä¸ºç©ºæˆ–å…¥æ ˆå…ƒç´ å€¼å°äºæ ˆé¡¶å…ƒç´ å€¼ï¼Œåˆ™å…¥æ ˆï¼›å¦åˆ™ï¼Œå¦‚æœå…¥æ ˆåˆ™ä¼šç ´åæ ˆçš„å•è°ƒæ€§ï¼Œåˆ™éœ€è¦æŠŠæ¯”å…¥æ ˆå…ƒç´ å°çš„å…ƒç´ å…¨éƒ¨å‡ºæ ˆã€‚ 10å…¥æ ˆæ—¶ï¼Œæ ˆä¸ºç©ºï¼Œç›´æ¥å…¥æ ˆï¼Œæ ˆå†…å…ƒç´ ä¸º10ã€‚ 3å…¥æ ˆæ—¶ï¼Œæ ˆé¡¶å…ƒç´ 10æ¯”3å¤§ï¼Œåˆ™å…¥æ ˆï¼Œæ ˆå†…å…ƒç´ ä¸º10ï¼Œ3ã€‚ 7å…¥æ ˆæ—¶ï¼Œæ ˆé¡¶å…ƒç´ 3æ¯”7å°ï¼Œåˆ™æ ˆé¡¶å…ƒç´ å‡ºæ ˆï¼Œæ­¤æ—¶æ ˆé¡¶å…ƒç´ ä¸º10ï¼Œæ¯”7å¤§ï¼Œåˆ™7å…¥æ ˆï¼Œæ ˆå†…å…ƒç´ ä¸º10ï¼Œ7ã€‚ 4å…¥æ ˆæ—¶ï¼Œæ ˆé¡¶å…ƒç´ 7æ¯”4å¤§ï¼Œåˆ™å…¥æ ˆï¼Œæ ˆå†…å…ƒç´ ä¸º10ï¼Œ7ï¼Œ4ã€‚ 12å…¥æ ˆæ—¶ï¼Œæ ˆé¡¶å…ƒç´ 4æ¯”12å°ï¼Œ4å‡ºæ ˆï¼Œæ­¤æ—¶æ ˆé¡¶å…ƒç´ ä¸º7ï¼Œä»æ¯”12å°ï¼Œæ ˆé¡¶å…ƒç´ 7ç»§ç»­å‡ºæ ˆï¼Œæ­¤æ—¶æ ˆé¡¶å…ƒç´ ä¸º10ï¼Œä»æ¯”12å°ï¼Œ10å‡ºæ ˆï¼Œæ­¤æ—¶æ ˆä¸ºç©ºï¼Œ12å…¥æ ˆï¼Œæ ˆå†…å…ƒç´ ä¸º12ã€‚ ä¼ªä»£ç  123456789101112131415161718stack&lt;int&gt; st;//å•è°ƒé€’å¢æ ˆfor (éå†è¿™ä¸ªæ•°ç»„){ if (æ ˆç©º || æ ˆé¡¶å…ƒç´ å¤§äºç­‰äºå½“å‰æ¯”è¾ƒå…ƒç´ ) { å…¥æ ˆ; } else { while (æ ˆä¸ä¸ºç©º &amp;&amp; æ ˆé¡¶å…ƒç´ å°äºå½“å‰å…ƒç´ ) { æ ˆé¡¶å…ƒç´ å‡ºæ ˆ; æ›´æ–°ç»“æœ; } å½“å‰æ•°æ®å…¥æ ˆ; }} åº”ç”¨ï¼š ä¸»è¦ç”¨äº$O(n)$ è§£å†³NGEé—®é¢˜ï¼ˆNext Greater Elementï¼‰ æ¯”å½“å‰å…ƒç´ æ›´å¤§çš„ä¸‹ä¸€ä¸ªå…ƒç´  æ¯”å½“å‰å…ƒç´ æ›´å¤§çš„å‰ä¸€ä¸ªå…ƒç´  æ¯”å½“å‰å…ƒç´ æ›´å°çš„ä¸‹ä¸€ä¸ªå…ƒç´  æ¯”å½“å‰å…ƒç´ æ›´å°çš„å‰ä¸€ä¸ªå…ƒç´  å‚è€ƒhttps://blog.csdn.net/lucky52529/article/details/89155694","link":"/2021/09/24/monotonous-stack/"},{"title":"å¤šæ ‡ç­¾","text":"1 åˆ†ç±»æ ‡ç­¾ æ–¹æ³• 1 è½¬æˆå¤šä¸ª2åˆ†ç±» 2 ç›´æ¥å¤šæ ‡ç­¾åˆ†ç±» lossï¼š æœ‰ä¸ªç–‘é—®ï¼Œç›´æ¥softmax+äº¤å‰ç†µä¸è¡Œå—ï¼Ÿï¼Ÿï¼Ÿ https://zhuanlan.zhihu.com/p/385475273 https://zhuanlan.zhihu.com/p/138117543 1 åŸæ¥çš„äº¤å‰ç†µ mä¸ºæ ·æœ¬æ€»å’Œï¼Œqä¸ºç±»åˆ«æ•°é‡ 2 â€œsoftmax+äº¤å‰ç†µâ€æ¨å¹¿ è¯„ä»·æŒ‡æ ‡ https://zhuanlan.zhihu.com/p/385475273 2 æ–‡æœ¬ç¿»è¯‘ä¸€å¥è‹±æ–‡è¾“å…¥ï¼Œæœ‰å¤šä¸ªç‰ˆæœ¬çš„ä¸­æ–‡ç¿»è¯‘ï¼Œè¿™ç§ä¸€å¯¹å¤šæ€ä¹ˆè®­ç»ƒï¼Ÿï¼Ÿï¼Ÿï¼Ÿ å‚è€ƒhttps://zhuanlan.zhihu.com/p/138117543 https://www.jianshu.com/p/ac3bec3dde3e","link":"/2022/06/08/multi-label/"},{"title":"å¤šæµè½¬æ¢","text":"ç®€å•åˆ’åˆ†çš„è¯ï¼Œå¤šæµè½¬æ¢å¯ä»¥åˆ†ä¸ºâ€œåˆ†æµâ€å’Œâ€œåˆæµâ€ä¸¤å¤§ç±»ã€‚åœ¨ Flinkä¸­ï¼Œåˆ†æµæ“ä½œå¯ä»¥é€šè¿‡å¤„ç†å‡½æ•°çš„ä¾§è¾“å‡ºæµï¼ˆ side outputï¼‰å¾ˆå®¹æ˜“åœ°å®ç°è€Œåˆæµåˆ™æä¾›ä¸åŒå±‚çº§çš„å„ç§ API ä»»åŠ¡ï¼š streamæ•°é‡ ï¼Œæ¯ä¸ªstreamå¯ä»¥æœ‰å¤šä¸ªå­ä»»åŠ¡ï¼ˆå¹¶è¡Œåº¦ï¼‰ keybyåªèƒ½ç®—åˆ†ç»„ï¼Œä¸ç®—åˆ†æµ èµ„æºï¼š task manageræ•°é‡ï¼Œslotæ•°é‡ 1 åˆ†æµæ‰€è°“â€œåˆ†æµâ€ï¼Œå°±æ˜¯å°†ä¸€æ¡æ•°æ®æµæ‹†åˆ†æˆå®Œå…¨ç‹¬ç«‹çš„ä¸¤æ¡ã€ç”šè‡³å¤šæ¡æµã€‚ä¹Ÿå°±æ˜¯åŸºäºä¸€ä¸ªDataStreamï¼Œå¾—åˆ°å®Œå…¨å¹³ç­‰çš„å¤šä¸ªå­ DataStreamï¼Œå¦‚å›¾ 8-1æ‰€ç¤ºã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä¼šå®šä¹‰ä¸€äº›ç­›é€‰æ¡ä»¶ï¼Œå°†ç¬¦åˆæ¡ä»¶çš„æ•°æ®æ‹£é€‰å‡ºæ¥æ”¾åˆ°å¯¹åº”çš„æµé‡Œã€‚ åœ¨Flink 1.13ç‰ˆæœ¬ä¸­ï¼Œå·²ç»å¼ƒç”¨äº† .split()æ–¹æ³•ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯ç›´æ¥ç”¨å¤„ç†å‡½æ•°ï¼ˆ process functionï¼‰çš„ä¾§è¾“å‡ºæµ ï¼ˆside outputï¼‰ã€‚ 2 åˆæµæ—¢ç„¶ä¸€æ¡æµå¯ä»¥åˆ†å¼€ï¼Œè‡ªç„¶å¤šæ¡æµå°±å¯ä»¥åˆå¹¶ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šé‡åˆ°æ¥æºä¸åŒçš„å¤šæ¡æµï¼Œéœ€è¦å°†å®ƒä»¬çš„æ•°æ®è¿›è¡Œè”åˆå¤„ç†ã€‚æ‰€ä»¥ Flinkä¸­åˆæµçš„æ“ä½œä¼šæ›´åŠ æ™®éï¼Œå¯¹åº”çš„APIä¹Ÿæ›´åŠ ä¸°å¯Œã€‚ 2.1 åŸºæœ¬åˆæµ1 è”åˆï¼ˆ Unionï¼‰ å¯ä»¥å¤šæ¡ï¼ˆå¤§äº2ï¼‰åˆå¹¶ï¼Œæ•°æ®ç±»å‹å¿…é¡»ä¸€è‡´ 2 è¿æ¥ï¼ˆ Connectï¼‰ å¿…é¡»ä¸¤æ¡ï¼Œæ•°æ®ç±»å‹å¯ä»¥ä¸åŒ 2.2 åŒæµè”ç»“ joinå¯¹äºä¸¤æ¡æµçš„åˆå¹¶ï¼Œå¾ˆå¤šæƒ…å†µæˆ‘ä»¬å¹¶ä¸æ˜¯ç®€å•åœ°å°†æ‰€æœ‰æ•°æ®æ”¾åœ¨ä¸€èµ·ï¼Œè€Œæ˜¯å¸Œæœ›æ ¹æ®æŸä¸ªå­—æ®µçš„å€¼å°†å®ƒä»¬è”ç»“èµ·æ¥ï¼Œâ€œé…å¯¹â€å»åšå¤„ç†ã€‚ 1 çª—å£è”ç»“ï¼ˆ Window Join 2 é—´éš”è”ç»“ï¼ˆ Interval Join 3 çª—å£åŒç»„è”ç»“ï¼ˆ Window CoGroup","link":"/2022/03/25/multi-stream-flink/"},{"title":"å¤šä»»åŠ¡å­¦ä¹ ","text":"å¥½å¤„1 å‡å°‘æ¨¡å‹æ•°é‡ï¼Œç›¸ä¼¼ä»»åŠ¡å¯ä»¥å…±äº« 2 å¯ä»¥æå‡å•ä¸€ä»»åŠ¡çš„æ•ˆæœ å¾®è½¯çš„MT-DNN[33]å·²ç»è¯æ˜åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„å¤šä»»åŠ¡Fine-tuningå¯ä»¥æå‡å„é¡¹å­ä»»åŠ¡æ•ˆæœ ç»“æ„ lossè®¾è®¡lossæ˜¯é‡ç‚¹ é™¤äº†å„ä¸ªå­ä»»åŠ¡çš„æŸå¤±ç›´æ¥ç›¸åŠ ï¼Œè¿˜æœ‰åˆ«çš„æ–¹å¼å— è¾…åŠ©ä»»åŠ¡æ€ä¹ˆè®¾è®¡ å‚è€ƒhttps://zhuanlan.zhihu.com/p/397196665 https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html","link":"/2022/06/11/multi-task-learning/"},{"title":"mysql","text":"å¼€æœºè‡ªå¯é…ç½®Binlogflinkcdcéœ€è¦ç”¨ 12345678910111213141 sudo vim /etc/my.cnf2 å†™å…¥server id = 1 log-bin=mysql-bin binlog_format=row binlog-do-db=gmall2021binlog-do-db=gmall2021_realtimeæ³¨æ„ï¼šbinlog-do-db æ ¹æ®è‡ªå·±çš„æƒ…å†µè¿›è¡Œä¿® æ”¹ï¼ŒæŒ‡å®šå…·ä½“è¦åŒæ­¥çš„æ•°æ®åº“ï¼Œå¤šä¸ªå°±å†™å¤šè¡Œ3 é‡å¯mysqlsudo systemctl restart mysqld4 æŸ¥çœ‹æœ‰æ²¡æœ‰ç”Ÿæ•ˆ cd /var/lib sudo ls -l mysql | grep bin ä¿®æ”¹mysqlåº“é‡Œæ•°æ®ï¼Œè§‚å¯Ÿ&quot;mysql-bin.æœ€æ–°&quot;æ–‡ä»¶å¤§å°çš„å˜åŒ– é—®é¢˜1 Job for mysqld.service failed because the control process exited with error code https://blog.csdn.net/qq_41179691/article/details/104598293 2 navicatè¿ä¸ä¸ŠæœåŠ¡å™¨çš„mysql https://blog.csdn.net/u014264373/article/details/85564524 https://blog.csdn.net/MTbaby/article/details/56836986","link":"/2022/05/21/mysql/"},{"title":"åˆ†ç±»ç®—æ³•ä¹‹æœ´ç´ è´å¶æ–¯","text":"https://www.cnblogs.com/pinard/p/6069267.html","link":"/2021/11/03/naive-bayse/"},{"title":"ipå’Œç«¯å£","text":"https://blog.csdn.net/weixin_33950757/article/details/90441617 IPåœ°å€ï¼ˆå®¶åº­åœ°å€ï¼‰ï¼š ä¾‹å¦‚ï¼š218.18.170.149ï¼›ç†è§£ä¸ºï¼šå¹¿ä¸œçœ.æ·±åœ³å¸‚.é¾™å²—åŒº.ç”µä¿¡ï¼ˆæ¡¥å¤´ä¸œè·¯äºŒé“å··149å·ï¼‰ï¼› ç«¯å£åï¼ˆé—¨ç‰Œå·ï¼‰ï¼š ä¾‹å¦‚ï¼š218.18.170.149:1011ï¼Œç«¯å£ä¸ºï¼ˆ1011ï¼‰å·ï¼›æ„æ€å°±æ˜¯æˆ‘å®¶æœ‰å¾ˆå¤šæˆ¿é—´ï¼Œå…¶ä¸­çš„ä¸€ä¸ªæˆ¿é—´ä¸º1011å·ï¼› ç¦æ­¢ç«¯å£ï¼šç¦æ­¢ä»»ä½•äººæ¥æ‰“å¼€æˆ‘çš„1011å·æˆ¿é—´ï¼› ç«¯å£ç™»é™†ï¼š1011å·æˆ¿é—´çš„é—¨æ˜¯åŠ å¯†çš„é˜²ç›—é—¨ï¼Œä½ å¿…é¡»è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ä½ æ‰èƒ½è¿›å…¥1011å·æˆ¿é—´","link":"/2022/03/01/netport/"},{"title":"nginx","text":"0 æ¦‚å¿µæ­£å‘ä»£ç†ï¼šä»£ç†çš„æ˜¯å®¢æˆ·ç«¯ åå‘ä»£ç†ï¼šä»£ç†çš„æ˜¯æœåŠ¡å™¨ç«¯ æ¦‚å¿µ 1 ä½œç”¨https://zhuanlan.zhihu.com/p/54793789 1ã€é™æ€HTTPæœåŠ¡å™¨ 2ã€åå‘ä»£ç†æœåŠ¡å™¨ 3ã€è´Ÿè½½å‡è¡¡ è´Ÿè½½å‡è¡¡é€šå¸¸æ˜¯æŒ‡å°†è¯·æ±‚â€å‡åŒ€â€åˆ†æ‘Šåˆ°é›†ç¾¤ä¸­å¤šä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ä¸Šæ‰§è¡Œ 4ã€è™šæ‹Ÿä¸»æœº 5ã€FastCGI 2 é—®é¢˜1 nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use) 12lsof -i :80 |grep nginx |grep -v grep|awk '{print $2}'kill -9 XXX XXX https://blog.csdn.net/fmwind/article/details/120786375","link":"/2022/05/15/nginxx/"},{"title":"nlpcda-NLPä¸­æ–‡æ•°æ®å¢å¼ºå·¥å…·ï¼Œå¼ºæ¨","text":"ä¸‹è½½ï¼špip install nlpcda å·¥å…·æ”¯æŒ 1.éšæœºå®ä½“æ›¿æ¢ 2.è¿‘ä¹‰è¯ 3.è¿‘ä¹‰è¿‘éŸ³å­—æ›¿æ¢ 4.éšæœºå­—åˆ é™¤ï¼ˆå†…éƒ¨ç»†èŠ‚ï¼šæ•°å­—æ—¶é—´æ—¥æœŸç‰‡æ®µï¼Œå†…å®¹ä¸ä¼šåˆ ï¼‰ 5.NERç±» BIO æ•°æ®å¢å¼º 6.éšæœºç½®æ¢é‚»è¿‘çš„å­—ï¼šç ”è¡¨ç©¶æ˜ï¼Œæ±‰å­—åºé¡ºå¹¶ä¸å®šä¸€å½±å“æ–‡å­—çš„é˜…è¯»ç†è§£&lt;&lt;æ˜¯ä¹±åºçš„ 7.ä¸­æ–‡ç­‰ä»·å­—æ›¿æ¢ï¼ˆ1 ä¸€ å£¹ â‘ ï¼Œ2 äºŒ è´° â‘¡ï¼‰ 8.ç¿»è¯‘äº’è½¬å®ç°çš„å¢å¼º 9.ä½¿ç”¨simbertåšç”Ÿæˆå¼ç›¸ä¼¼å¥ç”Ÿæˆ 10.Cluster2Clusterç”Ÿæˆæ›´å¤šæ ·åŒ–çš„æ–°æ•°æ®","link":"/2021/07/27/nlp-data-augment/"},{"title":"nlpæ•™æ","text":"ã€Šembeddings in natural language processingã€‹ http://josecamachocollados.com/book_embNLP_draft.pdf ã€ŠSpeech and Language Processingã€‹ https://web.stanford.edu/~jurafsky/slp3/","link":"/2022/04/06/nlp-reference/"},{"title":"å¸¸è§ç®—æ³•æ€»ç»“","text":"ç±»åˆ«å½’ç±»ï¼šè›®åŠ›ï¼Œåˆ†æ²»ï¼ŒåŠ¨æ€è§„åˆ’ï¼Œè´ªå¿ƒï¼Œå›æº¯ï¼Œåˆ†æ”¯é™ç•Œã€‚ å®ç°æ–¹å¼æœ‰ä¸¤ç§ï¼Œä¸€èˆ¬ä¸ºåŸºäºè¿­ä»£å’ŒåŸºäºé€’å½’ã€‚ ä¼˜åŒ–åŸåˆ™ï¼šæ— éæ—¶é—´æ¢ç©ºé—´æˆ–è€…ç©ºé—´æ¢æ—¶é—´ ä¸€.è›®åŠ›Brute-forceæ²¡æœ‰ä»€ä¹ˆå¥½è¯´ï¼Œå°±æ˜¯éå†æˆ–è€…æšä¸¾ã€‚ äºŒ.åˆ†æ²»åˆ†è€Œæ²»ä¹‹ï¼Œå°†å¤§é—®é¢˜æ‹†è§£æˆç›¸äº’ç‹¬ç«‹ä¸”ç›¸ä¼¼çš„å­é—®é¢˜ã€‚ æ­¥éª¤ï¼š1ã€å…ˆåˆ† 2 æ±‚è§£ 3 .åˆå¹¶ å®ç°æ–¹å¼ï¼šä¸€èˆ¬é€’å½’å®ç° ä¸‰.åŠ¨æ€è§„åˆ’å’Œæš´åŠ›ç›¸æ¯”ï¼Œdpåˆ©ç”¨äº†å­é—®é¢˜é—´çš„ä¾èµ–å…³ç³»ï¼Œå‡å°‘äº†ä¸€äº›è®¡ç®— é€‚ç”¨æ¡ä»¶ï¼š1.æ»¡è¶³æœ€ä¼˜å­ç»“æ„æ€§è´¨ï¼Œå³æœ€ä¼˜è§£æ‰€åŒ…å«çš„å­é—®é¢˜çš„è§£ä¹Ÿæ˜¯æœ€ä¼˜çš„ æ„é€ é€’æ¨å¼ï¼š 0.ç¡®å®šç»´åº¦ï¼Œä¸€èˆ¬ä¸€ç»´æˆ–è€…äºŒç»´ 1.æ³¨æ„å«ä¹‰ 2.é€‰æ‹©åˆ†éš”ç‚¹ â€‹ a. ä¸€èˆ¬å’Œå‰ä¸€æ­¥æˆ–è€…ä¸¤æ­¥æœ‰å…³,æ¯”å¦‚æœ€å¤§å­åºå’Œï¼Œ$dp[i]=max(s[i],s[i]+dp[i-1])$ â€‹ b. ä½†æœ‰æ—¶å€™éœ€è¦éå†å…¨éƒ¨åˆ†å‰²ç‚¹ï¼Œæ¯”å¦‚å•è¯æ‹†åˆ†ï¼Œ$dp[i]=dp[j] \\ \\&amp; \\&amp; \\ check(s[j..iâˆ’1])$ï¼Œ â€‹ c. æœ‰æ—¶å€™åŠ¨æ€é€‰æ‹©åˆ†éš”ç‚¹ï¼Œæ¯”å¦‚ä¸‘æ•°ï¼Œ$ dp[i]=min(dp[p2]2,dp[p3]3,dp[p5]*5) $,å…¶ä¸­$p2,p3,p5$åŠ¨æ€å˜åŒ– 3.æ³¨æ„+ï¼Œ - +ï¼Œ-å†³å®šè®¡ç®—æ¬¡åº ä¸€å®šæ˜¯ç”¨å·²æœ‰çš„é€’æ¨æ²¡æœ‰çš„ ä¸¾ä¾‹æ¯”å¦‚62. ä¸åŒè·¯å¾„ï¼Œ$dp[i][j] = dp[i-1][j] + dp[i][j-1]$ï¼› 123456789class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: dp = [[1]*n] + [[1]+[0] * (n-1) for _ in range(m-1)] #print(dp) for i in range(1, m): for j in range(1, n): dp[i][j] = dp[i-1][j] + dp[i][j-1] return dp[-1][-1] æ¯”å¦‚5. æœ€é•¿å›æ–‡å­ä¸²ï¼Œ$dp[i][j]=dp[i+1][j-1] \\ and \\ s[i]==s[j]$ s = â€œbabadâ€ n=5 ï¼ˆiï¼Œjï¼‰ (0,1) (1,2) (2,3) (3,4) (0,2) (1,3) (2,4) (0,3) 12345678910111213141516171819202122232425262728293031323334353637class Solution: def longestPalindrome(self, s: str) -&gt; str: n = len(s) if n &lt; 2: return s max_len = 1 begin = 0 # dp[i][j] è¡¨ç¤º s[i..j] æ˜¯å¦æ˜¯å›æ–‡ä¸² dp = [[False] * n for _ in range(n)] for i in range(n): dp[i][i] = True # é€’æ¨å¼€å§‹ # å…ˆæšä¸¾å­ä¸²é•¿åº¦ for L in range(2, n + 1): # æšä¸¾å·¦è¾¹ç•Œï¼Œå·¦è¾¹ç•Œçš„ä¸Šé™è®¾ç½®å¯ä»¥å®½æ¾ä¸€äº› for i in range(n): # ç”± L å’Œ i å¯ä»¥ç¡®å®šå³è¾¹ç•Œï¼Œå³ j - i + 1 = L å¾— j = L + i - 1 # å¦‚æœå³è¾¹ç•Œè¶Šç•Œï¼Œå°±å¯ä»¥é€€å‡ºå½“å‰å¾ªç¯ if j &gt;= n: break if s[i] != s[j]: dp[i][j] = False else: if j - i &lt; 3: dp[i][j] = True else: dp[i][j] = dp[i + 1][j - 1] # åªè¦ dp[i][L] == true æˆç«‹ï¼Œå°±è¡¨ç¤ºå­ä¸² s[i..L] æ˜¯å›æ–‡ï¼Œæ­¤æ—¶è®°å½•å›æ–‡é•¿åº¦å’Œèµ·å§‹ä½ç½® if dp[i][j] and j - i + 1 &gt; max_len: max_len = j - i + 1 begin = i return s[begin:begin + max_len] å®ç°æ–¹å¼ é€’å½’å®ç°ï¼šæ•ˆç‡ä¸é«˜çš„åŸå› åœ¨äºå­é—®é¢˜é‡å¤è®¡ç®—äº†ï¼Œæ¯”èµ·æš´åŠ›å“ªä¸ªå¿«ï¼Ÿåº”è¯¥è¿˜æ˜¯è¿™ä¸ª è¿­ä»£+å¤‡å¿˜å½•ï¼šä¸ä¸€å®šå…¨éƒ¨éƒ½è¦å­˜å‚¨ï¼Œéœ€è¦çš„å­˜ç€äº†å°±å¯ä»¥äº†ï¼Œæ¯æ¬¡å­é—®é¢˜è®¡ç®—ä¸€æ¬¡ï¼ˆç©ºé—´æ¢æ—¶é—´ï¼‰ ä¸€èˆ¬é‡‡ç”¨è¿­ä»£+å¤‡å¿˜å½• è§£çš„è¿½è¸ªï¼šæœ‰æ—¶å€™éœ€è¦å€ŸåŠ©å¤‡å¿˜å½•æœç´¢è§£ï¼Œæ—¶é—´å¤æ‚åº¦ä¸è¶…è¿‡è®¡ç®—å¤‡å¿˜å½• çŠ¶æ€å‹ç¼©åŠ¨æ€è§„åˆ’ https://jimmy-shen.medium.com/bitmask-state-compression-dp-39e7ba56978b https://segmentfault.com/a/1190000038223084 https://blog.csdn.net/wxgaws/article/details/114693162 Usually, the state of DP can use limited variables to represent such a dp[i] , dp[i] [j] ,dp[i] [j] [k]. However, sometimes, the states of a DP problem may contain multiple statuses. In this case, we can think about using the state compression approaches to represent the DP state. è¯´ç™½äº†å°±æ˜¯åœ¨çŠ¶æ€å¾ˆå¤šçš„æ—¶å€™å¯¹çŠ¶æ€é™ç»´ ç›®çš„ï¼šå¯ä»¥ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ï¼Œä¸çŸ¥é“å¯ä»¥ä¸å¯ä»¥ä¼˜åŒ–æ—¶é—´å¤æ‚åº¦ å››.è´ªå¿ƒçŸ­è§†ï¼ˆå°‘è€ƒè™‘å¾ˆå¤šï¼Œè®¡ç®—é‡å°±ä¸‹å»äº†ï¼‰ï¼Œå±€éƒ¨æœ€ä¼˜ï¼Œéœ€è¦è¯æ˜ äº”.å›æº¯å›æº¯ç®—æ³•æ˜¯æš´åŠ›æ±‚è§£çš„ä¸€ç§ï¼Œå®ƒèƒ½ç³»ç»Ÿåœ°æœç´¢ä¸€ä¸ªé—®é¢˜çš„æ‰€æœ‰è§£ï¼ŒåŒºåˆ«åœ¨äºå›æº¯ä¼šå›å¤´ï¼ˆå‡æï¼‰ï¼Œä»¥æ­¤å‡å°‘è®¡ç®—é‡ ä¸‰æ­¥ä¸€å›å¤´ï¼Œä¸€èˆ¬ç”¨äºå¯ä»¥ç”¨æ ‘å‹ç»“æ„å»ºæ¨¡çš„é—®é¢˜ã€‚ å®ç°æ–¹å¼ï¼šåˆ©ç”¨DFSæœç´¢è§£ç©ºé—´ï¼Œä¸€èˆ¬é€’å½’å®ç° https://zhuanlan.zhihu.com/p/93530380 https://zhuanlan.zhihu.com/p/112926891 ä¼˜åŒ–ç­–ç•¥ï¼š å‰ªæ https://blog.csdn.net/arabic1666/article/details/80147606 å…­.åˆ†æ”¯é™ç•Œä»£ä»·å‡½æ•° æå¤§å€¼é—®é¢˜ï¼Œä»¥å½“å‰ç»“ç‚¹ä¸ºæ ¹çš„å­æ ‘æ‰€æœ‰å¯è¡Œè§£çš„å€¼çš„ä¸Šç•Œï¼Œæ¯ä¸ªç»“ç‚¹éƒ½æœ‰è‡ªå·±çš„ ç•Œ æå¤§å€¼é—®é¢˜ï¼Œå½“å‰å¾—åˆ°çš„å¯è¡Œè§£çš„å€¼çš„æœ€å¤§å€¼ï¼Œå°±1ä¸ª ä»£ä»·å‡½æ•°å’Œç•Œå¯ä»¥ç”¨äºå‡æï¼Œå¯¹äºæå¤§å€¼é—®é¢˜ï¼Œç•Œå¤§äºæŸç»“ç‚¹ä»£ä»·å‡½æ•°ï¼Œè¯¥ç»“ç‚¹å°±ä¸éœ€è¦ç»§ç»­æœç´¢äº† ç±»ä¼¼å›æº¯ï¼ŒåŒºåˆ«å¦‚ä¸‹ å‚è€ƒæ–‡çŒ®https://blog.csdn.net/zm1_1zm/article/details/69224626 https://blog.csdn.net/wxgaws/article/details/114693162 https://segmentfault.com/a/1190000038223084 https://jimmy-shen.medium.com/bitmask-state-compression-dp-39e7ba56978b","link":"/2021/07/24/normal-algrithm/"},{"title":"nvidia-smi æŸ¥çœ‹GPUä½¿ç”¨ç‡å¾ˆé«˜ä½†æ˜¯çœ‹ä¸åˆ°è¿›ç¨‹","text":"https://blog.csdn.net/gostman/article/details/107456597","link":"/2022/01/19/nvidia/"},{"title":"OLAPå’ŒOLTPçš„åŒºåˆ«","text":"https://www.cnblogs.com/schoolbag/p/9759214.html","link":"/2022/02/09/olap-oltp/"},{"title":"ä»£ä»·å‡½æ•°ï¼ŒæŸå¤±å‡½æ•°ï¼Œç›®æ ‡å‡½æ•°åŒºåˆ«","text":"https://blog.csdn.net/lyl771857509/article/details/79428475","link":"/2021/11/04/object-func/"},{"title":"oovæ€ä¹ˆè§£å†³","text":"oovï¼šOut-Of-Vocabulary ä¸­æ–‡ï¼šé‡‡ç”¨å­—ç²’åº¦ è‹±æ–‡ï¼šsubword","link":"/2022/06/07/oov/"},{"title":"open set recognization","text":"1 A Survey on Open Set Recognition https://arxiv.org/abs/2109.00893 2 Open-Set Recognition: A Good Closed-Set Classifier is All You Need https://arxiv.org/abs/2110.06207 3 Recent Advances in Open Set Recognition: A Survey https://arxiv.org/abs/1811.08581","link":"/2022/03/29/open-set-recognization/"},{"title":"ä¼˜åŒ–ç®—æ³•","text":"mark https://www.cnblogs.com/zingp/p/11352012.html#_label8 https://www.jianshu.com/p/71f39c2ea512","link":"/2021/10/14/optimize-algorithm/"},{"title":"è¿‡æ‹Ÿåˆï¼Œæ¬ æ‹Ÿåˆä»¥åŠè§£å†³åŠæ³•","text":"1.åå·®å’Œæ–¹å·® \\overline{f}(\\textbf{x})=\\mathbb{E}_D[f(\\textbf{x};D)]a.åå·® æœŸæœ›è¾“å‡ºä¸çœŸå®æ ‡è®°çš„å·®åˆ«ç§°ä¸ºåå·®ï¼ˆbiasï¼‰ï¼Œå³ bias^{2}(\\textbf{x})=(\\overline{f}(\\textbf{x})-y)^{2}b.æ–¹å·® var(\\textbf{x})=\\mathbb{E}_D[(f(\\textbf{x};D)-\\overline{f}(x))^2]c.å™ªå£° \\xi^{2}=\\mathbb{E}_D[(y_D-y)^2]d.æ³›åŒ–è¯¯å·®ï¼ˆerrorï¼‰ \\begin{align*} error&=\\mathbb{E}_D[(f(\\textbf{x};D)-y_D)^2] \\\\&=... \\\\&=(\\overline{f}(\\textbf{x})-y)^{2}+\\mathbb{E}_D[(f(\\textbf{x};D)-\\overline{f}(x))^2]+\\mathbb{E}_D[(y_D-y)^2] \\\\&=bias^{2}(\\textbf{x})+var(\\textbf{x})+\\xi^{2} \\end{align*}2.è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆä¸åå·®ã€æ–¹å·®çš„å…³ç³» æ¬ æ‹Ÿåˆï¼šæ¨¡å‹ä¸èƒ½é€‚é…è®­ç»ƒæ ·æœ¬ï¼Œæœ‰ä¸€ä¸ªå¾ˆå¤§çš„åå·®ã€‚ è¿‡æ‹Ÿåˆï¼šæ¨¡å‹å¾ˆå¥½çš„é€‚é…è®­ç»ƒæ ·æœ¬ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°å¾ˆç³Ÿï¼Œæœ‰ä¸€ä¸ªå¾ˆå¤§çš„æ–¹å·®ã€‚ 3.å¦‚ä½•è§£å†³è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆa.æ¨¡å‹èƒ½åŠ›ï¼ˆä¸€ä¸ªæ¨¡å‹å‚æ•°æ•°é‡ä¸åŒï¼Œä¸åŒæ¨¡å‹ï¼‰ b.æ­£åˆ™åŒ– æ­£åˆ™åŒ–å‚æ•°å‡ºç°çš„ç›®çš„å…¶å®æ˜¯é˜²æ­¢è¿‡æ‹Ÿåˆæƒ…å½¢çš„å‡ºç°ï¼›å¦‚æœæˆ‘ä»¬çš„æ¨¡å‹å·²ç»å‡ºç°äº†æ¬ æ‹Ÿåˆçš„æƒ…å½¢ï¼Œå°±å¯ä»¥é€šè¿‡å‡å°‘æ­£åˆ™åŒ–å‚æ•°æ¥æ¶ˆé™¤æ¬ æ‹Ÿåˆ c.ç‰¹å¾æ•°é‡ æ¬ æ‹Ÿåˆï¼šå¢åŠ ç‰¹å¾é¡¹ è¿‡æ‹Ÿåˆï¼šå‡å°‘ç‰¹å¾é¡¹ dã€è®­ç»ƒçš„æ•°æ®é‡ æ¬ æ‹Ÿåˆï¼šå‡å°‘æ•°æ®é‡ è¿‡æ‹Ÿåˆï¼šå¢åŠ æ•°æ®é‡ å‚è€ƒhttps://zhuanlan.zhihu.com/p/38853908 https://blog.csdn.net/hurry0808/article/details/78148756 https://blog.csdn.net/cltcj/article/details/119155683","link":"/2021/09/04/overfit-underfit/"},{"title":"pairwise","text":"pairwise learning to rank çš„æ–¹æ³•å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»ã€‚ ç¬¬ä¸€ç±»æ˜¯åŸºäºæ‰“åˆ†å‡½æ•°ï¼Œå®ƒä»¬é€šè¿‡ä¸€äº›ç‰¹æ®Šçš„è®¾è®¡è®©æ¨¡å‹ä¾é â€œæ ·æœ¬å¯¹â€çš„ä¿¡æ¯æ¥å­¦ä¹ å¾—åˆ°æ¯ä¸ªæ ·æœ¬çš„scoreã€‚æ‰€ä»¥å¾—åˆ°è¿™ç±»æ–¹æ³•æœ€åçš„å…¨å±€æ’åºç»“æœå¾ˆç®€å•ï¼Œå°±æ˜¯ç”¨æ‰€æœ‰æ ·æœ¬çš„scoreæ¥æ’åºå³å¯ã€‚ å¦ä¸€ç±»æ–¹æ³•æ˜¯åŸºäºä¼˜å…ˆå‡½æ•°çš„æ–¹æ³•ã€‚è¿™ç±»æ–¹æ³•çš„æ•´ä¸ªè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µæ˜¯ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹æ¥å­¦ä¹ ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´çš„ä¼˜å…ˆå…³ç³»ï¼Œä¾‹å¦‚f(x1, x2)=1è¡¨ç¤ºæ ·æœ¬x1ä¼˜å…ˆäºx2ï¼ˆx1åº”è¯¥æ’åœ¨x2å‰é¢ï¼‰ï¼Œf(x1, x2)=-1è¡¨ç¤ºæ ·æœ¬x2ä¼˜å…ˆäºx1ï¼ˆx1åº”è¯¥æ’åœ¨x2åé¢ï¼‰ã€‚ä»é¢˜ä¸»çš„é—®é¢˜æ¥çœ‹ï¼Œå¯èƒ½é—®çš„æ˜¯â€œå½“æˆ‘ä»¬å·²ç»è®­ç»ƒå‡ºäº†ä¼˜å…ˆå‡½æ•°fä¹‹åï¼Œå¦‚ä½•å¯¹æ‰€æœ‰æ ·æœ¬è¿›è¡Œæ’åºï¼Œå¹¶ä¸”ä½¿è¯¥æ’åºåœ¨æœ€å¤§ç¨‹åº¦ä¸Šä¸fçš„ç»“æœä¸€è‡´â€ã€‚è¿™ä¸ªé—®é¢˜åœ¨å­¦ç•Œè¢«ç§°ä¸ºRank Aggregationï¼ˆæ’åˆ—èšåˆï¼‰ã€‚ å…·ä½“å‚è€ƒ https://www.zhihu.com/question/389068269 åˆ«çš„ç›¸å…³å‚è€ƒï¼š https://www.jianshu.com/p/235756fbf6b6 https://zhuanlan.zhihu.com/p/318300682 https://zhuanlan.zhihu.com/p/65224450 https://zhuanlan.zhihu.com/p/65756030 https://www.zhihu.com/question/389068269/answer/1180120736","link":"/2021/12/20/pairwise/"},{"title":"æ„ŸçŸ¥æœº","text":"","link":"/2022/08/20/perceptron/"},{"title":"æŒä¹…åŒ–","text":"https://cloud.tencent.com/developer/article/1760389 https://blog.csdn.net/dudadudadd/article/details/114102341 https://yiqingqing.blog.csdn.net/article/details/121772325 https://blog.csdn.net/feizuiku0116/article/details/122839247 https://blog.csdn.net/CyAurora/article/details/119654676 https://www.cnblogs.com/Transkai/p/11347224.html https://blog.csdn.net/CyAurora/article/details/119654676 https://blog.csdn.net/dudadudadd/article/details/114102341 1 ç¼“å­˜æ‡’æ‰§è¡Œ ç©ºé—´æ¢æ—¶é—´ rdd3å¦‚æœä¸æ¶ˆå¤±ï¼Œé‚£ä¹ˆç»¿è‰²é“¾è·¯å°±ä¸ç”¨æ‰§è¡Œä¸¤æ¬¡ æŒä¹…åŒ–çš„ç›®æ ‡å°±æ˜¯å°†rdd3ä¿å­˜åˆ°å†…å­˜æˆ–è€…ç£ç›˜ ä½†æ˜¯æœ‰ä¸¢å¤±é£é™©ï¼Œæ¯”å¦‚ç¡¬ç›˜æŸåï¼Œå†…å­˜è¢«æ¸…ç†ç­‰ï¼Œæ‰€ä»¥ä¸ºäº†è§„é¿é£é™©ï¼Œä¼šä¿ç•™rddçš„è¡€ç¼˜ï¼ˆä¾èµ–ï¼‰å…³ç³» å¦‚ä½•ä¿å­˜ï¼š 1 persist 2 cachehttps://blog.csdn.net/donger__chen/article/details/86366339 åº•å±‚è°ƒç”¨persistï¼Œpersistçš„ç‰¹æ®Šæƒ…å†µï¼Œpersist(MEMORY_ONLY) 2 checkpointç‰¹æ®Šçš„æŒä¹…åŒ– ä»…æ”¯æŒç¡¬ç›˜ è®¾è®¡ä¸Šè®¤ä¸ºå®‰å…¨æ²¡æœ‰é£é™©ï¼Œæ‰€ä»¥ä¸éœ€è¦ä¿ç•™è¡€ç¼˜å…³ç³» å¦‚ä½•ä¿å­˜ï¼š 3 å¯¹æ¯”","link":"/2022/03/04/persist/"},{"title":"ç‰©ç†åˆ†åŒº","text":"https://www.cnblogs.com/wdh01/p/16038278.html é¦–å…ˆå’Œé€»è¾‘åˆ†åŒºåŒºåˆ«å¼€ï¼Œé€»è¾‘åˆ†åŒºåŒ…æ‹¬keyByç­‰ç®—å­ é€»è¾‘åˆ†åŒºåªä¸è¿‡å°†æ•°æ®æŒ‰ç…§keyåˆ†ç»„ï¼Œå“ªä¸ªkeyåˆ†åˆ°å“ªä¸ªtaskï¼Œç³»ç»Ÿè‡ªåŠ¨æ§åˆ¶ï¼Œä¸‡ä¸€åˆ†é…ä¸å‡ï¼Œä¼šå‘ç”Ÿæ•°æ®å€¾æ–œ ç‰©ç†åˆ†åŒºå°±æ˜¯æŒ‰ä¸€å®šé€»è¾‘å°†æ•°æ®åˆ†é…åˆ°ä¸åŒTaskï¼Œå¯ä»¥ç¼“è§£æ•°æ®å€¾æ–œ sourceï¼ˆ1ï¼‰-ã€‹ä¸åŒç‰©ç†åˆ†åŒºæ–¹å¼ï¼ˆ3ï¼‰-ã€‹slot åˆ†ç±» 1 éšæœºåˆ†åŒº random 2 è½®è¯¢åˆ†åŒºround-robin 3 é‡ç¼©æ”¾åˆ†åŒº rescale 4 åˆ†å±€åˆ†åŒº global 5 è‡ªå®šä¹‰ custom 6 å¹¿æ’­ ä¸å®Œå…¨ç®—ç‰©ç†åˆ†åŒºæ–¹å¼","link":"/2022/05/09/phisical-partition/"},{"title":"phoenix","text":"åœ¨hbaseä¸Šæ„å»ºSQLå±‚ï¼Œä½¿å¾—hbase èƒ½å¤Ÿä½¿ç”¨æ ‡å‡†SQLç®¡ç†æ•°æ®ï¼ŒPhoenixä¸­çš„sqlè¯­å¥è¿˜æ˜¯æœ‰äº›ä¸åŒçš„ å®‰è£…é…ç½®https://www.hangge.com/blog/cache/detail_2980.html å¯åŠ¨ä½¿ç”¨python2ï¼Œpython2 sqlline.py é—®é¢˜1 KeeperErrorCode = NoNode for /hbase æˆ–è€… Retrieve cluster id failed å‚è€ƒhttps://www.hangge.com/blog/cache/detail_2980.html","link":"/2022/05/22/phoenix/"},{"title":"pointwise vs pairwise","text":"pairwiseç®—æ³•èšç„¦äºç²¾ç¡®çš„é¢„æµ‹æ¯ä¸ªæ–‡æ¡£ä¹‹é—´çš„ç›¸å…³åº¦ï¼Œpairwiseç®—æ³•ä¸»è¦å…³å¿ƒä¸¤ä¸ªæ–‡æ¡£ä¹‹é—´çš„é¡ºåºï¼Œç›¸æ¯”pointwiseçš„ç®—æ³•æ›´åŠ æ¥è¿‘äºæ’åºçš„æ¦‚å¿µã€‚","link":"/2022/01/17/pointwise-pairwise/"},{"title":"pom","text":"POM( Project Object Modelï¼Œé¡¹ç›®å¯¹è±¡æ¨¡å‹ ) æ˜¯ Maven å·¥ç¨‹çš„åŸºæœ¬å·¥ä½œå•å…ƒï¼Œæ˜¯ä¸€ä¸ªXMLæ–‡ä»¶ï¼ŒåŒ…å«äº†é¡¹ç›®çš„åŸºæœ¬ä¿¡æ¯ï¼Œç”¨äºæè¿°é¡¹ç›®å¦‚ä½•æ„å»ºï¼Œå£°æ˜é¡¹ç›®ä¾èµ–ï¼Œç­‰ç­‰ã€‚ æ‰§è¡Œä»»åŠ¡æˆ–ç›®æ ‡æ—¶ï¼ŒMaven ä¼šåœ¨å½“å‰ç›®å½•ä¸­æŸ¥æ‰¾ POMã€‚å®ƒè¯»å– POMï¼Œè·å–æ‰€éœ€çš„é…ç½®ä¿¡æ¯ï¼Œç„¶åæ‰§è¡Œç›®æ ‡ã€‚","link":"/2022/03/14/pom/"},{"title":"pointwise","text":"https://zhuanlan.zhihu.com/p/113302654#","link":"/2021/12/20/pointwise/"},{"title":"postman","text":"ä½œç”¨åç«¯æœåŠ¡å¯åŠ¨åï¼Œéœ€è¦å‰ç«¯è¯·æ±‚æ‰ä¼šæœ‰åé¦ˆï¼ŒçœŸå®åœºæ™¯æ˜¯éœ€è¦å‰ç«¯ç‚¹å‡»è§¦å‘ï¼Œä¸ºäº†ç®€åŒ–ï¼Œåˆ©ç”¨postmanæ¨¡æ‹Ÿå‰ç«¯çš„è¯·æ±‚ çœŸå®å‰ç«¯/postman ã€Šâ€”ã€‹åç«¯ ä½¿ç”¨æœåŠ¡å™¨ 1 åç«¯å¯åº”ç”¨ postman 2 å¡«å†™åç«¯è¯·æ±‚åœ°å€ 3 å‘é€æ•°æ® body raw json {ã€‚ã€‚ã€‚ã€‚} é—®é¢˜1 setting è®¾ç½® ssl certificate verification ä¸ºoff","link":"/2022/06/08/postman/"},{"title":"é¢„è®­ç»ƒä»»åŠ¡","text":"åˆ†ç±» TLM : Translation Language Modeling DAE: Denoising Autoencoder CTL: Contrastive Learning RTDï¼š Replaced Token Detection SOPï¼šSentence Order Prediction DIMï¼šDeep InfoMAx å‚è€ƒhttps://arxiv.org/pdf/2003.08271v4.pdf https://zhuanlan.zhihu.com/p/360892229","link":"/2022/05/29/pretrain-task/"},{"title":"ç²—æ’","text":"","link":"/2022/07/15/pre-ranking/"},{"title":"pretrain","text":"https://huggingface.co/docs/transformers/task_summary Language Modeling https://huggingface.co/blog/how-to-train","link":"/2022/01/24/pretrain/"},{"title":"Prompt-learningå°å¸®æ‰‹-openprompt","text":"æ¸…åNLPå®éªŒå®¤æ¨å‡ºOpenPromptå¼€æºå·¥å…·åŒ… 1 ç»“æ„ 2 æ•™ç¨‹å¯ä»¥å‚è€ƒå®˜æ–¹https://hub.fastgit.xyz/thunlp/OpenPrompt æœ‰è¯¦ç»†çš„æ­¥éª¤å’Œcase å‚è€ƒhttps://hub.fastgit.xyz/thunlp/OpenPrompt https://zhuanlan.zhihu.com/p/420335724 https://github.com/thunlp/OpenPrompt","link":"/2022/01/17/prompt-assitaant/"},{"title":"å…ˆéªŒæ¦‚ç‡ä¸åéªŒæ¦‚ç‡","text":"$P(X=ç© lol)=0.6ï¼›P(X=ä¸ç©lol)=0.4$ï¼Œè¿™ä¸ªæ¦‚ç‡æ˜¯ç»Ÿè®¡å¾—åˆ°çš„,æˆ–è€…ä½ è‡ªèº«ä¾æ®ç»éªŒç»™å‡ºçš„ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºå…ˆéªŒæ¦‚ç‡(prior probability)ï¼› $P(X=ç©lol|Y=ç”·æ€§)$ç§°ä¹‹ä¸º$X$çš„åéªŒæ¦‚ç‡ï¼Œå³å®ƒè·å¾—æ˜¯åœ¨è§‚å¯Ÿåˆ°äº‹ä»¶$Y=ç”·æ€§$å‘ç”Ÿåå¾—åˆ°çš„ å‚è€ƒhttps://zhuanlan.zhihu.com/p/26464206","link":"/2021/08/29/prior-Posterior/"},{"title":"prompt trick","text":"ç›®çš„é€šè¿‡æ¨¡æ¿ä½¿å¾—é¢„æµ‹ä»»åŠ¡ä¸é¢„è®­ç»ƒæ¨¡å‹çš„è®­ç»ƒä»»åŠ¡ç›¸ç»Ÿä¸€ï¼Œæ‹‰è¿‘é¢„è®­ç»ƒä»»åŠ¡ç›®æ ‡ä¸ä¸‹æ¸¸å¾®è°ƒç›®æ ‡çš„å·®è· å’Œfinetuneå·®å¼‚finetuneï¼šPTMå‘ä¸‹å…¼å®¹specific task promptï¼šspecific taskå‘ä¸Šå…¼å®¹PTM åº”ç”¨åœºæ™¯ç”±äºå…¶å½“å‰é¢„æµ‹ä»»åŠ¡ä¸é¢„è®­ç»ƒæ¨¡å‹çš„è®­ç»ƒä»»åŠ¡ç›¸ç»Ÿä¸€ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒæ•°æ®è¾ƒå°‘ï¼Œç”šè‡³æ²¡æœ‰çš„æƒ…å†µä¸‹å»å®Œæˆå½“å‰ä»»åŠ¡ï¼Œæ€»ç»“ä¸€ä¸‹ï¼Œå…¶æ¯”è¾ƒé€‚åˆçš„åº”ç”¨åœºæ™¯ï¼š zero-shot few-shot å†·å¯åŠ¨ å‚è€ƒhttps://zhuanlan.zhihu.com/p/424888379 https://zhuanlan.zhihu.com/p/440169921","link":"/2022/06/27/prompt-trick/"},{"title":"ptmä¹‹é—´çš„è”ç³»","text":"","link":"/2022/03/28/ptm-relation/"},{"title":"pysparkä¾èµ–","text":"PYSPARK_PYTHON= PYSPARK_DRIVER_PYTHON= JAVA_HOME = /usr/local/jdk1.8.0_11 HADOOP_CONF_DIR=/cloud/dahua/spark-2.4.4-binhadoop2.7/conf SPARK_HOME=/usr/local/spark-2.4.4-bin-hadoop2.7 SCALA_HOME=/usr/local/scala-2.11.8","link":"/2022/03/07/pyspark-dependency/"},{"title":"Pre-trained Models for Natural Language Processing A Survey","text":"åŸæ–‡å†…å®¹å¾ˆä¸°å¯Œï¼Œæ…¢æ…¢å­¦ä¹ æ›´æ–°ã€‚ æ‘˜è¦è¿™ç¯‡ç»¼è¿°ä»language representation learningå…¥æ‰‹ï¼Œç„¶åå…¨é¢çš„é˜è¿°Pre-trained Modelsçš„åŸç†ï¼Œç»“æ„ä»¥åŠdownstreamä»»åŠ¡ï¼Œæœ€åè¿˜ç½—åˆ—äº†PTMçš„æœªæ¥å‘å±•æ–¹å‘ã€‚è¯¥ç»¼è¿°ç›®çš„æ—¨åœ¨ä¸ºNLPå°ç™½ï¼ŒPTMå°ç™½åšå¼•è·¯äººï¼Œæ„Ÿäººã€‚ 1.Introductionéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼Œè®¸å¤šæ·±åº¦å­¦ä¹ æŠ€æœ¯è¢«åº”ç”¨åœ¨NLPï¼Œæ¯”å¦‚CNNï¼ŒRNNï¼ŒGNNä»¥åŠattentionã€‚ å°½ç®¡NLPä»»åŠ¡çš„å–å¾—å¾ˆå¤§æˆåŠŸï¼Œä½†æ˜¯å’ŒCVæ¯”è¾ƒï¼Œæ€§èƒ½æé«˜å¯èƒ½ä¸æ˜¯éå¸¸æ˜æ˜¾ã€‚è¿™ä¸»è¦æ˜¯å› ä¸ºNLPä»»åŠ¡çš„æ•°æ®é›†éƒ½éå¸¸å°ï¼ˆé™¤äº†æœºå™¨ç¿»è¯‘ï¼‰ï¼Œç„¶è€Œæ·±åº¦ç½‘ç»œå‚æ•°éå¸¸å¤šï¼Œæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ”¯æ’‘ç½‘ç»œè®­ç»ƒä¼šå¯¼è‡´è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ æœ€è¿‘ï¼Œå¤§é‡å·¥ä½œè¡¨æ˜ï¼Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼ˆPTMsï¼‰ï¼Œåœ¨å¤§å‹è¯­æ–™åº“ä¸Šå¯ä»¥å­¦ä¹ é€šç”¨è¯­è¨€è¡¨ç¤ºï¼Œè¿™æœ‰åˆ©äºä¸‹æ¸¸NLPä»»åŠ¡å¯ä»¥é¿å…ä»é›¶å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹ã€‚éšç€ç®—åŠ›çš„å‘å±•ï¼Œæ·±åº¦æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œtransformerï¼‰çš„å‡ºç°å’Œè®­ç»ƒæŠ€å·§çš„ä¸æ–­è°ƒé«˜ï¼ŒPTMçš„ç»“æ„ä»æµ…å±‚å‘å±•æˆæ·±å±‚ã€‚ç¬¬ä¸€ä»£PTMè¢«ç”¨äºNon-contextual word Embeddingã€‚ç”±äºä¸‹æ¸¸ä»»åŠ¡ä¸éœ€è¦è¿™äº›æ¨¡å‹æœ¬èº«ï¼Œåªéœ€è¦è®­ç»ƒå¥½çš„è¯å‘é‡çŸ©é˜µï¼Œå› æ­¤å¯¹äºç°åœ¨çš„ç®—åŠ›ï¼Œè¿™äº›æ¨¡å‹éå¸¸æµ…å±‚ï¼Œæ¯”å¦‚Skip-Gramå’ŒGloVeã€‚è™½ç„¶è¿™äº›é¢„è®­ç»ƒè¯å‘é‡å¯ä»¥æ•è·è¯è¯­çš„è¯­ä¹‰ï¼Œä½†å®ƒä»¬ä¸å—ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œæ— æ³•æ•è·ä¸Šä¸‹æ–‡ä¸­çš„é«˜çº§å«ä¹‰ï¼ŒæŸäº›ä»»åŠ¡ä¼šå¤±æ•ˆï¼Œä¾‹å¦‚å¤šä¹‰è¯ï¼Œå¥æ³•ç»“æ„ï¼Œè¯­ä¹‰è§’è‰²ã€å›æŒ‡ã€‚ç¬¬äºŒä»£PTMå…³æ³¨Contextual word embeddingsï¼Œæ¯”å¦‚BERTï¼ŒGPTç­‰ã€‚è¿™äº›ç¼–ç å™¨ä»»ç„¶éœ€è¦é€šè¿‡ä¸‹æ¸¸ä»»åŠ¡åœ¨ä¸Šä¸‹æ–‡ä¸­è¡¨ç¤ºè¯è¯­ã€‚ 2.Background2.1 Language Representation LearningThe core idea of distributed representation is to describe the meaning of a piece of text by low-dimensional real-valued vectors. And each dimension of the vector has no corresponding sense, while the whole represents a concrete concept. Non-contextual Embeddings è¿™ä¸€æ­¥ä¸»è¦æ˜¯å°†åˆ†å‰²çš„å­—ç¬¦ï¼Œæ¯”å¦‚å›¾ä¸­çš„$x$ï¼Œå˜æˆå‘é‡è¡¨è¾¾$e_x \\in \\mathbb{R}^{D_e}$ï¼Œ$D_e$æ˜¯è¯å‘é‡ç»´åº¦ã€‚å‘é‡åŒ–è¿‡ç¨‹å°±æ˜¯åŸºäºä¸€ä¸ªç¦»çº¿è®­ç»ƒçš„è¯å‘é‡çŸ©é˜µ$E\\in \\mathbb{R}^{D_e\\times |\\mathcal{V}|} $åšæŸ¥æ‰¾ï¼Œ$\\mathcal{V}$æ˜¯è¯æ±‡è¡¨ã€‚ è¿™ä¸ªè¿‡ç¨‹ä¸»è¦æœ‰ä¸¤ä¸ªé—®é¢˜ã€‚ç¬¬ä¸€ä¸ªæ˜¯è¿™ä¸ªè¯å‘é‡æ˜¯é™æ€çš„ï¼Œæ²¡æœ‰è€ƒè™‘ä¸Šä¸‹æ–‡å«ä¹‰ï¼Œæ— æ³•å¤„ç†å¤šä¹‰è¯ã€‚ç¬¬äºŒä¸ªæ˜¯oové—®é¢˜ï¼Œè®¸å¤šç®—æ³•å¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæ¯”å¦‚åŸºäºcharacter levelï¼Œæ¯”å¦‚åŸºäºsubwordï¼Œsubwordç®—æ³•æœ‰BPEï¼ŒCharCNNç­‰ã€‚ Contextual Embeddings To address the issue of polysemous and the context-dependent nature of words, we need distinguish the semantics of words in different contextsï¼š [\\textbf{h}_1,\\textbf{h}_2,...,\\textbf{h}_T]=f_{enc}(x_1,x_2,...,x_T)å…¶ä¸­$f_{enc}(\\cdot)$ä¸ºæ·±åº¦ç¼–ç å™¨ã€‚$\\textbf{h}_t$å°±æ˜¯contextual embeddingæˆ–è€…dynamical embeddingã€‚ 2.2 Neural Contextual Encoders å¯ä»¥åˆ†æˆä¸¤ç±»ï¼Œsequence models and non-sequence modelsã€‚ 2.2.1 sequence modelssequence models åˆ†ä¸ºä¸¤ç±»ï¼ŒConvolutional Modelså’ŒRecurrent Modelsï¼Œè§ä¸Šå›¾ã€‚ Convolutional Convolutional models take the embeddings of words in the input sentence and capture the meaning of a word by aggregating the local information from its neighbors by convolution operations Recurrent Recurrent models capture the contextual representations of words with short memory, such as LSTMs and GRUs . In practice, bi-directional LSTMs or GRUs are used to collect information from both sides of a word, but its performance is often affected by the long-term dependency problem. 2.2.2 non-sequence modelstransformerï¼š model the relation of every two words 2.2.3 AnalysisSequence modelsï¼š 1.Sequence models learn the contextual representation of the word with locality bias and are hard to capture the long-range interactions between words. 2.Nevertheless, sequence models are usually easy to train and get good results for various NLP tasks. fully-connected self-attention modelï¼š 1.can directly model the dependency between every two words in a sequence, which is more powerful and suitable to model long range dependency of language 2.However, due to its heavy structure and less model bias, the Transformer usually requires a large training corpus and is easy to overfit on small or modestly-sized datasets ç»“è®ºï¼šthe Transformer has become the mainstream architecture of PTMs due to its powerful capacity. 2.3 Why Pre-training? Pre-training on the huge text corpus can learn universal language representations and help with the downstream tasks. Pre-training provides a better model initialization,which usually leads to a better generalization performance and speeds up convergence on the target task. Pre-training can be regarded as a kind of regularization to avoid overfitting on small data 3 Overview of PTMs3.1 Pre-training Tasksé¢„è®­ç»ƒä»»åŠ¡å¯¹äºå­¦ä¹ é€šç”¨è¯­è¨€è¡¨ç¤ºè‡³å…³é‡è¦ã€‚é€šå¸¸ï¼Œè¿™äº›é¢„è®­ç»ƒä»»åŠ¡åº”å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶æ‹¥æœ‰å¤§é‡è®­ç»ƒæ•°æ®ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒä»»åŠ¡åˆ†æˆä¸‰ä¸ªç±»åˆ«ï¼šSupervised learningã€Unsupervised learningå’ŒSelf-Supervised learningã€‚ Self-Supervised learningï¼š is a blend of supervised learning and unsupervised learning. The learning paradigm of SSL is entirely the same as supervised learning, but the labels of training data are generated automatically. The key idea of SSL is to predict any part of the input from other parts in some form. For example, the masked language model (MLM) is a self-supervised task that attempts to predict the masked words in a sentence given the rest words. æ¥ä¸‹æ¥åŸºäºä»‹ç»å¸¸ç”¨çš„åŸºäºSelf-Supervised learningçš„é¢„è®­ç»ƒä»»åŠ¡ã€‚ 3.1.1 Language Modeling (LM)3.1.2 Masked Language Modeling (MLM)3.1.3 Permuted Language Modeling (PLM)3.1.4 Denoising Autoencoder (DAE)3.1.5 Contrastive Learning (CTL)nspä¹Ÿå±äºCTL https://zhuanlan.zhihu.com/p/360892229 3.1.6 Others3.2 Taxonomy of PTMs ä½œè€…ä»ä»¥ä¸‹å››ä¸ªè§’åº¦ï¼Œå³Representation Typeï¼ŒArchitecturesï¼ŒPre-Training Task Typesï¼ŒExtensionsï¼Œå¯¹ç°æœ‰çš„PTMåˆ†ç±»ï¼Œåˆ†ç±»ç»“æœå¦‚ä¸Šã€‚å›¾å’Œè¿™é‡Œæœ‰ä¸€ç‚¹ä¸ç»Ÿä¸€ï¼Œæ˜¯ä½œè€…æ²¡æ³¨æ„ï¼Ÿå›¾é‡Œæœ‰5ä¸ªç±»åˆ«ï¼Œå¤šäº†Tuning Strategiesï¼Œè€Œä¸”Representation Typeåœ¨å›¾ä¸­ä¸ºContextual?ã€‚ 3.3 Model Analysis4 Extensions of PTMs4.1 Knowledge-Enriched PTMs4.2 Multilingual and Language-Specific PTMs4.3 Multi-Modal PTMs4.4 Domain-Specific and Task-Specific PTMs4.5 Model Compression5 Adapting PTMs to Downstream Tasksè™½ç„¶PTMå­¦ä¹ äº†å¾ˆå¤šé€šç”¨çŸ¥è¯†ï¼Œä½†æ˜¯å¦‚ä½•å°†è¿™äº›çŸ¥è¯†æœ‰æ•ˆåº”ç”¨åˆ°ä¸‹æ¸¸ä»»åŠ¡æ˜¯ä¸ªæŒ‘æˆ˜ã€‚ 5.1 Transfer LearningTransfer learning is to adapt the knowledge from a source task (or domain) to a target task (or domain).å¦‚ä¸‹å›¾ã€‚ 5.2 How to Transfer?5.2.1 Choosing appropriate pre-training task, model architecture and corpus5.2.2 Choosing appropriate layersä½¿ç”¨å“ªäº›å±‚å‚ä¸ä¸‹æ¸¸ä»»åŠ¡ é€‰æ‹©çš„å±‚model1+ä¸‹æ¸¸ä»»åŠ¡model2 å¯¹äºæ·±åº¦æ¨¡å‹çš„ä¸åŒå±‚ï¼Œæ•è·çš„çŸ¥è¯†æ˜¯ä¸åŒçš„ï¼Œæ¯”å¦‚è¯´è¯æ€§æ ‡æ³¨ï¼Œå¥æ³•åˆ†æï¼Œé•¿æœŸä¾èµ–ï¼Œè¯­ä¹‰è§’è‰²ï¼ŒååŒå¼•ç”¨ã€‚å¯¹äºRNN basedçš„æ¨¡å‹ï¼Œç ”ç©¶è¡¨æ˜å¤šå±‚çš„LSTMç¼–ç å™¨çš„ä¸åŒå±‚å¯¹äºä¸åŒä»»åŠ¡çš„è¡¨ç°ä¸ä¸€æ ·ã€‚å¯¹äºtransformer based çš„æ¨¡å‹ï¼ŒåŸºæœ¬çš„å¥æ³•ç†è§£åœ¨ç½‘ç»œçš„æµ…å±‚å‡ºç°ï¼Œç„¶è€Œé«˜çº§çš„è¯­ä¹‰ç†è§£åœ¨æ·±å±‚å‡ºç°ã€‚ ç”¨$\\textbf{H}^{l}(1&lt;=l&lt;=L)$è¡¨ç¤ºPTMçš„ç¬¬$l$å±‚çš„representationï¼Œ$g(\\cdot)$ä¸ºç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ã€‚æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•é€‰æ‹©representation: a) Embedding Only choose only the pre-trained static embeddingsï¼Œå³$g(\\textbf{H}^{1})$ b) Top Layer é€‰æ‹©é¡¶å±‚çš„representationï¼Œç„¶åæ¥å…¥ç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ï¼Œå³$g(\\textbf{H}^{L})$ c) All Layers è¾“å…¥å…¨éƒ¨å±‚çš„representationï¼Œè®©æ¨¡å‹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„å±‚æ¬¡ï¼Œç„¶åæ¥å…¥ç‰¹å®šçš„ä»»åŠ¡æ¨¡å‹ï¼Œæ¯”å¦‚ELMoï¼Œå¼å­å¦‚ä¸‹ g(\\textbf{r}_t)=g(\\gamma \\sum_{l=1}^{L}\\alpha_l\\textbf{H}^{(l)})å…¶ä¸­$\\alpha$ is the softmax-normalized weight for layer $l$ and $\\gamma$ is a scalar to scale the vectors output by pre-trained model 5.2.3 To tune or not to tune?æ€»å…±æœ‰ä¸¤ç§å¸¸ç”¨çš„æ¨¡å‹è¿ç§»æ–¹å¼ï¼šfeature extraction (where the pre-trained parameters are frozen), and fine-tuning (where the pre-trained parameters are unfrozen and fine-tuned). é€‰æ‹©çš„å±‚model1å‚æ•°æ˜¯å¦å›ºå®šï¼Œmodel2ä¸€å®šè¦è®­ç»ƒ bert åªæœ‰top layer finetuneï¼Ÿï¼Ÿï¼Ÿï¼Ÿ 5.3 Fine-Tuning StrategiesTwo-stage fine-tuning ç¬¬ä¸€é˜¶æ®µä¸ºä¸­é—´ä»»åŠ¡ï¼Œç¬¬äºŒé˜¶æ®µä¸ºç›®æ ‡ä»»åŠ¡ Multi-task fine-tuning multi-task learning and pre-training are complementary technologies. Fine-tuning with extra adaptation modules The main drawback of fine-tuning is its parameter ineffciency: every downstream task has its own fine-tuned parameters. Therefore, a better solution is to inject some fine-tunable adaptation modules into PTMs while the original parameters are fixed. Others self-ensemble ï¼Œself-distillationï¼Œgradual unfreezingï¼Œsequential unfreezing å‚è€ƒhttps://arxiv.org/pdf/2003.08271v4.pdf","link":"/2021/08/10/ptm-survey/"},{"title":"pyspark","text":"PySparkå®—æ—¨æ˜¯åœ¨ä¸ç ´åSparkå·²æœ‰çš„è¿è¡Œæ—¶æ¶æ„ï¼Œåœ¨Sparkæ¶æ„å¤–å±‚åŒ…è£…ä¸€å±‚Python APIï¼Œå€ŸåŠ©Py4jå®ç°Pythonå’ŒJavaçš„äº¤äº’ï¼Œè¿›è€Œå®ç°é€šè¿‡Pythonç¼–å†™Sparkåº”ç”¨ç¨‹åºï¼Œå…¶è¿è¡Œæ—¶æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚","link":"/2022/03/02/pyspark/"},{"title":"python bif(å†…ç½®å‡½æ•°)","text":"1 ordï¼ˆï¼‰ å¦‚ä½•è·å–asciiç ï¼Œä½¿ç”¨å†…ç½®å‡½æ•°ordï¼ˆï¼‰ 1234ord(&quot;A&quot;)65ord(&quot;a&quot;)97 804. å”¯ä¸€æ‘©å°”æ–¯å¯†ç è¯2 sorted() https://www.runoob.com/python3/python3-func-sorted.html 1234sorted([-3,4,2],key=abs)Out[5]: [2, -3, 4]sorted([-3,4,2])Out[6]: [-3, 2, 4]","link":"/2022/04/10/python-bif/"},{"title":"è¿ç®—","text":"1. é€»è¾‘è¿ç®— operation result x or y if x is falseï¼Œthen y ,else x x and y if x is falseï¼Œthen x ,else y not x if x is falseï¼Œthen True , else False","link":"/2022/09/12/python-cal-symbol/"},{"title":"pythonä¸å¯å˜å¯¹è±¡å’Œå¯å˜å¯¹è±¡","text":"https://zhuanlan.zhihu.com/p/34395671 å¯å˜å¯¹è±¡ï¼šlist dict set ä¸å¯å˜å¯¹è±¡ï¼štuple string int float bool","link":"/2022/09/12/python-changed_obj/"},{"title":"collections","text":"1 Counter 1234from collections import CounterCounter([-3,4,2,2])Out[8]: Counter({-3: 1, 4: 1, 2: 2})","link":"/2022/04/01/python-counter/"},{"title":"pythonç¯å¢ƒ","text":"1.ç¯å¢ƒç®¡ç†å·¥å…·pythonç‰ˆæœ¬ä¸»è¦ä¸º2,3ä¸¤ä¸ªå¤§ç‰ˆæœ¬ anacondaç®¡ç†pythonå’ŒåŒ…çš„ç‰ˆæœ¬ 2.åŒ…2.1 ä¸‹è½½åŒ…ä¸‹è½½æºæœ‰å®˜æ–¹æºï¼Œé˜¿é‡Œæºï¼Œè±†ç“£æºï¼Œæ¸…åæºç­‰ 1 ç¦»çº¿ä¸‹è½½2 åœ¨çº¿ä¸‹è½½ä¸‹è½½å·¥å…·æœ‰pipï¼Œconda æ›´æ¢pipæº ä¿®æ”¹æ–‡ä»¶ 1vim ~/.pip/pip.conf # æ²¡æœ‰å°±åˆ›å»ºä¸€ä¸ªï¼Œåœ¨ ~/.pip/ä¸‹ å¢åŠ å†…å®¹ 12345[global]index-url=https://pypi.tuna.tsinghua.edu.cn/simple# index-url=http://pypi.douban.com/simple/[install]trusted-host=pypi.tuna.tsinghua.edu.cn æŸ¥çœ‹è·¯å¾„ which python, which pip ,which conda ï¼ˆ~ç”¨æˆ·ä¸»ç›®å½•ï¼Œ /æ ¹ç›®å½•ï¼‰ 2.2 ä½¿ç”¨åŒ…import ç»å¯¹è·¯å¾„ï¼šä»å·¥ç¨‹çš„æœ€å¤–å±‚å¼€å§‹ ç›¸å¯¹è·¯å¾„ï¼šåˆ©ç”¨.ï¼ˆåŒçº§ï¼‰å’Œ..ï¼ˆä¸Šçº§ï¼‰ æ€ä¹ˆæ·»åŠ åŒ…çš„æœè·¯å¾„ https://blog.csdn.net/weixin_40449300/article/details/79327201 3 ubuntuä¿®æ”¹pythonç¯å¢ƒå˜é‡1.vim ~/.bashrc 2.æ·»åŠ å¦‚ä¸‹å†…å®¹ export PYTHON_HOME=/usr/local/anaconda3/bin export PATH=$PYTHON_HOME/bin:$PATH export PATH=/home/user_name/anaconda3/bin:$PATH # æŒ‡å®špythonè·¯å¾„ 4.ubuntuä¿®æ”¹pytoné»˜è®¤ç‰ˆæœ¬https://blog.csdn.net/White_Idiot/article/details/78240298","link":"/2021/09/10/python-env/"},{"title":"å¯è¿­ä»£å¯¹è±¡ã€è¿­ä»£å™¨ä¸ç”Ÿæˆå™¨","text":"å¯è¿­ä»£å¯¹è±¡å¯¹è±¡+ iter () 123class IsIterable: def __iter__(self): pass è¿­ä»£å™¨å¯¹è±¡+ iter ()+next() 12345678910111213141516171819202122232425262728&gt;&gt;&gt; class MyIterator: &quot;&quot;&quot; è¿­ä»£å™¨ç±» Authorï¼šå¯ä¹pythonè¯´ &quot;&quot;&quot; def __init__(self): self.num = 0 def __iter__(self): return self def __next__(self): return_num = self.num # åªè¦å€¼å¤§äºç­‰äº6ï¼Œå°±åœæ­¢è¿­ä»£ if return_num &gt;= 6: raise StopIteration self.num += 2 return return_num&gt;&gt;&gt; my_iterator = MyIterator()&gt;&gt;&gt; next(my_iterator)0&gt;&gt;&gt; next(my_iterator)2&gt;&gt;&gt; next(my_iterator)4&gt;&gt;&gt; next(my_iterator)Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;StopIteration ç”Ÿæˆå™¨ç”Ÿæˆå™¨å‡½æ•°å®šä¹‰ä¸å¸¸è§„å‡½æ•°ç›¸åŒï¼ŒåŒºåˆ«åœ¨äºï¼Œå®ƒä½¿ç”¨ yield è¯­å¥ è€Œä¸æ˜¯ return è¯­å¥ 12345678910111213141516171819202122&gt;&gt;&gt; def my_generator(): my_num = 0 while my_num &lt; 5: yield my_num my_num += 1&gt;&gt;&gt;generator_ = my_generator()&gt;&gt;&gt; next(generator_)0&gt;&gt;&gt; next(generator_)1&gt;&gt;&gt; next(generator_)2&gt;&gt;&gt; next(generator_)3&gt;&gt;&gt; next(generator_)4&gt;&gt;&gt; next(generator_)# ç»ˆæ­¢è¿­ä»£åˆ™ä¼šæŠ›å‡º StopIteration å¼‚å¸¸Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;StopIteration ç”Ÿæˆå™¨è¡¨è¾¾å¼ä½¿ç”¨å°æ‹¬å· - () åŒ…è£¹ï¼Œè€Œä¸æ˜¯ä¸­æ‹¬å· 1234567891011import sysmy_list = [i for i in range(1000000)]print(&quot;åˆ—è¡¨æ¶ˆè€—çš„å†…å­˜ï¼š{}&quot;.format(sys.getsizeof(my_list)))my_generator = (i for i in range(1000000))print(&quot;ç”Ÿæˆå™¨æ¶ˆè€—çš„å†…å­˜ï¼š{}&quot;.format(sys.getsizeof(my_generator)))åˆ—è¡¨æ¶ˆè€—çš„å†…å­˜ï¼š8448728ç”Ÿæˆå™¨æ¶ˆè€—çš„å†…å­˜ï¼š112 å‚è€ƒhttps://www.runoob.com/python3/python3-iterator-generator.html https://kelepython.readthedocs.io/zh/latest/c01/c01_11.html","link":"/2022/09/12/python-iterator/"},{"title":"å‡½æ•°å‚æ•°","text":"1 é»˜è®¤å‚æ•°https://blog.csdn.net/weixin_41972881/article/details/81562731 https://blog.csdn.net/weixin_45775963/article/details/103696945 123456def fun(va1,va2=[]): print(va2) va2.append(va1) return va2te1=fun(10)te1=fun(20) va2å¦‚æœæ²¡æœ‰ä¼ å‚ï¼Œé‡‡ç”¨é»˜è®¤çš„ï¼Œé»˜è®¤çš„ä¼šå˜åŒ–ï¼Œä¸æ˜¯ä¸€ç›´æ˜¯[] va2å¦‚æœæ˜¯å¤–éƒ¨çš„ä¼ å‚ï¼Œä»¥ä¼ å‚ä¸ºä¸»ï¼Œä¼šè¦†ç›–","link":"/2021/12/15/python-paramerter/"},{"title":"æ­£åˆ™","text":"1 re.match1matchObj/None = re.match(pattern, string, flags=0) 2 re.search1matchObj/None = re.search(pattern, string, flags=0)","link":"/2022/09/12/python-pattern/"},{"title":"pythonåœ¨Ubuntuç³»ç»Ÿä¸‹çš„è°ƒè¯•å·¥å…·pdb","text":"https://blog.csdn.net/lemonaha/article/details/71305344 ä¸¤ç§æ–¹å¼ï¼š 1.ä¾µå…¥å¼ ä¸æ”¹ä»£ç  python -m pdb XX.py 2.éå€¾å…¥å¼ åŠ ä»£ç  import pdb pdb.set_trace()","link":"/2022/03/18/python-pdb/"},{"title":"ç¼–ç¨‹è§„èŒƒ","text":"1 å‘½åè§„èŒƒ1.å°å†™+_lower_with_fun åŒ…ï¼Œæ¨¡å—ï¼Œå‡½æ•°ï¼Œæ–¹æ³•ï¼Œå‡½æ•°å‚æ•°ï¼Œå˜é‡ 2.é¦–å­—æ¯å¤§å†™CapWords å¼‚å¸¸å¤„ç† 3.å…¨å¤§å†™+_CAPS_WITH_UNDER å¸¸é‡ 4._å¼€å¤´ç±»ç§æœ‰æˆå‘˜ï¼Œå¤–éƒ¨ä»å¯è®¿é—® a._ _fun b.__ __fun ä¼šè¢«ç¼–è¯‘å™¨è‡ªåŠ¨æ”¹åï¼Œä½¿ç”¨æ–°åå­—å¤–éƒ¨ä¹Ÿå¯ä»¥è®¿é—® 2.æ¯”è¾ƒNoneis is not boolä¸è¦==ï¼Œis ç›´æ¥ if XX 3.å­—å…¸å–å€¼ç”¨a.get(key)ï¼Œè€Œä¸æ˜¯a[key] 4.ç±»å‹åˆ¤æ–­ç”¨isinstance(variable,type) ä¸ç”¨typeï¼ˆvariableï¼‰","link":"/2022/09/12/python-program-std/"},{"title":"ide","text":"pycharm1 pycharmè¿æ¥è¿œç¨‹ï¼Œæœ¬åœ°æ— æ³•æŸ¥çœ‹æºç ï¼Œä½†æ˜¯å¯ä»¥æ­£å¸¸è¿è¡Œ1 åŸå›  ç”±äºè¿œç¨‹çš„åŒ…æ²¡æœ‰åŒæ­¥åˆ°æœ¬åœ°ï¼Œå¯¼è‡´æ— æ³•åœ¨æœ¬åœ°æŸ¥çœ‹ï¼Œä½†æ˜¯ä»£ç è¿è¡Œåœ¨è¿œç¨‹ï¼ŒæœåŠ¡å™¨ä¸Šæœ‰åŒ…ï¼Œæ‰€ä»¥å¯ä»¥è¿è¡Œ 2.è§£å†³ å°†åŒ…ä»è¿œç¨‹åŒæ­¥åˆ°æœ¬åœ°ï¼Œä¸€èˆ¬æƒ…å†µé‡å¯pycharmä¼šè‡ªåŠ¨åŒæ­¥ï¼Œæˆ–è€…é‡æ–°å®‰è£…","link":"/2021/07/25/python_ide/"},{"title":"å­—ç¬¦ä¸²","text":"1 æ ¼å¼åŒ–https://blog.csdn.net/zjbyough/article/details/96466658 f-stringhttps://blog.csdn.net/sunxb10/article/details/81036693 %format","link":"/2022/09/12/python-string/"},{"title":"é­”æ³•æ–¹æ³•","text":"getitemhttps://zhuanlan.zhihu.com/p/27661382 all","link":"/2022/01/13/python_magic/"},{"title":"ç»§æ‰¿","text":"1 superå­ç±»æŠŠçˆ¶ç±»çš„ __init__()æ”¾åˆ°è‡ªå·±çš„ __init__() å½“ä¸­ , è¿™æ ·å­ç±»å°±æœ‰äº†çˆ¶ç±»çš„ __init__() çš„é‚£äº›ä¸œè¥¿ 12345678910111213141516171819202122232425262728293031323334class test1: def __init__(self): self.a=1class test2(test1): def __init__(self): super(test2, self).__init__() self.b=2tt=test2()# print(tt.a)print(tt.b)print(tt.a)21############################class test1: def __init__(self): self.a=1class test2(test1): def __init__(self): # super(test2, self).__init__() self.b=2tt=test2()# print(tt.a)print(tt.b)print(tt.a)2AttributeError: 'test2' object has no attribute 'a' 12345class pointwise_hybird_contrasive(hybird): def __init__(self,config_roberta, path,num): super(pointwise_hybird_contrasive, self).__init__(config_roberta, path,num)super(pointwise_hybird_contrasive, self).\\__init\\__(config_roberta, path,num)å°±æ˜¯å¯¹çˆ¶ç±»hybirdçš„å±æ€§è¿›è¡Œåˆå§‹åŒ– å‚è€ƒhttps://blog.csdn.net/zyh19980527/article/details/107206483","link":"/2021/12/09/python_succed/"},{"title":"pytorchå¸¸è§é—®é¢˜","text":"1 Gather function not implemented for CPU tensorså¤šå¡è®­ç»ƒæ—¶å€™ï¼Œnetçš„forwardé‡Œé¢å­˜åœ¨Tensorå˜æˆå…¶å®ƒç±»å‹çš„æ“ä½œï¼Œæ¯”å¦‚å˜æˆnumpyï¼Œlist è§£å†³ï¼šæ”¹æˆTensoræ“ä½œ 2 RuntimeError: element 0 of tensors does not require grad and does not have a grad_fnhttps://blog.csdn.net/weixin_41990278/article/details/90311313 https://blog.csdn.net/wu_xin1/article/details/116502378","link":"/2022/04/12/pytorch-problem/"},{"title":"queryç†è§£","text":"https://zhuanlan.zhihu.com/p/112719984 https://zhuanlan.zhihu.com/p/383733052 https://zhuanlan.zhihu.com/p/344631739","link":"/2021/10/08/query-understanding/"},{"title":"Ranger","text":"æ¶æ„ Ranagerçš„æ ¸å¿ƒæ˜¯Webåº”ç”¨ç¨‹åºï¼Œä¹Ÿç§°ä¸ºRangerAdminæ¨¡å—ï¼Œæ­¤æ¨¡å—ç”±ç®¡ç†ç­–ç•¥ï¼Œå®¡è®¡æ—¥å¿—å’ŒæŠ¥å‘Šç­‰ä¸‰éƒ¨åˆ†ç»„æˆã€‚ ç®¡ç†å‘˜è§’è‰²çš„ç”¨æˆ·å¯ä»¥é€šè¿‡RangerAdminæä¾›çš„webç•Œé¢æˆ–REST APISæ¥å®šåˆ¶å®‰å…¨ç­–ç•¥ã€‚è¿™äº›ç­–ç•¥ä¼šç”±Rangeræä¾›çš„è½»é‡çº§çš„é’ˆå¯¹ä¸åŒHadoopä½“ç³»ä¸­ç»„ä»¶çš„æ’ä»¶æ¥æ‰§è¡Œã€‚æ’ä»¶ä¼šåœ¨Hadoopçš„ä¸åŒç»„ä»¶çš„æ ¸å¿ƒè¿›ç¨‹å¯åŠ¨åï¼Œå¯åŠ¨å¯¹åº”çš„æ’ä»¶è¿›ç¨‹æ¥è¿›è¡Œå®‰å…¨ç®¡ç†ï¼ Rangerå¯¹Hiveè¿›è¡Œæƒé™ç®¡ç†https://www.jianshu.com/p/d9941b8687b7","link":"/2022/02/07/ranger/"},{"title":"A Deep Look into Neural Ranking Models for Information Retrieval","text":"https://par.nsf.gov/servlets/purl/10277191 3 A Unified Model Formulation So a generalized LTR problem is to find the optimal ranking function f âˆ— by minimizing the loss function over some labeled dataset f æ˜¯ranking functionï¼Œsæ˜¯queryï¼Œtæ˜¯å€™é€‰é›†ï¼Œy is the label set where labels represent grades Without loss of generality, the ranking function f could be further abstracted by the following unified formulation Ïˆ, Ï•are representation functions which extract features from s and t respectively Î· is the interaction function which extracts features from (s, t) pair, and g is the evaluation function which computes the relevance score based on the feature representations. 4. Model Architecture4.1. Symmetric vs. Asymmetric ArchitecturesSymmetric Architecture: The inputs s and t are assumed to be homogeneous, so that symmetric network structure could be applied over the inputs Asymmetric Architecture: The inputs s and t are assumed to be heterogeneous, so that asymmetric network structures should be applied over the inputs 4.2. Representation-focused vs. Interaction-focused Architectures Representation-focused Architecture: The underlying assumption of this type of architecture is that relevance depends on compositional meaning of the input texts. Therefore, models in this category usually define complex representation functions Ï• and Ïˆ (i.e., deep neural networks), but no interaction function Î· Interaction-focused Architecture: The underlying assumption of this type of architecture is that relevance is in essence about the relation between the input texts, so it would be more effective to directly learn from interactions rather than from individual representations. Models in this category thus define the interaction function Î· rather than the representation functions Ï• and Ïˆ Hybrid Architecture: In order to take advantage of both representation focused and interaction-focused architectures, a natural way is to adopt a hybrid architecture for feature learning. We find that there are two major hybrid strategies to integrate the two architectures, namely combined strategy and coupled strategy. 4.3. Single-granularity vs. Multi-granularity ArchitectureSingle-granularity Architecture: The underlying assumption of the single granularity architecture is that relevance can be evaluated based on the high level features extracted by Ï•, Ïˆ and Î· from the single-form text inputs. Multi-granularity Architecture: The underlying assumption of the multigranularity architecture is that relevance estimation requires multiple granularities of features, either from different-level feature abstraction or based on different types of language units of the inputs 5. Model Learning5.1. Learning objectiveSimilar to other LTR algorithms, the learning objective of neural ranking models can be broadly categorized into three groups: pointwise, pairwise, and listwise. 5.1.1. Pointwise Ranking Objective1 loss The idea of pointwise ranking objectives is to simplify a ranking problem to a set of classification or regression problems a. Cross Entropy For example, one of the most popular pointwise loss functions used in neural ranking models is Cross Entropy: b. Mean Squared Error There are other pointwise loss functions such as Mean Squared Error for numerical labels, but they are more commonly used in recommendation tasks. 2 ä¼˜ç¼ºç‚¹ a.advantages First, it simple and easy to scale. Second, the outputs have real meanings and value in practice. For instance, in sponsored search, a model learned with cross entropy loss and clickthrough rates can directly predict the probability of user clicks on search ads, which is more important than creating a good result list in some application scenarios. b.disadvantages less effective ï¼ŒBecause pointwise loss functions consider no document preference or order information, they do not guarantee to produce the best ranking list when the model loss reaches the global minimum. 5.1.2. Pairwise Ranking Objective1 loss Pairwise ranking objectives focus on optimizing the relative preferences between documents rather than their labels. a.Hinge loss b.cross entropy â€‹ RankNet 2 ä¼˜ç¼ºç‚¹ a.advantages effective in many tasks b.disadvantages pairwise methods does not always lead to the improvement of final ranking metrics due to two reasons: (1) it is impossible to develop a ranking model that can correctly predict document preferences in all cases; and (2) in the computation of most existing ranking metrics, not all document pairs are equally important. 5.1.3. Listwise Ranking Objective1 loss listwise loss functions compute ranking loss with each query and their candidate document list together a. ListMLE https://blog.csdn.net/qq_36478718/article/details/122598406 b.Attention Rank function https://arxiv.org/abs/1804.05936 c. softmax-based listwise https://arxiv.org/pdf/1811.04415.pdf 2 ä¼˜ç¼ºç‚¹ a.advantages While listwise ranking objectives are generally more effective than pairwise ranking objectives b.disadvantages their high computational cost often limits their applications. They are suitable for the re-ranking phase over a small set of candidate documents 5.1.4. Multi-task Learning Objective the optimization of neural ranking models may include the learning of multiple ranking or non-ranking objectives at the same time. 5.2. Training Strategies1 Supervised learning 2 Weakly supervised learning 3 Semi-supervised learning 6. Model Comparisonæ¯”è¾ƒäº†å¸¸è§æ¨¡å‹åœ¨ä¸åŒåº”ç”¨çš„æ•ˆæœ 1 Ad-hoc Retrieval https://blog.csdn.net/qq_44092699/article/details/106335971 Ad-hoc information retrieval refers to the task of returning information resources related to a user query formulated in natural language. 2 QA","link":"/2022/03/31/ranking-survey/"},{"title":"ranknetå¯¹æ¯”listnet","text":"The ListNet method grows on the bases of RankNet, they both employ the Cross Entropy function as a loss function and Gradient Descendant as algorithm to train a Neural Network Model. While the ListNet uses document list as instances, RankNet uses document pairs. We investigated why the listwise method ListNet can outperform the pairwise methods of RankNet, Ranking SVM, and RankBoost. https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf 1.for the pairwise approach the number of document pairs varies largely from query to query 2.The pairwise approach actually employs a â€˜pairwiseâ€™ loss function, which might be too loose as an approximation of the performance measures","link":"/2022/01/04/ranknet-listnet/"},{"title":"å®æ—¶æ•°ä»“æ¡ˆä¾‹ï¼ˆç”µå•†ï¼‰","text":"0 æ¶æ„ 1 ods1 æ—¥å¿—æ•°æ® å‰ç«¯ï¼ˆjarï¼Œäº§ç”Ÿæ—¥å¿—æ•°æ®ï¼‰-ã€‹Nginxï¼ˆé›†ç¾¤é—´è´Ÿè½½å‡è¡¡ï¼‰-ã€‹æ—¥å¿—æœåŠ¡å™¨ï¼ˆspringbootï¼Œé‡‡é›†æ•°æ®ï¼Œjarï¼‰-ã€‹logï¼Œods(kafka) æœ¬åœ°æµ‹è¯•ï¼Œæœ¬åœ°èµ·åº”ç”¨ -ã€‹ å•æœºéƒ¨ç½²ï¼Œå•æœåŠ¡å™¨èµ·åº”ç”¨ -ã€‹ é›†ç¾¤éƒ¨ç½²ï¼Œé›†ç¾¤èµ·åº”ç”¨ 2 ä¸šåŠ¡æ•°æ® å‰ç«¯ï¼Œjarï¼Œäº§ç”Ÿä¸šåŠ¡æ•°æ®-ã€‹mysql,é…ç½®ä»€ä¹ˆåŒæ­¥-ã€‹flinkcdc-ã€‹ods(kafka) 2 dimã€dwd1 ç”¨æˆ·è¡Œä¸ºæ—¥å¿— ods(Kafka)-&gt; flink -&gt; dwd(kafka) 1 è¯†åˆ«æ–°è€ç”¨æˆ· ä¸šåŠ¡éœ€è¦ 2 æ—¥å¿—æ•°æ®æ‹†åˆ† è¿™3ç±»æ—¥å¿—ï¼Œç»“æ„ä¸åŒï¼Œå†™å›Kafkaä¸åŒä¸»é¢˜ 2 ä¸šåŠ¡æ•°æ® ods(kafka) -&gt; flink -&gt; 1 ç»´åº¦æ•°æ®ï¼Œdimï¼ˆHBASEï¼‰ 2 äº‹å®æ•°æ® dwd(kafka) 1 ETL è¿‡æ»¤æ§åˆ¶ 2 åŠ¨æ€åˆ†æµ ç»´åº¦æ•°æ®åˆ°hbase äº‹å®æ•°æ®åˆ°kafka æ€ä¹ˆåˆ†æµï¼Ÿ odsçš„è¡¨é‡Œé¢å“ªäº›æ˜¯ç»´åº¦è¡¨ï¼Œå“ªäº›æ˜¯äº‹å®è¡¨ï¼Œéœ€è¦æå‰çŸ¥é“è¡¨çš„åˆ†ç±»ä¿¡æ¯ï¼Œåé¢æ‰å¯ä»¥åˆ†æµã€‚ä¸šåŠ¡åº“çš„è¡¨ä¼šå˜åŒ–ï¼Œè¡¨çš„åˆ†ç±»ä¿¡æ¯å®æ—¶æ›´æ–°ï¼Œéœ€è¦åŠ¨æ€åŒæ­¥ã€‚è¿™é‡Œå°†è¡¨çš„åˆ†ç±»ä¿¡æ¯å­˜åœ¨mysqlï¼Œåˆ©ç”¨å¹¿æ’­æµå‘é€ã€‚ 3 dwmdmdï¼ˆkafkaï¼‰-&gt; flink -&gt; dwmï¼ˆkafkaï¼‰ 1 è®¿é—®uvè®¡ç®— UVï¼Œunique visitor 2 è·³å‡ºæ˜ç»†è®¡ç®— è·³å‡ºç‡=è·³å‡ºæ¬¡æ•° / è®¿é—®æ¬¡æ•° 3 è®¢å•ä¸»é¢˜è¡¨ 4 æ”¯ä»˜ä¸»é¢˜è¡¨ 4 dwsdwmï¼ˆkafkaï¼‰-&gt; flink -&gt; dwsï¼ˆclickhouseï¼‰ 1 è®¿å®¢ä¸»é¢˜å®½è¡¨ 2 å•†å“ä¸»é¢˜å®½è¡¨ 3 åœ°åŒºä¸»é¢˜è¡¨ 4 å…³é”®è¯ä¸»é¢˜è¡¨ 5 ads","link":"/2022/04/14/real-datawarehouse-case/"},{"title":"åˆ†å±‚ç»“æ„","text":"DWMhttps://blog.csdn.net/jianghuaijie/article/details/122009653 ä½œç”¨ DWMå±‚çš„å®šä½æ˜¯ä»€ä¹ˆï¼ŒDWMå±‚ä¸»è¦æœåŠ¡DWSï¼Œå› ä¸ºéƒ¨åˆ†éœ€æ±‚ç›´æ¥ä»DWDå±‚åˆ°DWSå±‚ä¸­é—´ä¼šæœ‰ä¸€å®šçš„è®¡ç®—é‡ï¼Œè€Œä¸”è¿™éƒ¨åˆ†è®¡ç®—çš„ç»“æœå¾ˆæœ‰å¯èƒ½è¢«å¤šä¸ªDWSå±‚ä¸»é¢˜å¤ç”¨ æ„å»º åˆ†ä¸»é¢˜ dwtå®æ—¶æ•°ä»“æ²¡æœ‰dwtï¼Œå› ä¸ºdwtæ˜¯ç´¯è®¡ç»Ÿè®¡ï¼Œå®æ—¶ç³»ç»Ÿä¸é€‚ç”¨ dwsä½œç”¨ è½»åº¦èšåˆï¼Œç”Ÿæˆä¸€ç³»åˆ—çš„ä¸­é—´è¡¨ï¼Œæå‡å…¬å…±æŒ‡æ ‡çš„å¤ç”¨æ€§ï¼Œå‡å°‘é‡å¤åŠ å·¥ åˆ†ä¸»é¢˜ï¼Œä¾¿äºç®¡ç† æ„å»º åˆ†ä¸»é¢˜ å®½è¡¨ è½»åº¦èšåˆ","link":"/2022/04/10/realware-multi-layer/"},{"title":"æ¨èä¹‹å¬å›","text":"æ€»ç»“ https://blog.csdn.net/luanfenlian0992/article/details/107416438 https://zhuanlan.zhihu.com/p/364053939 å¥½ç”¨çš„å·¥å…· https://hub.fastgit.org/shenweichen/DeepMatch","link":"/2021/10/25/recall-survey/"},{"title":"æ¨èç³»ç»Ÿè¯„ä»·æŒ‡æ ‡","text":"https://zhuanlan.zhihu.com/p/67287992 http://sofasofa.io/forum_main_post.php?postid=1000292","link":"/2021/10/21/recommend-metrice/"},{"title":"æ¨èç³»ç»Ÿ","text":"ä¸€èˆ¬æ¨èç³»ç»Ÿçš„ç»“æ„æ‹†åˆ†ä¸ºï¼šå¬å›-ã€‹ç²—æ’-ã€‹ç²¾æ’-ã€‹é‡æ’ å¤§ä½¬æ€»ç»“çš„å¹²è´§ï¼š https://xieyangyi.blog.csdn.net/article/details/123095982 0 å¬å›ç¼©å°è§„æ¨¡ï¼Œå‡å°å€™é€‰é›†ï¼Œä¸éœ€è¦ååˆ†å‡†ç¡®ï¼Œä½†ä¸å¯é—æ¼ å¿…é¡»è½»é‡å¿«é€Ÿä½å»¶è¿Ÿ 1 ç²—æ’å…¼é¡¾ç²¾å‡†æ€§å’Œä½å»¶è¿Ÿ ä¸€èˆ¬æ¨¡å‹ä¹Ÿä¸èƒ½è¿‡äºå¤æ‚ 2 ç²¾æ’è¦æ±‚å‡† å¤šç‰¹å¾ï¼Œå¤æ‚æ¨¡å‹ 3 é‡æ’ä¸šåŠ¡ç›¸å…³ è§„åˆ™æ¯”è¾ƒå¤š å‚è€ƒhttps://xieyangyi.blog.csdn.net/article/details/123095982 https://www.cnblogs.com/gczr/p/12564617.html","link":"/2021/08/30/recommmend-sys/"},{"title":"é€’å½’,è¿­ä»£","text":"é¦–å…ˆï¼Œè¿­ä»£ï¼ˆæœ‰é€’æ¨è¿‡ç¨‹ï¼‰åŒºåˆ«äºéé€’å½’ å…³ç³» è¿­ä»£å¯ä»¥è½¬æ¢ä¸ºé€’å½’ï¼Œä½†é€’å½’ä¸ä¸€å®šèƒ½è½¬æ¢ä¸ºè¿­ä»£ é€’å½’ä¸€å®šå¯ä»¥éé€’å½’è¡¨ç¤º é€’å½’ï¼Œè¿­ä»£å¯¹æ¯” ç©ºé—´å¤æ‚åº¦ï¼šé€’å½’éœ€è¦é¢å¤–å¼€é”€ æ—¶é—´å¤æ‚åº¦ï¼š å‚è€ƒhttps://www.jianshu.com/p/32bcc45efd32","link":"/2022/05/23/recusive-iteration/"},{"title":"é€’å½’","text":"è‡ªå·±è°ƒç”¨è‡ªå·± æ³¨æ„å‡ºå£ 123def function(): 1 æœ€å°å­é—®é¢˜ï¼Œå‡ºå£ï¼Œç‰¹è§£ 2 é€šé‡Š","link":"/2022/05/31/recusive/"},{"title":"Use reduceByKey instead of groupByKey","text":"groupByKey creates a lot of shuffling which hampers the performance, while reduceByKey does not shuffle the data as much https://blog.csdn.net/qq_17685725/article/details/123033552","link":"/2022/03/04/reduceByKey/"},{"title":"æ­£åˆ™åŒ–","text":"æ˜¯æœºå™¨å­¦ä¹ ä¸­å¯¹åŸå§‹æŸå¤±å‡½æ•°å¼•å…¥é¢å¤–ä¿¡æ¯ï¼Œä»¥ä¾¿é˜²æ­¢è¿‡æ‹Ÿåˆå’Œæé«˜æ¨¡å‹æ³›åŒ–æ€§èƒ½çš„ä¸€ç±»æ–¹æ³•çš„ç»Ÿç§°ã€‚ 1.L1æ­£åˆ™ï¼ˆLassoå›å½’ï¼‰L1æ­£åˆ™åŒ–å¯ä»¥ä½¿å¾—å‚æ•°ç¨€ç–åŒ–ï¼Œå³å¾—åˆ°çš„å‚æ•°æ˜¯ä¸€ä¸ªç¨€ç–çŸ©é˜µï¼Œå¯ä»¥ç”¨äºç‰¹å¾é€‰æ‹©ã€‚ \\begin{align*} L_{L1}(w)&=L(w)+\\lambda\\Vert w \\Vert_1=L(w)+\\lambda\\sum_{i=1}^{N}|w_i| \\\\ \\frac{\\partial L_{L1}}{\\partial w_i}&=\\frac{\\partial L}{\\partial w_i}+\\lambda \\ sgn(w_i) \\\\w_i &\\rightarrow w_i-\\eta(\\frac{\\partial L}{\\partial w_i}+\\lambda \\ sgn(w_i)) \\rightarrow w_i-\\eta\\lambda \\ sgn(w_i)-\\eta\\frac{\\partial L}{\\partial w_i} \\end{align*}L1æ˜¯æ¯æ¬¡å‡å»ä¸€ä¸ªå¸¸æ•°çš„æ”¶æ•›ï¼Œæ‰€ä»¥L1æ›´å®¹æ˜“æ”¶æ•›åˆ°0ã€‚ 2.L2æ­£åˆ™ï¼ˆRidgeå›å½’ï¼‰L2æ­£åˆ™åŒ–ä½¿å¾—å‚æ•°å¹³æ»‘ã€‚ \\begin{align*} L_{L2}(w)&=L(w)+\\lambda\\Vert w \\Vert_2^2=L(w)+\\lambda\\sum_{i=1}^{N}w_i^2 \\\\ \\frac{\\partial L_{L2}}{\\partial w_i}&=\\frac{\\partial L}{\\partial w_i}+2\\lambda w_i \\\\w_i& \\rightarrow w_i-\\eta(\\frac{\\partial L}{\\partial w_i}+2\\lambda w_i) \\rightarrow(1-2\\eta\\lambda)w_i-\\eta \\frac{\\partial L}{\\partial w_i} \\end{align*}L2æ˜¯æ¯æ¬¡ä¹˜ä¸Šä¸€ä¸ªå°äº1çš„å€æ•°è¿›è¡Œæ”¶æ•›ï¼Œæ‰€ä»¥L2ä½¿å¾—å‚æ•°å¹³æ»‘ã€‚ 3.dropout ä½¿ç”¨ï¼šåœ¨è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªç¥ç»å•å…ƒä»¥æ¦‚ç‡$p$è¢«ä¿ç•™(Dropoutä¸¢å¼ƒç‡ä¸º$1âˆ’p$)ï¼›åœ¨é¢„æµ‹é˜¶æ®µï¼Œæ¯ä¸ªç¥ç»å•å…ƒéƒ½æ˜¯å­˜åœ¨çš„ã€‚ åŸç†ï¼šç¥ç»ç½‘ç»œé€šè¿‡Dropoutå±‚ä»¥ä¸€å®šæ¯”ä¾‹éšå³çš„ä¸¢å¼ƒç¥ç»å…ƒï¼Œä½¿å¾—æ¯æ¬¡è®­ç»ƒçš„ç½‘ç»œæ¨¡å‹éƒ½ä¸ç›¸åŒï¼Œå¤šä¸ªEpochä¸‹æ¥ç›¸å½“äºè®­ç»ƒäº†å¤šä¸ªæ¨¡å‹ï¼ŒåŒæ—¶æ¯ä¸€ä¸ªæ¨¡å‹éƒ½å‚ä¸äº†å¯¹æœ€ç»ˆç»“æœçš„æŠ•ç¥¨ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œç±»ä¼¼baggingã€‚ å‚è€ƒhttps://www.cnblogs.com/zingp/p/11631913.html https://blog.csdn.net/b876144622/article/details/81276818 https://www.zhihu.com/question/37096933/answer/70494622","link":"/2021/09/07/regulize/"},{"title":"å®ä½“å…³ç³»æŠ½å–","text":"å‚è€ƒhttps://zhuanlan.zhihu.com/p/77868938","link":"/2022/06/11/relation-extract/"},{"title":"RNNæ€»ç»“","text":"1.å•å…ƒ1.1 æ™®é€šRNNå•å…ƒ1.2 LSTM1.3 GRU2.ç»“æ„1.1 è¾“å…¥ã€è¾“å‡º 1.2 æ˜¯å¦åŒå‘ 1.3 æ˜¯å¦å †å  å‚è€ƒhttps://blog.csdn.net/gaohanjie123/article/details/88699664 https://www.cnblogs.com/Luv-GEM/p/10788849.html","link":"/2021/09/15/rnn/"},{"title":"RoBERTa A Robustly Optimized BERT Pretraining Approach","text":"1.å’ŒBERTæ¯”è¾ƒåœ¨ç»“æ„ä¸Šå’ŒåŸç‰ˆBERTæ²¡æœ‰å·®å¼‚ï¼Œä¸»è¦çš„æ”¹åŠ¨åœ¨äºï¼š 2.æ”¹åŠ¨åˆ†æ2.1 Static vs. Dynamic Maskingstatic masking: åŸæœ¬çš„BERTé‡‡ç”¨çš„æ˜¯static maskçš„æ–¹å¼ï¼Œå°±æ˜¯åœ¨create pretraining dataä¸­ï¼Œå…ˆå¯¹æ•°æ®è¿›è¡Œæå‰çš„mask dynamic masking: æ¯ä¸€æ¬¡å°†è®­ç»ƒexampleå–‚ç»™æ¨¡å‹çš„æ—¶å€™ï¼Œæ‰è¿›è¡Œéšæœºmaskã€‚ ç»“æœå¯¹æ¯”ï¼š ç»“è®ºï¼šåŠ¨æ€å ä¼˜ 2.2 Model Input Format and Next Sentence Predictionåšäº†ç»“æœå¯¹æ¯”è¯•éªŒï¼Œç»“æœå¦‚ä¸‹ï¼š ç»“è®ºï¼š Model Input Format: â€‹ 1.find that using individual sentences hurts performance on downstream tasks Next Sentence Prediction: â€‹ 1.removing the NSP loss matches or slightly improves downstream task performance 2.3 Training with large batches 2.4 Text Encodingé‡‡ç”¨BBPEè€Œä¸æ˜¯wordpiece 3 å¸¸è§é—®é¢˜1 roberta tokenizer æ²¡æœ‰token_type_idsï¼Ÿroberta å–æ¶ˆäº†NSPï¼Œæ‰€ä»¥ä¸éœ€è¦segment embedding ä¹Ÿå°±ä¸éœ€è¦token_type_idsï¼Œä½†æ˜¯ä½¿ç”¨çš„æ—¶å€™å‘ç°ä¸­æ–‡æ˜¯æœ‰token_type_idsçš„ï¼Œè‹±æ–‡æ²¡æœ‰token_type_idsçš„ã€‚æ²¡æœ‰token_type_idsï¼Œä¸¤å¥è¯æ€ä¹ˆåŒºåˆ«ï¼Œåˆ†éš”ç¬¦sepè¿˜æ˜¯æœ‰çš„ï¼Œåªæ˜¯æ²¡æœ‰segment embedding 2 ä½¿ç”¨é¿å‘ https://blog.csdn.net/zwqjoy/article/details/107533184 https://hub.fastgit.org/ymcui/Chinese-BERT-wwm å‚è€ƒhttps://zhuanlan.zhihu.com/p/103205929 https://zhuanlan.zhihu.com/p/143064748 https://blog.csdn.net/zwqjoy/article/details/107533184 https://hub.fastgit.org/ymcui/Chinese-BERT-wwm","link":"/2021/09/15/roberta/"},{"title":"æœç´¢ç³»ç»Ÿ","text":"ç»¼è¿° https://zhuanlan.zhihu.com/p/112719984 https://zhuanlan.zhihu.com/p/382001982 https://www.cnblogs.com/davidwang456/articles/10251599.html DeepRank: A New Deep Architecture for Relevance Ranking in Information Retrieval https://arxiv.org/pdf/1710.05649.pdf","link":"/2021/08/06/search-rank-init/"},{"title":"IaaSã€PaaSå’ŒSaaS","text":"IaaSï¼š Infrastructure-as-a-Serviceï¼ˆåŸºç¡€è®¾æ–½å³æœåŠ¡ï¼‰ PaaSï¼š Platform-as-a-Serviceï¼ˆå¹³å°å³æœåŠ¡ï¼‰ SaaSï¼š Software-as-a-Serviceï¼ˆè½¯ä»¶å³æœåŠ¡ï¼‰ https://www.ruanyifeng.com/blog/2017/07/iaas-paas-saas.html","link":"/2022/03/01/saas/"},{"title":"Sentence-BERT Sentence Embeddings using Siamese BERT-Networks","text":"paper: https://arxiv.org/abs/1908.10084 giit: https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications 1.è´¡çŒ®åŸºäºbertåˆ©ç”¨å­ªç”Ÿç»“æ„æˆ–è€…ä¸‰èƒèƒç»“æ„è®­ç»ƒï¼Œä½¿å¾—äº§ç”Ÿåœ¨ä½ç»´ç©ºé—´å¯ç”¨çš„å¥å­Embeddingã€‚å¯¹äºæ–‡æœ¬åŒ¹é…ä»»åŠ¡ï¼Œå¯ä»¥ç¦»çº¿è®¡ç®—å¥å­Embeddingï¼Œç„¶ååŸºäºå¥å­Embeddingåœ¨çº¿åŒ¹é…ï¼Œå¯å®ç°å¿«é€Ÿé«˜ç²¾åº¦çš„åŒ¹é…ã€‚ 2.ç»“æ„ æ–‡ç« æå‡ºä¸‰ç§ç»“æ„å’Œç›®æ ‡å‡½æ•°ï¼Œä¸‰èƒèƒç»“æ„ä½œè€…æ²¡æœ‰ç”»å›¾ 1.Classification Objective Function loss=cross-entropy(softmax(W_t(u,v,|u-v|)),y_{true})2.Regression Objective Function loss=MSE(cosine-sim(u, v),y_{true})3.Triplet Objective Function loss=max(||s_a-s_p||-||s_a-s_n||+\\sigma,0)$||.||$è®¡ç®—å‘é‡è·ç¦»ï¼Œ$s_a$ä¸ºæ ·æœ¬æœ¬èº«ï¼Œ$s_p$ä¸ºæ­£æ ·æœ¬ï¼Œ$s_n$ä¸ºè´Ÿæ ·æœ¬ï¼Œ$\\sigma$ä½¿å¾—æ­£æ ·æœ¬è‡³å°‘æ¯”è´Ÿæ ·æœ¬è·ç¦»æ ·æœ¬è¿‘$\\sigma$ã€‚ å¯¹äºpoolingï¼Œæ–‡ç« æå‡ºä¸‰ç§ç­–ç•¥ 1.Using the output of the CLS-token2.computing the mean of all output vectors (MEAN_strategy)3.computing a max-over-time of the output vectors (MAX_strategy). The default configuration is MEAN. 3.å®éªŒç»“æœ3.1 Unsupervised STS 3.2 Supervised STS 3.3 Argument Facet Similarity 3.4 Wikipedia Sections DistinctionWe use the Triplet Objective 4.ä»£ç 123456789101112131415161718192021222324252627282930313233from sentence_bert.sentence_transformers import SentenceTransformer, util###load modelmodel = SentenceTransformer(model_path)# Single list of sentencessentences = ['The cat sits outside', 'A man is playing guitar', 'I love pasta', 'The new movie is awesome', 'The cat plays in the garden', 'A woman watches TV', 'The new movie is so great', 'Do you like pizza?']#Compute embeddingsembeddings = model.encode(sentences, convert_to_tensor=True)#Compute cosine-similarities for each sentence with each other sentencecosine_scores = util.pytorch_cos_sim(embeddings, embeddings)#Find the pairs with the highest cosine similarity scorespairs = []for i in range(len(cosine_scores)-1): for j in range(i+1, len(cosine_scores)): pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})#Sort scores in decreasing orderpairs = sorted(pairs, key=lambda x: x['score'], reverse=True)for pair in pairs[0:10]: i, j = pair['index'] print(&quot;{} \\t\\t {} \\t\\t Score: {:.4f}&quot;.format(sentences[i], sentences[j], pair['score'])) 1234567891011The new movie is awesome The new movie is so great Score: 0.9283The cat sits outside The cat plays in the garden Score: 0.6855I love pasta Do you like pizza? Score: 0.5420I love pasta The new movie is awesome Score: 0.2629I love pasta The new movie is so great Score: 0.2268The new movie is awesome Do you like pizza? Score: 0.1885A man is playing guitar A woman watches TV Score: 0.1759The new movie is so great Do you like pizza? Score: 0.1615The cat plays in the garden A woman watches TV Score: 0.1521The cat sits outside The new movie is awesome Score: 0.1475","link":"/2021/07/27/sentence-bert/"},{"title":"attention seq2seq","text":"1.ç»“æ„ å·¦è¾¹ä¸ºencoderï¼Œå¯¹è¾“å…¥æ–‡æœ¬ç¼–ç ï¼Œå³è¾¹ä¸ºdecoderï¼Œè§£ç å¹¶åº”ç”¨ã€‚ æ•´ä¸ªæµç¨‹çš„å›¾è§£å¯ä»¥å‚è€ƒhttps://blog.csdn.net/weixin_44388679/article/details/102575223 ä¸­çš„â€œå››ã€å›¾è§£Attention Seq2Seqâ€ï¼Œéå¸¸è¯¦ç»†ã€‚ 2.Teacher Forcingåœ¨è®­ç»ƒé˜¶æ®µï¼Œå¦‚æœä½¿ç”¨Teacher Forcingç­–ç•¥ï¼Œé‚£ä¹ˆç›®æ ‡å¥å­å•è¯çš„word embeddingä½¿ç”¨çœŸå€¼ï¼Œä¸é€‚ç”¨Teacher Forcingåˆ™ä¸ºä½¿ç”¨é¢„æµ‹ç»“æœï¼›è‡³äºé¢„æµ‹é˜¶æ®µä¸èƒ½ä½¿ç”¨Teacher Forcingã€‚ 3.beam searchbeam searchæœ¬è´¨ä¸ºä»‹äºè›®åŠ›ä¸è´ªå¿ƒä¹‹é—´çš„ç­–ç•¥ã€‚å¯¹äºè´ªå¿ƒï¼Œæ¯ä¸€çº§çš„è¾“å‡ºåªé€‰æ‹©top1çš„ç»“æœä½œä¸ºä¸‹ä¸€çº§è¾“å…¥ï¼Œç„¶åtop1çš„ç»“æœåªæ˜¯å±€éƒ¨æœ€ä¼˜ï¼Œä¸ä¸€å®šæ˜¯å…¨å±€æœ€ä¼˜ï¼Œç²¾åº¦å¯èƒ½è¾ƒä½ã€‚å¯¹äºè›®åŠ›ï¼Œæ¯çº§å°†å…¨éƒ¨ç»“æœè¾“å…¥ä¸‹çº§ï¼Œå‡è®¾$L$ä¸ºè¯è¡¨å¤§å°ï¼Œé‚£ä¹ˆæœ€åä¸€çº§çš„æ•°æ®é‡ä¸º$L^{m}$ï¼Œ$m$ä¸ºdecoder çš„cellæ•°é‡ï¼Œè®¡ç®—æ•ˆç‡å¤ªä½ã€‚å¯¹äºbeam searchï¼Œæ¯çº§é€‰æ‹©top kä½œä¸ºä¸‹çº§è¾“å…¥ï¼Œç»¼åˆäº†æ•ˆç‡å’Œç²¾åº¦ã€‚ 4 å¸¸è§é—®é¢˜0 ä¸ºä»€ä¹ˆrnn based seq2seqä¸éœ€è¦é¢å¤–æ·»åŠ ä½ç½®ä¿¡æ¯ï¼Ÿ å¤©ç„¶æœ‰ä½ç½®ä¿¡æ¯ï¼ˆè¿­ä»£é¡ºåºï¼‰ 1 ä¸ºä»€ä¹ˆrnn based seq2seqè¾“å…¥è¾“å‡ºé•¿åº¦å¯å˜ï¼Ÿ å› ä¸ºrnn based seq2seqæ˜¯è¿­ä»£è¿›è¡Œçš„ï¼Œæ‰€ä»¥é•¿åº¦å¯å˜ 2 è®­ç»ƒçš„æ—¶å€™è¦paddingå—ï¼Ÿ ä¸ç”¨padding å‚è€ƒhttps://zhuanlan.zhihu.com/p/47929039 https://www.cnblogs.com/liuxiaochong/p/14399416.html https://blog.csdn.net/thriving_fcl/article/details/74853556","link":"/2021/07/24/seq2seq/"},{"title":"åºåˆ—æ ‡æ³¨","text":"åºåˆ—æ ‡æ³¨ï¼ˆSequence Taggingï¼‰æ˜¯NLPä¸­æœ€åŸºç¡€çš„ä»»åŠ¡ï¼Œåº”ç”¨ååˆ†å¹¿æ³›ï¼Œå¦‚åˆ†è¯ã€è¯æ€§æ ‡æ³¨ï¼ˆPOS taggingï¼‰ã€å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognitionï¼ŒNERï¼‰ã€å…³é”®è¯æŠ½å–ã€è¯­ä¹‰è§’è‰²æ ‡æ³¨ï¼ˆSemantic Role Labelingï¼‰ã€æ§½ä½æŠ½å–ï¼ˆSlot Fillingï¼‰ç­‰å®è´¨ä¸Šéƒ½å±äºåºåˆ—æ ‡æ³¨çš„èŒƒç•´ã€‚ æ ‡æ³¨æ–¹å¼https://zhuanlan.zhihu.com/p/147537898# å‚è€ƒhttps://zhuanlan.zhihu.com/p/268579769 https://zhuanlan.zhihu.com/p/147537898#","link":"/2022/06/09/sequence-annotation/"},{"title":"Neural Graph Matching Networks for Chinese Short Text Matching","text":"https://aclanthology.org/2020.acl-main.547.pdf 1.æ‘˜è¦å¯¹äºä¸­æ–‡çŸ­æ–‡æœ¬åŒ¹é…ï¼Œé€šå¸¸åŸºäºè¯ç²’åº¦è€Œä¸æ˜¯å­—ç²’åº¦ã€‚ä½†æ˜¯åˆ†è¯ç»“æœå¯èƒ½æ˜¯é”™è¯¯çš„ã€æ¨¡ç³Šçš„æˆ–ä¸ä¸€è‡´çš„ï¼Œä»è€ŒæŸå®³æœ€ç»ˆçš„åŒ¹é…æ€§èƒ½ã€‚æ¯”å¦‚ä¸‹å›¾ï¼šå­—ç¬¦åºåˆ—â€œå—äº¬å¸‚é•¿æ±Ÿå¤§æ¡¥â€ç»è¿‡ä¸åŒçš„åˆ†è¯å¯èƒ½è¡¨è¾¾ä¸ºä¸åŒçš„æ„æ€ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œçš„ä¸­æ–‡çŸ­æ–‡æœ¬åŒ¹é…æ–¹æ³•ã€‚ä¸æ˜¯å°†å¥å­åˆ†å‰²æˆä¸€ä¸ªå•è¯åºåˆ—ï¼Œè€Œæ˜¯ä¿ç•™æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²è·¯å¾„ï¼Œå½¢æˆä¸€ä¸ªLatticeï¼ˆsegment1ï¼Œsegment2ï¼Œsegment3ï¼‰ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚ 2.é—®é¢˜å®šä¹‰å°†ä¸¤ä¸ªå¾…åŒ¹é…ä¸­æ–‡çŸ­æ–‡æœ¬åˆ†åˆ«å®šä¹‰ä¸º$S_a=\\left \\{ C_1^a,C_2^a,â€¦,C_{t_a}^a \\right \\}$ï¼Œ$S_b=\\left \\{ C_1^b,C_2^b,â€¦,C_{t_b}^b \\right \\}$ï¼Œå…¶ä¸­$C_i^a$è¡¨ç¤ºå¥å­$a$ç¬¬$i$ä¸ªå­—ï¼Œ$C_j^b$è¡¨ç¤ºå¥å­$b$ç¬¬$j$ä¸ªå­—ï¼Œ$t_a$ï¼Œ$t_b$åˆ†åˆ«è¡¨ç¤ºä¸¤ä¸ªå¥å­çš„é•¿åº¦ã€‚$f(S_a,S_b)$æ˜¯ç›®æ ‡å‡½æ•°ï¼Œè¾“å‡ºä¸ºä¸¤ä¸ªæ–‡æœ¬çš„åŒ¹é…åº¦ã€‚è¯æ ¼å›¾ç”¨$G=(\\nu,\\xi)$è¡¨ç¤ºï¼Œå…¶ä¸­$\\nu$æ˜¯èŠ‚ç‚¹é›†ï¼ŒåŒ…æ‹¬æ‰€æœ‰å­—ç¬¦åºåˆ—ã€‚$\\xi$è¡¨ç¤ºè¾¹é›†ï¼Œå¦‚æœ$\\nu$ä¸­ä¸¤ä¸ªé¡¶ç‚¹$v_i$å’Œ$v_j$ç›¸é‚»ï¼Œé‚£ä¹ˆå°±å­˜åœ¨ä¸€ä¸ªè¾¹ä¸º$e_{ij}$ã€‚$N_{fw}(v_i)$è¡¨ç¤ºèŠ‚ç‚¹$v_i$ æ­£å‘çš„æ‰€æœ‰å¯è¾¾èŠ‚ç‚¹çš„é›†åˆ,$N_{bw}(v_i)$è¡¨ç¤ºèŠ‚ç‚¹$v_i$ åå‘çš„æ‰€æœ‰å¯è¾¾èŠ‚ç‚¹çš„é›†åˆã€‚å¥å­$a$çš„è¯æ ¼å›¾ä¸º$G^a(\\nu_a,\\xi_a)$ï¼Œå¥å­$b$çš„è¯æ ¼å›¾ä¸º$G^b(\\nu_b,\\xi_b)$ã€‚ 3.æ¨¡å‹ç»“æ„ æ¨¡å‹åˆ†æˆ3ä¸ªéƒ¨åˆ†ï¼Œ1.è¯­è¨€èŠ‚ç‚¹è¡¨ç¤º 2.å›¾ç¥ç»åŒ¹é… 3.ç›¸å…³æ€§åˆ†ç±»å™¨ 3.1 è¯­è¨€èŠ‚ç‚¹è¡¨ç¤ºè¿™ä¸€éƒ¨åˆ†åŸºäºBERTçš„ç»“æ„ã€‚BERTçš„tokenè¡¨ç¤ºåŸºäºå­—ç²’åº¦ï¼Œå¯ä»¥å¾—åˆ°$\\left \\{ [CLS],C_1^a,C_2^a,â€¦,C_{ta}^a,[SEP],C_1^b,C_2^b,â€¦,C_{t_b}^b,[SEP] \\right \\}$,å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚BERTçš„è¾“å‡ºä¸ºå„ä¸ªå­—çš„Embeddingï¼Œ$ \\left \\{\\textbf{C}^{CLS},\\textbf{C}_1^a,\\textbf{C}_2^a,â€¦,\\textbf{C}_{t_a}^a,\\textbf{C}^{SEP},\\textbf{C}_1^b,\\textbf{C}_2^b,â€¦,\\textbf{C}_{t_b},\\textbf{C}^{SEP} \\right \\}$ã€‚ 3.2 å›¾ç¥ç»åŒ¹é…åˆå§‹åŒ–ï¼šå‡è®¾èŠ‚ç‚¹$v_i$åŒ…å«$n_i$ä¸ªè¿ç»­å­—ç¬¦ï¼Œèµ·å§‹å­—ç¬¦ä½ç½®ä¸º$s_i$ï¼Œå³$ \\left \\{C_{s_i},C_{s_{i+1}},â€¦,C_{s_{i}+n_i-1} \\right \\}$ï¼Œè¿™é‡Œ$v_i$è¡¨ç¤ºå¥å­$a$æˆ–è€…$b$çš„ç»“ç‚¹ã€‚$V_i=\\sum_{k=0}^{n_i-1}\\textbf{U}_{s_i+k}\\odot\\textbf{C}_{s_i+k}$ï¼Œå…¶ä¸­$\\odot$è¡¨ç¤ºä¸¤ä¸ªå‘é‡å¯¹åº”å„ä¸ªå…ƒç´ ç›¸ä¹˜ã€‚ç‰¹å¾è¯†åˆ«åˆ†æ•°å‘é‡$\\textbf{U}_{s_i+k}=softmax(FFN(\\textbf{C}_{s_i+k}))$ï¼Œ$FFN$ä¸ºä¸¤å±‚ã€‚$h$ä¸ºç»“ç‚¹çš„å‘é‡è¡¨ç¤ºï¼Œå°†$h_i^0$ç­‰äº$V_i$ Message Propagation : å¯¹äºç¬¬$l$æ¬¡è¿­ä»£ï¼Œ$G_a$ä¸­æŸä¸ªç»“ç‚¹$v_i$ç”±å¦‚ä¸‹å››ä¸ªéƒ¨åˆ†ç»„æˆ m_i^{fw}=\\sum_{v_j \\in N_{fw}(v_i)}\\alpha_{ij}(W^{fw}h_j^{l-1}), \\\\m_i^{bw}=\\sum_{v_k \\in N_{bw}(v_i)}\\alpha_{ik}(W^{bw}h_k^{l-1}), \\\\m_i^{b1}=\\sum_{v_m \\in V^b}\\alpha_{im}(W^{fw}h_m^{l-1}), \\\\m_i^{b2}=\\sum_{v_q \\in V^b}\\alpha_{iq}(W^{bw}h_q^{l-1})ï¼Œå…¶ä¸­$\\alpha_{ij},\\alpha_{ik},\\alpha_{im},\\alpha_{iq}$æ˜¯æ³¨æ„åŠ›ç³»æ•°ï¼Œ$W^{fw},W^{bw}$æ˜¯æ³¨æ„åŠ›ç³»æ•°å‚æ•° ç„¶åå®šä¹‰ä¸¤ç§ä¿¡æ¯ä¸º$m_i^{self}\\triangleq[m_i^{fw},m_i^{bw}]ï¼Œm_i^{cross}\\triangleq[m_i^{b1},m_i^{b2}]$ Representation Updatingï¼šå¾—åˆ°ä¸¤ç§ä¿¡æ¯åï¼Œéœ€è¦æ›´æ–°ç»“ç‚¹$ v_i$çš„å‘é‡è¡¨ç¤º d_k=cosine(w_k^{cos}\\odot m_i^{self},w_k^{cos}\\odot m_i^{cross})å…¶ä¸­$w_k^{cos}$ä¸ºå‚æ•°ï¼Œ$d_k$ä¸ºmulti-perspective cosine distanceï¼Œå¯ä»¥è¡¡é‡ä¸¤ç§ä¿¡æ¯çš„è·ç¦»ï¼Œ$k \\in \\left \\{ 1,2,3,â€¦P\\right\\}$ï¼Œ$P$æ˜¯è§†è§’çš„æ•°é‡ã€‚ h_i^l=FFN([m_i^{self},\\textbf{d}_i])å…¶ä¸­$\\textbf{d}_i\\triangleq[d_1,d_2,â€¦,d_P]$,$FFN$ä¸¤å±‚ã€‚ å¥å­çš„å›¾çº§åˆ«è¡¨ç¤ºï¼š æ€»å…±ç»å†äº†$L$æ¬¡è¿­ä»£ï¼ˆlayerï¼‰ï¼Œå¾—åˆ°$h_i^L$ä¸ºç»“ç‚¹$v_i$æœ€ç»ˆçš„å‘é‡è¡¨ç¤ºï¼ˆ$h_i^L$includes not only the information from its reachable nodes but also information of pairwise comparison with all nodes in another graph) æœ€ç»ˆï¼Œä¸¤ä¸ªå¥å­çš„å›¾çº§åˆ«è¡¨ç¤ºåˆ†åˆ«ä¸º g^a=attentive pooling(\\left \\{ h_{1a}^L,h_{2a}^L,...,h_{node-num_a a}^L \\right \\}), \\\\g^b=attentive pooling(\\left \\{ h_{1b}^L,h_{2b}^L,...,h_{node-num_b b}^L \\right \\})3.3 åˆ†ç±»å™¨å¾—åˆ°$g^a,g^b$åï¼Œä¸¤å¥å­çš„ç›¸ä¼¼åº¦å¯ä»¥ç”¨åˆ†ç±»å™¨è¡¡é‡ï¼š P=FFN([g^a,g^b,g^a \\odot g^b,|g^a-g^b|])å…¶ä¸­$P \\in [0,1]$ã€‚ 4.å®éªŒç»“æœ latticeå’ŒJIEBA+PKUçš„åŒºåˆ«ï¼Ÿ JIEBA+PKU is a small lattice graph generated by merging two word segmentation results latticeï¼šoverall latticeï¼Œåº”è¯¥æ˜¯å…¨éƒ¨çš„ç»„åˆ ä¸¤è€…æ•ˆæœå·®ä¸å¤šæ˜¯å› ä¸ºCompared with the tiny graph, the overall lattice has more noisy nodes (i.e. invalid words in the corresponding sentence). å‚è€ƒhttps://blog.csdn.net/qq_43390809/article/details/114077216","link":"/2021/08/04/short-chinese-text-match/"},{"title":"shellå‘½ä»¤æ‰§è¡Œhiveè„šæœ¬","text":"https://blog.csdn.net/longshenlmj/article/details/50542683","link":"/2022/02/15/shell-hive/"},{"title":"SimCSE Simple Contrastive Learning of Sentence Embeddings","text":"https://arxiv.org/pdf/2104.08821.pdf 1.èƒŒæ™¯ 1 target å¯¹äº$D=\\{(x_i,x_i^{+})\\}_{i=1}^{m}$,where $x_i$ and $x_i^{+}$ are semantically related. xi,xj+ are not semantically related x-&gt;h Contrastive learning aims to learn effective representation by pulling semantically close neighbors together and pushing apart non-neighbors N is mini-batch sizeï¼Œåˆ†å­æ˜¯æ­£æ ·æœ¬ï¼Œåˆ†æ¯ä¸ºè´Ÿæ ·æœ¬ï¼ˆæœ‰ä¸€ä¸ªæ­£æ ·æœ¬,æ„Ÿè§‰æ˜¯å¯ä»¥å¿½ç•¥ï¼‰ åˆ†æ¯ä¼šåŒ…å«åˆ†å­çš„é¡¹å—ï¼Ÿä»ä»£ç çœ‹ï¼Œä¼šçš„ loss https://www.jianshu.com/p/d73e499ec859 12345678910111213141516171819202122232425def loss(self,y_pred,y_true,lamda=0.05): ''' exist a query q1 and ranked condidat list [d1,d2,d3,...,dn] loss= -log( exp^sim(q1,d1)/t / sum(exp^sim(q1,di)/t) i=2,...,n) [q1,q2] [[d11,d12,d13],[d21,d22,d23]] similarities=[[sim(q1d11),sim(q1d12),sim(q1d13)],[sim(q2d21),sim(q2d22),sim(q2d23)] ] y_true=[y1 ,y2 ] loss = F.cross_entropy(similarities, y_true) ref ï¼š https://www.jianshu.com/p/d73e499ec859 ''' # idxs = torch.arange(0, y_pred.shape[0]) # y_true = idxs + 1 - idxs % 2 * 2 y_pred = y_pred.reshape(-1, y_true.shape[1]) # y_true=[0]*y_pred.sha pe[0] # similarities = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=2) # similarities = similarities - torch.eye(y_pred.shape[0]) * 1e12 y_pred = y_pred / lamda y_true = torch.argmax(y_true, dim=1) loss = F.cross_entropy(y_pred, y_true) return loss 2 representationsè¯„ä»·æŒ‡æ ‡ Alignmentï¼š calculates expected distance between embeddings of the paired instancesï¼ˆpaired instanceså°±æ˜¯æ­£ä¾‹ï¼‰ uniformityï¼š measures how well the embeddings are uniformly distributed 2.ç»“æ„ 2.1 Unsupervised$x_i-&gt;h_i^{z_i},x_i-&gt;h_i^{z_i^{â€˜}}$ z is a random mask for dropoutï¼Œlossä¸º 2.2 Supervisedå¼•å…¥éç›®æ ‡ä»»åŠ¡çš„æœ‰æ ‡ç­¾æ•°æ®é›†ï¼Œæ¯”å¦‚NLIä»»åŠ¡ï¼Œ$(x_i,x_i^{+},x_i^{-})$,where $x_i$ is the premise, $x_i^{+}$and $x_i^{-}$are entailment and contradiction hypotheses. $(h_i,h_j^{+})$ä¸ºnormal negativesï¼Œ$(h_i,h_j^{-})$ä¸ºhard negatives","link":"/2021/10/20/simcse/"},{"title":"Semi-supervised Learningå’ŒSelf-Supervised Learning","text":"https://blog.csdn.net/qq_44015059/article/details/106448533","link":"/2021/11/22/simi-self-learning/"},{"title":"Solr","text":"https://zhuanlan.zhihu.com/p/71629409?fileGuid=It0Qkg2AiecFMx62 Solræ˜¯Apacheä¸‹çš„ä¸€ä¸ªé¡¶çº§å¼€æºé¡¹ç›®ï¼Œé‡‡ç”¨Javaå¼€å‘ï¼Œå®ƒæ˜¯åŸºäºLuceneçš„å…¨æ–‡æœç´¢æœåŠ¡å™¨ã€‚Solræä¾›äº†æ¯”Luceneæ›´ä¸ºä¸°å¯Œçš„æŸ¥è¯¢è¯­è¨€ï¼ŒåŒæ—¶å®ç°äº†å¯é…ç½®ã€å¯æ‰©å±•ï¼Œå¹¶å¯¹ç´¢å¼•ã€æœç´¢æ€§èƒ½è¿›è¡Œäº†ä¼˜åŒ–ã€‚","link":"/2022/02/07/solr/"},{"title":"sota","text":"https://www.jiqizhixin.com/sota","link":"/2021/11/22/sota/"},{"title":"Spark æ•°æ®å€¾æ–œ","text":"https://blog.csdn.net/kaede1209/article/details/81145560 https://tech.meituan.com/2016/05/12/spark-tuning-pro.html å‘ç”Ÿåœ¨ä¸¤ä¸ªè¿‡ç¨‹ï¼š æ•°æ®æºæ•°æ®ä¸å‡åŒ€ shuffleè¿‡ç¨‹ä¸­keyçš„åˆ†å¸ƒä¸å‡ å•ä¸ªrddä¸­è¿›è¡Œèšåˆçš„æ—¶å€™keyåˆ†å¸ƒä¸å‡ å¤šä¸ªrddè¿›è¡Œjoinè¿‡ç¨‹ä¸­keyçš„ä¸å‡åŒ€","link":"/2022/01/20/spark-data-im/"},{"title":"sparkå®¹é”™æœºåˆ¶","text":"https://blog.csdn.net/JasonDing1354/article/details/46882585 https://blog.csdn.net/dengxing1234/article/details/73613484 å®¹é”™æŒ‡çš„æ˜¯ä¸€ä¸ªç³»ç»Ÿåœ¨éƒ¨åˆ†æ¨¡å—å‡ºç°æ•…éšœæ—¶è¿˜èƒ½å¦æŒç»­çš„å¯¹å¤–æä¾›æœåŠ¡ 1 Lineageæœºåˆ¶2 Checkpointæœºåˆ¶","link":"/2022/04/04/spark-error-telerant/"},{"title":"sparkå¸¸è§é”™è¯¯","text":"Python in worker has different version 2.7 than that in driver 3.7, PySpark cannot run with different minor versionsæ ¸å¿ƒæ€è·¯ï¼šåˆ†åˆ«æŒ‡å®šdriverå’Œexcutorçš„pythonç‰ˆæœ¬ï¼Œä½¿å…¶ç»Ÿä¸€ æ–¹æ³•ä¸€ï¼šä¿®æ”¹ç¯å¢ƒå˜é‡ 1./åœ¨ç¯å¢ƒå˜é‡æ–‡ä»¶ /etc/profile ä¸­æ·»åŠ æŒ‡å®šçš„pysparkï¼Œpythonçš„ç‰ˆæœ¬ 12export PYSPARK_PYTHON=æŒ‡å®šçš„pythonè·¯å¾„export PYSPARK_DRIVER_PYTHON=æŒ‡å®šçš„pythonè·¯å¾„ ä¿å­˜åsourceä¸€ä¸‹ /etc/profile ,ä½¿ä¹‹ç”Ÿæ•ˆ 2.ä»£ç å†…æŒ‡å®š 12os.environ[&quot;PYSPARK_DRIVER_PYTHON&quot;]=&quot;&quot; ##driver os.environ[&quot;PYSPARK_PYTHON&quot;]=&quot;&quot; ### worker ,excutor æ–¹æ³•äºŒï¼šspark-submitå·¥å…·æŒ‡å®š åœ¨spark-submitæ—¶å¢åŠ å‚æ•° --conf spark.pyspark.pythonå’Œ --conf spark.pyspark.driver.python 123spark-submit \\--driver-memory 5g --num-executors 5 --executor-cores 1 --executor-memory 1G --conf spark.pyspark.python=./.../bin/python --conf spark.pyspark.driver.python=./.../bin/python xx.py spark.sql ä¸èƒ½æŸ¥è¯¢åˆ°hiveçš„æ•°æ®åº“ï¼ŒåªæŸ¥è¯¢åˆ°defaultæ•°æ®åº“è¯´æ˜sparkæ²¡æœ‰è¿æ¥åˆ°hive https://www.cnblogs.com/yjt1993/p/13963144.html","link":"/2022/03/09/spark-error/"},{"title":"sparkäº¤äº’å·¥å…·","text":"https://blog.csdn.net/u010886217/article/details/82916401 spark-shellã€spark-sqlï¼Œthriftserver","link":"/2022/03/19/spark-intercation-tool/"},{"title":"æ•°æ®åˆ’åˆ†,rddåˆ†åŒº","text":"1 applicationï¼Œjobï¼Œstageï¼Œtask 0 application ä»»åŠ¡ 1 Job ä¸€ä¸ªaction ä¸€ä¸ªjob 2 Stage ä¸€ä¸ªjobåŒ…å«ä¸€ä¸ªæˆ–è€…å¤šä¸ªstageï¼Œæ ¹æ®rddçš„ä¾èµ–å…³ç³»æ„å»ºdagï¼Œæ ¹æ®dagåˆ’åˆ†stage 3 Task 1ä¸ªstageåŒ…å«1ä¸ªæˆ–è€…å¤šä¸ªtask Taskçš„ç±»å‹åˆ†ä¸º2ç§ï¼šShuffleMapTaskå’ŒResultTask ShuffleMapTaskè¦è¿›è¡ŒShuffleï¼ŒResultTaskè´Ÿè´£è¿”å›è®¡ç®—ç»“æœï¼Œä¸€ä¸ªJobä¸­åªæœ‰æœ€åçš„Stageé‡‡ç”¨ResultTaskï¼Œå…¶ä»–çš„å‡ä¸ºShuffleMapTaskã€‚å¦‚æœè¦æŒ‰ç…§mapç«¯å’Œreduceç«¯æ¥åˆ†æçš„è¯ï¼ŒShuffleMapTaskå¯ä»¥å³æ˜¯mapç«¯ä»»åŠ¡ï¼Œåˆæ˜¯reduceç«¯ä»»åŠ¡ï¼Œå› ä¸ºSparkä¸­çš„Shuffleæ˜¯å¯ä»¥ä¸²è¡Œçš„ï¼›ResultTaskåˆ™åªèƒ½å……å½“reduceç«¯ä»»åŠ¡çš„è§’è‰²ã€‚ 2 rddåˆ†åŒº recordå°±æ˜¯è®°å½• 2 ä¸ºä»€ä¹ˆåˆ†åŒºï¼Ÿ åˆ†åŒºçš„ä¸»è¦ä½œç”¨æ˜¯ç”¨æ¥å®ç°å¹¶è¡Œè®¡ç®—ï¼Œæé«˜æ•ˆç‡ 3 åˆ†åŒºæ–¹å¼ SparkåŒ…å«ä¸¤ç§æ•°æ®åˆ†åŒºæ–¹å¼ï¼šHashPartitionerï¼ˆå“ˆå¸Œåˆ†åŒºï¼‰å’ŒRangePartitionerï¼ˆèŒƒå›´åˆ†åŒºï¼‰ã€‚ 4 åˆ†åŒºæ•°è®¾ç½® https://justdodt.github.io/2018/04/23/Spark-RDD-%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F%E7%A1%AE%E5%AE%9A/ 3 å…³ç³» taskæ•°é‡å’ŒPartitionæ•°é‡ä¸€æ · å‚è€ƒhttps://www.jianshu.com/p/3aa52ee3a802 https://blog.csdn.net/hjw199089/article/details/77938688 https://blog.csdn.net/mys_35088/article/details/80864092 https://blog.csdn.net/dmy1115143060/article/details/82620715 https://blog.csdn.net/xxd1992/article/details/85254666 https://blog.csdn.net/m0_46657040/article/details/108737350 https://blog.csdn.net/heiren_a/article/details/111954523 https://blog.csdn.net/u011564172/article/details/53611109 https://blog.csdn.net/qq_22473611/article/details/107822168 https://www.jianshu.com/p/3aa52ee3a802","link":"/2022/02/26/spark-job_partition/"},{"title":"sparkæ¨¡å—","text":"æ•´ä¸ªSpark æ¡†æ¶æ¨¡å—åŒ…å«ï¼šSpark Coreã€Spark SQLã€Spark Streamingã€Spark GraphXã€Spark MLlibï¼Œè€Œåå››é¡¹çš„èƒ½åŠ›éƒ½æ˜¯å»ºç«‹åœ¨æ ¸å¿ƒå¼•æ“ä¹‹ä¸Š Spark Coreï¼šSparkçš„æ ¸å¿ƒï¼ŒSparkæ ¸å¿ƒåŠŸèƒ½å‡ç”±Spark Coreæ¨¡å—æä¾›ï¼Œæ˜¯Sparkè¿è¡Œçš„åŸºç¡€ã€‚Spark Coreä»¥RDDä¸ºæ•°æ®æŠ½è±¡ï¼Œæä¾›Pythonã€Javaã€Scalaã€Rè¯­è¨€çš„APIï¼Œå¯ä»¥ç¼–ç¨‹è¿›è¡Œæµ·é‡ç¦»çº¿æ•°æ®æ‰¹å¤„ç†è®¡ç®—ã€‚SparkSQLï¼šåŸºäºSparkCoreä¹‹ä¸Šï¼Œæä¾›ç»“æ„åŒ–æ•°æ®çš„å¤„ç†æ¨¡å—ã€‚SparkSQLæ”¯æŒä»¥SQLè¯­è¨€å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼ŒSparkSQLæœ¬èº«é’ˆå¯¹ç¦»çº¿è®¡ç®—åœºæ™¯ã€‚åŒæ—¶åŸºäºSparkSQLï¼ŒSparkæä¾›äº†StructuredStreamingæ¨¡å—ï¼Œå¯ä»¥ä»¥SparkSQLä¸ºåŸºç¡€ï¼Œè¿›è¡Œæ•°æ®çš„æµå¼è®¡ç®—ã€‚ æ•°æ®æŠ½è±¡:dataset(Javaã€Scala) dataframe(Javaã€Scalaã€Pythonã€R)SparkStreamingï¼šä»¥SparkCoreä¸ºåŸºç¡€ï¼Œæä¾›æ•°æ®çš„æµå¼è®¡ç®—åŠŸèƒ½ã€‚MLlibï¼šä»¥SparkCoreä¸ºåŸºç¡€ï¼Œè¿›è¡Œæœºå™¨å­¦ä¹ è®¡ç®—ï¼Œå†…ç½®äº†å¤§é‡çš„æœºå™¨å­¦ä¹ åº“å’ŒAPIç®—æ³•ç­‰ã€‚æ–¹ä¾¿ç”¨æˆ·ä»¥åˆ†å¸ƒå¼è®¡ç®—çš„æ¨¡å¼è¿›è¡Œæœºå™¨å­¦ä¹ è®¡ç®—ã€‚GraphXï¼šä»¥SparkCoreä¸ºåŸºç¡€ï¼Œè¿›è¡Œå›¾è®¡ç®—ï¼Œæä¾›äº†å¤§é‡çš„å›¾è®¡ç®—APIï¼Œæ–¹ä¾¿ç”¨äºä»¥åˆ†å¸ƒå¼è®¡ç®—æ¨¡å¼è¿›è¡Œå›¾è®¡ç®—ã€‚","link":"/2022/02/26/spark-module/"},{"title":"spark oom(out of memory)é—®é¢˜","text":"https://blog.csdn.net/yhb315279058/article/details/51035631 https://www.cnblogs.com/yanshw/p/11988347.html 1 driverå†…å­˜ä¸å¤Ÿå¢åŠ  Driver å†…å­˜ 1--driver-memory MEM Memory for driver (e.g. 1000M, 2G) (Default: 1024M). 1 è¯»å…¥æ•°æ®å¤ªå¤§ è§£å†³æ€è·¯æ˜¯å¢åŠ  Driver å†…å­˜ 12345from pyspark import SparkContextsc = SparkContext(master='yarn')rdd = sc.parallelize(range(300000000))# spark-submit --master yarn-client --driver-memory 512M driver_oom.py å†…å­˜æº¢å‡º# spark-submit --master yarn-client --driver-memory 3G driver_oom.py å¯ä»¥æ‰§è¡Œ 2 æ•°æ®å›ä¼ å¤ªå¤§ï¼Œä¹Ÿå°±æ˜¯èšåˆåˆ°driverçš„æ•°æ®å¤ªå¤§ è§£å†³æ€è·¯æ˜¯åˆ†åŒºè¾“å‡ºï¼Œå…·ä½“åšæ³•æ˜¯ foreach 12345rdd = sc.parallelize(range(100))rdd.flatMap(lambda x: ['%d'%x*50 for _ in range(100000)]).collect() # å†…å­˜æº¢å‡ºdef func(x): print(x)rdd.flatMap(lambda x: ['%d'%x*50 for _ in range(100000)]).foreach(func) # åˆ†åŒºè¾“å‡º 2 excutorå†…å­˜ä¸å¤Ÿé€šç”¨çš„è§£å†³åŠæ³•å°±æ˜¯å¢åŠ  Executor å†…å­˜ ä½†è¿™å¹¶ä¸ä¸€å®šæ˜¯æœ€å¥½çš„åŠæ³• 1 map è¿‡ç¨‹äº§ç”Ÿå¤§é‡å¯¹è±¡ è§£å†³æ€è·¯æ˜¯å‡å°‘æ¯ä¸ª task çš„å¤§å°ï¼Œä»è€Œå‡å°‘æ¯ä¸ª task çš„è¾“å‡º å…·ä½“åšæ³•æ˜¯åœ¨ ä¼šäº§ç”Ÿå¤§é‡å¯¹è±¡çš„ map æ“ä½œå‰ æ·»åŠ  repartition(é‡æ–°åˆ†åŒº) æ–¹æ³•ï¼Œåˆ†åŒºæˆæ›´å°çš„å—ä¼ å…¥ map 1234rdd.flatMap(lambda x: ['%d'%x*50 for _ in range(100000000)]).count() # 100 * 100000000 ä¸ªå¯¹è±¡ï¼Œå†…å­˜æº¢å‡ºrdd.flatMap(lambda x: len(['%d'%x*50 for _ in range(100000000)])).sum() # å†…å­˜æº¢å‡ºrdd.repartition(1000000).flatMap(lambda x: ['%d'%x*50 for _ in range(100000000)]).count() 2 shuffleå¯¼è‡´ shuffleå†…å­˜æº¢å‡ºçš„æƒ…å†µå¯ä»¥è¯´éƒ½æ˜¯shuffleåå‘ç”Ÿæ•°æ®å€¾æ–œï¼Œå•ä¸ªæ–‡ä»¶è¿‡å¤§å¯¼è‡´ å‚è€ƒæ•°æ®å€¾æ–œè§£å†³æ–¹æ¡ˆ","link":"/2022/04/05/spark-oom/"},{"title":"sparkä¼˜åŒ–","text":"8 Performance Optimization Techniques Using Spark https://www.syntelli.com/eight-performance-optimization-techniques-using-spark# Sparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—ï¼ˆç¾å›¢ï¼‰ https://tech.meituan.com/2016/04/29/spark-tuning-basic.html https://tech.meituan.com/2016/05/12/spark-tuning-pro.html","link":"/2022/01/05/spark-optimaization/"},{"title":"sparkä¼˜åŒ–æ‰‹æ®µ","text":"1.å¤šä¸ªmapåˆå¹¶ï¼ˆå­˜ç–‘ï¼‰1rdd1.map().map() -&gt; rdd1.map() 2.å‡å°‘jobæ•°é‡ä¹Ÿå°±æ˜¯å‡å°‘action è¯´ç™½äº†å°±æ˜¯å¤šä¸ªactionæ“ä½œï¼Œtransformationé€»è¾‘å¯ä»¥å†™ä¸€èµ·ï¼Œæœ€åaction 3 å¹¿æ’­å¤§å˜é‡é¦–å…ˆå¹¿æ’­æ˜¯æ“ä½œï¼Œå¤§å˜é‡æ˜¯å¯¹è±¡","link":"/2022/04/19/spark-optimazation-operation/"},{"title":"æ•°æ®æŠ½è±¡","text":"1.RDDï¼ŒDataFrameï¼ŒDatasethttps://blog.knoldus.com/spark-rdd-vs-dataframes/ https://blog.csdn.net/hellozhxy/article/details/82660610 https://www.cnblogs.com/lestatzhang/p/10611320.html#Spark_16 https://www.jianshu.com/p/77811ae29fdd https://zhuanlan.zhihu.com/p/379578271 https://spark.apache.org/docs/3.2.0/sql-programming-guide.html#content 1 DataFrame å’Œ RDDs åº”è¯¥å¦‚ä½•é€‰æ‹©ï¼ŸDataFrame å’Œ RDDs æœ€ä¸»è¦çš„åŒºåˆ«åœ¨äºä¸€ä¸ªé¢å‘çš„æ˜¯ç»“æ„åŒ–æ•°æ®ï¼Œä¸€ä¸ªé¢å‘çš„æ˜¯éç»“æ„åŒ–æ•°æ® å¦‚æœä½ çš„æ•°æ®æ˜¯ç»“æ„åŒ–çš„ (å¦‚ RDBMS ä¸­çš„æ•°æ®) æˆ–è€…åŠç»“æ„åŒ–çš„ (å¦‚æ—¥å¿—)ï¼Œå‡ºäºæ€§èƒ½ä¸Šçš„è€ƒè™‘ï¼Œåº”ä¼˜å…ˆä½¿ç”¨ DataFrameã€‚ å¦‚æœä½ çš„æ•°æ®æ˜¯éç»“æ„åŒ–çš„ (æ¯”å¦‚æµåª’ä½“æˆ–è€…å­—ç¬¦æµ)ï¼Œåˆ™ä½¿ç”¨ RDDsï¼Œ 2 ä¸ºä»€ä¹ˆå‡ºç°Datasetï¼Ÿ1.ç›¸æ¯”DataFrameï¼ŒDatasetæä¾›äº†ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥ï¼Œå¯¹äºåˆ†å¸ƒå¼ç¨‹åºæ¥è®²ï¼Œæäº¤ä¸€æ¬¡ä½œä¸šå¤ªè´¹åŠ²äº†ï¼ˆè¦ç¼–è¯‘ã€æ‰“åŒ…ã€ä¸Šä¼ ã€è¿è¡Œï¼‰ï¼Œåˆ°æäº¤åˆ°é›†ç¾¤è¿è¡Œæ—¶æ‰å‘ç°é”™è¯¯ï¼Œå®åœ¨æ˜¯æƒ³éª‚äººï¼Œè¿™ä¹Ÿæ˜¯å¼•å…¥Datasetçš„ä¸€ä¸ªé‡è¦åŸå› ã€‚ 2.RDDè½¬æ¢DataFrameåä¸å¯é€†ï¼Œä½†RDDè½¬æ¢Datasetæ˜¯å¯é€†çš„ï¼ˆè¿™ä¹Ÿæ˜¯Datasetäº§ç”Ÿçš„åŸå› ï¼‰ æ³¨æ„ï¼š The Dataset API is available in Scala and Java. Python does not have the support for the Dataset API. But due to Pythonâ€™s dynamic nature, many of the benefits of the Dataset API are already available (i.e. you can access the field of a row by name naturally row.columnName). 2.RDDç®—å­å°±æ˜¯åˆ†å¸ƒå¼é›†åˆå¯¹è±¡çš„api rddç®—å­åˆ†ä¸ºä¸¤ç±»ï¼š1.transformation 2.action https://blog.csdn.net/weixin_45271668/article/details/106441457 3.dataframeDataFrameæ”¯æŒä¸¤ç§é£æ ¼è¿›è¡Œç¼–ç¨‹ï¼Œåˆ†åˆ«æ˜¯ï¼š 1 DSLé£æ ¼DSLç§°ä¹‹ä¸ºï¼šé¢†åŸŸç‰¹å®šè¯­è¨€ã€‚å…¶å®å°±æ˜¯æŒ‡DataFrameçš„ç‰¹æœ‰APIDSLé£æ ¼æ„æ€å°±æ˜¯ä»¥è°ƒç”¨APIçš„æ–¹å¼æ¥å¤„ç†Dataæ¯”å¦‚ï¼šdf.where().limit() 2 SQLé£æ ¼SQLè¯­æ³•é£æ ¼SQLé£æ ¼å°±æ˜¯ä½¿ç”¨SQLè¯­å¥å¤„ç†DataFrameçš„æ•°æ®æ¯”å¦‚ï¼šspark.sql(â€œSELECT * FROM xxx)","link":"/2022/01/25/spark-rdd/"},{"title":"shuffle","text":"https://www.cnblogs.com/arachis/p/Spark_Shuffle.html https://zhuanlan.zhihu.com/p/70331869 https://www.educba.com/spark-shuffle/ https://lmrzero.blog.csdn.net/article/details/106015264?spm=1001.2014.3001.5502 https://blog.csdn.net/zp17834994071/article/details/107887292 https://zhuanlan.zhihu.com/p/431015932 0 shuffleæ˜¯ä»€ä¹ˆï¼Œä»€ä¹ˆæ—¶å€™shuffle whatï¼šå¤šä¸ªpartitionçš„æ•°æ®æµå‘ä¸€ä¸ªpartition whenï¼šå®½ä¾èµ–ä¼šæœ‰shuffle shuffleåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šshuffle read ï¼Œ shuffle write mapç«¯-ã€‹shuffle read-ã€‹ shuffle write-ã€‹reduceç«¯ 1 mapreduce shuffle 2 spark shuffle1 ç®€ä»‹ 2 åˆ†ç±»https://www.51cto.com/article/703950.html# è¿‡å»hash shuffle ï¼Œç°åœ¨sort shuffle 1.Hash Shuffle 2.Sort Shuffle1 æ™®é€šæœºåˆ¶çš„SortShuffleManager 2 bypass æ­¤æ—¶taskä¼šä¸ºæ¯ä¸ªreduceç«¯çš„taskéƒ½åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç£ç›˜æ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®æŒ‰keyè¿›è¡Œhashï¼Œç„¶åæ ¹æ®keyçš„hashå€¼ï¼Œå°†keyå†™å…¥å¯¹åº”çš„ç£ç›˜æ–‡ä»¶ä¹‹ä¸­ã€‚å½“ç„¶ï¼Œå†™å…¥ç£ç›˜æ–‡ä»¶æ—¶ä¹Ÿæ˜¯å…ˆå†™å…¥å†…å­˜ç¼“å†²ï¼Œç¼“å†²å†™æ»¡ä¹‹åå†æº¢å†™åˆ°ç£ç›˜æ–‡ä»¶çš„ã€‚æœ€åï¼ŒåŒæ ·ä¼šå°†æ‰€æœ‰ä¸´æ—¶ç£ç›˜æ–‡ä»¶éƒ½åˆå¹¶æˆä¸€ä¸ªç£ç›˜æ–‡ä»¶ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„ç´¢å¼•æ–‡ä»¶ã€‚ è¯¥è¿‡ç¨‹çš„ç£ç›˜å†™æœºåˆ¶å…¶å®è·Ÿæœªç»ä¼˜åŒ–çš„HashShuffleManageræ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œå› ä¸ºéƒ½è¦åˆ›å»ºæ•°é‡æƒŠäººçš„ç£ç›˜æ–‡ä»¶ï¼Œåªæ˜¯åœ¨æœ€åä¼šåšä¸€ä¸ªç£ç›˜æ–‡ä»¶çš„åˆå¹¶è€Œå·²ã€‚å› æ­¤å°‘é‡çš„æœ€ç»ˆç£ç›˜æ–‡ä»¶ï¼Œä¹Ÿè®©è¯¥æœºåˆ¶ç›¸å¯¹æœªç»ä¼˜åŒ–çš„HashShuffleManageræ¥è¯´ï¼Œshuffle readçš„æ€§èƒ½ä¼šæ›´å¥½ã€‚ 3 æ€»ç»“ bypassä¸æ™®é€šSortShuffleManagerè¿è¡Œæœºåˆ¶çš„ä¸åŒåœ¨äºï¼šç¬¬ä¸€ï¼Œç£ç›˜å†™æœºåˆ¶ä¸åŒ;ç¬¬äºŒï¼Œä¸ä¼šè¿›è¡Œæ’åºã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯ç”¨è¯¥æœºåˆ¶çš„æœ€å¤§å¥½å¤„åœ¨äºï¼Œshuffle writeè¿‡ç¨‹ä¸­ï¼Œä¸éœ€è¦è¿›è¡Œæ•°æ®çš„æ’åºæ“ä½œï¼Œä¹Ÿå°±èŠ‚çœæ‰äº†è¿™éƒ¨åˆ†çš„æ€§èƒ½å¼€é”€ã€‚ 3 å¯¹æ¯”https://www.zhihu.com/question/27643595 4 ä¼˜åŒ–å› æ­¤åœ¨æˆ‘ä»¬çš„å¼€å‘è¿‡ç¨‹ä¸­ï¼Œèƒ½é¿å…åˆ™å°½å¯èƒ½é¿å…ä½¿ç”¨ä¼šè¿›è¡Œshuffleçš„ç®—å­ï¼Œå°½é‡ä½¿ç”¨éshuffleç®—å­ 1 shuffleç®—å­ï¼š https://blog.csdn.net/py_tamir/article/details/95457813 reduceByKeyã€joinã€distinctã€repartition 2 éshuffleç®—å­ mapï¼ŒflatMap","link":"/2022/01/19/spark-shuffle/"},{"title":"Sparkæ”¯æŒçš„å­˜å‚¨ä»‹è´¨","text":"Spark æ”¯æŒå¤šç§çš„å­˜å‚¨ä»‹è´¨ï¼Œåœ¨å­˜å‚¨å±‚ Spark æ”¯æŒä» HDFSã€HBaseã€Hiveã€ESã€MongoDBã€MySQLã€PostgreSQLã€AWSã€Ali Cloud ç­‰ä¸åŒçš„å­˜å‚¨ç³»ç»Ÿã€å¤§æ•°æ®åº“ã€å…³ç³»å‹æ•°æ®åº“ä¸­è¯»å…¥å’Œå†™å‡ºæ•°æ®ï¼Œåœ¨å®æ—¶æµè®¡ç®—ä¸­å¯ä»¥ä» Flumeã€Kafka ç­‰å¤šç§æ•°æ®æºè·å–æ•°æ®å¹¶æ‰§è¡Œæµå¼è®¡ç®—ã€‚ https://cloud.tencent.com/developer/article/1942980","link":"/2022/02/21/spark-store/"},{"title":"Sparkæ¶æ„","text":"https://zhuanlan.zhihu.com/p/70424613 https://zhuanlan.zhihu.com/p/348024116 https://spark.apache.org/docs/latest/cluster-overview.html https://www.zhihu.com/question/437293024 There are several useful things to note about this architecture: Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads. This has the benefit of isolating applications from each other, on both the scheduling side (each driver schedules its own tasks) and executor side (tasks from different applications run in different JVMs). However, it also means that data cannot be shared across different Spark applications (instances of SparkContext) without writing it to an external storage system. Spark is agnostic to the underlying cluster manager. As long as it can acquire executor processes, and these communicate with each other, it is relatively easy to run it even on a cluster manager that also supports other applications (e.g. Mesos/YARN/Kubernetes). The driver program must listen for and accept incoming connections from its executors throughout its lifetime (e.g., see spark.driver.port in the network config section). As such, the driver program must be network addressable from the worker nodes. Because the driver schedules tasks on the cluster, it should be run close to the worker nodes, preferably on the same local area network. If youâ€™d like to send requests to the cluster remotely, itâ€™s better to open an RPC to the driver and have it submit operations from nearby than to run a driver far away from the worker nodes. ä¸Šå›¾çš„4ä¸ªæ¡†åº”è¯¥ä¸æ˜¯æŒ‡å››å°æœºå™¨ï¼Œä»…ä»…ç”¨æ¥ç¤ºæ„sparkçš„æ¶æ„ç»„æˆï¼Œåœ¨æœºå™¨ä¸Šçš„åˆ†å¸ƒå–å†³äºéƒ¨ç½²æ–¹å¼ å®¢æˆ·ç«¯/å®¢æˆ·æœºæŒ‡çš„æ˜¯æäº¤ä»»åŠ¡çš„æœºå™¨ ä¸»ä»æ¶æ„ï¼ˆmaster/slaveï¼‰ï¼šé›†ç¾¤ç”±ä¸€ä¸ªä¸»æœåŠ¡å™¨å’Œè‹¥å¹²ä¸ªä»æœåŠ¡å™¨ï¼ˆæœºå™¨ï¼‰ç»„æˆ ä¸€ä¸ªworkerå¯ä»¥æœ‰å¤šä¸ªexcutorï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåªä¼šå¯åŠ¨ä¸€ä¸ªExecutor https://www.cnblogs.com/ExMan/p/14358363.html ä¸€ä¸ªexecutorå¯ä»¥æ‰§è¡Œå¤šä¸ªtaskï¼Œå–å†³äºcpuçš„æ ¸æ•° https://blog.csdn.net/mzqadl/article/details/104217828","link":"/2022/01/05/spark-struct/"},{"title":"æäº¤Sparkä»»åŠ¡","text":"1.spark-submithttps://spark.apache.org/docs/latest/submitting-applications.html The spark-submit script in Sparkâ€™s bin directory is used to launch applications on a cluster. It can use all of Sparkâ€™s supported cluster managers through a uniform interface so you donâ€™t have to configure your application especially for each one. 12345678./bin/spark-submit \\ --class &lt;main-class&gt; \\ --master &lt;master-url&gt; \\ --deploy-mode &lt;deploy-mode&gt; \\ --conf &lt;key&gt;=&lt;value&gt; \\ ... # other options &lt;application-jar&gt; \\ [application-arguments] --class: The entry point for your application (e.g. org.apache.spark.examples.SparkPi) --master: The master URL for the cluster (e.g. spark://23.195.26.187:7077) --deploy-mode: Whether to deploy your driver on the worker nodes (cluster) or locally as an external client (client) (default: client) â€  --conf: Arbitrary Spark configuration property in key=value format. For values that contain spaces wrap â€œkey=valueâ€ in quotes (as shown). Multiple configurations should be passed as separate arguments. (e.g. --conf = --conf =) application-jar: Path to a bundled jar including your application and all dependencies. The URL must be globally visible inside of your cluster, for instance, an hdfs:// path or a file:// path that is present on all nodes. application-arguments: Arguments passed to the main method of your main class, if any å½“å‰ä¸ºå®¢æˆ·ç«¯ï¼Œdriveråœ¨å“ªå–å†³äºdeploy mode 2.run file.pyå½“å‰ä¸ºå®¢æˆ·æœºï¼Œè€Œä¸”è¿™ç§æ–¹å¼é»˜è®¤driveråœ¨å®¢æˆ·æœºï¼Œä¹Ÿå°±æ˜¯clientæ¨¡å¼ æ­¤æ—¶è‹¥æ˜¯ä»£ç æŒ‡å®šclusterä¼šæŠ¥é”™ 1config(&quot;spark.submit.deployMode&quot;, &quot;cluster&quot;) Exception in thread â€œmainâ€ org.apache.spark.SparkException: Cluster deploy mode is not applicable to Spark shells.","link":"/2022/02/17/spark-task/"},{"title":"RDDä¾èµ–å…³ç³»","text":"ä¸ºä»€ä¹ˆè¦æå‡ºå®½çª„ä¾èµ–æ ¹æ®rddçš„ä¾èµ–å…³ç³»æ„å»ºdagï¼Œæ ¹æ®dagåˆ’åˆ†stage å¦‚ä½•åŒºåˆ«å®½çª„ä¾èµ– çˆ¶rdd -&gt; å­rddï¼Œ è“è‰²æ¡†æ˜¯rddåˆ†åŒº unionï¼š2ä¸ªçˆ¶rdd -&gt; 1ä¸ªå­rdd åŒºåˆ†å®½çª„ä¾èµ–ä¸»è¦å°±æ˜¯çœ‹çˆ¶RDDæ•°æ®æµå‘ï¼Œè¦æ˜¯æµå‘ä¸€ä¸ªçš„è¯å°±æ˜¯çª„ä¾èµ–ï¼Œæµå‘å¤šä¸ªçš„è¯å°±æ˜¯å®½ä¾èµ–ã€‚ åˆ’åˆ†stagehttps://blog.csdn.net/weixin_40271036/article/details/79996516 æ•´ä½“æ€è·¯æ˜¯ï¼šä»åå¾€å‰æ¨ï¼Œé‡åˆ°å®½ä¾èµ–å°±æ–­å¼€ï¼Œåˆ’åˆ†ä¸ºä¸€ä¸ªstageï¼›é‡åˆ°çª„ä¾èµ–å°±å°†è¿™ä¸ªRDDåŠ å…¥è¯¥stageä¸­ å‚è€ƒhttps://www.jianshu.com/p/5c2301dfa360 https://zhuanlan.zhihu.com/p/67068559 https://blog.csdn.net/m0_49834705/article/details/113111596 https://lmrzero.blog.csdn.net/article/details/106015264?spm=1001.2014.3001.5502","link":"/2022/01/19/spark-wide-narrow-dependancy/"},{"title":"sparkèµ„æºå‚æ•°è°ƒä¼˜","text":"æ¦‚å¿µå¹¶å‘ï¼šè°ƒåº¦å™¨åˆ‡æ¢CPUç»™ä¸åŒè¿›ç¨‹ä½¿ç”¨ï¼Œå®é™…ä¸ŠCPUåœ¨åŒä¸€æ—¶åˆ»åªåœ¨è¿è¡Œä¸€ä¸ªè¿›ç¨‹ å¹¶è¡Œï¼š 1ã€ä¸€å°ç‰©ç†æœºçš„ç‰©ç†CPUçš„ä¸ªæ•° 2ã€ä¸€ä¸ªCPUä¸Šçš„æ ¸æ•° 3ã€ä¸€ä¸ªæ ¸ä¸Šé¢æ”¯æŒçš„çº¿ç¨‹æ•°ï¼ˆé€»è¾‘cpuï¼‰ 123456789101112131415# æŸ¥çœ‹CPUä¿¡æ¯ï¼ˆå‹å·ï¼‰cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz # æŸ¥çœ‹ç‰©ç†CPUä¸ªæ•° cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l2 # æŸ¥çœ‹æ¯ä¸ªç‰©ç†CPUä¸­coreçš„ä¸ªæ•°(å³æ ¸æ•°) cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniqcpu cores : 6 # æŸ¥çœ‹é€»è¾‘CPUçš„ä¸ªæ•°cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l24 è¿›ç¨‹ï¼ˆè¦æ‹¿cpuä¸ºå•ä½ï¼‰ï¼šå•CPUä¸­è¿›ç¨‹åªèƒ½æ˜¯å¹¶å‘ï¼Œå¤šCPUè®¡ç®—æœºä¸­è¿›ç¨‹å¯ä»¥å¹¶è¡Œã€‚ çº¿ç¨‹ï¼ˆæ ¸ä½œä¸ºå•ä½ï¼‰ï¼šå•CPUå•æ ¸ä¸­çº¿ç¨‹åªèƒ½å¹¶å‘ï¼Œå•CPUå¤šæ ¸ä¸­çº¿ç¨‹å¯ä»¥å¹¶è¡Œ å‚æ•°taskçš„æ‰§è¡Œé€Ÿåº¦æ˜¯è·Ÿæ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡æœ‰ç›´æ¥å…³ç³»çš„ã€‚ä¸€ä¸ªCPU coreåŒä¸€æ—¶é—´åªèƒ½æ‰§è¡Œä¸€ä¸ªçº¿ç¨‹ã€‚è€Œæ¯ä¸ªExecutorè¿›ç¨‹ä¸Šåˆ†é…åˆ°çš„å¤šä¸ªtaskï¼Œéƒ½æ˜¯ä»¥æ¯ä¸ªtaskä¸€æ¡çº¿ç¨‹çš„æ–¹å¼ï¼Œå¤šçº¿ç¨‹å¹¶å‘è¿è¡Œçš„ã€‚å¦‚æœCPU coreæ•°é‡æ¯”è¾ƒå……è¶³ï¼Œè€Œä¸”åˆ†é…åˆ°çš„taskæ•°é‡æ¯”è¾ƒåˆç†ï¼Œé‚£ä¹ˆé€šå¸¸æ¥è¯´ï¼Œå¯ä»¥æ¯”è¾ƒå¿«é€Ÿå’Œé«˜æ•ˆåœ°æ‰§è¡Œå®Œè¿™äº›taskçº¿ç¨‹ã€‚ worker: å‡ ä¸ªæ‰§è¡ŒèŠ‚ç‚¹ ï¼Œä¸€ä¸ªworker å¯¹åº”å‡ ä¸ª executor executorï¼šå¯¹åº”è¿›ç¨‹ num-executors å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®Sparkä½œä¸šæ€»å…±è¦ç”¨å¤šå°‘ä¸ªExecutorè¿›ç¨‹æ¥æ‰§è¡Œã€‚Driveråœ¨å‘YARNé›†ç¾¤ç®¡ç†å™¨ç”³è¯·èµ„æºæ—¶ï¼ŒYARNé›†ç¾¤ç®¡ç†å™¨ä¼šå°½å¯èƒ½æŒ‰ç…§ä½ çš„è®¾ç½®æ¥åœ¨é›†ç¾¤çš„å„ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œå¯åŠ¨ç›¸åº”æ•°é‡çš„Executorè¿›ç¨‹ã€‚è¿™ä¸ªå‚æ•°éå¸¸ä¹‹é‡è¦ï¼Œå¦‚æœä¸è®¾ç½®çš„è¯ï¼Œé»˜è®¤åªä¼šç»™ä½ å¯åŠ¨å°‘é‡çš„Executorè¿›ç¨‹ï¼Œæ­¤æ—¶ä½ çš„Sparkä½œä¸šçš„è¿è¡Œé€Ÿåº¦æ˜¯éå¸¸æ…¢çš„ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šæ¯ä¸ªSparkä½œä¸šçš„è¿è¡Œä¸€èˆ¬è®¾ç½®50~100ä¸ªå·¦å³çš„Executorè¿›ç¨‹æ¯”è¾ƒåˆé€‚ï¼Œè®¾ç½®å¤ªå°‘æˆ–å¤ªå¤šçš„Executorè¿›ç¨‹éƒ½ä¸å¥½ã€‚è®¾ç½®çš„å¤ªå°‘ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨é›†ç¾¤èµ„æºï¼›è®¾ç½®çš„å¤ªå¤šçš„è¯ï¼Œå¤§éƒ¨åˆ†é˜Ÿåˆ—å¯èƒ½æ— æ³•ç»™äºˆå……åˆ†çš„èµ„æºã€‚ executor-cores å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡ã€‚è¿™ä¸ªå‚æ•°å†³å®šäº†æ¯ä¸ªExecutorè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œtaskçº¿ç¨‹çš„èƒ½åŠ›ã€‚å› ä¸ºæ¯ä¸ªCPU coreåŒä¸€æ—¶é—´åªèƒ½æ‰§è¡Œä¸€ä¸ªtaskçº¿ç¨‹ï¼Œå› æ­¤æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡è¶Šå¤šï¼Œè¶Šèƒ½å¤Ÿå¿«é€Ÿåœ°æ‰§è¡Œå®Œåˆ†é…ç»™è‡ªå·±çš„æ‰€æœ‰taskçº¿ç¨‹ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šExecutorçš„CPU coreæ•°é‡è®¾ç½®ä¸º2~4ä¸ªè¾ƒä¸ºåˆé€‚ã€‚åŒæ ·å¾—æ ¹æ®ä¸åŒéƒ¨é—¨çš„èµ„æºé˜Ÿåˆ—æ¥å®šï¼Œå¯ä»¥çœ‹çœ‹è‡ªå·±çš„èµ„æºé˜Ÿåˆ—çš„æœ€å¤§CPU coreé™åˆ¶æ˜¯å¤šå°‘ï¼Œå†ä¾æ®è®¾ç½®çš„Executoræ•°é‡ï¼Œæ¥å†³å®šæ¯ä¸ªExecutorè¿›ç¨‹å¯ä»¥åˆ†é…åˆ°å‡ ä¸ªCPU coreã€‚åŒæ ·å»ºè®®ï¼Œå¦‚æœæ˜¯è·Ÿä»–äººå…±äº«è¿™ä¸ªé˜Ÿåˆ—ï¼Œé‚£ä¹ˆnum-executors * executor-coresä¸è¦è¶…è¿‡é˜Ÿåˆ—æ€»CPU coreçš„1/3~1/2å·¦å³æ¯”è¾ƒåˆé€‚ï¼Œä¹Ÿæ˜¯é¿å…å½±å“å…¶ä»–åŒå­¦çš„ä½œä¸šè¿è¡Œã€‚ task:çº¿ç¨‹ï¼Œåº”è¯¥ç­‰äºpartitionæ•°é‡ jobæ•°é‡å–å†³äºactionæ•°é‡ï¼Œstageæ•°é‡å–å†³äºrddä¾èµ–å…³ç³»çš„åˆ’åˆ† spark.default.parallelism å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªstageçš„é»˜è®¤taskæ•°é‡ã€‚è¿™ä¸ªå‚æ•°æä¸ºé‡è¦ï¼Œå¦‚æœä¸è®¾ç½®å¯èƒ½ä¼šç›´æ¥å½±å“ä½ çš„Sparkä½œä¸šæ€§èƒ½ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šSparkä½œä¸šçš„é»˜è®¤taskæ•°é‡ä¸º500~1000ä¸ªè¾ƒä¸ºåˆé€‚ã€‚å¾ˆå¤šåŒå­¦å¸¸çŠ¯çš„ä¸€ä¸ªé”™è¯¯å°±æ˜¯ä¸å»è®¾ç½®è¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆæ­¤æ—¶å°±ä¼šå¯¼è‡´Sparkè‡ªå·±æ ¹æ®åº•å±‚HDFSçš„blockæ•°é‡æ¥è®¾ç½®taskçš„æ•°é‡ï¼Œé»˜è®¤æ˜¯ä¸€ä¸ªHDFS blockå¯¹åº”ä¸€ä¸ªtaskã€‚é€šå¸¸æ¥è¯´ï¼ŒSparké»˜è®¤è®¾ç½®çš„æ•°é‡æ˜¯åå°‘çš„ï¼ˆæ¯”å¦‚å°±å‡ åä¸ªtaskï¼‰ï¼Œå¦‚æœtaskæ•°é‡åå°‘çš„è¯ï¼Œå°±ä¼šå¯¼è‡´ä½ å‰é¢è®¾ç½®å¥½çš„Executorçš„å‚æ•°éƒ½å‰åŠŸå°½å¼ƒã€‚è¯•æƒ³ä¸€ä¸‹ï¼Œæ— è®ºä½ çš„Executorè¿›ç¨‹æœ‰å¤šå°‘ä¸ªï¼Œå†…å­˜å’ŒCPUæœ‰å¤šå¤§ï¼Œä½†æ˜¯taskåªæœ‰1ä¸ªæˆ–è€…10ä¸ªï¼Œé‚£ä¹ˆ90%çš„Executorè¿›ç¨‹å¯èƒ½æ ¹æœ¬å°±æ²¡æœ‰taskæ‰§è¡Œï¼Œä¹Ÿå°±æ˜¯ç™½ç™½æµªè´¹äº†èµ„æºï¼å› æ­¤Sparkå®˜ç½‘å»ºè®®çš„è®¾ç½®åŸåˆ™æ˜¯ï¼Œè®¾ç½®è¯¥å‚æ•°ä¸ºnum-executors * executor-coresçš„2~3å€è¾ƒä¸ºåˆé€‚ï¼Œæ¯”å¦‚Executorçš„æ€»CPU coreæ•°é‡ä¸º300ä¸ªï¼Œé‚£ä¹ˆè®¾ç½®1000ä¸ªtaskæ˜¯å¯ä»¥çš„ï¼Œæ­¤æ—¶å¯ä»¥å……åˆ†åœ°åˆ©ç”¨Sparké›†ç¾¤çš„èµ„æºã€‚ æ³¨æ„ï¼šexecutor-coresä¸ºå¯ç”¨çš„è®¡ç®—èµ„æºï¼Œtaskä¸ºæ‹†åˆ†çš„ä»»åŠ¡æ•°é‡ å†…å­˜ï¼š driver-memory å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®Driverè¿›ç¨‹çš„å†…å­˜ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šDriverçš„å†…å­˜é€šå¸¸æ¥è¯´ä¸è®¾ç½®ï¼Œæˆ–è€…è®¾ç½®1Gå·¦å³åº”è¯¥å°±å¤Ÿäº†ã€‚å”¯ä¸€éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œå¦‚æœéœ€è¦ä½¿ç”¨collectç®—å­å°†RDDçš„æ•°æ®å…¨éƒ¨æ‹‰å–åˆ°Driverä¸Šè¿›è¡Œå¤„ç†ï¼Œé‚£ä¹ˆå¿…é¡»ç¡®ä¿Driverçš„å†…å­˜è¶³å¤Ÿå¤§ï¼Œå¦åˆ™ä¼šå‡ºç°OOMå†…å­˜æº¢å‡ºçš„é—®é¢˜ã€‚ executor-memory å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„å†…å­˜ã€‚Executorå†…å­˜çš„å¤§å°ï¼Œå¾ˆå¤šæ—¶å€™ç›´æ¥å†³å®šäº†Sparkä½œä¸šçš„æ€§èƒ½ï¼Œè€Œä¸”è·Ÿå¸¸è§çš„JVM OOMå¼‚å¸¸ï¼Œä¹Ÿæœ‰ç›´æ¥çš„å…³è”ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šæ¯ä¸ªExecutorè¿›ç¨‹çš„å†…å­˜è®¾ç½®4G~8Gè¾ƒä¸ºåˆé€‚ã€‚ä½†æ˜¯è¿™åªæ˜¯ä¸€ä¸ªå‚è€ƒå€¼ï¼Œå…·ä½“çš„è®¾ç½®è¿˜æ˜¯å¾—æ ¹æ®ä¸åŒéƒ¨é—¨çš„èµ„æºé˜Ÿåˆ—æ¥å®šã€‚å¯ä»¥çœ‹çœ‹è‡ªå·±å›¢é˜Ÿçš„èµ„æºé˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é™åˆ¶æ˜¯å¤šå°‘ï¼Œnum-executorsä¹˜ä»¥executor-memoryï¼Œæ˜¯ä¸èƒ½è¶…è¿‡é˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é‡çš„ã€‚æ­¤å¤–ï¼Œå¦‚æœä½ æ˜¯è·Ÿå›¢é˜Ÿé‡Œå…¶ä»–äººå…±äº«è¿™ä¸ªèµ„æºé˜Ÿåˆ—ï¼Œé‚£ä¹ˆç”³è¯·çš„å†…å­˜é‡æœ€å¥½ä¸è¦è¶…è¿‡èµ„æºé˜Ÿåˆ—æœ€å¤§æ€»å†…å­˜çš„1/3~1/2ï¼Œé¿å…ä½ è‡ªå·±çš„Sparkä½œä¸šå ç”¨äº†é˜Ÿåˆ—æ‰€æœ‰çš„èµ„æºï¼Œå¯¼è‡´åˆ«çš„åŒå­¦çš„ä½œä¸šæ— æ³•è¿è¡Œã€‚ å› æ­¤Executorçš„å†…å­˜ä¸»è¦åˆ†ä¸ºä¸‰å—ï¼šç¬¬ä¸€å—æ˜¯è®©taskæ‰§è¡Œæˆ‘ä»¬è‡ªå·±ç¼–å†™çš„ä»£ç æ—¶ä½¿ç”¨ï¼Œé»˜è®¤æ˜¯å Executoræ€»å†…å­˜çš„20%ï¼›ç¬¬äºŒå—æ˜¯è®©taské€šè¿‡shuffleè¿‡ç¨‹æ‹‰å–äº†ä¸Šä¸€ä¸ªstageçš„taskçš„è¾“å‡ºåï¼Œè¿›è¡Œèšåˆç­‰æ“ä½œæ—¶ä½¿ç”¨ï¼Œé»˜è®¤ä¹Ÿæ˜¯å Executoræ€»å†…å­˜çš„20%ï¼›ç¬¬ä¸‰å—æ˜¯è®©RDDæŒä¹…åŒ–æ—¶ä½¿ç”¨ï¼Œé»˜è®¤å Executoræ€»å†…å­˜çš„60%ã€‚ spark.storage.memoryFraction å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®RDDæŒä¹…åŒ–æ•°æ®åœ¨Executorå†…å­˜ä¸­èƒ½å çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.6ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé»˜è®¤Executor 60%çš„å†…å­˜ï¼Œå¯ä»¥ç”¨æ¥ä¿å­˜æŒä¹…åŒ–çš„RDDæ•°æ®ã€‚æ ¹æ®ä½ é€‰æ‹©çš„ä¸åŒçš„æŒä¹…åŒ–ç­–ç•¥ï¼Œå¦‚æœå†…å­˜ä¸å¤Ÿæ—¶ï¼Œå¯èƒ½æ•°æ®å°±ä¸ä¼šæŒä¹…åŒ–ï¼Œæˆ–è€…æ•°æ®ä¼šå†™å…¥ç£ç›˜ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šå¦‚æœSparkä½œä¸šä¸­ï¼Œæœ‰è¾ƒå¤šçš„RDDæŒä¹…åŒ–æ“ä½œï¼Œè¯¥å‚æ•°çš„å€¼å¯ä»¥é€‚å½“æé«˜ä¸€äº›ï¼Œä¿è¯æŒä¹…åŒ–çš„æ•°æ®èƒ½å¤Ÿå®¹çº³åœ¨å†…å­˜ä¸­ã€‚é¿å…å†…å­˜ä¸å¤Ÿç¼“å­˜æ‰€æœ‰çš„æ•°æ®ï¼Œå¯¼è‡´æ•°æ®åªèƒ½å†™å…¥ç£ç›˜ä¸­ï¼Œé™ä½äº†æ€§èƒ½ã€‚ä½†æ˜¯å¦‚æœSparkä½œä¸šä¸­çš„shuffleç±»æ“ä½œæ¯”è¾ƒå¤šï¼Œè€ŒæŒä¹…åŒ–æ“ä½œæ¯”è¾ƒå°‘ï¼Œé‚£ä¹ˆè¿™ä¸ªå‚æ•°çš„å€¼é€‚å½“é™ä½ä¸€äº›æ¯”è¾ƒåˆé€‚ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼ˆé€šè¿‡spark web uiå¯ä»¥è§‚å¯Ÿåˆ°ä½œä¸šçš„gcè€—æ—¶ï¼‰ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚ spark.shuffle.memoryFraction å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®shuffleè¿‡ç¨‹ä¸­ä¸€ä¸ªtaskæ‹‰å–åˆ°ä¸Šä¸ªstageçš„taskçš„è¾“å‡ºåï¼Œè¿›è¡Œèšåˆæ“ä½œæ—¶èƒ½å¤Ÿä½¿ç”¨çš„Executorå†…å­˜çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.2ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒExecutoré»˜è®¤åªæœ‰20%çš„å†…å­˜ç”¨æ¥è¿›è¡Œè¯¥æ“ä½œã€‚shuffleæ“ä½œåœ¨è¿›è¡Œèšåˆæ—¶ï¼Œå¦‚æœå‘ç°ä½¿ç”¨çš„å†…å­˜è¶…å‡ºäº†è¿™ä¸ª20%çš„é™åˆ¶ï¼Œé‚£ä¹ˆå¤šä½™çš„æ•°æ®å°±ä¼šæº¢å†™åˆ°ç£ç›˜æ–‡ä»¶ä¸­å»ï¼Œæ­¤æ—¶å°±ä¼šæå¤§åœ°é™ä½æ€§èƒ½ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šå¦‚æœSparkä½œä¸šä¸­çš„RDDæŒä¹…åŒ–æ“ä½œè¾ƒå°‘ï¼Œshuffleæ“ä½œè¾ƒå¤šæ—¶ï¼Œå»ºè®®é™ä½æŒä¹…åŒ–æ“ä½œçš„å†…å­˜å æ¯”ï¼Œæé«˜shuffleæ“ä½œçš„å†…å­˜å æ¯”æ¯”ä¾‹ï¼Œé¿å…shuffleè¿‡ç¨‹ä¸­æ•°æ®è¿‡å¤šæ—¶å†…å­˜ä¸å¤Ÿç”¨ï¼Œå¿…é¡»æº¢å†™åˆ°ç£ç›˜ä¸Šï¼Œé™ä½äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚ èµ„æºå‚æ•°å‚è€ƒç¤ºä¾‹ä»¥ä¸‹æ˜¯ä¸€ä»½spark-submitå‘½ä»¤çš„ç¤ºä¾‹ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒä¸€ä¸‹ï¼Œå¹¶æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µè¿›è¡Œè°ƒèŠ‚ï¼š 123456789./bin/spark-submit \\ --master yarn-cluster \\ --num-executors 100 \\ --executor-memory 6G \\ --executor-cores 4 \\ --driver-memory 1G \\ --conf spark.default.parallelism=1000 \\ --conf spark.storage.memoryFraction=0.5 \\ --conf spark.shuffle.memoryFraction=0.3 \\ å‚è€ƒhttps://www.cnblogs.com/gtscool/p/13072051.html https://blog.csdn.net/l1394049664/article/details/81811642 https://tech.meituan.com/2016/04/29/spark-tuning-basic.html","link":"/2022/03/16/spark_para_optimization-resoucrece/"},{"title":"sparkcore","text":"1 å…±äº«å˜é‡https://blog.csdn.net/Android_xue/article/details/79780463 https://chowdera.com/2022/02/202202091419262471.html ä¸¤ç§å…±äº«å˜é‡ï¼šå¹¿æ’­å˜é‡ï¼ˆbroadcast variableï¼‰ä¸ç´¯åŠ å™¨ï¼ˆaccumulatorï¼‰ å¹¿æ’­å˜é‡è§£å†³äº†ä»€ä¹ˆé—®é¢˜?åˆ†å¸ƒå¼é›†åˆRDDå’Œæœ¬åœ°é›†åˆè¿›è¡Œå…³è”ä½¿ç”¨çš„æ—¶å€™, é™ä½å†…å­˜å ç”¨ä»¥åŠå‡å°‘ç½‘ç»œIOä¼ è¾“, æé«˜æ€§èƒ½. ç´¯åŠ å™¨è§£å†³äº†ä»€ä¹ˆé—®é¢˜?åˆ†å¸ƒå¼ä»£ç æ‰§è¡Œä¸­, è¿›è¡Œå…¨å±€ç´¯åŠ  1.å¹¿æ’­å˜é‡ 2.ç´¯åŠ å™¨ 123456789101112131415161718192021222324sc = spark.sparkContextrdd1=sc.parallelize([1,2,3,4,5,6,7,8,9,10],2)count=sc.accumulator(0)def map_func(data):global countcount+=data# count = sc.accumulator(0)# rdd3=rdd2.map(lambda x:x)# rdd3.collect()# print(count)start_time = time.time()result=rdd1.reduce(lambda a, b: a + b)end_time = time.time()print(result)print(end_time - start_time)# print(count)start_time = time.time()rdd2 = rdd1.map(map_func)rdd2.collect()end_time = time.time()print(count)print(end_time - start_time) 1234551.092909574508667550.09459614753723145 ç´¯åŠ å™¨å’Œreduceéƒ½å¯ä»¥å¾—åˆ°èšåˆç»“æœï¼Œæ•ˆç‡ï¼Ÿï¼Ÿï¼Ÿè°å…ˆæ‰§è¡Œ è°çŸ­ï¼Œæ€ä¹ˆè¡¡é‡ 2 *ByKey æ“ä½œhttps://blog.csdn.net/weixin_43810802/article/details/120772452 https://blog.csdn.net/zhuzuwei/article/details/104446388 https://blog.csdn.net/weixin_40161254/article/details/103472056 Use reduceByKey instead of groupByKey groupByKey creates a lot of shuffling which hampers the performance, while reduceByKey does not shuffle the data as much 3 reduce1234567inï¼štable=pd.DataFrame({&quot;num&quot;:[1,1,2]})table = spark.createDataFrame(table)from pyspark.sql import Rowtable.rdd.reduce(lambda a,b:Row(num=a[0]+b[0]))outï¼šRow(num=4) èšåˆçš„ä½œç”¨ æ³¨æ„ç‚¹å°±æ˜¯ a,b æ“ä½œåçš„æ•°æ®ç±»å‹å’Œaï¼Œbä¿æŒä¸€è‡´ï¼Œä¸¾ä¸ªä¾‹å­ a+b å’Œa ï¼Œbç±»å‹ä¸€è‡´ï¼Œå¦åˆ™ï¼ˆa+bï¼‰+cä¼šæŠ¥é”™ 4 collectã€ takeã€topã€firstï¼Œforeach1 collect collect() è¿”å›åŒ…å«æ­¤RDDä¸­çš„æ‰€æœ‰å…ƒç´ çš„åˆ—è¡¨ æ³¨æ„ï¼šå› ä¸ºæ‰€æœ‰æ•°æ®éƒ½ä¼šåŠ è½½åˆ°driverï¼Œæ‰€æœ‰åªé€‚ç”¨äºæ•°æ®é‡ä¸å¤§çš„æƒ…å†µ 2 first first() è¿”å›RDDä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´  3 take take(num) å–RDDçš„å‰numä¸ªå…ƒç´  4 top top(num, key=None) æ’åº Get the top N elements from an RDD 5 foreach foreach(f) Applies a function to all elements of this RDD åˆ†åŒºè¾“å‡º 1234567891011121314151617def f(x): print(x) sc.parallelize([1,2,3,4,5]).foreach(f)outputï¼š43215ä¼šå˜35241","link":"/2022/02/27/sparkcore/"},{"title":"Sparkcoreè¿è¡Œæµç¨‹","text":"è¿è¡Œæµç¨‹ 1 æ³¨å†Œå¹¶ç”³è¯·èµ„æºï¼Œåˆ†é…èµ„æº 2 job-&gt;stage-&gt;task 3 4 5 driver executor äº¤äº’æ‰§è¡Œä»»åŠ¡ executor å‘driverç”³è¯·ä»»åŠ¡ï¼Œ è¿˜æ˜¯driverç»™executor åˆ†é…ä»»åŠ¡ï¼Ÿ ä¾‹å­","link":"/2022/03/02/sparkcore-run/"},{"title":"Spark on Hive &amp; Hive on Spark","text":"https://cloud.tencent.com/developer/article/1624245 https://blog.csdn.net/weixin_41290471/article/details/106203419 https://www.cnblogs.com/qingyunzong/p/8992664.html 1 Hive on Sparkå°±æ˜¯å°†sparkä½œä¸ºhiveçš„è®¡ç®—å¼•æ“ Hiveæ—¢ä½œä¸ºå­˜å‚¨å…ƒæ•°æ®åˆè´Ÿè´£SQLçš„è§£æä¼˜åŒ–ï¼Œè¯­æ³•æ˜¯HQLè¯­æ³•ï¼Œæ‰§è¡Œå¼•æ“å˜æˆäº†Sparkï¼ŒSparkè´Ÿè´£é‡‡ç”¨RDDæ‰§è¡Œã€‚ 2 Spark on Hiveå°±æ˜¯å› ä¸ºSparkè‡ªèº«æ²¡æœ‰å…ƒæ•°æ®ç®¡ç†åŠŸèƒ½ï¼Œæ‰€ä»¥ä½¿ç”¨Hiveçš„MetastoreæœåŠ¡ä½œä¸ºå…ƒæ•°æ®ç®¡ç†æœåŠ¡ã€‚è®¡ç®—ç”±Sparkæ‰§è¡Œã€‚ Hiveåªä½œä¸ºå­˜å‚¨å…ƒæ•°æ®ï¼ŒSparkè´Ÿè´£SQLè§£æä¼˜åŒ–ï¼Œè¯­æ³•æ˜¯Spark SQLè¯­æ³•ï¼ŒSparkè´Ÿè´£é‡‡ç”¨RDDæ‰§è¡Œã€‚ SparkSQL çš„å…ƒæ•°æ®çš„çŠ¶æ€æœ‰ä¸¤ç§ï¼š 1ã€in_memory,ç”¨å®Œäº†å…ƒæ•°æ®ä¹Ÿå°±ä¸¢äº† 2ã€hive , é€šè¿‡hiveå»ä¿å­˜çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œhiveçš„å…ƒæ•°æ®å­˜åœ¨å“ªå„¿ï¼Œå®ƒçš„å…ƒæ•°æ®ä¹Ÿå°±å­˜åœ¨å“ªå„¿ã€‚æ¢å¥è¯è¯´ï¼ŒSparkSQLçš„æ•°æ®ä»“åº“åœ¨å»ºç«‹åœ¨Hiveä¹‹ä¸Šå®ç°çš„ã€‚æˆ‘ä»¬è¦ç”¨SparkSQLå»æ„å»ºæ•°æ®ä»“åº“çš„æ—¶å€™ï¼Œå¿…é¡»ä¾èµ–äºHiveã€‚","link":"/2022/02/01/sparkonhive/"},{"title":"sparksqlå¯¹æ¯”hive sql","text":"Hiveå’ŒSpark å‡æ˜¯â€œåˆ†å¸ƒå¼SQLè®¡ç®—å¼•æ“â€ï¼Œmysqlç­‰ä¸æ˜¯ï¼Œmysqlè·‘å•æœºä¸Š å‡æ˜¯æ„å»ºå¤§è§„æ¨¡ç»“æ„åŒ–æ•°æ®è®¡ç®—çš„ç»ä½³åˆ©å™¨ï¼ŒåŒæ—¶SparkSQLæ‹¥æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚ç›®å‰ï¼Œä¼ä¸šä¸­ä½¿ç”¨Hiveä»æ—§å±…å¤šï¼Œä½†SparkSQLå°†ä¼šåœ¨å¾ˆè¿‘çš„æœªæ¥æ›¿ä»£Hiveæˆä¸ºåˆ†å¸ƒå¼SQLè®¡ç®—å¸‚åœºçš„é¡¶çº§","link":"/2022/02/27/sparksql-vs-hql/"},{"title":"Sparksqlè¿è¡Œæµç¨‹","text":"è½¬æˆrddæ¥åš https://blog.csdn.net/qq_25002995/article/details/104748504","link":"/2022/03/02/sparksql-run/"},{"title":"sparksql","text":"1 ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•° æ­¥éª¤ï¼š https://blog.csdn.net/qq_43665254/article/details/112379113 https://blog.csdn.net/sunflower_sara/article/details/104044412 1ã€å®šä¹‰å‡½æ•° 2ã€æ³¨å†Œå‡½æ•° 3ã€ä½¿ç”¨å‡½æ•° 2 withColumn12345678910from pyspark.sql.functions import col, lit###df.withColumn('age2', df.age + 2).collect()### ç»“åˆudfdef fun(A,B): XXXX return XXfun1 = udf(fun, StringType())df.withColumn('age2', fun1(col_name1,col_name2))###","link":"/2022/02/27/sparksql/"},{"title":"ç‰¹å¾ç¨€ç–","text":"What are sparse features?Features with sparse data are features that have mostly zero values. This is different from features with missing data. Why is machine learning difficult with sparse features?Common problems with sparse features include: If the model has many sparse features, it will increase the space and time complexity of models. Linear regression models will fit more coefficients, and tree-based models will have greater depth to account for all features. Model algorithms and diagnostic measures might behave in unknown ways if the features have sparse data. Kuss [2002] shows that goodness-of-fit tests are flawed when the data is sparse. If there are too many features, models fit the noise in the training data. This is called overfitting. When models overfit, they are unable to generalize to newer data when they are put in production. This negatively impacts the predictive power of models. Some models may underestimate the importance of sparse features and given preference to denser features even though the sparse features may have predictive power. Tree-based models are notorious for behaving like this. For example, random forests overpredict the importance of features that have more categories than those features that have fewer categories. Methods for dealing with sparse features Removing features from the model Make the features dense Using models that are robust to sparse features å‚è€ƒhttps://www.kdnuggets.com/2021/01/sparse-features-machine-learning-models.html#:~:text=%20Methods%20for%20dealing%20with%20sparse%20features%20,that%20are%20robust%20to%20sparse%20features%20More%20","link":"/2021/09/30/sparsity-feature/"},{"title":"springboot","text":"javaæ¡†æ¶ï¼Œå¯¹springçš„æ”¹è¿›","link":"/2022/04/23/springboot/"},{"title":"å»ºè¡¨","text":"1234567CREATE TABLE IF NOT EXISTS `runoob_tbl`( `runoob_id` INT UNSIGNED AUTO_INCREMENT, `runoob_title` VARCHAR(100) NOT NULL, `runoob_author` VARCHAR(40) NOT NULL, `submission_date` DATE, PRIMARY KEY ( `runoob_id` ))ENGINE=InnoDB DEFAULT CHARSET=utf8; å­—æ®µæ•°æ®ç±»å‹https://www.w3school.com.cn/sql/sql_datatypes.asp array https://www.educba.com/array-in-sql/ çº¦æŸï¼ˆConstraintsï¼‰ NOT NULL - æŒ‡ç¤ºæŸåˆ—ä¸èƒ½å­˜å‚¨ NULL å€¼ã€‚ UNIQUE - ä¿è¯æŸåˆ—çš„æ¯è¡Œå¿…é¡»æœ‰å”¯ä¸€çš„å€¼ã€‚ PRIMARY KEY - NOT NULL å’Œ UNIQUE çš„ç»“åˆã€‚ç¡®ä¿æŸåˆ—ï¼ˆæˆ–ä¸¤ä¸ªåˆ—å¤šä¸ªåˆ—çš„ç»“åˆï¼‰æœ‰å”¯ä¸€æ ‡è¯†ï¼Œæœ‰åŠ©äºæ›´å®¹æ˜“æ›´å¿«é€Ÿåœ°æ‰¾åˆ°è¡¨ä¸­çš„ä¸€ä¸ªç‰¹å®šçš„è®°å½•ã€‚ FOREIGN KEY - ä¿è¯ä¸€ä¸ªè¡¨ä¸­çš„æ•°æ®åŒ¹é…å¦ä¸€ä¸ªè¡¨ä¸­çš„å€¼çš„å‚ç…§å®Œæ•´æ€§ã€‚ CHECK - ä¿è¯åˆ—ä¸­çš„å€¼ç¬¦åˆæŒ‡å®šçš„æ¡ä»¶ã€‚ DEFAULT - è§„å®šæ²¡æœ‰ç»™åˆ—èµ‹å€¼æ—¶çš„é»˜è®¤å€¼ã€‚ è‡ªå¢å­—æ®µ AUTO INCREMENT 123456789CREATE TABLE Persons(ID int NOT NULL AUTO_INCREMENT,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (ID)) å¼€å§‹å€¼æ˜¯ 1ï¼Œæ¯æ¡æ–°è®°å½•é€’å¢ 1","link":"/2022/05/05/sql-buildtable/"},{"title":"sqlå¸¸è§æ“ä½œ","text":"1 æ‹¼æ¥1 union ï¼Œunion all https://www.w3school.com.cn/sql/sql_union.asp 123select 'mobile' as platform unionselect 'desktop' as platform unionselect 'both' as platform 2 join left join ã€right joinã€ inner joinï¼ŒFULL OUTER JOINï¼Œé»˜è®¤join ä¸º inner join https://www.cnblogs.com/ingstyle/p/4368064.html 12345678#å¤šä¸ªleft joinselect a.*,b.*,c.* from a left join b on a.id=b.id left join c on b.id=c.idselect *from Trips T left join Users U1 on T.client_id =U1.users_id left join Users U2 on T.driver_id =U2.users_id 12345from Trips T1left join Users U1 on (T1.client_id =U1.users_id and U1.banned =&quot;Yes&quot; ) ä¸å¯from Trips T1join Users U1 on (T1.client_id =U1.users_id and U1.banned =&quot;Yes&quot; ) å¯ 3.from student A,student B,student C å°†ä¸‰ä¸ª student è¡¨ç›¸äº’è¿æ¥æˆä¸€ä¸ª https://blog.csdn.net/zhangyj_315/article/details/2249209 2 åˆ†ç»„1 group by åˆ†ç»„, åˆ†å®Œæ¯ç»„å°±ä¸€è¡Œï¼Œå–æ¯ç»„ç¬¬ä¸€è¡Œæ•°æ® group by columns1,columns2 #æœ‰æ—¶å€™ä¸èƒ½å–ç¬¬ä¸€è¡Œï¼Œæ€ä¹ˆè§£å†³ï¼Ÿ1070. äº§å“é”€å”®åˆ†æ III a å¯ä»¥å…ˆæ’åºï¼ŒæŠŠç›®æ ‡è¡Œå˜æˆç¬¬ä¸€è¡Œ å¯ä»¥å‚è€ƒhttps://blog.csdn.net/shiyong1949/article/details/78482737 å¥½åƒä¸è¡Œ b ä½¿ç”¨å¼€çª—å‡½æ•°è§£å†³ï¼Œå¯ä»¥ #åˆ†ç»„+æ¡ä»¶åˆ¤æ–­ Having having å­å¥çš„ä½œç”¨æ˜¯ç­›é€‰æ»¡è¶³æ¡ä»¶çš„ç»„ï¼Œä¸æ˜¯åœ¨ç»„å†…é€‰è¡Œ åœ¨ SQL ä¸­å¢åŠ  HAVING å­å¥åŸå› æ˜¯ï¼ŒWHERE å…³é”®å­—æ— æ³•ä¸èšåˆå‡½æ•°ä¸€èµ·ä½¿ç”¨ã€‚ #4 å­æŸ¥è¯¢åµŒå¥— http://c.biancheng.net/sql/sub-query.html 1234select a.Score as Score, (select count(DISTINCT b.Score) from Scores b where b.Score &gt;= a.Score) as 'Rank'from Scores aorder by a.Score DESC 5 åˆ«åasååŠ åˆ«åï¼Œä¹Ÿå¯ä¸è¦as 6 åŒ¹é…åˆ†ä¸ºå®Œæ•´åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é… https://www.cnblogs.com/Leophen/p/11397621.html å…³é”®å­—like 1select * from table where name like &quot;%ä¸‰%&quot; é€šé…ç¬¦ï¼š%ï¼Œ_ï¼Œ[charlist] ï¼Œ[!charlist] 7 æ¡ä»¶1.IF è¡¨è¾¾å¼ï¼šIF( expr1 , expr2 , expr3 ) expr1æ¡ä»¶ï¼Œæ¡ä»¶ä¸ºtrueï¼Œåˆ™å€¼æ˜¯expr2 ï¼Œfalseï¼Œå€¼å°±æ˜¯expr3 2 case inputå‡ è¡Œoutputå‡ è¡Œ ä¸€è¡Œä¸€è¡Œæ¥ https://zhuanlan.zhihu.com/p/240717732 ä¸¤ç§å½¢å¼ï¼š 1234567891011121314--type1CASE &lt;è¡¨è¾¾å¼&gt; WHEN &lt;å€¼1&gt; THEN &lt;æ“ä½œ&gt; WHEN &lt;å€¼2&gt; THEN &lt;æ“ä½œ&gt; ... ELSE &lt;æ“ä½œ&gt;END--type2CASE WHEN &lt;æ¡ä»¶1&gt; THEN &lt;å‘½ä»¤&gt; WHEN &lt;æ¡ä»¶2&gt; THEN &lt;å‘½ä»¤&gt; ... ELSE commandsEND thenåé¢å¤šä¸ªå€¼ then 1 å¯ then (1,1) ä¸å¯ where xx in ï¼ˆ1,1ï¼‰å¯ 3 where 1126. æŸ¥è¯¢æ´»è·ƒä¸šåŠ¡12345678# Write your MySQL query statement belowselect t.business_id from (select *, avg(E1.occurences ) over(partition by E1.event_type ) as ave_occufrom Events E1 ) twhere t.occurences &gt; t.ave_occugroup by t.business_idhaving count(t.business_id)&gt;=2 4 æ¡ä»¶åˆ¤æ–­ (E1.id , E1.month) in ((1,8)) BETWEEN â€˜2019-06-28â€™ AND â€˜2019-07-27â€™ EXISTS ï¼šç”¨äºåˆ¤æ–­æŸ¥è¯¢å­å¥æ˜¯å¦æœ‰è®°å½•ï¼Œå¦‚æœæœ‰ä¸€æ¡æˆ–å¤šæ¡è®°å½•å­˜åœ¨è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚ 1234SELECT column_name(s)FROM table_nameWHERE EXISTS(SELECT column_name FROM table_name WHERE condition); 8 NULL1.ç©ºå­—ç¬¦å’Œnullçš„åŒºåˆ« https://blog.csdn.net/weixin_42214393/article/details/80463912 2.åˆ¤æ–­NULL is not NULL !=NULL æœ‰é—®é¢˜ ifnull(sum(quantity), 0) 3 inã€not in https://blog.csdn.net/qq_22592457/article/details/108024521 ä½¿ç”¨inæ—¶ï¼Œinåé¢çš„æ‹¬å·ä¸­å¿½ç•¥nullå€¼ ä½¿ç”¨not inæ—¶ï¼Œå¦‚æœ not inåé¢çš„æ‹¬å·ä¸­æ²¡æœ‰nullï¼Œæ­£å¸¸åˆ¤æ–­ï¼Œä¼šæŸ¥è¯¢æ¡ä»¶åˆ—ä¸­ç¬¦åˆè¦æ±‚çš„æ•°æ® ä½¿ç”¨not inæ—¶ï¼Œå¦‚æœ not inåé¢çš„æ‹¬å·ä¸­æœ‰nullï¼Œç›´æ¥è¿”å›falseï¼ŒæŸ¥è¯¢ç»“æœä¸ºç©ºã€‚ 9 æ—¥æœŸ1 å¤§å°åˆ¤æ–­ available_from &lt; â€˜2019-05-23â€™ datediff(date1,date2) 2 æ ¼å¼è½¬åŒ– DATE_FORMAT() https://www.w3school.com.cn/sql/func_date_format.asp 10 å»é‡1 distinct https://blog.csdn.net/zhangzehai2234/article/details/88361586 1select distinct expression[,expression...] from tables [where conditions]; åœ¨ä½¿ç”¨distinctçš„è¿‡ç¨‹ä¸­ä¸»è¦æ³¨æ„ä¸€ä¸‹å‡ ç‚¹ï¼š åœ¨å¯¹å­—æ®µè¿›è¡Œå»é‡çš„æ—¶å€™ï¼Œè¦ä¿è¯distinctåœ¨æ‰€æœ‰å­—æ®µçš„æœ€å‰é¢ å¦‚æœdistinctå…³é”®å­—åé¢æœ‰å¤šä¸ªå­—æ®µæ—¶ï¼Œåˆ™ä¼šå¯¹å¤šä¸ªå­—æ®µè¿›è¡Œç»„åˆå»é‡ï¼Œåªæœ‰å¤šä¸ªå­—æ®µç»„åˆèµ·æ¥çš„å€¼æ˜¯ç›¸ç­‰çš„æ‰ä¼šè¢«å»é‡ distinct , count ä¸€èµ·ç”¨ 12345678910111213141516171819##å»ºè¡¨Create table If Not Exists Spending (user_id int, spend_date date, platform ENUM('desktop', 'mobile'), amount int);Truncate table Spending;insert into Spending (user_id, spend_date, platform, amount) values ('1', '2019-07-01', 'mobile', '100');insert into Spending (user_id, spend_date, platform, amount) values ('1', '2019-07-01', 'desktop', '100');insert into Spending (user_id, spend_date, platform, amount) values ('2', '2019-07-01', 'mobile', '100');insert into Spending (user_id, spend_date, platform, amount) values ('2', '2019-07-02', 'mobile', '100');insert into Spending (user_id, spend_date, platform, amount) values ('3', '2019-07-01', 'desktop', '100');insert into Spending (user_id, spend_date, platform, amount) values ('3', '2019-07-02', 'desktop', '100');###æŸ¥è¯¢select distinct spend_date ,count(user_id ) from Spending##result##è¿”å›ç»“æœå°±ä¸€è¡Œï¼Œdistinctåå¤šè¡Œï¼Œcountä¸€è¡Œï¼Œå¤šè¡Œä¸€è¡Œè¿˜æ˜¯ä¸€è¡Œï¼›countç»“æœè¿˜æ˜¯distinctå‰çš„æ•°é‡spend_date count(user_id )2019-07-01 6 11 show statushttps://blog.csdn.net/qq_29168493/article/details/79149132 æŸ¥çœ‹å½“å‰æ•°æ®åº“çŠ¶æ€ï¼Œå¯ä»¥ç»Ÿè®¡å½“å‰æ•°æ®åº“ä¸åŒè¯­å¥çš„æ‰§è¡Œé¢‘æ¬¡ 12 explainè·å–sqlæ‰§è¡Œè®¡åˆ’ï¼Œç»“æœæ˜ç»†å‚è€ƒ https://cloud.tencent.com/developer/article/1093229 14 äº‹åŠ¡http://m.biancheng.net/sql/transaction.html 15 é€’å½’æŸ¥è¯¢https://zhuanlan.zhihu.com/p/372330656 https://medium.com/swlh/recursion-in-sql-explained-graphically-679f6a0f143b https://www.sqlservertutorial.net/sql-server-basics/sql-server-recursive-cte/ 123456789101112WITH expression_name (column_list)AS( -- Anchor member initial_query UNION ALL -- Recursive member that references expression_name. recursive_query )-- references expression nameSELECT *FROM expression_name åˆ†æ https://zhuanlan.zhihu.com/p/372330656 R0 ï¼š 123SELECT UserID,ManagerID,Name,Name AS ManagerName FROM dbo.Employee WHERE ManagerID=-1 userid managerid name managername 1 -1 boss boss R1ï¼š 123SELECT c.UserID,c.ManagerID,c.Name,p.Name AS ManagerNameFROM CTE PINNER JOIN dbo.Employee c ON p.UserID=c.ManagerID æ­¤æ—¶Employeeä¸ºå®Œæ•´çš„ï¼Œcteä¸º userid managerid name managername 1 -1 boss boss å¾—åˆ°ç»“æœä¸º c.userid c.managerid c.name c.managername p.userid p.managerid p.name p.managername 11 1 A1 A1 1 -1 boss boss 12 1 A2 A2 1 -1 boss boss 13 1 A3 A3 1 -1 boss boss 1SELECT c.UserID,c.ManagerID,c.Name,p.Name AS ManagerName userid managerid name name 11 1 A1 boss 12 1 A2 boss 13 1 A3 boss R2,R3â€¦ æœ€åunion all R0ï¼ŒR1ï¼ŒR2ï¼Œã€‚ã€‚ã€‚ 16 select å¸¸æ•°12345678910111213SELECT 1,-1,N'Boss'UNION ALLSELECT 11,1,N'A1'UNION ALLSELECT 12,1,N'A2'UNION ALLSELECT 13,1,N'A3'UNION ALLSELECT 111,11,N'B1'UNION ALLSELECT 112,11,N'B2'UNION ALLSELECT 121,12,N'C1' 1 -1 Boss â€”å­—æ®µ 1 -1 Boss11 1 A112 1 A213 1 A3111 11 B1112 11 B2121 12 C1 17 CTECommon Table Expression with â€¦asâ€¦ 18 è§¦å‘å™¨å°±æ˜¯åšäº†æŸäº›æ“ä½œï¼Œè‡ªåŠ¨è§¦å‘çš„è¡Œä¸º è§¦å‘å™¨æ˜¯è‡ªåŠ¨æ‰§è¡Œçš„ï¼Œå½“ç”¨æˆ·å¯¹è¡¨ä¸­æ•°æ®ä½œäº†æŸäº›æ“ä½œä¹‹åç«‹å³è¢«è§¦å‘ã€‚ https://blog.csdn.net/weixin_48033173/article/details/111713117","link":"/2022/02/27/sql-common-operation/"},{"title":"sqlå¢åˆ æ”¹æŸ¥","text":"https://blog.csdn.net/Zhangxichao100/article/details/55099118 1 å¢1 insert insert into table (å§“å,æ€§åˆ«,å‡ºç”Ÿæ—¥æœŸ) values (â€˜ç‹ä¼Ÿåâ€™,â€™ç”·â€™,â€™1983/6/15â€™) insert into table (â€˜å§“åâ€™,â€™åœ°å€â€™,â€™ç”µå­é‚®ä»¶â€™)select name,address,email from Strdents 2 SELECT INTO 123SELECT column_nameINTO newtableFROM table1; 2 åˆ 1 delete åˆ é™¤æ•°æ®æŸäº›æ•°æ® delete from table where name=â€™ç‹ä¼Ÿåâ€™ 2 truncate åˆ é™¤æ•´ä¸ªè¡¨çš„æ•°æ® truncate table addressList 3 æ”¹1 update update table set å¹´é¾„=18 where å§“å=â€™ç‹ä¼Ÿåâ€™ 4 æŸ¥ 1 select","link":"/2022/04/02/sql-crud/"},{"title":"sqlå‡½æ•°","text":"1 å•è¡Œå‡½æ•°å’Œå¤šè¡Œå‡½æ•°å•è¡Œå‡½æ•°ï¼šå•å…¥å•å‡º å¤šè¡Œå‡½æ•°ï¼šå¤šå…¥å•å‡ºï¼Œæœ€å¸¸è§çš„å°±æ˜¯èšåˆå‡½æ•° åº”è¯¥ä¸å­˜åœ¨å•å…¥å¤šå‡ºï¼Œå¤šå…¥å¤šå‡ºå¯ä»¥ç®€åŒ–ä¸ºå•å…¥å•å‡ºçš„å¤šæ¬¡ https://blog.csdn.net/lailai186/article/details/12570899 æ³¨æ„ï¼š å¤šè¡Œï¼Œå•è¡Œç»“æœç»„åˆè¿”å›ä¸€è¡Œ ä¾‹å­ï¼šselect column1 ,count(column2) ï¼Œåªè¿”å›ä¸€è¡Œ é—®é¢˜æ¥äº†ï¼Œå¤šå¤šä¸ä¸€æ ·å‘¢ï¼Œæ¯”å¦‚3å’Œ2ï¼Œåº”è¯¥ä¸å­˜åœ¨ 2 ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°https://blog.csdn.net/qq_23833037/article/details/53170789 3 èšåˆå‡½æ•°é¡¾åæ€ä¹‰ï¼Œå°†æ•°æ®èšé›†è¿”å›å•ä¸€çš„å€¼ https://blog.csdn.net/qq_40456829/article/details/83657396 4 å¼€çª—å‡½æ•°ï¼ˆWindow Functionï¼‰https://segmentfault.com/a/1190000040088969 https://www.51cto.com/article/639541.html https://blog.csdn.net/weixin_43412569/article/details/107992998 ä½œç”¨ è¡Œæ•°ä¿æŒä¸å˜ è¾“å…¥å¤šè¡Œï¼ˆä¸€ä¸ªçª—å£ï¼‰ã€è¿”å›ä¸€ä¸ªå€¼ è®¡ç®—è¿‡ç¨‹ å½“å‰è¡Œ-ã€‹åˆ†åŒº-ã€‹æ’åº-ã€‹èŒƒå›´-ã€‹è®¡ç®—-ã€‹ç»“æœå¡«å…¥å½“å‰è¡Œ è¯­æ³• 1234window_function ([expression]) OVER ( [ PARTITION BY part_list ] [ ORDER BY order_list ] [ { ROWS | RANGE } BETWEEN frame_start AND frame_end ] ) expression PARTITION BY è¡¨ç¤ºå°†æ•°æ®æŒ‰ part_list è¿›è¡Œåˆ†åŒºï¼Œ ä¸åŠ partition by é»˜è®¤ç”¨å…¨éƒ¨ï¼ˆä¸€ä¸ªåˆ†åŒºï¼‰ partition by columns1,columns2 ORDER BY è¡¨ç¤ºå°†å„ä¸ªåˆ†åŒºå†…çš„æ•°æ®æŒ‰ order_listè¿›è¡Œæ’åº ROWS / RANGE å†³å®šæ•°æ®èŒƒå›´ https://blog.csdn.net/qq_42374697/article/details/115109386 åˆ†ç±» https://www.cnblogs.com/52xf/p/4209211.html å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ 3 ç±»ï¼š èšåˆï¼ˆAggregateï¼‰ï¼šAVG(), COUNT(), MIN(), MAX(), SUM()â€¦ 1234567891011sum(frequency) over(partiton by num ) --åˆ†ç»„ç´¯åŠ sum(frequency) over() --total_frequency å…¨éƒ¨ç´¯åŠ sum(frequency) over(order by num desc) --desc_frequency, é€†åºç´¯åŠ sum(frequency) over(order by num asc) --asc_frequency,æ­£åºç´¯åŠ SUM(Salary) OVER (PARTITION BY Id ORDER BY Month asc range 2 PRECEDING) --range 2 PRECEDING å½“å‰ä»¥åŠå‰é¢2è¡Œavg(frequency) over() --total_frequency ï¼Œå…¨éƒ¨å¹³å‡avg(frequency) over(order by num desc) --desc_frequency, é€†åºå¹³å‡avg(frequency) over(order by num asc) --asc_frequency, æ­£åºå¹³å‡ â€‹ https://blog.csdn.net/qq_54494937/article/details/119537881 â€‹ https://leetcode-cn.com/problems/find-median-given-frequency-of-numbers/ â€‹ https://blog.csdn.net/qq_54494937/article/details/119537881 å–å€¼ï¼ˆValueï¼‰ï¼šFIRST_VALUE(), LAST_VALUE(), LEAD(), LAG()â€¦ æ’åºï¼ˆRankingï¼‰ï¼šRANK(), DENSE_RANK(), ROW_NUMBER(), NTILE()â€¦ 1rank() OVER (PARTITION BY Id ORDER BY Month DESC) https://leetcode-cn.com/problems/find-cumulative-salary-of-an-employee/ 5 æ•°å­¦è¿ç®—å‡½æ•°https://blog.csdn.net/a_lllll/article/details/87880389 abs1234select distinct C1.seat_id as seat_idfrom Cinema C1 join Cinema C2on C1.free=1 and C2.free=1 and abs(C1.seat_id-C2.seat_id)=1order by seat_id power1234# Write your MySQL query statement belowselect round(min(Power(Power(P1.x-P2.x,2)+Power(P1.y-P2.y,2),0.5)),2) as shortest from Point2D P1 join Point2D P2 on P1.x!=P2.x or P1.y!=P2.y","link":"/2022/02/27/sql-func/"},{"title":"sqlä¼˜åŒ–","text":"1 æ±‡æ€»https://blog.csdn.net/hguisu/article/details/5731629 https://www.analyticsvidhya.com/blog/2021/10/a-detailed-guide-on-sql-query-optimization/ https://blog.devart.com/how-to-optimize-sql-query.html#sql-query-optimization-basics 2 å‡å°‘å…¨è¡¨æ‰«æhttps://www.cnblogs.com/feiling/p/3393356.html https://www.jianshu.com/p/03968ac9d8ad 3 åˆ›å»ºç´¢å¼•https://blog.csdn.net/happyheng/article/details/53143345 https://www.runoob.com/mysql/mysql-index.html https://blog.csdn.net/wangfeijiu/article/details/113409719 0 ä½œç”¨å¯ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡ å’Œä¸»é”®çš„åŒºåˆ«ï¼Œä¸»é”®æ˜¯ç‰¹æ®Šçš„ç´¢å¼•ï¼Œç´¢å¼•ä¸ä¸€å®šæ˜¯ä¸»é”® https://blog.csdn.net/krismile__qh/article/details/98477484 https://blog.csdn.net/weixin_33375360/article/details/113371197 æ—¢ç„¶æœ‰ä¸»é”®ä¸ºå•¥è¿˜è¦ç´¢å¼•ï¼Œå…³é”®åœ¨äºè¿™æ˜¯ä¸¤ä¸ªä¸œè¥¿ï¼Œä¸€ä¸ªæ˜¯ä¸ºäº†å”¯ä¸€è¡¨ç¤ºï¼Œä¸€ä¸ªæ˜¯ä¸ºäº†æé«˜æŸ¥è¯¢æ•ˆç‡ï¼Œåº•å±‚ä¹Ÿä¸åŒ https://cache.one/read/17347789 1 ç´¢å¼•åˆ†ç±»èšé›†ç´¢å¼•ä¸éèšé›†ç´¢å¼• 2 å¸¸è§æ“ä½œ1ã€åˆ›å»ºç´¢å¼• åˆ›å»ºè¡¨æ—¶æŒ‡å®šç´¢å¼• 123456789drop TABLE if EXISTS s1;create table s1( id int , age int, email varchar(30),index(id) ); åˆ›å»ºè¡¨å CREATE INDEX ç´¢å¼•å ON è¡¨å(åˆ—çš„åˆ—è¡¨);/ALTER TABLE è¡¨å ADD INDEX ç´¢å¼•å (åˆ—å1ï¼Œåˆ—å2,â€¦); 2ã€åˆ é™¤ç´¢å¼• DROP INDEX index_name ON talbe_nameALTER TABLE table_name DROP INDEX index_name 3ã€æŸ¥çœ‹ç´¢å¼• SHOW INDEX FROM table_name; 4ã€ä½¿ç”¨ç´¢å¼• å»ºç«‹äº†ç´¢å¼•ï¼Œåº•å±‚æŸ¥è¯¢æ•ˆç‡å˜é«˜äº† æŸ¥è¯¢è¯­å¥ç¼–å†™ä¸Šå’ŒåŸæ¥ä¸€æ ·ï¼Œæ²¡æœ‰åŒºåˆ« https://blog.csdn.net/lenux2017/article/details/80086265 3 ç´¢å¼•å¤±æ•ˆhttps://www.cnblogs.com/technologykai/articles/14172224.html 4 ç´¢å¼•è®¾è®¡http://c.biancheng.net/view/7366.html 4 è§†å›¾https://blog.csdn.net/talentluke/article/details/6420197 http://m.biancheng.net/sql/create-view.html è§†å›¾ä¸ºè™šæ‹Ÿçš„è¡¨ï¼ŒåŒ…å«çš„ä¸æ˜¯æ•°æ®è€Œæ˜¯sqlæŸ¥è¯¢ è§†å›¾å’Œè¡¨çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼š è¡¨å ç”¨ç‰©ç†å­˜å‚¨ç©ºé—´ï¼Œä¹ŸåŒ…å«çœŸæ­£çš„æ•°æ®ï¼› è§†å›¾ä¸éœ€è¦ç‰©ç†å­˜å‚¨ç©ºé—´ï¼ˆé™¤éæ‚¨ä¸ºè§†å›¾æ·»åŠ ç´¢å¼•ï¼‰ï¼Œä¹Ÿä¸åŒ…å«çœŸæ­£çš„æ•°æ®ï¼Œå®ƒåªæ˜¯ä»è¡¨ä¸­å¼•ç”¨æ•°æ®ã€‚ ä½œç”¨ ç®€åŒ–æ•°æ®è®¿é—®ï¼Œè®©å¤æ‚çš„ SQL è¯­å¥ç®€å•åŒ–ã€‚ç”¨æˆ·åªéœ€è¦å¯¹è§†å›¾å†™ç®€å•çš„ä»£ç å°±èƒ½è¿”å›éœ€è¦çš„æ•°æ®ï¼Œä¸€äº›å¤æ‚çš„é€»è¾‘æ”¾åœ¨è§†å›¾ä¸­å®Œæˆã€‚ é˜²æ­¢æ•æ„Ÿçš„å­—æ®µè¢«é€‰ä¸­ï¼ŒåŒæ—¶ä»ç„¶æä¾›å¯¹å…¶å®ƒé‡è¦æ•°æ®çš„è®¿é—®ã€‚ å¯ä»¥å¯¹è§†å›¾æ·»åŠ ä¸€äº›é¢å¤–çš„ç´¢å¼•ï¼Œæ¥æé«˜æŸ¥è¯¢çš„æ•ˆç‡ã€‚ ä½¿ç”¨è§†å›¾çš„æ—¶å€™è·Ÿè¡¨ä¸€æ · å’Œcteçš„åŒºåˆ« https://blog.csdn.net/happyboy53/article/details/2731420 å­æŸ¥è¯¢åŒ…å«çš„æ˜¯æ•°æ®ï¼Œå°†æ•°æ®å­˜åœ¨å†…å­˜ï¼Œè€Œè§†å›¾åŒ…å«çš„ä¸æ˜¯æ•°æ®è€Œæ˜¯sqlæŸ¥è¯¢ 5 å­˜å‚¨è¿‡ç¨‹ SQL è¯­è¨€å±‚é¢çš„ä»£ç å°è£…ä¸é‡ç”¨ https://www.runoob.com/w3cnote/mysql-stored-procedure.html","link":"/2022/02/27/sql-optimization/"},{"title":"sql","text":"1.SQLè¯­å¥ç±»åˆ«SQL è¯­å¥ä¸»è¦å¯ä»¥åˆ’åˆ†ä¸ºä»¥ä¸‹ 3 ä¸ªç±»åˆ«ã€‚ DDLï¼ˆData Definition Languagesï¼‰è¯­å¥ï¼šæ•°æ®å®šä¹‰è¯­è¨€ï¼Œè¿™äº›è¯­å¥å®šä¹‰äº†ä¸åŒçš„æ•°æ®æ®µã€æ•°æ®åº“ã€è¡¨ã€åˆ—ã€ç´¢å¼•ç­‰æ•°æ®åº“å¯¹è±¡çš„å®šä¹‰ã€‚å¸¸ç”¨çš„è¯­å¥å…³é”®å­—ä¸»è¦åŒ…æ‹¬ createã€dropã€alterç­‰ã€‚ DMLï¼ˆData Manipulation Languageï¼‰è¯­å¥ï¼šæ•°æ®æ“çºµè¯­å¥ï¼Œç”¨äºæ·»åŠ ã€åˆ é™¤ã€æ›´æ–°å’ŒæŸ¥è¯¢æ•°æ®åº“è®°å½•ï¼Œå¹¶æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼Œå¸¸ç”¨çš„è¯­å¥å…³é”®å­—ä¸»è¦åŒ…æ‹¬ insertã€deleteã€udpate å’Œselect ç­‰ã€‚(å¢æ·»æ”¹æŸ¥ï¼‰ DCLï¼ˆData Control Languageï¼‰è¯­å¥ï¼šæ•°æ®æ§åˆ¶è¯­å¥ï¼Œç”¨äºæ§åˆ¶ä¸åŒæ•°æ®æ®µç›´æ¥çš„è®¸å¯å’Œè®¿é—®çº§åˆ«çš„è¯­å¥ã€‚è¿™äº›è¯­å¥å®šä¹‰äº†æ•°æ®åº“ã€è¡¨ã€å­—æ®µã€ç”¨æˆ·çš„è®¿é—®æƒé™å’Œå®‰å…¨çº§åˆ«ã€‚ä¸»è¦çš„è¯­å¥å…³é”®å­—åŒ…æ‹¬ grantã€revoke ç­‰ã€‚ 2.sqlè¯­å¥æ‰§è¡Œé¡ºåºhttps://www.cnblogs.com/Qian123/p/5669259.html https://www.cnblogs.com/Qian123/p/5669259.html https://cloud.tencent.com/developer/article/1600323 123456781ã€fromå­å¥ç»„è£…æ¥è‡ªä¸åŒæ•°æ®æºçš„æ•°æ®ï¼›2ã€whereå­å¥åŸºäºæŒ‡å®šçš„æ¡ä»¶å¯¹è®°å½•è¡Œè¿›è¡Œç­›é€‰ï¼› 3ã€group byå­å¥å°†æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªåˆ†ç»„ï¼› 4ã€èšåˆå‡½æ•°è¿›è¡Œè®¡ç®—ï¼› 5ã€havingå­å¥ç­›é€‰åˆ†ç»„ï¼› 6ã€è®¡ç®—æ‰€æœ‰çš„è¡¨è¾¾å¼ï¼› 7ã€selectå­—æ®µï¼› 8ã€order byå¯¹ç»“æœé›†è¿›è¡Œæ’åºã€‚ æ„Ÿè§‰å¥½åƒå…ˆselectåhaving","link":"/2022/02/07/sql/"},{"title":"sqoop","text":"https://www.yangshuaibin.com/detail/388673 ä½œç”¨å…³ç³»å‹æ•°æ®åº“ &lt;&lt;â€”â€”&gt;&gt; hdfs ï¼ŒåŒå‘ï¼Œç”¨çš„mapreduce sqoopçš„ä½œç”¨å°±æ˜¯å°†å…³ç³»å‹æ•°æ®åº“ä¸­çš„æŸå¼ è¡¨æ•°æ®æŠ½å–åˆ°Hadoopçš„hdfsæ–‡ä»¶ç³»ç»Ÿå½“ä¸­ï¼Œåº•å±‚è¿ç”¨çš„è¿˜æ˜¯Map Reduce ã€‚ å®ƒåˆ©ç”¨MapReduceåŠ å¿«æ•°æ®ä¼ è¾“é€Ÿåº¦ï¼Œæ‰¹å¤„ç†æ–¹å¼è¿›è¡Œæ•°æ®ä¼ è¾“ã€‚ ä¹Ÿå¯ä»¥å°†HDFSä¸Šçš„æ–‡ä»¶æ•°æ®å¯¼å‡ºåˆ°å…³ç³»å‹æ•°æ®åº“ä¸­çš„æŸå¼ è¡¨ã€‚ è„šæœ¬https://blog.csdn.net/qq_44665283/article/details/120709047","link":"/2022/01/31/sqoop/"},{"title":"sugar","text":"ç™¾åº¦çš„BIå¯è§†åŒ–å·¥å…·","link":"/2022/04/23/sugar/"},{"title":"superset","text":"ä½œç”¨Apache Supersetæ˜¯ä¸€ä¸ªå¼€æºçš„ã€ç°ä»£çš„ã€è½»é‡çº§BIï¼ˆBusiness Intelligenceï¼‰åˆ†æå·¥å…·ï¼Œèƒ½å¤Ÿå¯¹æ¥å¤šç§æ•°æ®æºã€æ‹¥æœ‰ä¸°å¯Œçš„å›¾è¡¨å±•ç¤ºå½¢å¼ã€æ”¯æŒè‡ªå®šä¹‰ä»ªè¡¨ç›˜ï¼Œä¸”æ‹¥æœ‰å‹å¥½çš„ç”¨æˆ·ç•Œé¢ï¼Œååˆ†æ˜“ç”¨ã€‚ ç”±äºSupersetèƒ½å¤Ÿå¯¹æ¥å¸¸ç”¨çš„å¤§æ•°æ®åˆ†æå·¥å…·ï¼Œå¦‚Hiveã€Kylinã€Druidç­‰ï¼Œä¸”æ”¯æŒè‡ªå®šä¹‰ä»ªè¡¨ç›˜ï¼Œæ•…å¯ä½œä¸ºæ•°ä»“çš„å¯è§†åŒ–å·¥å…·ã€‚","link":"/2022/02/05/superset/"},{"title":"SVM","text":"1.å›é¡¾çº¿æ€§å›å½’å’ŒLRçº¿æ€§å›å½’æ˜¯è§£å†³å›å½’ä»»åŠ¡çš„çº¿æ€§æ¨¡å‹ LRæ˜¯äºŒåˆ†ç±»æ¨¡å‹ï¼Œåœ¨çº¿æ€§æ¨¡å‹çš„åŸºç¡€ä¸ŠåŠ å…¥æ¿€æ´»å‡½æ•°sigmoidï¼Œé€‚ç”¨åœ¨çº¿æ€§å¯åˆ†çš„äºŒåˆ†ç±»ä»»åŠ¡ 2.ä»‹ç»svmç®€å•æ€»ç»“ï¼š1.å¯¹äºå®Œå…¨çº¿æ€§å¯åˆ†ï¼Œç¡¬é—´éš” 2.ä¸èƒ½å¤Ÿå®Œå…¨çº¿æ€§å¯åˆ†ï¼Œå¼•å…¥æ¾å¼›å˜é‡ ï¼Œè½¯é—´éš” 3.çº¿æ€§ä¸å¯åˆ†ï¼Œå¼•å…¥æ ¸å‡½æ•° åŸç†å¯å‚è€ƒï¼š https://zhuanlan.zhihu.com/p/77750026 æˆ–è€… https://blog.csdn.net/qq_37321378/article/details/108807595 æ ¸å‡½æ•° https://blog.csdn.net/mengjizhiyou/article/details/103437423 ä¸LRåŒºåˆ«ï¼š https://www.jianshu.com/p/1b4d9de7000c","link":"/2021/10/09/svm/"},{"title":"å„ç§è¡¨","text":"1 åˆ†åŒºè¡¨https://www.jianshu.com/p/1cdd3e3c5b3c https://www.jianshu.com/p/163f8375c0d6 1 mysqlåˆ†åŒº RANGEåˆ†åŒºï¼šåŸºäºå±äºä¸€ä¸ªç»™å®šè¿ç»­åŒºé—´çš„åˆ—å€¼ï¼ŒæŠŠå¤šè¡Œåˆ†é…ç»™åˆ†åŒºã€‚ LISTåˆ†åŒºï¼šç±»ä¼¼äºæŒ‰RANGEåˆ†åŒºï¼ŒåŒºåˆ«åœ¨äºLISTåˆ†åŒºæ˜¯åŸºäºåˆ—å€¼åŒ¹é…ä¸€ä¸ªç¦»æ•£å€¼é›†åˆä¸­çš„æŸä¸ªå€¼æ¥è¿›è¡Œé€‰æ‹©ã€‚ HASHåˆ†åŒºï¼šåŸºäºç”¨æˆ·å®šä¹‰çš„è¡¨è¾¾å¼çš„è¿”å›å€¼æ¥è¿›è¡Œé€‰æ‹©çš„åˆ†åŒºï¼Œè¯¥è¡¨è¾¾å¼ä½¿ç”¨å°†è¦æ’å…¥åˆ°è¡¨ä¸­çš„è¿™äº›è¡Œçš„åˆ—å€¼è¿›è¡Œè®¡ç®—ã€‚è¿™ä¸ªå‡½æ•°å¯ä»¥åŒ…å«MySQL ä¸­æœ‰æ•ˆçš„ã€äº§ç”Ÿéè´Ÿæ•´æ•°å€¼çš„ä»»ä½•è¡¨è¾¾å¼ã€‚ KEYåˆ†åŒºï¼šç±»ä¼¼äºæŒ‰HASHåˆ†åŒºï¼ŒåŒºåˆ«åœ¨äºKEYåˆ†åŒºåªæ”¯æŒè®¡ç®—ä¸€åˆ—æˆ–å¤šåˆ—ï¼Œä¸”MySQL æœåŠ¡å™¨æä¾›å…¶è‡ªèº«çš„å“ˆå¸Œå‡½æ•°ã€‚å¿…é¡»æœ‰ä¸€åˆ—æˆ–å¤šåˆ—åŒ…å«æ•´æ•°å€¼ã€‚ 2 Hiveä¸­åˆ†åŒºè¡¨ åˆ†ä¸¤ç±»ï¼šé™æ€åˆ†åŒºã€åŠ¨æ€åˆ†åŒºï¼› Hiveä¸­æ²¡æœ‰å¤æ‚çš„åˆ†åŒºç±»å‹ï¼ˆList,Range,Hashï¼‰ 2 å†…éƒ¨è¡¨&amp;å¤–éƒ¨è¡¨https://www.cnblogs.com/qiaoyihang/p/6225151.html https://blog.csdn.net/qq_36743482/article/details/78393678 1 æœªè¢«externalä¿®é¥°çš„æ˜¯å†…éƒ¨è¡¨ï¼ˆmanaged tableï¼‰ï¼Œè¢«externalä¿®é¥°çš„ä¸ºå¤–éƒ¨è¡¨ï¼ˆexternal tableï¼‰ï¼› 2 å†…éƒ¨è¡¨æ•°æ®ç”±Hiveè‡ªèº«ç®¡ç†ï¼Œå¤–éƒ¨è¡¨æ•°æ®ç”±HDFSç®¡ç†ï¼› 3 å†…éƒ¨è¡¨æ•°æ®å­˜å‚¨çš„ä½ç½®æ˜¯hive.metastore.warehouse.dirï¼ˆé»˜è®¤ï¼š/user/hive/warehouseï¼‰ï¼Œå¤–éƒ¨è¡¨æ•°æ®çš„å­˜å‚¨ä½ç½®ç”±è‡ªå·±åˆ¶å®šï¼ˆå¦‚æœæ²¡æœ‰LOCATIONï¼ŒHiveå°†åœ¨HDFSä¸Šçš„/user/hive/warehouseæ–‡ä»¶å¤¹ä¸‹ä»¥å¤–éƒ¨è¡¨çš„è¡¨ååˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå¹¶å°†å±äºè¿™ä¸ªè¡¨çš„æ•°æ®å­˜æ”¾åœ¨è¿™é‡Œï¼‰ï¼›4 åˆ é™¤å†…éƒ¨è¡¨ä¼šç›´æ¥åˆ é™¤å…ƒæ•°æ®ï¼ˆmetadataï¼‰åŠå­˜å‚¨æ•°æ®ï¼›åˆ é™¤å¤–éƒ¨è¡¨ä»…ä»…ä¼šåˆ é™¤å…ƒæ•°æ®ï¼ŒHDFSä¸Šçš„æ–‡ä»¶å¹¶ä¸ä¼šè¢«åˆ é™¤ï¼›5 å¯¹å†…éƒ¨è¡¨çš„ä¿®æ”¹ä¼šå°†ä¿®æ”¹ç›´æ¥åŒæ­¥ç»™å…ƒæ•°æ®ï¼Œè€Œå¯¹å¤–éƒ¨è¡¨çš„è¡¨ç»“æ„å’Œåˆ†åŒºè¿›è¡Œä¿®æ”¹ï¼Œåˆ™éœ€è¦ä¿®å¤ï¼ˆMSCK REPAIR TABLE table_name;ï¼‰ 3 ä¸´æ—¶è¡¨https://www.cnblogs.com/duanxz/p/3724120.html 4 å­—å…¸è¡¨https://www.cnblogs.com/jpfss/p/10418873.html 5 å…¨é‡è¡¨ï¼Œå¢é‡è¡¨ã€å¿«ç…§è¡¨ã€æµæ°´è¡¨å…¨é‡è¡¨ï¼šæ‰€æœ‰æ•°æ®çš„æœ€æ–°çŠ¶æ€ å¢é‡è¡¨ï¼šæ–°å¢æ•°æ® å¿«ç…§è¡¨ï¼š æµæ°´è¡¨ï¼š å¯¹äºè¡¨çš„æ¯ä¸€ä¸ªä¿®æ”¹éƒ½ä¼šè®°å½•ï¼Œå¯ä»¥ç”¨äºåæ˜ å®é™…è®°å½•çš„å˜æ›´ã€‚ 6 åˆ‡ç‰‡è¡¨åˆ‡ç‰‡è¡¨ï¼šåˆ‡ç‰‡è¡¨æ ¹æ®åŸºç¡€è¡¨ï¼Œå¾€å¾€åªåæ˜ æŸä¸€ä¸ªç»´åº¦çš„ç›¸åº”æ•°æ®ã€‚å…¶è¡¨ç»“æ„ä¸åŸºç¡€è¡¨ç»“æ„ç›¸åŒï¼Œä½†æ•°æ®å¾€å¾€åªæœ‰æŸä¸€ç»´åº¦ï¼Œæˆ–è€…æŸä¸€ä¸ªäº‹å®æ¡ä»¶çš„æ•°æ® 7 æ‹‰é“¾è¡¨1 å®šä¹‰ 2 åº”ç”¨åœºæ™¯ 3 åˆ†åŒº 4 æ•°æ®åŠ è½½ 1ï¼‰é¦–æ—¥è£…è½½ æ‹‰é“¾è¡¨é¦–æ—¥è£…è½½ï¼Œéœ€è¦è¿›è¡Œåˆå§‹åŒ–æ“ä½œï¼Œå…·ä½“å·¥ä½œä¸ºå°†æˆªæ­¢åˆ°åˆå§‹åŒ–å½“æ—¥çš„å…¨éƒ¨å†å²ç”¨æˆ·å¯¼å…¥ä¸€æ¬¡æ€§å¯¼å…¥åˆ°æ‹‰é“¾è¡¨ä¸­ã€‚ç›®å‰çš„ods_user_info è¡¨çš„ç¬¬ä¸€ä¸ªåˆ†åŒºï¼Œå³2020-06-14 åˆ†åŒºä¸­å°±æ˜¯å…¨éƒ¨çš„å†å²ç”¨æˆ·ï¼Œæ•…å°†è¯¥åˆ†åŒºæ•°æ®è¿›è¡Œä¸€å®šå¤„ç†åå¯¼å…¥æ‹‰é“¾è¡¨çš„9999-99-99 åˆ†åŒºå³å¯ã€‚ 2ï¼‰æ¯æ—¥è£…è½½","link":"/2022/01/30/table/"},{"title":"Embedding based Product Retrieval in Taobao Search","text":"https://arxiv.org/pdf/2106.09297.pdf http://xtf615.com/2021/10/07/taobao-ebr/ 1.INTRODUCTION æ¡†æ¶æ˜¯æœç´¢ç³»ç»Ÿä¸»æµçš„ç»“æ„ï¼Œå³åŒ¹é…/æ£€ç´¢ï¼Œç²—æ’ï¼Œç²¾æ’ï¼Œé‡æ’ã€‚ 2.RELATED WORK2.1 Deep Matching in Searchfall into two categories: representation-based learning and interaction-based learning. Other than semantic and relevance matching, more complex factors/trade-offs, e.g., user personalization [2, 3, 10] and retrieval efficiency [5], need to be considered when applying deep models to a large-scale online retrieval system. 2.2 Deep Retrieval in Industry SearchRepresentation-based models with an ANN (approximate near neighbor) algorithm have become the mainstream trend to efficiently deploy neural retrieval models in industry. 3 MODELæ•´ä½“ç»“æ„å…¥ä¸‹ï¼š 3.1 Problem Formulation$\\mathcal{U}=\\{u_1,â€¦,u_u,â€¦u_N\\}$è¡¨ç¤º$N$ä¸ªç”¨æˆ·ï¼Œ$\\mathcal{Q}=\\{q_1,â€¦,q_u,â€¦q_N\\}$è¡¨ç¤ºä¸ç”¨æˆ·å¯¹åº”çš„$N$ä¸ªqueryï¼Œ$\\mathcal{I}=\\{i_1,â€¦,i_u,â€¦i_M\\}$è¡¨ç¤º$M$ä¸ªå•†å“ã€‚å°†ç”¨æˆ·$u$çš„å†å²è¡Œä¸ºæ ¹æ®æ—¶é—´åˆ†æˆ3ä¸ªéƒ¨åˆ†ï¼š1.real-timeï¼Œbeforethe current time stepï¼Œ$\\mathcal{R}^u=\\{i_1^u,â€¦,i_t^u,â€¦i_T^u\\}$ 2.short-term, before $\\mathcal{R}$ and within ten days,$\\mathcal{S}^u=\\{i_1^u,â€¦,i_t^u,â€¦i_T^u\\}$ 3.long-term sequences,before $\\mathcal{S}$ and within one month,$\\mathcal{L}^u=\\{i_1^u,â€¦,i_t^u,â€¦i_T^u\\}$ ï¼Œ$T$ä¸ºæ—¶é—´é•¿åº¦ã€‚ä»»åŠ¡å¯ä»¥å®šä¹‰ä¸ºï¼š z=\\mathcal{F}(\\phi(q_u,\\mathcal{R}^u,\\mathcal{S}^u,\\mathcal{L}^u),\\varphi(i))å…¶ä¸­$\\mathcal{F}(\\cdot),\\phi(\\cdot),\\varphi(\\cdot)$åˆ†åˆ«è¡¨ç¤ºscoring function, query and behaviors encoder, and item encoder 3.2 User Tower3.2.1 Multi-Granular Semantic UnitæŒ–æ˜queryçš„è¯­ä¹‰ï¼ŒåŸå§‹è¾“å…¥åŒ…å«å½“å‰queryå’Œå†å²query æ²¡æœ‰è¯´æ˜ä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ï¼Œæ„Ÿè§‰å°±æ˜¯å·¥ç¨‹è¯•éªŒçš„ç»“è®ºã€‚æœ‰ä¸ªç–‘é—®ï¼Œç›´æ¥ç”¨BERTç­‰æ·±åº¦è¯­è¨€æ¨¡å‹æ¥æŒ–æ˜queryçš„è¯­ä¹‰ä¸å¥½å—ï¼Ÿ queryè¡¨ç¤ºä¸º$q_u=\\{w_1^u,â€¦,w_n^u\\}$,ä¾‹å¦‚{çº¢è‰²ï¼Œè¿è¡£è£™}ï¼Œ$w_u=\\{c_1^u,â€¦,c_m^u\\}$,ä¾‹å¦‚{çº¢ï¼Œè‰²}ï¼Œhistory queryè¡¨ç¤ºä¸º$q_{his}=\\{q_1^u,â€¦,q_k^u\\} $,ä¾‹å¦‚{ç»¿è‰²ï¼ŒåŠèº«è£™ï¼Œé»„è‰²ï¼Œé•¿è£™}ï¼Œå…¶ä¸­$w_n \\in \\mathbb{R}^{1\\times d},c_m \\in \\mathbb{R}^{1\\times d},q_k \\in \\mathbb{R}^{1\\times d}$ q_{1\\_gram}=mean\\_pooling(c_1,...,c_m) \\\\q_{2\\_gram}=mean\\_pooling(c_1c_2,...,c_{m-1}c_m) \\\\q_{seq}=mean\\_pooling(w_1,...,w_n) \\\\q_{seq\\_seq}=mean\\_pooling(T_{rm}(w_1,...,w_n)) \\\\q_{his\\_seq}=softmax(q_{seg}\\cdot(q_{his})^{T})q_{his} \\\\q_{mix}=q_{1\\_gram}+q_{2\\_gram}+q_{seq}+q_{seq\\_seq}+q_{his\\_seq} \\\\Q_{mgs}=concat(q_{1\\_gram},q_{2\\_gram},q_{seq},q_{seq\\_seq},q_{his\\_seq},q_{mix})å…¶ä¸­ğ‘‡ğ‘Ÿğ‘š,ğ‘šğ‘’ğ‘ğ‘›_ğ‘ğ‘œğ‘œğ‘™ğ‘–ğ‘›ğ‘”, and ğ‘ğ‘œğ‘›ğ‘ğ‘ğ‘¡ denote the Transformer ,average, and vertical concatenation operation, respectively 3.2.2 User Behaviors Attention e_i^f=W_f\\cdot x_i^{f} \\in \\mathbb{R}^{1\\times d_f} \\tag{9} \\\\i_t^u=concat(\\{e_i^f\\ | \\ f \\in \\mathcal{F} \\})å…¶ä¸­$W_f$æ˜¯embedding matrixï¼Œ$x_i^{f}$æ˜¯one-hot vector, $\\mathcal{F}$æ˜¯side information (e.g., leaf category, first-level category, brand and,shop) real-time sequences Userâ€™s click_item \\mathcal{R}_{lstm}^u=LSTM(\\mathcal{R}^u)=\\{h_1^{u},...,h_t^{u},...,h_T^{u} \\} \\\\\\mathcal{R}_{self\\_att}^u=multihead\\_selfattention(\\mathcal{R}_{lstm}^u)=\\{h_1^{u},...,h_t^{u},...,h_T^{u} \\} \\\\\\mathcal{R}_{zero\\_att}^u=\\{0,h_1^{u},...,h_t^{u},...,h_T^{u} \\} \\ \\# add \\ a \\ zero \\ vector \\ at \\ the \\ first \\ position \\ of \\ \\mathcal{R}_{self\\_att}^u \\\\H_{real}=softmax(Q_{mgs}\\cdot\\mathcal{R}_{zero\\_att}^T)\\cdot\\mathcal{R}_{zero\\_att}^Tshort-term sequences Userâ€™s click_item \\mathcal{S}_{self\\_att}^u=multihead\\_selfattention(\\mathcal{S}^u)=\\{h_1^{u},...,h_t^{u},...,h_T^{u} \\} \\\\\\mathcal{S}_{zero\\_att}^u=\\{0,h_1^{u},...,h_t^{u},...,h_T^{u} \\} \\\\H_{short}=softmax(Q_{mgs}\\cdot\\mathcal{S}_{zero\\_att}^T)\\cdot\\mathcal{S}_{zero\\_att}^Tlong-term sequence $\\mathcal{L}^u$ç”±å››ä¸ªéƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«ä¸º$\\mathcal{L}^{u}_{item},\\mathcal{L}^{u}_{shop},\\mathcal{L}^{u}_{leaf},\\mathcal{L}^{u}_{brand}$,æ¯ä¸ªéƒ¨åˆ†åŒ…å«3ä¸ªåŠ¨ä½œï¼Œåˆ†åˆ«ä¸ºclickï¼Œbuyï¼Œcollectã€‚ \\\\ \\mathcal{L}_{click\\_item},\\mathcal{L}_{buy\\_item},\\mathcal{L}_{collect\\_item} \\rightarrow L^{T}_{item} \\\\H_{a\\_item}=softmax(Q_{mgs}\\cdot L^{T}_{item})\\cdot L^{T}_{item} \\\\H_{long}=H_{a\\_item}+H_{a\\_shop}+H_{a\\_leaf}+H_{a\\_brand}3.2.3 Fusion of Semantics and Personalization H_{qu}=Self\\_Att^{first}([[cls],Q_{mgs},H_{real},H_{short},H_{long}]) \\in \\mathbb{R}^{1\\times d}3.3 Item TowerFor the item tower, we experimentally use item ID and title to obtain the item representation ğ»ğ‘–ğ‘¡ğ‘’ğ‘š.Given the representation of item ğ‘–â€™s ID, $e_i \\in \\mathbb{R}^{1\\times d}$ , and its title segmentation result $T_i=\\{w_1^{i},â€¦,w_N^{i}\\}$ H_{item}=e+tanh(W_t\\cdot\\frac{\\sum_{i=1}^Nw_i}{N})where $W_t$ is the transformation matrix. We empirically find that applying LSTM [12] or Transformer [27] to capture the context of the title is not as effective as simple mean-pooling since the title is stacked by keywords and lacks grammatical structure. 3.4 Loss Functionadapt the softmax cross-entropy loss as the training objective \\hat{y}(i^+|q_u)=\\frac{exp(\\mathcal{F}(q_u,i^{+}))}{\\sum_{i^{'}\\in I }exp(\\mathcal{F}(q_u,i^{'}))} \\\\L(\\nabla )=-\\sum_{i\\in I}y_ilog(\\hat{y_i})where $\\mathcal{F},I,i^+,q_u$denote the inner product, the full item pool, the item towerâ€™s representation $H_{item}$, and the user towerâ€™s representation $H_{qu}$, respectively. 3.4.1 Smoothing Noisy Training Datathe softmax function with the temperature parameter $\\tau$ is defined as follows \\hat{y}(i^+|q_u)=\\frac{exp(\\mathcal{F}(q_u,i^{+})/\\tau)}{\\sum_{i^{'}\\in I }exp(\\mathcal{F}(q_u,i^{'})/\\tau)}If ğœ-&gt;0, the fitted distribution is close to one hot distribution,If ğœ-&gt;âˆ, the fitted distribution is close to a uniform distribution 3.4.2 Generating Relevance-improving Hard Negative SamplesWe first select the negative items of $i^-$ that have the top-ğ‘ inner product scores with $q_u $ to form the hard sample set $I_{hard}$ I_{mix}=\\alpha i^++(1-\\alpha)I_{hard}å…¶ä¸­$\\alpha\\in \\mathbb{R}^{N\\times1}$is sampled from the uniform distribution ğ‘ˆ (ğ‘, ğ‘) (0 â‰¤ ğ‘ &lt; ğ‘ â‰¤ 1). \\hat{y}(i^+|q_u)=\\frac{exp(\\mathcal{F}(q_u,i^{+})/\\tau)}{\\sum_{i^{'}\\in (I\\cup I_{mix}) }exp(\\mathcal{F}(q_u,i^{'})/\\tau)}","link":"/2021/09/28/tao-emb-search/"},{"title":"ä¸­æ–‡æ–‡æœ¬åˆ†ç±»å·¥å…·","text":"æ„Ÿè°¢å¤§ä½¬å¼€æº https://github.com/649453932/Chinese-Text-Classification-Pytorch","link":"/2021/11/30/text-classifying/"},{"title":"TextCNN TextRNN TextRCNN","text":"1.TextCNN (Convolutional Neural Networks for Sentence Classification)åŸæ–‡ https://arxiv.org/abs/1408.5882 è°ƒå‚è®ºæ–‡ https://arxiv.org/abs/1510.03820 æ¨¡å‹çš„æ•´ä½“ç»“æ„å¦‚ä¸Šæ‰€ç¤ºã€‚Feature Mapæ˜¯è¾“å…¥å›¾åƒç»è¿‡ç¥ç»ç½‘ç»œå·ç§¯äº§ç”Ÿçš„ç»“æœï¼Œfilteræ˜¯å·ç§¯æ ¸ã€‚ è¾“å…¥è¡¨ç¤ºï¼š å‡è®¾è¾“å…¥æ–‡æœ¬çš„é•¿åº¦ä¸º$n$ï¼Œå¯¹äºé•¿åº¦ä¸å¤Ÿçš„éœ€è¦åšpaddingï¼Œä»»æ„ä¸€ä¸ªå•è¯å¯ä»¥ç”¨ä¸€ä¸ª$k$ç»´çš„å‘é‡è¡¨ç¤ºï¼Œå³$X_i \\in \\mathbb{R}^{k}$ï¼Œé‚£ä¹ˆä¸€ä¸ªå¥å­å¯ä»¥è¡¨ç¤ºä¸º X_{1:n}=X_1 \\oplus X_2\\oplus...\\oplus X_nå…¶ä¸­$\\oplus$æ˜¯å‘é‡æ‹¼æ¥æ“ä½œï¼Œ$X_{1:n} \\in \\mathbb{R}^{nk\\times 1}$ã€‚ å·ç§¯ï¼š å¯¹äºæŸä¸ªæ»‘çª—$X_{i,i+h-1}=\\{X_i,X_{i+1},â€¦,X_{i+h-1}\\}$ç»è¿‡æŸä¸ªå·ç§¯æ ¸$W_j$å¯å¾— c_{i,j}=f(W_j\\cdot X_{i,i+h-1}+b)å…¶ä¸­$f=tanh(\\cdot)$ï¼Œ$W_j\\in \\mathbb{R}^{ 1\\times hk}ï¼Œc_{i,j} $æ˜¯æ ‡é‡ å‡è®¾å·ç§¯é€šé“æ•°ä¸º$m$ï¼Œåœ¨NLPä¸­ï¼Œå·ç§¯æ»‘åŠ¨æ­¥ä¼$k=1$ï¼Œé‚£ä¹ˆç»è¿‡å·ç§¯å±‚åå¾—åˆ°çš„å®Œæ•´çš„ç‰¹å¾çŸ©é˜µä¸º C=[[c_{1,1},c_{2,1},...,c_{n-h+1,1}]^T,[c_{1,2},c_{2,2},...,c_{n-h+1,2}]^T,...,[c_{1,m},c_{2,m},...,c_{n-h+1,m}]^T]å…¶ä¸­$C \\in \\mathbb{R}^{(n-h+1)\\times m}$ maxpoolingï¼š \\hat{C}=max\\{C\\} , \\hat{C}\\in \\mathbb{R}^{m}å…¨è¿æ¥ï¼š ç„¶åå°†$\\hat{C}$æ¥ä¸ªå…¨è¿æ¥ï¼Œå°±å¯ä»¥åšåˆ†ç±»æˆ–è€…å›å½’ä»»åŠ¡äº†ã€‚ 2.TextRNN (Recurrent Neural Network for Text Classification with Multi-Task Learning)åŸæ–‡ https://www.ijcai.org/Proceedings/16/Papers/408.pdf è¯¥æ–‡çš„åœºæ™¯ä¸ºRecurrent Neural Network for Text Classification with Multi-Task Learningï¼Œå°±æ˜¯è®ºæ–‡çš„é¢˜ç›®ã€‚æ–‡ä¸­ç»™å‡ºäº†ä¸‰ç§ç»“æ„ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå›¾ä¸­çš„RNNå•å…ƒä¸ºLSTMã€‚ Model-I: Uniform-Layer Architecture å¯¹äºä»»åŠ¡$m$ï¼Œè¾“å…¥$\\hat X_t$åŒ…å«ä¸¤ä¸ªéƒ¨åˆ† \\hat{X}_t^{(m)}=X_{t}^{(m)}\\oplus X_{t}^{(s)}å…¶ä¸­$X_{t}^{(m)}$è¡¨ç¤ºç‰¹å®šä»»åŠ¡çš„è¯å‘é‡ï¼Œ$X_{t}^{(s)}$è¡¨ç¤ºå…±äº«çš„è¯å‘é‡ï¼Œ$\\oplus$è¡¨ç¤ºå‘é‡æ‹¼æ¥çš„æ“ä½œã€‚ Model-II: Coupled-Layer Architecture \\hat{c}_t=tanh(W_cX_t+U_ch_{t-1}) \\ \\#åŸæ¥ \\\\\\downarrow \\\\\\hat{c}_t^{(m)}=tanh(W_c^{(m)}X_t+\\sum_{i\\in\\{m,n\\}}g^{(i\\longrightarrow m)}U_c^{(i\\longrightarrow m)}h_{t-1}^{(i)}) \\ \\#ç°åœ¨ \\\\g^{(i\\longrightarrow m)}=\\sigma(W_{g}^{(m)}x_t+U_g^{(i)}h_{t-1}^{(i)})Model-III: Shared-Layer Architecture \\hat{c}_t=tanh(W_cX_t+U_ch_{t-1}) \\ \\#åŸæ¥ \\\\\\downarrow \\\\\\hat{c}_t^{(m)}=tanh(W_c^{(m)}X_t+g^{(m)}U_c^{(m)}h_{t-1}^{(m)}+g^{(s\\longrightarrow m)}U_c^{(s)}h_{t}^{(s)} \\ \\#ç°åœ¨ \\\\g^{( m)}=\\sigma(W_{g}^{(m)}x_t+U_g^{(m)}h_{t-1}^{(m)}), g^{( s\\longrightarrow m)}=\\sigma(W_{g}^{(m)}x_t+U_g^{(s\\longrightarrow m)}h_{t}^{(s)}), h_t^{(s)}=\\overrightarrow{h_t^{(s)}}\\oplus\\overleftarrow{h_t^{(s)}}3.TextRCNN(Recurrent Convolutional Neural Networks for Text Classification)åŸæ–‡ https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf æ•´ä½“ç»“æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè§£é‡Šä¸€ä¸‹ä¸ºå•¥å«RCNNï¼Œä¸€èˆ¬çš„ CNN ç½‘ç»œï¼Œéƒ½æ˜¯å·ç§¯å±‚ + æ± åŒ–å±‚ï¼Œè¿™é‡Œæ˜¯å°†å·ç§¯å±‚æ¢æˆäº†åŒå‘ RNNï¼Œæ‰€ä»¥ç»“æœæ˜¯ï¼ŒåŒå‘ RNN + æ± åŒ–å±‚ã€‚ä½œè€…åŸè¯ä¸ºï¼šFrom the perspective of convolutional neural networks, the recurrent structure we previously mentioned is the convolutional layer. è¯è¯­è¡¨ç¤º å¯¹äºä¸€ä¸ªè¯è¯­$w_i$ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªä¸‰å…ƒç»„è¡¨ç¤ºä¸º x_i=[c_l(w_i);e(w_i);c_r(w_i)]å…¶ä¸­$e(w_i)$è¡¨ç¤º$w_i$çš„è¯å‘é‡ï¼Œ$c_l(w_i)$è¡¨ç¤º$w_i$å¥å­å·¦è¾¹çš„å†…å®¹çš„å‘é‡è¡¨ç¤ºï¼Œ$c_r(w_i)$è¡¨ç¤º$w_i$å¥å­å³è¾¹çš„å†…å®¹çš„å‘é‡è¡¨ç¤ºï¼Œç”¨å¼å­è¡¨ç¤ºå¦‚ä¸‹ c_l(w_i)=f(W^{l}c_l(w_{i-1})+W^{(sl)}e(w_{i-1})) \\\\c_r(w_i)=f(W^{r}c_r(w_{i-1})+W^{(sr)}e(w_{i-1}))ç„¶åå°†$x_i$ç»è¿‡å…¨è¿æ¥å¾—åˆ°$y_i^{(2)}$ï¼Œ$y_i^{(2)}$is a latent semantic vector y_i^{(2)}=tanh(W^{(2)}x_i+b^{(2)})è¯­å¥è¡¨ç¤º è·å–ä¼—å¤šçš„è¯è¯­è¡¨ç¤ºåï¼Œé€šè¿‡max-poolingå¾—åˆ°å¥å­è¡¨ç¤º y^{(3)}=\\mathop{\\max}_{i=1}^{n}y_i^{(2)}ç„¶åæ¥å…¨è¿æ¥å’Œsoftmax y^{(4)}=W^{(4)}y^{(3)}+b^{(4)} \\\\p=softmax(y^{(4)})å‚è€ƒhttps://www.cnblogs.com/wangduo/p/6773601.html","link":"/2021/08/23/text-cnn/"},{"title":"text edit","text":"https://blog.csdn.net/qq_27590277/article/details/118534238 https://thinkwee.top/2021/05/11/text-edit-generation/ https://zhuanlan.zhihu.com/p/144995580#:","link":"/2021/11/08/text-edit/"},{"title":"æ–‡æœ¬ç”Ÿæˆè¯„ä»·æŒ‡æ ‡","text":"1.BLEUBLEU,å…¨ç§°ä¸ºbilingual evaluation understudyï¼Œä¸€èˆ¬ç”¨äºæœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆçš„è¯„ä»·ï¼Œæ¯”è¾ƒå€™é€‰è¯‘æ–‡å’Œå‚è€ƒè¯‘æ–‡é‡Œçš„é‡åˆç¨‹åº¦ï¼Œé‡åˆç¨‹åº¦è¶Šé«˜å°±è®¤ä¸ºè¯‘æ–‡è´¨é‡è¶Šé«˜ï¼Œå–å€¼èŒƒå›´ä¸º[0,1]ã€‚ ä¼˜ç‚¹ å®ƒçš„æ˜“äºè®¡ç®—ä¸”é€Ÿåº¦å¿«ï¼Œç‰¹åˆ«æ˜¯ä¸äººå·¥ç¿»è¯‘æ¨¡å‹çš„è¾“å‡ºå¯¹æ¯”ï¼› å®ƒåº”ç”¨èŒƒå›´å¹¿æ³›ï¼Œè¿™å¯ä»¥è®©ä½ å¾ˆè½»æ¾å°†æ¨¡å‹ä¸ç›¸åŒä»»åŠ¡çš„åŸºå‡†ä½œå¯¹æ¯”ã€‚ ç¼ºç‚¹ å®ƒä¸è€ƒè™‘è¯­ä¹‰ï¼Œå¥å­ç»“æ„ ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†å½¢æ€ä¸°å¯Œçš„è¯­å¥ï¼ˆBLEUåŸæ–‡å»ºè®®å¤§å®¶é…å¤‡4æ¡ç¿»è¯‘å‚è€ƒè¯‘æ–‡ï¼‰ BLEU æŒ‡æ ‡åå‘äºè¾ƒçŸ­çš„ç¿»è¯‘ç»“æœï¼ˆbrevity penalty æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆå¼ºï¼‰ 1.1 å®Œæ•´å¼å­BLEUå®Œæ•´å¼å­ä¸ºï¼š BLEU=BP*e^{\\sum_{n=1}^{N}W_nlogP_{n}}1.2 $BP$ç›®çš„ï¼š$n-gram$åŒ¹é…åº¦å¯èƒ½ä¼šéšç€å¥å­é•¿åº¦çš„å˜çŸ­è€Œå˜å¥½ï¼Œæ¯”å¦‚ï¼Œåªç¿»è¯‘äº†ä¸€ä¸ªè¯ä¸”å¯¹äº†ï¼Œé‚£ä¹ˆåŒ¹é…åº¦å¾ˆé«˜,ä¸ºäº†é¿å…è¿™ç§è¯„åˆ†çš„åå‘æ€§,å¼•å…¥é•¿åº¦æƒ©ç½šå› å­ Brevity Penaltyä¸ºé•¿åº¦æƒ©ç½šå› å­ï¼Œå…¶ä¸­$l_c$è¡¨ç¤ºæœºå™¨ç¿»è¯‘çš„è¯‘æ–‡é•¿åº¦ï¼Œ$l_s$è¡¨ç¤ºå‚è€ƒç­”æ¡ˆçš„æœ‰æ•ˆé•¿åº¦ BP=\\begin{equation} \\left\\{ \\begin{aligned} 1 & & if \\ \\ l_c>l_s \\\\e^{1-\\frac{l_s}{l_c}} & & l_c","link":"/2021/07/27/text-generate-evaluate/"},{"title":"Evaluation of Text Generation A Survey","text":"ä»3ä¸ªç»´åº¦å°†è¯„ä»·æŒ‡æ ‡åˆ†ç±» 1 Human-Centric Evaluation Methods â€‹ gold standard expensive to execute 2 Untrained Automatic Evaluation Metrics widely used æ±‡æ€» propertyï¼š åº”è¯¥æ˜¯è¯´è¿™ä¸ªæ–¹æ³•çš„å…³æ³¨ç‚¹ 3 Untrained Automatic Evaluation Metrics over fitting and `gaming of the metric.â€™ å‚è€ƒhttps://arxiv.org/abs/2006.14799","link":"/2022/05/18/text-generate-metric-survey/"},{"title":"æ–‡æœ¬åŒ¹é…","text":"1.æ— ç›‘ç£1.1 ç¼–è¾‘è·ç¦»å®šä¹‰ç¼–è¾‘è·ç¦»ï¼Œè‹±æ–‡åå­—ä¸ºLevenshtein distanceï¼Œé€šè¿‡æè¿°ä¸€ä¸ªå­—ç¬¦ä¸²Aéœ€è¦å¤šå°‘æ¬¡åŸºæœ¬æ“ä½œå¯ä»¥å˜æˆå­—ç¬¦ä¸²Bï¼Œæ¥è¡¡é‡ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ã€‚ åŸºæœ¬æ“ä½œåŒ…æ‹¬ï¼šå¢ã€åˆ ã€æ”¹ å¢ï¼šå­—ç¬¦ä¸²Aä¸ºâ€œASâ€ï¼Œå­—ç¬¦ä¸²Bä¸ºâ€œ ASDâ€œï¼Œå­—ç¬¦ä¸²A-&gt;å­—ç¬¦ä¸²Béœ€è¦å¢åŠ ä¸€ä¸ªå­—ç¬¦â€œDâ€ åˆ ï¼šå­—ç¬¦ä¸²Aä¸ºâ€œASDâ€ï¼Œå­—ç¬¦ä¸²Bä¸ºâ€œ ASâ€œï¼Œå­—ç¬¦ä¸²A-&gt;å­—ç¬¦ä¸²Béœ€è¦åˆ é™¤ä¸€ä¸ªå­—ç¬¦â€œDâ€ æ”¹ï¼šå­—ç¬¦ä¸²Aä¸ºâ€œASXâ€ï¼Œå­—ç¬¦ä¸²Bä¸ºâ€œ ASDâ€œï¼Œå­—ç¬¦ä¸²A-&gt;å­—ç¬¦ä¸²Béœ€è¦å°†å­—ç¬¦â€œXâ€å˜æˆå­—ç¬¦â€œDâ€ ä»£ç å®ç°è¿‡ç¨‹ä½¿ç”¨åŠ¨æ€è§„åˆ’ï¼Œé€’æ¨å…¬å¼ä¸º lev_{a,b}(i,j)= \\begin{equation} f(x)=\\left\\{ \\begin{aligned} max(i,j) & & if\\ \\min(i,j)=0 \\\\ min\\left\\{ \\begin{aligned} lev_{a,b}(i-1,j)+1 \\\\ lev_{a,b}(i,j-1)+1 \\\\ lev_{a,b}(i-1,j-1)+1_{(a_i\\neq b_j)} \\end{aligned} \\right. \\end{aligned} \\right. \\end{equation}$i$å’Œ$j$åˆ†åˆ«è¡¨ç¤ºå­—ç¬¦ä¸²$a$å’Œå­—ç¬¦ä¸²$b$çš„ä¸‹æ ‡ï¼Œ$lev_{a,b}(i,j)$è¡¨ç¤ºå­ä¸²$a[:i]$åˆ°å­ä¸²$b[:j]$çš„ç¼–è¾‘è·ç¦»ã€‚ 123456789101112131415161718192021222324def lev(str_a,str_b): &quot;&quot;&quot; EDè·ç¦»ï¼Œç”¨æ¥è¡¡é‡å•è¯ä¹‹é—´çš„ç›¸ä¼¼åº¦ :param str_a: :param str_b: :return: &quot;&quot;&quot; str_a=str_a.lower() str_b=str_b.lower() matrix_ed=np.zeros((len(str_a)+1,len(str_b)+1),dtype=np.int) matrix_ed[0]=np.arange(len(str_b)+1) matrix_ed[:,0] = np.arange(len(str_a) + 1) for i in range(1,len(str_a)+1): for j in range(1,len(str_b)+1): # è¡¨ç¤ºåˆ é™¤a_i dist_1 = matrix_ed[i - 1, j] + 1 # è¡¨ç¤ºæ’å…¥b_i dist_2 = matrix_ed[i, j - 1] + 1 # è¡¨ç¤ºæ›¿æ¢b_i dist_3 = matrix_ed[i - 1, j - 1] + (1 if str_a[i - 1] != str_b[j - 1] else 0) #å–æœ€å°è·ç¦» matrix_ed[i,j]=np.min([dist_1, dist_2, dist_3]) print(matrix_ed) return matrix_ed[-1,-1] 1.2 TF-IDFåŸç†ï¼ˆ1ï¼‰TF é’ˆå¯¹æŸä¸ªæ–‡æœ¬ $TF_{word}=\\frac{wordåœ¨æ–‡æœ¬ä¸­å‡ºç°çš„æ¬¡æ•°}{æ–‡æœ¬ä¸­æ‰€æœ‰è¯çš„æ€»æ•°}$ ï¼ˆ2ï¼‰IDF é’ˆå¯¹è¯­æ–™åº“ $IDF_{word}=log(\\frac{è¯­æ–™åº“çš„æ–‡æœ¬æ€»æ•°}{åŒ…å«è¯¥wordçš„æ–‡æœ¬æ•°+1})$ ï¼ˆ3ï¼‰TF-IDF $TF-IDF_{word}=TF_{word}*IDF_{word}$ ï¼ˆ4ï¼‰TF-IDF VEC ç°æœ‰å¥å­Aï¼šâ€ä»Šå¤©å¤©æ°”çœŸå¥½â€ï¼Œå¯¹å¥å­Aåšåˆ†è¯å¾—åˆ°[â€œä»Šå¤©â€,â€å¤©æ°”â€,â€çœŸå¥½â€],è¯åº“åŒ…å«[â€œä»Šå¤©â€,â€å¤©æ°”â€,â€çœŸå¥½â€,â€å¤©æ°”â€,â€ä¸é”™å‘€â€] $VEC_{A}=[TF-IDF_{ä»Šå¤©},TF-IDF_{å¤©æ°”}ï¼ŒTF-IDF_{çœŸå¥½},0,0]$ ï¼ˆ5ï¼‰è®¡ç®—ä¸¤å¥è¯çš„æ–‡æœ¬ç›¸ä¼¼åº¦ å‡è®¾è¯åº“åŒ…å«[â€œä»Šå¤©â€,â€å¤©æ°”â€,â€çœŸå¥½â€,â€å¤©æ°”â€,â€ä¸é”™å‘€â€],ç°æœ‰å¥å­Aï¼šâ€ä»Šå¤©å¤©æ°”çœŸå¥½â€ï¼Œå¯¹å¥å­Aåšåˆ†è¯å¾—åˆ°[â€œä»Šå¤©â€,â€å¤©æ°”â€,â€çœŸå¥½â€],å¥å­B:â€å¤©æ°”ä¸é”™å‘€â€ï¼Œåˆ†è¯å[â€œå¤©æ°”â€,â€ä¸é”™å‘€â€] åˆ©ç”¨ï¼ˆ3ï¼‰å¾—åˆ°å¥å­Açš„TF-IDF VEC $VEC_{A}$ï¼Œå¥å­Bçš„TF-IDF VEC $VEC_B$ï¼Œåˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ ä»£ç 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import pandas as pdimport jiebaimport numpy as npfrom sklearn.externals import joblibfrom scipy.linalg import normclass TF_IDF_Model(object): def __init__(self, corpus_list): self.documents_list = corpus_list self.documents_number = len(corpus_list) self.get_idf() def get_idf(self): df = {} self.idf = {} tf = [] for document in self.documents_list: temp = {} for word in document: temp[word] = temp.get(word, 0) + 1 / len(document) tf.append(temp) for key in temp.keys(): df[key] = df.get(key, 0) + 1 for key, value in df.items(): self.idf[key] = np.log10(self.documents_number / (value + 1)) def get_tf(self, document): document = list(jieba.cut(document)) # tf = [] temp = {} for word in document: temp[word] = temp.get(word, 0) + 1 / len(document) # tf.append(temp) return temp def tf_idf_vec(self, text): tf = self.get_tf(text) word = list(self.idf.keys()) vec = [0] * len(self.idf) text = list(jieba.cut(text)) for ele in text: if ele in word: vec[word.index(ele)] = tf[ele] * self.idf[ele] return vec def cal_similarty(self, sentence1, sentence2): vec1 = self.tf_idf_vec(sentence1) vec2 = self.tf_idf_vec(sentence2) similarty = np.dot(vec1, vec2) / (norm(vec1) * norm(vec2)) return similartydef train_model(): #####bulid corpus corpus = pd.read_csv(corpus_path) corpus_list = corpus[&quot;name&quot;].get_values().tolist() # corpus_list = corpus1[&quot;name&quot;].get_values().tolist() corpus_list = [list(jieba.cut(str(doc))) for doc in corpus_list] tf_idf_model = TF_IDF_Model(corpus_list) joblib.dump(tf_idf_model, model_path)def load_model(path): tf_idf_model = joblib.load(path) return tf_idf_modelif __name__ == '__main__': from supercat.data_qualifier.tf_idf import TF_IDF_Model #### train_model() ###### tf_idf_model = load_model(model_path) sentence1=&quot;XXXX&quot; sentence2=&quot;XXXX&quot; print(tf_idf_model.get_tf(sentence1)) print(tf_idf_model.idf) print(tf_idf_model.tf_idf_vec(sentence1)) print(tf_idf_model.cal_similarty(sentence1,sentence2)) 2.æœ‰ç›‘ç£åŸºäºè¡¨ç¤ºçš„åŒ¹é…æ–¹æ³•ï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ†åˆ«è¡¨å¾Queryå’ŒDocï¼Œé€šè¿‡è®¡ç®—å‘é‡ç›¸ä¼¼åº¦æ¥ä½œä¸ºè¯­ä¹‰åŒ¹é…åˆ†æ•°ã€‚å¾®è½¯çš„DSSM[26]åŠå…¶æ‰©å±•æ¨¡å‹å±äºåŸºäºè¡¨ç¤ºçš„è¯­ä¹‰åŒ¹é…æ–¹æ³•ï¼Œç¾å›¢æœç´¢å€Ÿé‰´DSSMçš„åŒå¡”ç»“æ„æ€æƒ³ï¼Œå·¦è¾¹å¡”è¾“å…¥Queryä¿¡æ¯ï¼Œå³è¾¹å¡”è¾“å…¥POIã€å“ç±»ä¿¡æ¯ï¼Œç”ŸæˆQueryå’ŒDocçš„é«˜é˜¶æ–‡æœ¬ç›¸å…³æ€§ã€é«˜é˜¶å“ç±»ç›¸å…³æ€§ç‰¹å¾ï¼Œåº”ç”¨äºæ’åºæ¨¡å‹ä¸­å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œæ¯”è¾ƒæœ‰ä»£è¡¨æ€§çš„è¡¨ç¤ºåŒ¹é…æ¨¡å‹è¿˜æœ‰ç™¾åº¦æå‡º SimNet[27]ï¼Œä¸­ç§‘é™¢æå‡ºçš„å¤šè§†è§’å¾ªç¯ç¥ç»ç½‘ç»œåŒ¹é…æ¨¡å‹ï¼ˆMV-LSTMï¼‰[28]ç­‰ã€‚ åŸºäºäº¤äº’çš„åŒ¹é…æ–¹æ³•ï¼šè¿™ç§æ–¹æ³•ä¸ç›´æ¥å­¦ä¹ Queryå’ŒDocçš„è¯­ä¹‰è¡¨ç¤ºå‘é‡ï¼Œè€Œæ˜¯åœ¨ç¥ç»ç½‘ç»œåº•å±‚å°±è®©Queryå’ŒDocæå‰äº¤äº’ï¼Œä»è€Œè·å¾—æ›´å¥½çš„æ–‡æœ¬å‘é‡è¡¨ç¤ºï¼Œæœ€åé€šè¿‡ä¸€ä¸ªMLPç½‘ç»œè·å¾—è¯­ä¹‰åŒ¹é…åˆ†æ•°ã€‚ä»£è¡¨æ€§æ¨¡å‹æœ‰åä¸ºæå‡ºçš„åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„åŒ¹é…æ¨¡å‹ARC-II[29]ï¼Œä¸­ç§‘é™¢æå‡ºçš„åŸºäºçŸ©é˜µåŒ¹é…çš„çš„å±‚æ¬¡åŒ–åŒ¹é…æ¨¡å‹MatchPyramid[30]ã€‚ åŸºäºè¡¨ç¤ºçš„åŒ¹é…æ–¹æ³•ä¼˜åŠ¿åœ¨äºDocçš„è¯­ä¹‰å‘é‡å¯ä»¥ç¦»çº¿é¢„å…ˆè®¡ç®—ï¼Œåœ¨çº¿é¢„æµ‹æ—¶åªéœ€è¦é‡æ–°è®¡ç®—Queryçš„è¯­ä¹‰å‘é‡ï¼Œç¼ºç‚¹æ˜¯æ¨¡å‹å­¦ä¹ æ—¶Queryå’ŒDocä¸¤è€…æ²¡æœ‰ä»»ä½•äº¤äº’ï¼Œä¸èƒ½å……åˆ†åˆ©ç”¨Queryå’ŒDocçš„ç»†ç²’åº¦åŒ¹é…ä¿¡å·ã€‚åŸºäºäº¤äº’çš„åŒ¹é…æ–¹æ³•ä¼˜åŠ¿åœ¨äºQueryå’ŒDocåœ¨æ¨¡å‹è®­ç»ƒæ—¶èƒ½å¤Ÿè¿›è¡Œå……åˆ†çš„äº¤äº’åŒ¹é…ï¼Œè¯­ä¹‰åŒ¹é…æ•ˆæœå¥½ï¼Œç¼ºç‚¹æ˜¯éƒ¨ç½²ä¸Šçº¿æˆæœ¬è¾ƒé«˜ã€‚ åŒ¹é…ä¸åŒäºæ’åºï¼ŒåŒ¹é…æ˜¯1å¯¹1çš„ï¼Œæ’åºæ˜¯1å¯¹å¤š 2.1åŸºäºè¡¨ç¤ºhttps://zhuanlan.zhihu.com/p/138864580 https://blog.csdn.net/qq_27590277/article/details/121391770 2.2.åŸºäºäº¤äº’https://blog.csdn.net/guofei_fly/article/details/107501276","link":"/2021/10/26/text-matching/"},{"title":"æ–‡æœ¬æ”¹å†™å’Œtermåˆ†æ","text":"1.æ–‡æœ¬æ”¹å†™æ”¹å†™ä¸»è¦æ­¥éª¤queryçº é”™ã€queryå¯¹é½ã€queryæ‰©å±• 1.1queryçº é”™åœ¨æœç´¢è¿‡ç¨‹ä¸­ç”±äºå¯¹å…ˆéªŒçŸ¥è¯†çš„æŒæ¡ä¸è¶³æˆ–è€…åœ¨ä½¿ç”¨è¾“å…¥æ³•çš„æ—¶å€™è¯¯è¾“å…¥å¯¼è‡´çš„ï¼Œæœ¬è´¨ä¸ºå»å™ªè¿‡ç¨‹ã€‚ å¸¸ç”¨çš„queryçº é”™æ–¹æ³•æœ‰æ•°å­—ã€æ‹¼éŸ³ã€æ¼å­—ã€é‡å¤å­—ã€è°éŸ³/å½¢è¿‘å­—ç­‰æ–¹å¼ã€‚ 1.2queryå¯¹é½å¯¹äºè¾“å…¥queryå¹¶æ— é”™è¯¯ï¼Œä½†è¡¨è¾¾ä¸Šä¸æœç´¢å¼•æ“ç´¢å¼•å†…å®¹ä¸ç›¸ç¬¦è€Œä½œçš„ä¸€ç§æ”¹å†™æ“ä½œã€‚ä¾‹å¦‚â€œæ˜Ÿçˆ·æ˜¯å“ªä¸€å¹´ç”Ÿçš„â€ï¼Œé€šè¿‡å®ä½“å¯¹é½ï¼Œå¯æ”¹å†™ä¸ºâ€œå‘¨æ˜Ÿé©°çš„å‡ºç”Ÿæ—¶é—´â€ã€‚ æ–¹æ³•:1.å¯¹é½è§„åˆ™ 2.æ–‡æœ¬æ”¹å†™æ¨¡å‹ 1.3 queryæ‰©å±•æ˜¯å°†ä¸ç”¨æˆ·è¾“å…¥çš„queryçš„ç›¸ä¼¼æ‰©å±•queryè¿›è¡Œå±•ç¤ºï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥é€‰æ‹©æ›´å¤šçš„æœç´¢å†…å®¹ï¼Œå¸®åŠ©ç”¨æˆ·æŒ–æ˜æ½œåœ¨éœ€æ±‚ã€‚ 2.termåˆ†æä¸€æ®µæ–‡æœ¬åˆ†è¯åï¼Œå¯¹äºä¸åŒçš„è¯è¯­ï¼Œåœ¨ç›¸åŒæ–‡æœ¬ä¸­çš„é‡è¦æ€§åº”è¯¥æ˜¯ä¸åŒçš„ã€‚ baselineçš„æ— ç›‘ç£æ–¹æ³•å¯ä»¥æ˜¯ï¼štf-idfã€‚ å‚è€ƒhttps://zhuanlan.zhihu.com/p/344631739","link":"/2021/10/12/text-mod/"},{"title":"TextGCN Graph Convolutional Networks for Text Classification","text":"https://arxiv.org/abs/1809.05679 1.build a single text graph for a corpus based on word co-occurrence and document word relations, 2.then learn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents.","link":"/2022/01/19/textgcn/"},{"title":"tensorflowæ¨¡å‹å¯¼å‡ºæ€»ç»“","text":"https://zhuanlan.zhihu.com/p/113734249","link":"/2021/12/29/tf-export/"},{"title":"tf ranking","text":"https://zhuanlan.zhihu.com/p/52447211# https://github.com/tensorflow/ranking","link":"/2021/11/16/tf-ranking/"},{"title":"Tensorflowä¸­çš„Seq2Seqå…¨å®¶æ¡¶","text":"https://zhuanlan.zhihu.com/p/47929039","link":"/2021/11/16/tf-seq2seq/"},{"title":"PyTorch VS TensorFlow","text":"https://zhuanlan.zhihu.com/p/37102973 éšç€TF2.0å‡ºç°ï¼ŒTFä¹Ÿæœ‰åŠ¨æ€å›¾äº†","link":"/2022/01/18/tf-torch/"},{"title":"tensorflow2.x å’Œtensorflow1.xå¯¹æ¯”","text":"tf 1.x : 1. session run 2. å®˜æ–¹æ¨è tf.data.Dataset + tf.estimator.Estimator tf 2.x: å®˜æ–¹æ¨èçš„æ˜¯ tf.data.Dataset + tf.keras å‚è€ƒhttps://blog.csdn.net/qq_38978225/article/details/108942427 https://blog.csdn.net/keeppractice/article/details/105934521 https://blog.csdn.net/sxlsxl119/article/details/104835420 https://www.zhihu.com/question/267809209","link":"/2021/11/16/tf/"},{"title":"å¤©æ± æ–°é—»æ¨è","text":"ç›®æ ‡: ä¸ºä¸åŒç”¨æˆ·ï¼ˆæµ‹è¯•ä¸º5ä¸‡ï¼‰åˆ†åˆ«æ¨ètop5çš„æ–°é—»æ–‡ç« ï¼ˆæ€»æ•°36ä¸‡ï¼‰ æ ‡ç­¾ï¼šä¸åŒç”¨æˆ·åœ¨ä¸åŒæ—¶é—´çš„ç‚¹å‡»æ–°é—» ç‰¹å¾ï¼š æ•´ä½“æ¡†æ¶ä¹Ÿæ˜¯ï¼šå¤šè·¯å¬å›+æ’åº å¬å›123456# å®šä¹‰ä¸€ä¸ªå¤šè·¯å¬å›çš„å­—å…¸ï¼Œå°†å„è·¯å¬å›çš„ç»“æœéƒ½ä¿å­˜åœ¨è¿™ä¸ªå­—å…¸å½“ä¸­user_multi_recall_dict = {'itemcf_sim_itemcf_recall': {}, 'embedding_sim_item_recall': {}, 'youtubednn_recall': {}, 'youtubednn_usercf_recall': {}, 'cold_start_recall': {}} åŸºäºitemcfè®¡ç®—çš„itemä¹‹é—´çš„ç›¸ä¼¼åº¦simè¿›è¡Œçš„å¬å› åŸºäºembeddingæœç´¢å¾—åˆ°çš„itemä¹‹é—´çš„ç›¸ä¼¼åº¦è¿›è¡Œçš„å¬å› YoutubeDNNå¬å› YoutubeDNNå¾—åˆ°çš„userä¹‹é—´çš„ç›¸ä¼¼åº¦è¿›è¡Œçš„å¬å› åŸºäºå†·å¯åŠ¨ç­–ç•¥çš„å¬å› æ’åºæ’åº LGBçš„æ’åºæ¨¡å‹ LGBçš„åˆ†ç±»æ¨¡å‹ æ·±åº¦å­¦ä¹ çš„åˆ†ç±»æ¨¡å‹DIN æ¨¡å‹é›†æˆ è¾“å‡ºç»“æœåŠ æƒèåˆ Staking å‚è€ƒhttps://tianchi.aliyun.com/notebook-ai/detail","link":"/2022/06/09/tianchi-recommend/"},{"title":"æ—¶é—´å¤æ‚åº¦è®¡ç®—","text":"1 æ™®é€šhttps://blog.csdn.net/firefly_2002/article/details/8008987 2 é€’å½’https://www.jianshu.com/p/d6b94dac001d# 1 ä»£æ¢æ³• 2 é€’å½’æ ‘æ–¹æ³• 3 ä¸»å®šç† 3 å›æº¯https://blog.csdn.net/u013009552/article/details/107064859 https://zhuanlan.zhihu.com/p/62335966","link":"/2021/11/12/time-complex/"},{"title":"æ—¶é—´åºåˆ—é¢„æµ‹æ€»ç»“","text":"https://zhuanlan.zhihu.com/p/67832773 https://cloud.tencent.com/developer/article/1800614 https://blog.csdn.net/weixin_39653948/article/details/105422337 transformer based https://arxiv.org/pdf/2001.08317.pdf https://arxiv.org/pdf/2012.07436.pdf https://arxiv.org/abs/1907.00235 https://arxiv.org/pdf/1912.09363.pdf","link":"/2021/11/22/time-series-survey/"},{"title":"token embedding","text":"https://www.cnblogs.com/d0main/p/10447853.html start=>start: å¼€å§‹ io=>inputoutput: è¾“å…¥æ–‡æœ¬ cond=>condition: æ¡ä»¶ sub=>subroutine: å­æµç¨‹ end=>end: ç»“æŸ op1=>operation: è¾“å…¥æ–‡æœ¬ op2=>operation: tokenize op3=>operation: è¯å‘é‡çŸ©é˜µï¼ˆé¢„è®­ç»ƒçš„æˆ–è€…éšæœºåˆå§‹åŒ–ï¼‰ op4=>operation: token embbedding op1->op2->op3->op4{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);","link":"/2021/11/22/token-emb/"},{"title":"Tokenization","text":"å¯¹äºä¸­æ–‡å’Œè‹±æ–‡è€Œè¨€ï¼Œç”±äºè¯­è¨€å·®å¼‚å¯¼è‡´ç®—æ³•ä¹Ÿæœ‰å·®å¼‚ã€‚å¯¹äºä¸­æ–‡ï¼Œå­˜åœ¨å­—ç²’åº¦å’Œè¯ç²’åº¦ã€‚å¯¹äºè‹±æ–‡ï¼Œå­˜åœ¨ä¸‰ä¸ªçº§åˆ«çš„ç²’åº¦ï¼Œcharacter levelï¼Œsubword levelï¼Œword levelã€‚ä¸‹é¢ä¸»è¦é˜è¿°ä¸­æ–‡çš„è¯ç²’åº¦å’Œè‹±æ–‡çš„subword levelã€‚ ä¸€ã€ä¸­æ–‡1.1 åŸç†https://zhuanlan.zhihu.com/p/146792308 1.2 å¸¸è§ä¸­æ–‡åˆ†è¯å·¥å…·12345678910111213141516171819202122232425# #####stanfordcorenlpfrom timeit import default_timer as timerfrom stanfordcorenlp import StanfordCoreNLPtic = timer()path=&quot;XXXXX&quot;nlp_zh = StanfordCoreNLP(path,lang='zh')#æ¨¡å‹æ–‡ä»¶è·¯å¾„sentence = &quot;æœç´¢å¼•æ“ä¼šé€šè¿‡æ—¥å¿—æ–‡ä»¶æŠŠç”¨æˆ·æ¯æ¬¡æ£€ç´¢ä½¿ç”¨çš„æ‰€æœ‰æ£€ç´¢ä¸²éƒ½è®°å½•ä¸‹æ¥&quot;tic = timer()print ('Tokenize:', nlp_zh.word_tokenize(sentence))toc = timer()print(toc - tic) # è¾“å‡ºçš„æ—¶é—´ï¼Œç§’ä¸ºå•ä½#########thulacimport thulacthu1 = thulac.thulac(seg_only=True) #é»˜è®¤æ¨¡å¼tic = timer()text = thu1.cut(&quot;æœç´¢å¼•æ“ä¼šé€šè¿‡æ—¥å¿—æ–‡ä»¶æŠŠç”¨æˆ·æ¯æ¬¡æ£€ç´¢ä½¿ç”¨çš„æ‰€æœ‰æ£€ç´¢ä¸²éƒ½è®°å½•ä¸‹æ¥&quot;, text=True).split(&quot; &quot;) #è¿›è¡Œä¸€å¥è¯åˆ†è¯toc = timer()print(text)print(toc - tic)####jiebaimport jiebatic = timer()print(jieba.lcut(str(&quot;æœç´¢å¼•æ“ä¼šé€šè¿‡æ—¥å¿—æ–‡ä»¶æŠŠç”¨æˆ·æ¯æ¬¡æ£€ç´¢ä½¿ç”¨çš„æ‰€æœ‰æ£€ç´¢ä¸²éƒ½è®°å½•ä¸‹æ¥&quot;)))toc = timer()print(toc - tic) 123456Tokenize: ['æœç´¢', 'å¼•æ“', 'ä¼š', 'é€šè¿‡', 'æ—¥å¿—', 'æ–‡ä»¶', 'æŠŠ', 'ç”¨æˆ·', 'æ¯æ¬¡', 'æ£€ç´¢', 'ä½¿ç”¨', 'çš„', 'æ‰€æœ‰', 'æ£€ç´¢', 'ä¸²éƒ½', 'è®°å½•', 'ä¸‹æ¥']è¿è¡Œæ—¶é—´ï¼š22.68650701455772['æœç´¢å¼•æ“ä¼š', 'é€šè¿‡', 'æ—¥å¿—', 'æ–‡ä»¶', 'æŠŠ', 'ç”¨æˆ·', 'æ¯', 'æ¬¡', 'æ£€ç´¢', 'ä½¿ç”¨', 'çš„', 'æ‰€æœ‰', 'æ£€ç´¢', 'ä¸²', 'éƒ½', 'è®°å½•', 'ä¸‹', 'æ¥']è¿è¡Œæ—¶é—´ï¼š0.0016864966601133347['æœç´¢å¼•æ“', 'ä¼š', 'é€šè¿‡', 'æ—¥å¿—', 'æ–‡ä»¶', 'æŠŠ', 'ç”¨æˆ·', 'æ¯æ¬¡', 'æ£€ç´¢', 'ä½¿ç”¨', 'çš„', 'æ‰€æœ‰', 'æ£€ç´¢', 'ä¸²', 'éƒ½', 'è®°å½•ä¸‹æ¥']è¿è¡Œæ—¶é—´ï¼š0.9094752036035061 è§‚å¯Ÿç»“æœï¼Œå¯ä»¥çœ‹å‡ºthulacåˆ†è¯æ•ˆç‡æœ€é«˜ï¼Œjiebaåˆ†è¯çš„ç²¾åº¦å’Œæ•ˆç‡æ¯”è¾ƒå¹³è¡¡ï¼Œstanfordcorenlpåˆ†è¯ç²’åº¦å¾ˆç»†ï¼Œä½†æ˜¯é€Ÿåº¦æ…¢ äºŒã€è‹±æ–‡SubWordç®—æ³•å¦‚ä»Šå·²æˆä¸ºä¸€ä¸ªé‡è¦çš„NLPæ¨¡å‹çš„æå‡ç®—æ³•ã€‚å…¶ä¸»è¦ä¼˜åŠ¿å¦‚ä¸‹ï¼š 1.word levelå­˜åœ¨OOVé—®é¢˜ï¼Œä¸€æ—¦ç¢°åˆ°å°±æ˜¯back off to a dictionaryï¼Œæ— æ³•å¾ˆå¥½åœ°å¤„ç†æœªçŸ¥å’Œç½•è§è¯æ±‡2.Character levelå¯ä»¥è§£å†³OOVï¼Œä½†æ˜¯ç›¸æ¯”äº word-level , Character-level çš„è¾“å…¥å¥å­å˜é•¿ï¼Œä½¿å¾—æ•°æ®å˜å¾—ç¨€ç–ï¼Œè€Œä¸”å¯¹äºè¿œè·ç¦»çš„ä¾èµ–éš¾ä»¥å­¦åˆ°ï¼Œè®­ç»ƒé€Ÿåº¦é™ä½ã€‚å¸¸è§çš„SubWordç®—æ³•æœ‰ï¼šBPEï¼ŒWordPieceï¼ŒUnigram Language Modelç­‰ 2.1 BPEå…¨ç§°ä¸ºByte Pair Encodingï¼Œç®—æ³•æ¥è‡ªpaperã€ŠNeural Machine Translation of Rare Words with Subword Unitsã€‹ã€‚ 2.1.1 æ„å»ºBPE subwordè¯è¡¨åŸç† å‡†å¤‡è¶³å¤Ÿå¤§çš„è®­ç»ƒè¯­æ–™ ç¡®å®šæœŸæœ›çš„subwordè¯è¡¨å¤§å° å°†å•è¯æ‹†åˆ†ä¸ºå­—ç¬¦åºåˆ—å¹¶åœ¨æœ«å°¾æ·»åŠ åç¼€â€œ &lt;/ w&gt;â€å¹¶ä¸”ç»Ÿè®¡å•è¯é¢‘ç‡ã€‚åœæ­¢ç¬¦â€&lt;/w&gt;â€çš„æ„ä¹‰åœ¨äºè¡¨ç¤ºsubwordæ˜¯è¯åç¼€ã€‚å…·ä½“æ¥è¯´ï¼Œä¸åŠ â€&lt;/w&gt;â€å¯ä»¥å‡ºç°åœ¨è¯é¦–ï¼ŒåŠ äº†â€&lt;/w&gt;â€åªèƒ½ä½äºè¯å°¾ã€‚ä¾‹å¦‚ï¼Œâ€œ lowâ€çš„é¢‘ç‡ä¸º5ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†å…¶æ”¹å†™ä¸ºâ€œ l o w &lt;/ w&gt;â€ï¼š5 ç»Ÿè®¡æ¯ä¸€ä¸ªè¿ç»­å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ï¼Œé€‰æ‹©æœ€é«˜é¢‘è€…åˆå¹¶æˆæ–°çš„subword é‡å¤ç¬¬4æ­¥ç›´åˆ°è¾¾åˆ°ç¬¬2æ­¥è®¾å®šçš„subwordè¯è¡¨å¤§å°æˆ–ä¸‹ä¸€ä¸ªæœ€é«˜é¢‘çš„å­—èŠ‚å¯¹å‡ºç°é¢‘ç‡ä¸º1 æ³¨æ„ï¼Œæ¯æ¬¡åˆå¹¶åè¯è¡¨å¯èƒ½å‡ºç°3ç§å˜åŒ–ï¼š +1ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯è¿˜ä¿ç•™ï¼ˆ2ä¸ªå­—è¯éƒ½ä¸æ˜¯å®Œå…¨éšç€å¦ä¸€ä¸ªå­—è¯çš„å‡ºç°è€Œç´§è·Ÿç€å‡ºç°ï¼‰ +0ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯ä¸­ä¸€ä¸ªä¿ç•™ï¼Œä¸€ä¸ªè¢«æ¶ˆè§£ï¼ˆåªæœ‰ä¸€ä¸ªå­—è¯å®Œå…¨éšç€å¦ä¸€ä¸ªå­—è¯çš„å‡ºç°è€Œç´§è·Ÿç€å‡ºç°ï¼‰ -1ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯éƒ½è¢«æ¶ˆè§£ï¼ˆ2ä¸ªå­—è¯åŒæ—¶è¿ç»­å‡ºç°ï¼‰ ä¾‹å­ï¼š è®­ç»ƒè¯­æ–™ä¸ºï¼š 1{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3} Iter 1, æœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹â€eâ€å’Œâ€sâ€å‡ºç°äº†6+3=9æ¬¡ï¼Œåˆå¹¶æˆâ€esâ€ï¼Œè¾“å‡ºï¼š 1{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3} Iter 2, æœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹â€esâ€å’Œâ€tâ€å‡ºç°äº†6+3=9æ¬¡, åˆå¹¶æˆâ€estâ€ï¼Œè¾“å‡ºï¼š 1{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3} Iter 3, ä»¥æ­¤ç±»æ¨ï¼Œæœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹ä¸ºâ€estâ€å’Œâ€&lt;/w&gt;â€ ï¼Œåˆå¹¶åè¾“å‡ºï¼š 1{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3} â€¦â€¦ Iter n, ç»§ç»­è¿­ä»£ç›´åˆ°è¾¾åˆ°é¢„è®¾çš„subwordè¯è¡¨å¤§å°æˆ–ä¸‹ä¸€ä¸ªæœ€é«˜é¢‘çš„å­—èŠ‚å¯¹å‡ºç°é¢‘ç‡ä¸º1ã€‚ ä»£ç  12345678910111213141516171819202122232425import re, collectionsdef get_stats(vocab): pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairsdef merge_vocab(pair, v_in): v_out = {} bigram = re.escape(' '.join(pair)) p = re.compile(r'(?&lt;!\\S)' + bigram + r'(?!\\S)') for word in v_in: w_out = p.sub(''.join(pair), word) v_out[w_out] = v_in[word] return v_outvocab = {'l o w &lt;/w&gt;' : 5, 'l o w e r &lt;/w&gt;' : 2,'n e w e s t &lt;/w&gt;':6, 'w i d e s t &lt;/w&gt;':3}num_merges = 10for i in range(num_merges): pairs = get_stats(vocab) best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print(best) 12345678910('e', 's')('es', 't')('est', '&lt;/w&gt;')('l', 'o')('lo', 'w')('n', 'e')('ne', 'w')('new', 'est&lt;/w&gt;')('low', '&lt;/w&gt;')('w', 'i') 2.1.2 ç¼–è§£ç ç¼–ç  1.å°†subwordè¯è¡¨æŒ‰ç…§å­è¯é•¿åº¦ç”±å¤§åˆ°å°æ’åºã€‚ 2.å¯¹äºæ¯ä¸ªå•è¯ï¼Œéå†æ’å¥½åºçš„subwordè¯è¡¨ï¼Œå¯»æ‰¾æ˜¯å¦æœ‰tokenæ˜¯å½“å‰å•è¯çš„å­å­—ç¬¦ä¸²ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬å°†è¿­ä»£æ‰€æœ‰tokenï¼Œå¹¶å°†æ‰€æœ‰å­å­—ç¬¦ä¸²æ›¿æ¢ä¸ºtokenã€‚ 3.å¦‚æœä»ç„¶æœ‰å­å­—ç¬¦ä¸²æ²¡è¢«æ›¿æ¢ä½†æ‰€æœ‰tokenéƒ½å·²è¿­ä»£å®Œæ¯•ï¼Œåˆ™å°†å‰©ä½™çš„å­å­—ç¬¦ä¸²æ›¿æ¢ä¸ºç‰¹æ®Štokenï¼Œå¦‚ã€‚ ä¾‹å­ï¼š 12345678910# ç»™å®šå•è¯åºåˆ—[â€œthe&lt;/w&gt;â€, â€œhighest&lt;/w&gt;â€, â€œmountain&lt;/w&gt;â€]# å‡è®¾å·²æœ‰æ’å¥½åºçš„subwordè¯è¡¨[â€œerrrr&lt;/w&gt;â€, â€œtain&lt;/w&gt;â€, â€œmounâ€, â€œest&lt;/w&gt;â€, â€œhighâ€, â€œthe&lt;/w&gt;â€, â€œa&lt;/w&gt;â€]# è¿­ä»£ç»“æœ&quot;the&lt;/w&gt;&quot; -&gt; [&quot;the&lt;/w&gt;&quot;]&quot;highest&lt;/w&gt;&quot; -&gt; [&quot;high&quot;, &quot;est&lt;/w&gt;&quot;]&quot;mountain&lt;/w&gt;&quot; -&gt; [&quot;moun&quot;, &quot;tain&lt;/w&gt;&quot;] ç¼–ç çš„è®¡ç®—é‡å¾ˆå¤§ã€‚å¯¹äºå·²çŸ¥æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥pre-tokenizeæ‰€æœ‰å•è¯ï¼Œå¹¶åœ¨è¯å…¸ä¸­ä¿å­˜å•è¯å’Œtokenizeçš„ç»“æœã€‚å¦‚æœå­˜åœ¨å­—å…¸ä¸­ä¸å­˜åœ¨çš„æœªçŸ¥å•è¯ï¼Œå¯ä»¥åº”ç”¨ä¸Šè¿°ç¼–ç æ–¹æ³•å¯¹å•è¯è¿›è¡Œtokenizeï¼Œç„¶åå°†æ–°å•è¯ä»¥åŠtokenizeçš„ç»“æœæ·»åŠ åˆ°å­—å…¸ä¸­å¤‡ç”¨ã€‚ è§£ç  å°†æ‰€æœ‰çš„subwordæ‹¼åœ¨ä¸€èµ·ã€‚ ä¾‹å­ï¼š 12345# ç¼–ç åºåˆ—[[â€œthe&lt;/w&gt;â€], [â€œhighâ€, â€œest&lt;/w&gt;â€], [â€œmounâ€, â€œtain&lt;/w&gt;â€]]# è§£ç åºåˆ—[â€œthe&lt;/w&gt;â€, â€œhighest&lt;/w&gt;â€, â€œmountain&lt;/w&gt;â€] 2.1.3 å’Œembeddingç»“åˆ1.æ„å»ºè¯è¡¨ï¼Œå‡è®¾æœ‰subwordè¯è¡¨ï¼š[â€œerrrr&lt;/w&gt;â€, â€œtain&lt;/w&gt;â€, â€œmounâ€, â€œest&lt;/w&gt;â€, â€œhighâ€, â€œthe&lt;/w&gt;â€, â€œa&lt;/w&gt;â€] 2.ç¼–ç ï¼Œè¯è¯­â€highestâ€ç¼–ç æˆ[â€œhighâ€, â€œest&lt;/w&gt;â€] 3.å‘é‡è¡¨ç¤ºï¼Œ$[E_{high},\\ E_{est(/w)}]$] https://www.cnblogs.com/d0main/p/10447853.html 2.2 WordPieceç®—æ³•æ¥è‡ªäºã€ŠGoogleâ€™s Neural Machine Translation System: Bridging the Gap between Human and Machine Translationã€‹ WordPieceç®—æ³•å¯ä»¥çœ‹ä½œæ˜¯BPEçš„å˜ç§ã€‚ä¸åŒç‚¹åœ¨äºï¼ŒWordPieceåŸºäºæ¦‚ç‡ç”Ÿæˆæ–°çš„subwordè€Œä¸æ˜¯ä¸‹ä¸€æœ€é«˜é¢‘å­—èŠ‚å¯¹ã€‚ 2.2.1 åŸç† å‡†å¤‡è¶³å¤Ÿå¤§çš„è®­ç»ƒè¯­æ–™ ç¡®å®šæœŸæœ›çš„subwordè¯è¡¨å¤§å° å°†å•è¯æ‹†åˆ†æˆå­—ç¬¦åºåˆ— åŸºäºç¬¬3æ­¥æ•°æ®è®­ç»ƒè¯­è¨€æ¨¡å‹ ä»æ‰€æœ‰å¯èƒ½çš„subwordå•å…ƒä¸­é€‰æ‹©åŠ å…¥è¯­è¨€æ¨¡å‹åèƒ½æœ€å¤§ç¨‹åº¦åœ°å¢åŠ è®­ç»ƒæ•°æ®æ¦‚ç‡çš„å•å…ƒä½œä¸ºæ–°çš„å•å…ƒ é‡å¤ç¬¬5æ­¥ç›´åˆ°è¾¾åˆ°ç¬¬2æ­¥è®¾å®šçš„subwordè¯è¡¨å¤§å°æˆ–æ¦‚ç‡å¢é‡ä½äºæŸä¸€é˜ˆå€¼ 2.3 ULM2.4 char n-gramhttps://arxiv.org/abs/1607.04606 2.5 Byte-Level BPEã€ŠNeural Machine Translation with Byte-Level Subwordsã€‹ 3.æ€»ç»“æˆ‘ä»¬åœ¨è¿›è¡Œä¸­æ–‡NLPä»»åŠ¡çš„æ—¶å€™ï¼Œç›®å‰åŸºæœ¬éƒ½æ˜¯å­—ç²’åº¦ï¼›è‹±æ–‡çš„è¯å¤§å¤šæ•°æ˜¯ä½¿ç”¨subwordçš„wordpieceã€‚ å‚è€ƒhttps://zhuanlan.zhihu.com/p/112444056 https://arxiv.org/pdf/1508.07909.pdf https://zhuanlan.zhihu.com/p/38130825 https://zhuanlan.zhihu.com/p/86965595 https://blog.csdn.net/zhangxiaolinxin/article/details/107052054?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.base&amp;spm=1001.2101.3001.4242 https://www.cnblogs.com/mj-selina/p/13687291.html","link":"/2021/07/20/tokenization/"},{"title":"TensorFlowï¼Œpytorchï¼Œcudaï¼Œcudnnï¼Œæ˜¾å¡é©±åŠ¨ä¹‹é—´çš„åŒºåˆ«ä»¥åŠå¯¹åº”å…³ç³»","text":"ä¸€.æ¦‚å¿µç†è§£æ˜¾å¡é©±åŠ¨è¿æ¥æ“ä½œç³»ç»Ÿä¸åº•å±‚ç¡¬ä»¶ã€‚ CUDAå’ŒNVIDIAçš„æ˜¾å¡é©±åŠ¨ç¨‹åºå®Œå…¨æ˜¯ä¸¤ä¸ªä¸åŒçš„æ¦‚å¿µã€‚CUDAæ˜¯NVIDIAæ¨å‡ºçš„ç”¨äºè‡ªå®¶GPUçš„å¹¶è¡Œè®¡ç®—æ¡†æ¶ï¼Œä¹Ÿå°±æ˜¯è¯´CUDAåªèƒ½åœ¨NVIDIAçš„GPUä¸Šè¿è¡Œï¼Œè€Œä¸”åªæœ‰å½“è¦è§£å†³çš„è®¡ç®—é—®é¢˜æ˜¯å¯ä»¥å¤§é‡å¹¶è¡Œè®¡ç®—çš„æ—¶å€™æ‰èƒ½å‘æŒ¥CUDAçš„ä½œç”¨ã€‚CUDAçš„æœ¬è´¨æ˜¯ä¸€ä¸ªå·¥å…·åŒ…ï¼ˆToolKitï¼‰ã€‚ cuDNNæ˜¯ä¸€ä¸ªSDKï¼Œæ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºç¥ç»ç½‘ç»œçš„åŠ é€ŸåŒ…ï¼Œæ³¨æ„ï¼Œå®ƒè·Ÿæˆ‘ä»¬çš„CUDAæ²¡æœ‰ä¸€ä¸€å¯¹åº”çš„å…³ç³»ï¼Œå³æ¯ä¸€ä¸ªç‰ˆæœ¬çš„CUDAå¯èƒ½æœ‰å¥½å‡ ä¸ªç‰ˆæœ¬çš„cuDNNä¸ä¹‹å¯¹åº”ï¼Œä½†ä¸€èˆ¬æœ‰ä¸€ä¸ªæœ€æ–°ç‰ˆæœ¬çš„cuDNNç‰ˆæœ¬ä¸CUDAå¯¹åº”æ›´å¥½ã€‚ TensorFlowä¸ºè°·æ­Œæ¨å‡ºçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œpytorchæ˜¯Facebook æ¨å‡ºçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚ äºŒ.ç‰ˆæœ¬å¯¹åº”å…³ç³»æ·±åº¦å­¦ä¹ æ¡†æ¶åŸºäºGPUè¿ç®—æ•ˆç‡è¿œé«˜äºCPUï¼Œä½†æ˜¯éœ€è¦æ»¡è¶³æ¡†æ¶çš„ç‰ˆæœ¬å’Œcudaï¼Œcudnnä»¥åŠæ˜¾å¡é©±åŠ¨ç‰ˆæœ¬åŒ¹é…æ‰å¯ä»¥æ­£å¸¸å·¥ä½œã€‚ tensorflow pytorch cuDNNä¸CUDA CUDAå’ŒNVIDIAæ˜¾å¡é©±åŠ¨å…³ç³» ä¸‰.å¸¸ç”¨å‘½ä»¤æŸ¥çœ‹GPUå‹å· 1lspci | grep -i nvidia æŸ¥çœ‹NVIDIAé©±åŠ¨ç‰ˆæœ¬ 1cat /proc/driver/nvidia/version Python æŸ¥çœ‹pytorchç‰ˆæœ¬ã€åˆ¤æ–­CUDAæ˜¯å¦å¯ç”¨ 123import torch print(torch.__version__) print(torch.cuda.is_available()) æŸ¥çœ‹cudaç‰ˆæœ¬ 12cat /usr/local/cuda/version.txtconda list | grep cuda Tensorflowä¸­æŸ¥çœ‹GPUæ˜¯å¦å¯ç”¨ 12import tensorflow as tftf.test.is_gpu_available() å››.å‚è€ƒæ–‡çŒ®https://blog.csdn.net/caiguanhong/article/details/112184290","link":"/2021/07/20/torch-cuda/"},{"title":"pytorch GPUè®­ç»ƒ","text":"æ¨¡å‹ï¼Œæ•°æ®éœ€è¦æŒ‡å®šè®¾å¤‡ å•æœºå•å¡å•æœºå¤šå¡https://blog.csdn.net/weixin_38208912/article/details/105122668 https://blog.csdn.net/leviopku/article/details/109318226 https://blog.csdn.net/weixin_43750248/article/details/115698356 https://zhuanlan.zhihu.com/p/74792767 å¤šæœºå¤šå¡","link":"/2022/01/17/torch-multi-GPU/"},{"title":"pytorchå¸¸è§æ“ä½œ","text":"1 pytorchä¸­å¯¹tensoræ“ä½œhttps://blog.csdn.net/HailinPan/article/details/109818774 2 æ¨¡å‹åŠ è½½1 model.load_state_dict(torch.load(path)) 2 model=BertModel.from_pretrained åè€…çš„åº•å±‚ä¸ºå‰è€… ç”¨æ³•ä¸åŒï¼Œå‰è€…modelä¸ºä¸€ä¸ªå¯¹è±¡ï¼Œç„¶åç”¨load_state_dictåŠ è½½æƒé‡ï¼›åè€…BertModelä¸ºä¸€ä¸ªç±»ï¼Œç„¶åç”¨from_pretrainedåˆ›å»ºå¯¹è±¡å¹¶åŠ è½½æƒé‡","link":"/2021/12/09/torch-normal/"},{"title":"torchå¯ä»¥æŠŠstringå˜Tensorå—ï¼Ÿ","text":"NO. there is no string tensor so you cannot directly convert string to tensor","link":"/2022/01/13/torch-notice/"},{"title":"pytorchæ­å»ºç¥ç»ç½‘ç»œ","text":"0.å‡†å¤‡æ•°æ®ï¼Œå¤„ç†æ•°æ®1.æ­å»ºç½‘ç»œç»“æ„https://www.cnblogs.com/tian777/p/15341522.html 12345678910111213141516171819202122232425262728293031323334353637class pointwise_hybird_contrasive(hybird): def __init__(self,config_roberta, path,num): super(pointwise_hybird_contrasive, self).__init__(config_roberta, path,num) # self.softmax=torch.nn.Softmax() # self.CrossEntropyLoss=torch.nn.CrossEntropyLoss() # self.FFN2= # self.softmax = nn.Softmax(dim=1) return def forward(self, input_ids, input_mask, segment_ids, all_en_query, all_en_ans): ch_match_embedding = self.ch_matching_model(input_ids, input_mask, segment_ids) en_match_embedding = self.en_matching_model(all_en_query, all_en_ans) hybird_represent = torch.cat([ch_match_embedding, en_match_embedding], dim=1) output = self.FFN2(self.relu(self.FFN1(self.dropout(hybird_represent)))) # y_pred_prob, y_pred = torch.max(self.softmax(output.data), 1) return output def loss(self,predict,target): # predict=predict.reshape(-1,target.shape[1]) # predict = torch.squeeze(predict, dim=1) # predict=torch.unsqueeze(predict, dim=0) # target=torch.argmax(target,dim=1) # target= torch.unsqueeze(target, dim=0) # self.loss(predict,target) CrossEntropyLoss=torch.nn.CrossEntropyLoss() return CrossEntropyLoss(predict,target) def predict(self, output): softmax = nn.Softmax(dim=1) y_pred_prob, y_pred = torch.max(softmax(output.data), 1) # y_pred = y_pred.cpu().numpy() y_pred_prob = y_pred_prob.cpu().numpy() for i in range(len(y_pred_prob)): if not y_pred[i]: y_pred_prob[i] = 1 - y_pred_prob[i] return y_pred_prob nn.Module https://www.cnblogs.com/tian777/p/15341522.html 1 init2 forward3 losspytorchå„ç§äº¤å‰ç†µå‡½æ•°çš„æ±‡æ€»å…·ä½“ä½¿ç”¨ https://blog.csdn.net/comway_Li/article/details/121490170 L2å’ŒL1æ­£åˆ™åŒ– https://blog.csdn.net/guyuealian/article/details/88426648 ä¼˜åŒ–å™¨å›ºå®šå®ç°L2æ­£åˆ™åŒ–,æºç æ³¨é‡Šï¼šweight_decay (:obj:float, optional, defaults to 0):Weight decay (L2 penalty) 123456param_optimizer = list(model.named_parameters())no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']optimizer_grouped_parameters = [ {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01}, {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}] 4 predict2.æ„å»ºè®­ç»ƒæ¡†æ¶a.è¿­ä»£å™¨Dataset/TensorDataset -ã€‹ Sampler -ã€‹ Dataloader https://zhuanlan.zhihu.com/p/337850513# https://blog.csdn.net/ljp1919/article/details/116484330 https://blog.csdn.net/qq_39507748/article/details/105385709 b.ä¼˜åŒ–å™¨https://pytorch.org/docs/stable/optim.html 12345optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)optimizer=optim.SGD([ {'params': model.base.parameters()}, {'params': model.classifier.parameters(), 'lr': 1e-3} ], lr=1e-2, momentum=0.9) c è®­ç»ƒoptimizer.zero_grad() æ¢¯åº¦å½’é›¶, loss.backward() åå‘ä¼ æ’­ , optimizer.step() å‚æ•°æ›´æ–° https://blog.csdn.net/PanYHHH/article/details/107361827 d. éªŒè¯with torch.no_grad() éªŒè¯ï¼Œæµ‹è¯•æ—¶å€™ç”¨ï¼šå¯æ˜¾è‘—å‡å°‘æ˜¾å­˜å ç”¨ https://wstchhwp.blog.csdn.net/article/details/108405102 https://blog.csdn.net/weixin_44134757/article/details/105775027 e. è¯„ä»·æŒ‡æ ‡f. æ¨¡å‹ä¿å­˜https://blog.csdn.net/m0_37605642/article/details/120325062 https://blog.csdn.net/weixin_41278720/article/details/80759933 g. å¯è§†åŒ–https://blog.csdn.net/Wenyuanbo/article/details/118937790 3.é¢„æµ‹åŠ è½½æ¨¡å‹ï¼Œè¾“å…¥æ•°æ®ï¼Œè°ƒç”¨ç½‘ç»œç»“æ„ å‚è€ƒhttps://blog.csdn.net/qq_45847624/article/details/114885655","link":"/2021/11/10/torch_buildnet/"},{"title":"æ¨¡å‹è”åˆè®­ç»ƒ","text":"https://www4.comp.polyu.edu.hk/~csxmwu/papers/KDD-2021-Taobao-Search.pdf user towerï¼ˆmodel1ï¼‰ï¼Œitem towerï¼ˆmodel2ï¼‰ åˆ©ç”¨softmax cross entropy as the trainning objective","link":"/2022/05/11/train-union/"},{"title":"è®­ç»ƒ,éªŒè¯åŒæ­¥è¿›è¡Œ","text":"å‚æ•°æ²¡å˜ï¼Œåªæ˜¯é€‰æ‹©äº†è®­ç»ƒä¸­éªŒè¯æœ€å¥½çš„æ¨¡å‹ï¼Œç±»ä¼¼early stop ä¸åŒæ—¶è¡Œä¸è¡Œï¼Ÿä¸åŒæ—¶å¯èƒ½æ— æ³•å¾—åˆ°æœ€ä¼˜çš„stepï¼Œæœ‰å¯èƒ½è¿‡æ‹Ÿåˆ","link":"/2022/06/01/train-with-valid/"},{"title":"transformerç»¼è¿°","text":"Transformer-XL https://arxiv.org/abs/1901.02860v3 RoFormer https://arxiv.org/pdf/2104.09864.pdf google2020å‡ºå“çš„transformerçš„ç»¼è¿° https://arxiv.org/pdf/2009.06732.pdf","link":"/2021/10/26/transformer-survey/"},{"title":"Transformeræ—¶é—´åºåˆ—é¢„æµ‹","text":"1.åŸºæœ¬çš„Transformer https://zhuanlan.zhihu.com/p/360829130 2.æ”¹è¿›çš„Transformer Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting https://arxiv.org/pdf/1907.00235.pdf https://zhuanlan.zhihu.com/p/391337035","link":"/2021/10/29/transformer-time-seties/"},{"title":"Transformer-XL  Attentive Language Models Beyond a Fixed-Length Context","text":"https://arxiv.org/abs/1901.02860 Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling ( memory and computationå—é™ï¼Œé•¿åº¦ä¸å¯èƒ½å¾ˆå¤§ ). propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. 3 Model3.1 Vanilla Transformer Language Models é—®é¢˜ï¼šIn order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation.é€šå¸¸åšæ³•ä¸ºvanilla modelã€‚ vanilla modelå°±æ˜¯è¯´æŠŠé•¿æ–‡æœ¬åˆ†éš”æˆå›ºå®šé•¿åº¦çš„segæ¥å¤„ç†ï¼Œå¦‚ä¸Šå›¾ã€‚ During trainingï¼ŒThere are two critical limitations of using a fixed length context. First, the largest possible dependency length is upper bounded by the segment length. Second. simply chunking a sequence into fixed-length segments will lead to the context fragmentation problem During evaluation, As shown in Fig. 1b, this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive. 3.2 Segment-Level Recurrence with State Reuse introduce a recurrence mechanism to the Transformer architecture. å®šä¹‰å˜é‡ è½¬æ¢è¿‡ç¨‹ SG(ï¼‰ stands for stop-gradientï¼Œ$\\circ$ è¡¨ç¤ºçŸ©é˜µæ‹¼æ¥ å…·ä½“è¿‡ç¨‹å¦‚ä¸‹å›¾ During training, the hidden state sequence computed for the previous segment is fixed and cached to be reused as an extended context when the model processes the next new segment, as shown in Fig. 2a. during evaluation, the representations from the previous segments can be reused instead of being computed from scratch as in the case of the vanilla model. 3.3 Relative Positional Encodingshow can we keep the positional information coherent when we reuse the states? å¦‚æœä¿ç•™åŸæ¥çš„ä½ç½®ç¼–ç å½¢å¼ï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹ è¿™ç§æ–¹å¼å­˜åœ¨é—®é¢˜ï¼š ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜æå‡ºäº†relative positional informationã€‚ standard Transformer we propose 3.4 å®Œæ•´ç®—æ³•æµç¨‹","link":"/2021/12/06/transformer-xl/"},{"title":"transformer(attention is all your need)","text":"1.We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. 2.Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. 1 Positional Encodingin order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. There are many choices of positional encodings, learned and fixed [9]. In this work, we use sine and cosine functions of different frequencies: PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\\\\ PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})è¯¦ç»†å¯å‚è€ƒ https://wmathor.com/index.php/archives/1453/ 2 Attention å…¶ä¸­ä¸åŒé¢œè‰²è¡¨ç¤ºä¸åŒheadï¼Œé¢œè‰²æ·±æµ…è¡¨ç¤ºè¯çš„å…³è”ç¨‹åº¦ã€‚ ä¸åŒheadè¡¨ç¤ºä¸åŒåº”ç”¨åœºæ™¯ ï¼Œå•ä¸€headè¡¨ç¤ºæŸä¸ªåœºæ™¯ä¸‹ï¼Œå„ä¸ªå­—ä¹‹é—´çš„å…³è”ç¨‹åº¦ 1 Scaled Dot-Product Attention Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_{k}}})V$d_{k}$ ï¼š keys of dimension ä¸ºä»€ä¹ˆscaleï¼ŸWe suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients. Mask å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šAttention Maskå’ŒPadding Maskï¼Œæ¥ä¸‹æ¥å…·ä½“è®²è§£ã€‚ 1.Attention Mask ensures that the predictions for position i can depend only on the known outputs at positions less than i. sotfmaxå‰è¦maskï¼Œä¸Šä¸‰è§’maskæ‰ 2.Padding Mask Paddingä½ç½®ä¸Šçš„ä¿¡æ¯æ˜¯æ— æ•ˆçš„ï¼Œæ‰€ä»¥éœ€è¦ä¸¢å¼ƒã€‚ è¿‡ç¨‹å¦‚ä¸‹å›¾ç¤ºï¼š 2 Multi-Head Attention Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. MultiHead(Q,K,V)=Concat(head1,...,head_n)W^O \\\\ where \\ head_{i}=Attetion(QW_{i}^{Q},kW_{i}^{K},VW_{i}^{V})3 Applications of Attention in our Model1.encoder-decoder attention layers ç»“æ„ï¼šqueries come from the previous decoder layer,and the memory keys and values come from the output of the encoder. ç›®çš„ï¼šThis allows every position in the decoder to attend over all positions in the input sequence. 2.encoder contains self-attention layers ç»“æ„ï¼škeys, values and queries come from the same place ç›®çš„ï¼šEach position in the encoder can attend to all positions in the previous layer of the encoder. 3.self-attention layers in the decoder ç»“æ„ï¼škeys, values and queries come from the same place ç›®çš„ï¼šallow each position in the decoder to attend to all positions in the decoder up to and including that position 3 Encoder and Decoder Stacks1 encoder1).Input Embeddingä¸Positional Encoding X = \\text{Input Embedding}+ \\text{Positional Encoding}\\\\2). multi-head attention Q = \\text{Linear}_q(X) = XW_{Q}\\\\ K = \\text{Linear}_k(X) = XW_{K}\\\\ V = \\text{Linear}_v(X) = XW_{V}\\\\ X_{attention} = \\text{Attention}(Q,K,V)3). æ®‹å·®è¿æ¥ä¸ Layer Normalization X_{attention} = X + X_{attention}\\\\ X_{attention} = \\text{LayerNorm}(X_{attention})4). FeedForward X_{hidden} = \\text{Linear}(\\text{ReLU}(\\text{Linear}(X_{attention})))5). æ®‹å·®è¿æ¥ä¸ Layer Normalization X_{hidden} = X_{attention} + X_{hidden}\\\\ X_{hidden} = \\text{LayerNorm}(X_{hidden})å…¶ä¸­$ X_{hidden} \\in \\mathbb{R}^{batch_size \\ \\ seq_len \\ \\ embed_dim} $ 2 decoderæˆ‘ä»¬å…ˆä» HighLevel çš„è§’åº¦è§‚å¯Ÿä¸€ä¸‹ Decoder ç»“æ„ï¼Œä»ä¸‹åˆ°ä¸Šä¾æ¬¡æ˜¯ï¼š Masked Multi-Head Self-Attention Multi-Head Encoder-Decoder Attention FeedForward Network 4 å¸¸è§é—®é¢˜1 å¹¶è¡ŒåŒ– è®­ç»ƒencoderï¼Œdecoderéƒ½å¹¶è¡Œï¼Œæµ‹è¯•encoderå¹¶è¡Œï¼Œdecoderä¸æ˜¯å¹¶è¡Œ https://zhuanlan.zhihu.com/p/368592551 2 self-attentionå’Œæ™®é€šattentionçš„åŒºåˆ« å–å†³äºqueryå’Œkeyæ˜¯å¦åœ¨ä¸€ä¸ªåœ°æ–¹ 3 Why Self-Attention Motivating our use of self-attention we consider three desiderata. 1.One is the total computational complexity per layer. 2.Another is the amount of computation that can be parallelized, as measured by the minimum number of sequential operations required. 3.The third is the path length between long-range dependencies in the network å‚è€ƒhttps://arxiv.org/abs/1706.03762 å¤§ä½¬è¯¦è§£ï¼š https://jalammar.github.io/illustrated-transformer/","link":"/2021/07/18/transformer/"},{"title":"å­—å…¸æ ‘","text":"ä¸€.æ ¸å¿ƒæ€æƒ³Trie treeï¼Œå³å­—å…¸æ ‘ï¼Œåˆç§°å•è¯æŸ¥æ‰¾æ ‘æˆ–é”®æ ‘ï¼Œæ˜¯ä¸€ç§æ ‘å½¢ç»“æ„ï¼Œæ˜¯ä¸€ç§å“ˆå¸Œæ ‘çš„å˜ç§ã€‚å…¸å‹åº”ç”¨æ˜¯ç”¨äºç»Ÿè®¡å’Œæ’åºå¤§é‡çš„å­—ç¬¦ä¸²ï¼ˆä½†ä¸ä»…é™äºå­—ç¬¦ä¸²ï¼‰ï¼Œæ‰€ä»¥ç»å¸¸è¢«æœç´¢å¼•æ“ç³»ç»Ÿç”¨äºæ–‡æœ¬è¯é¢‘ç»Ÿè®¡ã€‚å®ƒçš„ä¼˜ç‚¹æ˜¯ï¼šæœ€å¤§é™åº¦åœ°å‡å°‘æ— è°“çš„å­—ç¬¦ä¸²æ¯”è¾ƒã€‚Trieçš„æ ¸å¿ƒæ€æƒ³æ˜¯ç©ºé—´æ¢æ—¶é—´ã€‚åˆ©ç”¨å­—ç¬¦ä¸²çš„å…¬å…±å‰ç¼€æ¥é™ä½æŸ¥è¯¢æ—¶é—´çš„å¼€é”€ä»¥è¾¾åˆ°æé«˜æ•ˆç‡çš„ç›®çš„ã€‚å­—å…¸æ ‘çš„æŸ¥è¯¢æ—¶é—´å¤æ‚åº¦æ˜¯O (L)ï¼ŒLæ˜¯å¾…æŸ¥å­—ç¬¦ä¸²çš„é•¿åº¦ã€‚å¦‚æœæ˜¯æ™®é€šçš„çº¿æ€§è¡¨ç»“æ„ï¼Œé‚£ä¹ˆæŸ¥è¯¢æ•ˆç‡ä¸ºOï¼ˆNLï¼‰ï¼ŒNä¸ºå¾…æŸ¥æ•°æ®é›†çš„å¤§å°ã€‚ å‡è®¾æœ‰bï¼Œabcï¼Œabdï¼Œbcdï¼Œabcdï¼Œefgï¼Œhii è¿™6ä¸ªå•è¯,é‚£æˆ‘ä»¬åˆ›å»ºå­—å…¸æ ‘å¦‚ä¸‹ï¼š äºŒ.åº”ç”¨ç›®çš„ï¼šåˆ©ç”¨æ±‰è¯­æ‹¼éŸ³ç¼©å†™è¿˜åŸä¸­æ–‡æ±‰å­— å‡†å¤‡ï¼šæ•°æ®é›†ï¼ˆåŒ…å«ä¸­æ–‡æ±‰å­—ä»¥åŠå¯¹åº”æ±‰è¯­ç¼©å†™ï¼‰ æ€æƒ³ï¼š1.åŸºäºæ±‰è¯­æ‹¼éŸ³ç¼©å†™æ£€ç´¢å‡ºæ•°æ®é›†ä¸­å¯¹åº”çš„æ‰€æœ‰ä¸­æ–‡æ±‰å­— 2.åŸºäºä¸­æ–‡æ±‰å­—å‡ºç°é¢‘æ¬¡æ’åºï¼Œå°†top1ä½œä¸ºæ±‰è¯­æ‹¼éŸ³çš„è¿˜åŸç»“æœ ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123import pandas as pdimport pickleimport osimport joblibclass TrieNode(object): def __init__(self): &quot;&quot;&quot; Initialize your data structure here. &quot;&quot;&quot; self.data = {}###å­—æ¯å­—ç¬¦ self.data1={}###ä¸­æ–‡ self.is_word = False###æ ‡è¯†æ˜¯å¦æ±‰å­—class Trie(object): def __init__(self): self.root = TrieNode() def insert(self, word,word1): &quot;&quot;&quot; Inserts a word into the trie. :type word: str :rtype: void &quot;&quot;&quot; node = self.root for letter in word: child = node.data.get(letter) if not child: node.data[letter] = TrieNode() node = node.data[letter] node.is_word = True if word1 not in node.data1: node.data1[word1]=1 else: node.data1[word1]+=1 def search(self, word): &quot;&quot;&quot; Returns if the word is in the trie. :type word: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in word: node = node.data.get(letter) if not node: return False return node.is_word def starts_with(self, prefix): &quot;&quot;&quot; Returns if there is any word in the trie that starts with the given prefix. :type prefix: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in prefix: node = node.data.get(letter) if not node: return False return True def get_start(self, prefix): &quot;&quot;&quot; Returns words started with prefix :param prefix: :return: words (list) &quot;&quot;&quot; def _get_key(pre, pre_node): words_list = [] if pre_node.is_word: words_list.append([pre,pre_node.data1]) for x in pre_node.data.keys(): words_list.extend(_get_key(pre + str(x), pre_node.data.get(x))) return words_list words = [] if not self.starts_with(prefix): return words # if self.search(prefix): # words.append(prefix) # return words node = self.root for letter in prefix: node = node.data.get(letter) return _get_key(prefix, node) def find_result(self,string): result =self.get_start(string) result = sort_by_value(result[0][1]) result.reverse() return result[0] def sort_by_value(d): return sorted(d.items(), key=lambda k: k[1]) # k[1] å–åˆ°å­—å…¸çš„å€¼ã€‚def build_tree(data,save_path): trie = Trie() for element in data.values: trie.insert(element[0], element[1]) joblib.dump(trie, save_path) returndef load_tree(path): trie = joblib.load(path) return trieif __name__ == '__main__': ### build_tree(data,save_path) ### tree=load_tree(save_path) print(tree.find_result(&quot;XXXXXXXX&quot;)) å‚è€ƒhttps://zhuanlan.zhihu.com/p/28891541","link":"/2021/08/02/trie-tree/"},{"title":"åŒæŒ‡é’ˆ","text":"æŒ‡é’ˆ$i$ï¼ŒæŒ‡é’ˆ$j$ï¼Œåºåˆ—é•¿åº¦ä¸º$n$ 1 $O(n^2)$ $i$æ€»å…±éå†$n$ï¼Œ$j$æ€»å…±éå†$n^2$ 1 $O(n )$ $i$æ€»å…±éå†$n$ï¼Œ$j$æ€»å…±éå†$n$","link":"/2022/06/16/two-pointer/"},{"title":"text SpanæŠ½å–","text":"åŸºäºé—®é¢˜åœ¨æ®µè½ä¸­å¯»æ‰¾ç­”æ¡ˆ 1231 é—®é¢˜ï¼šè‹è½¼æ˜¯å“ªé‡Œäººï¼Ÿ2 æè¿°ï¼šè‹è½¼æ˜¯åŒ—å®‹è‘—åçš„æ–‡å­¦å®¶ä¸æ”¿æ²»å®¶ï¼Œçœ‰å·çœ‰å±±äººã€‚3 æ ‡ç­¾ï¼šçœ‰å·çœ‰å±±äºº bertä¸­çš„SQuADé—®ç­”ä»»åŠ¡ æ ‡ç­¾å¼•å…¥start å’Œ end æ ‡ç­¾ ç»“æ„ æŸå¤±123456789sequence_output = all_encoder_outputs[-1] #[src_len, batch_size, hidden_size]logits = self.qa_outputs(sequence_output) # [src_len, batch_size,2] start_logits, end_logits = logits.split(1, dim=-1)start_logits = start_logits.squeeze(-1).transpose(0, 1) # [batch_size,src_len]end_logits = end_logits.squeeze(-1).transpose(0, 1) # [batch_size,src_len]loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)start_loss = loss_fct(start_logits, start_positions)end_loss = loss_fct(end_logits, end_positions)final_loss=(start_loss + end_loss) / 2 æ¨¡å‹è¾“å‡ºä¸ºï¼š [src_len, batch_size,2] ä¸¤ä¸ªï¼ˆstart å’Œ end ï¼‰src_lenåˆ†ç±»çš„å¹³å‡ é¢„æµ‹å‡è®¾å€™é€‰æ–‡æœ¬é•¿åº¦ä¸ºnï¼Œè¾“å‡ºnä¸ª2åˆ†ç±»ç»“æœï¼Œé€‰å‡ºæœ€å¤§çš„startæ¦‚ç‡å’Œendæ¦‚ç‡æœ€ä¸ºstartå’Œend label å‚è€ƒhttps://zhuanlan.zhihu.com/p/77868938 https://blog.csdn.net/guangyacyb/article/details/105526482 https://zhuanlan.zhihu.com/p/473157694","link":"/2022/06/11/txt-span/"},{"title":"å¤„ç†æ— ç•Œå’Œæœ‰ç•Œæ•°æ®","text":"https://flink.apache.org/zh/flink-architecture.html ä»»ä½•ç±»å‹çš„æ•°æ®éƒ½å¯ä»¥å½¢æˆä¸€ç§äº‹ä»¶æµã€‚ä¿¡ç”¨å¡äº¤æ˜“ã€ä¼ æ„Ÿå™¨æµ‹é‡ã€æœºå™¨æ—¥å¿—ã€ç½‘ç«™æˆ–ç§»åŠ¨åº”ç”¨ç¨‹åºä¸Šçš„ç”¨æˆ·äº¤äº’è®°å½•ï¼Œæ‰€æœ‰è¿™äº›æ•°æ®éƒ½å½¢æˆä¸€ç§æµã€‚ æ•°æ®å¯ä»¥è¢«ä½œä¸ºæ— ç•Œæˆ–è€…æœ‰ç•Œæµæ¥å¤„ç†ã€‚ æ— ç•Œæµ æœ‰å®šä¹‰æµçš„å¼€å§‹ï¼Œä½†æ²¡æœ‰å®šä¹‰æµçš„ç»“æŸã€‚å®ƒä»¬ä¼šæ— ä¼‘æ­¢åœ°äº§ç”Ÿæ•°æ®ã€‚æ— ç•Œæµçš„æ•°æ®å¿…é¡»æŒç»­å¤„ç†ï¼Œå³æ•°æ®è¢«æ‘„å–åéœ€è¦ç«‹åˆ»å¤„ç†ã€‚æˆ‘ä»¬ä¸èƒ½ç­‰åˆ°æ‰€æœ‰æ•°æ®éƒ½åˆ°è¾¾å†å¤„ç†ï¼Œå› ä¸ºè¾“å…¥æ˜¯æ— é™çš„ï¼Œåœ¨ä»»ä½•æ—¶å€™è¾“å…¥éƒ½ä¸ä¼šå®Œæˆã€‚å¤„ç†æ— ç•Œæ•°æ®é€šå¸¸è¦æ±‚ä»¥ç‰¹å®šé¡ºåºæ‘„å–äº‹ä»¶ï¼Œä¾‹å¦‚äº‹ä»¶å‘ç”Ÿçš„é¡ºåºï¼Œä»¥ä¾¿èƒ½å¤Ÿæ¨æ–­ç»“æœçš„å®Œæ•´æ€§ã€‚ æœ‰ç•Œæµ æœ‰å®šä¹‰æµçš„å¼€å§‹ï¼Œä¹Ÿæœ‰å®šä¹‰æµçš„ç»“æŸã€‚æœ‰ç•Œæµå¯ä»¥åœ¨æ‘„å–æ‰€æœ‰æ•°æ®åå†è¿›è¡Œè®¡ç®—ã€‚æœ‰ç•Œæµæ‰€æœ‰æ•°æ®å¯ä»¥è¢«æ’åºï¼Œæ‰€ä»¥å¹¶ä¸éœ€è¦æœ‰åºæ‘„å–ã€‚æœ‰ç•Œæµå¤„ç†é€šå¸¸è¢«ç§°ä¸ºæ‰¹å¤„ç† Apache Flink æ“…é•¿å¤„ç†æ— ç•Œå’Œæœ‰ç•Œæ•°æ®é›†ç²¾ç¡®çš„æ—¶é—´æ§åˆ¶å’ŒçŠ¶æ€åŒ–ä½¿å¾— Flink çš„è¿è¡Œæ—¶(runtime)èƒ½å¤Ÿè¿è¡Œä»»ä½•å¤„ç†æ— ç•Œæµçš„åº”ç”¨ã€‚æœ‰ç•Œæµåˆ™ç”±ä¸€äº›ä¸“ä¸ºå›ºå®šå¤§å°æ•°æ®é›†ç‰¹æ®Šè®¾è®¡çš„ç®—æ³•å’Œæ•°æ®ç»“æ„è¿›è¡Œå†…éƒ¨å¤„ç†ï¼Œäº§ç”Ÿäº†å‡ºè‰²çš„æ€§èƒ½ã€‚","link":"/2022/03/20/unboundstream-boundstream/"},{"title":"å¯è§†åŒ–æŠ¥è¡¨","text":"https://zhuanlan.zhihu.com/p/410170345","link":"/2022/02/09/visrion-report/"},{"title":"å„ç»„ä»¶web uiçš„åœ°å€","text":"https://blog.csdn.net/qq_41851454/article/details/79938811 node ip+port yarnresource maneger +8088 hdfsnamenode +50070/9870/9871 spark4040: æ˜¯ä¸€ä¸ªè¿è¡Œçš„Applicationåœ¨è¿è¡Œçš„è¿‡ç¨‹ä¸­ä¸´æ—¶ç»‘å®šçš„ç«¯å£,ç”¨ä»¥æŸ¥çœ‹å½“å‰ä»»åŠ¡çš„çŠ¶æ€.4040è¢«å ç”¨ä¼šé¡ºå»¶åˆ°4041.4042ç­‰.4040æ˜¯ä¸€ä¸ªä¸´æ—¶ç«¯å£,å½“å‰ç¨‹åºè¿è¡Œå®Œæˆå, 4040å°±ä¼šè¢«æ³¨é”€å“¦ã€‚å½“ä½¿ç”¨sparkäº¤äº’å·¥å…·ï¼Œå¦‚spark-sql,spark-shell 8080: é»˜è®¤æ˜¯StandAloneä¸‹, Masterè§’è‰²(è¿›ç¨‹)çš„WEBç«¯å£,ç”¨ä»¥æŸ¥çœ‹å½“å‰Master(é›†ç¾¤)çš„çŠ¶æ€ 18080: é»˜è®¤æ˜¯å†å²æœåŠ¡å™¨çš„ç«¯å£, ç”±äºæ¯ä¸ªç¨‹åºè¿è¡Œå®Œæˆå,4040ç«¯å£å°±è¢«æ³¨é”€äº†. åœ¨ä»¥åæƒ³å›çœ‹æŸä¸ªç¨‹åºçš„è¿è¡ŒçŠ¶æ€å°±å¯ä»¥é€šè¿‡å†å²æœåŠ¡å™¨æŸ¥çœ‹,å†å²æœåŠ¡å™¨é•¿æœŸç¨³å®šè¿è¡Œ,å¯ä¾›éšæ—¶æŸ¥çœ‹è¢«è®°å½•çš„ç¨‹åºçš„è¿è¡Œè¿‡ç¨‹. é…ç½®å†å²æœåŠ¡å™¨ https://blog.csdn.net/Heitao5200/article/details/79674684 https://blog.csdn.net/yu0_zhang0/article/details/80396080 æ³¨æ„ç«¯å£å·å’Œhadoopä¸€è‡´ï¼Œ9000-&gt;8020 flinkApache Flink runs the dashboard on port 8081. Since this is a common port there might be conflict with some other services running on the same machines portå’Œç«¯å£å¯ä»¥åœ¨flink/conf/flink-conf.yaml ä¸­æŸ¥çœ‹ hive metastoreç«¯å£9083 hbase16010","link":"/2022/03/01/web-ui/"},{"title":"æƒé‡åˆå§‹åŒ–","text":"å‚æ•°åˆå§‹æƒé‡ä¸ºä»€ä¹ˆä¸å…¨0æˆ–è€…ä»»æ„ç›¸åŒå€¼ æŸä¸€å±‚ä»»æ„ä¸€ä¸ªç¥ç»å…ƒ \\\\ z=W_{1\\times m}X_{m\\times 1}+b_{1\\times1}å¦‚æœæˆ‘ä»¬å°†ç¥ç»ç½‘ç»œä¸­çš„æƒé‡é›†åˆå§‹åŒ–ä¸ºé›¶æˆ–è€…ç›¸åŒï¼Œé‚£ä¹ˆåŒä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒå°†åœ¨åå‘ä¼ æ’­æœŸé—´å¼€å§‹äº§ç”Ÿç›¸åŒçš„è¾“å‡ºå’Œç›¸åŒçš„æ¢¯åº¦ã€‚å¯¼è‡´åŒä¸€å±‚æ¯ä¸ªç¥ç»å…ƒå®Œå…¨ä¸€æ ·ï¼Œç­‰ä»·äºåªæœ‰ä¸€ä¸ª å¸¸ç”¨çš„ä¸‰ç§æƒå€¼åˆå§‹åŒ–æ–¹æ³• éšæœºåˆå§‹åŒ–ã€Xavier initializationã€He initialization å‚è€ƒhttps://mdnice.com/writing/6fe7dfe1954945d180d6b36562658af8 https://m.ofweek.com/ai/2021-06/ART-201700-11000-30502442.html https://blog.csdn.net/qq_15505637/article/details/79362970","link":"/2021/11/26/weiht-init/"},{"title":"nlpä¸­ä½¿ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡å’Œéšæœºåˆå§‹åŒ–çš„è¯å‘é‡çš„åŒºåˆ«åœ¨å“ªé‡Œï¼Ÿ","text":"å½“ä½ è®­ç»ƒæ•°æ®ä¸å……è¶³çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨åˆ«äººå·²ç»é¢„è®­ç»ƒå¥½çš„è¯å‘é‡ï¼Œä¹Ÿå¯ä»¥æ ¹æ®è‡ªå·±çš„è®­ç»ƒæ•°æ®å¾®è°ƒ(fine-tuning)é¢„è®­ç»ƒè¯å‘é‡ï¼Œä¹Ÿå¯ä»¥æŠŠè¯å‘é‡å’Œæ•´ä¸ªæ¨¡å‹ä¸€å—è®­ç»ƒï¼Œä½†æ˜¯é€šå¸¸é¢„è®­ç»ƒçš„è¯å‘é‡æˆ‘ä»¬ä¸ä¼šå†åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­è¿›è¡Œæ›´æ–°ã€‚ å½“ä½ çš„è®­ç»ƒæ•°æ®æ¯”è¾ƒå……è¶³çš„æ—¶å€™ï¼Œå¹¶ä¸”æƒ³è®©è¯å‘é‡èƒ½æ›´å¥½çš„æ•æ‰è‡ªå·±çš„è®­ç»ƒæ•°æ®çš„è¯­ä¹‰ä¿¡æ¯æ—¶ï¼Œåº”è¯¥ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„è¯å‘é‡ã€‚å½“ç„¶ï¼Œéšæœºåˆå§‹åŒ–çš„è¯å‘é‡å¿…é¡»è¦åœ¨è®­ç»ƒç½‘ç»œçš„è¿‡ç¨‹ä¸­ä¸æ–­è¿›è¡Œæ›´æ–°ï¼Œå°±å’Œç¥ç»ç½‘ç»œçš„æƒé‡å‚æ•°ä¸€æ ·è¿›è¡Œè®­ç»ƒã€‚ ä¾‹å­ï¼š 1.ç›´è§‚å±•ç¤º 123456789101112import torchfrom torch import nnfrom torch.autograd import Variable###randomembeds = nn.Embedding(2, 5) print(embeds.weight)embeds = nn.Embedding(2, 5) print(embeds.weight)###from pretrainweight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])embedding = nn.Embedding.from_pretrained(weight)print(embedding.weight) 123456789Parameter containing:tensor([[-0.1754, 1.6604, -1.5025, -1.0980, -0.4718], [-1.1276, 0.1408, -1.0746, -1.2768, -0.6789]], requires_grad=True)Parameter containing:tensor([[-0.7366, 0.0607, 0.6151, 0.2282, 0.3878], [-1.1365, 0.1844, -1.1191, -0.8787, -0.5121]], requires_grad=True)Parameter containing:tensor([[1.0000, 2.3000, 3.0000], [4.0000, 5.1000, 6.3000]]) 2.n-gram 123self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)self.embedding_ngram2 = nn.Embedding(config.n_gram_vocab, config.embed)self.embedding_ngram3 = nn.Embedding(config.n_gram_vocab, config.embed) å‚è€ƒhttps://www.zhihu.com/question/337950427","link":"/2021/07/28/word-emb-add/"},{"title":"æ–‡æœ¬è¡¨ç¤º","text":"æ–‡æœ¬è¡¨ç¤ºçš„è¡¨ç¤ºå½¢å¼å¯ä»¥æ˜¯å•ä¸€æ•°å€¼ï¼ˆåŸºæœ¬æ²¡äººç”¨ï¼‰ï¼Œå¯ä»¥æ˜¯å‘é‡ï¼ˆç›®å‰ä¸»æµï¼‰ï¼Œå¥½å¥‡æœ‰æ²¡æœ‰é«˜çº¬tensorè¡¨ç¤ºçš„ï¼Ÿä¸‹æ–‡æ˜¯åŸºäºå‘é‡è¡¨ç¤ºçš„ã€‚ 1.è¯è¯­è¡¨ç¤º1.1 one hotä¸¾ä¸ªä¾‹å­ï¼Œæœ‰æ ·æœ¬å¦‚ä¸‹ï¼š â€‹ Jane wants to go to Shenzhen. â€‹ Bob wants to go to Shanghai. åŸºäºä¸Šè¿°ä¸¤ä¸ªæ–‡æ¡£ä¸­å‡ºç°çš„å•è¯ï¼Œæ„å»ºå¦‚ä¸‹ä¸€ä¸ªè¯å…¸ï¼š Vocabulary= [Jane, wants, to, go, Shenzhen, Bob, Shanghai] é‚£ä¹ˆwants å¯ä»¥è¡¨ç¤ºä¸º 1[0,1,0,0,0,0,0] 1.2 word embeddingè¯å‘é‡æ¨¡å‹æ˜¯è€ƒè™‘è¯è¯­ä½ç½®å…³ç³»çš„ä¸€ç§æ¨¡å‹ã€‚é€šè¿‡å¤§é‡è¯­æ–™çš„è®­ç»ƒï¼Œå°†æ¯ä¸€ä¸ªè¯è¯­æ˜ å°„åˆ°é«˜ç»´åº¦çš„å‘é‡ç©ºé—´å½“ä¸­ï¼Œä½¿å¾—è¯­æ„ç›¸ä¼¼çš„è¯åœ¨å‘é‡ç©ºé—´ä¸Šä¹Ÿä¼šæ¯”è¾ƒç›¸è¿‘ï¼Œä¸¾ä¸ªä¾‹å­ï¼Œå¦‚ ä¸Šè¡¨ä¸ºè¯å‘é‡çŸ©é˜µï¼Œå…¶ä¸­è¡Œè¡¨ç¤ºä¸åŒç‰¹å¾ï¼Œåˆ—è¡¨ç¤ºä¸åŒè¯ï¼ŒManå¯ä»¥è¡¨ç¤ºä¸º 1[-1,0.01,0.03,0.09] æ€§è´¨ï¼š$emb_{Man}-emb_{Women}\\approx emb_{King}-emb_{Queen}$ å¸¸è§çš„è¯å‘é‡çŸ©é˜µæ„å»ºæ–¹æ³•æœ‰ï¼Œword2vecï¼ŒGloVe 2.å¥å­è¡¨ç¤º2.1 è¯è¢‹æ¨¡å‹è¯è¢‹æ¨¡å‹ä¸è€ƒè™‘æ–‡æœ¬ä¸­è¯ä¸è¯ä¹‹é—´çš„ä¸Šä¸‹æ–‡å…³ç³»ï¼Œä»…ä»…åªè€ƒè™‘æ‰€æœ‰è¯çš„æƒé‡ã€‚è€Œæƒé‡ä¸è¯åœ¨æ–‡æœ¬ä¸­å‡ºç°çš„é¢‘ç‡æœ‰å…³ã€‚ ä¾‹å¥: â€‹ Jane wants to go to Shenzhen. â€‹ Bob wants to go to Shanghai. åŸºäºä¸Šè¿°ä¸¤ä¸ªæ–‡æ¡£ä¸­å‡ºç°çš„å•è¯ï¼Œæ„å»ºå¦‚ä¸‹ä¸€ä¸ªè¯å…¸ï¼š Vocabulary= [Jane, wants, to, go, Shenzhen, Bob, Shanghai] é‚£ä¹ˆä¸Šé¢ä¸¤ä¸ªä¾‹å¥å°±å¯ä»¥ç”¨ä»¥ä¸‹ä¸¤ä¸ªå‘é‡è¡¨ç¤ºï¼Œå…¶å€¼ä¸ºè¯¥è¯è¯­å‡ºç°çš„æ¬¡æ•°ï¼š 12[1,1,2,1,1,0,0][0,1,2,1,0,1,1] 2.2 Sentence Embedding2.2.1 è¯„ä»·å·¥å…·SentEval is a popular toolkit to evaluate the quality of sentence embeddings. 2.2.2 å¸¸è§æ–¹æ³•sentence BERT BERT-flow https://zhuanlan.zhihu.com/p/444346578 å‚è€ƒæ–‡çŒ®https://zhuanlan.zhihu.com/p/353187575 https://www.jianshu.com/p/0587bc01e414 https://www.cnblogs.com/chenyusheng0803/p/10978883.html","link":"/2021/07/19/word-representation/"},{"title":"è¯è¯­çš„æ–‡æœ¬ç›¸ä¼¼åº¦","text":"ä¸€.åŸºäºè¯å…¸äººä¸ºæ„å»ºï¼Œæ¯”è¾ƒä¸»è§‚ï¼Œä¸åˆ©äºç»´æŠ¤ 1.1 åŸºäºè¯æ—1.1.1 ç»“æ„æ‰©å±•ç‰ˆåŒä¹‰è¯è¯æ—åˆ†ä¸º5å±‚ç»“æ„ï¼Œå¦‚å›¾ï¼Œéšç€çº§åˆ«çš„é€’å¢ï¼Œè¯ä¹‰åˆ»ç”»è¶Šæ¥è¶Šç»†ï¼Œåˆ°äº†ç¬¬äº”å±‚ï¼Œæ¯ä¸ªåˆ†ç±»é‡Œè¯è¯­æ•°é‡å·²ç»ä¸å¤§ï¼Œå¾ˆå¤šåªæœ‰ä¸€ä¸ªè¯è¯­ï¼Œå·²ç»ä¸å¯å†åˆ†ï¼Œå¯ä»¥ç§°ä¸ºåŸå­è¯ç¾¤ã€åŸå­ç±»æˆ–åŸå­èŠ‚ç‚¹ã€‚ä¸åŒçº§åˆ«çš„åˆ†ç±»ç»“æœå¯ä»¥ä¸ºè‡ªç„¶è¯­è¨€å¤„ç†æä¾›ä¸åŒçš„æœåŠ¡ï¼Œä¾‹å¦‚ç¬¬å››å±‚çš„åˆ†ç±»å’Œç¬¬äº”å±‚çš„åˆ†ç±»åœ¨ä¿¡æ¯æ£€ç´¢ã€æ–‡æœ¬åˆ†ç±»ã€è‡ªåŠ¨é—®ç­”ç­‰ç ”ç©¶é¢†åŸŸå¾—åˆ°åº”ç”¨ã€‚æœ‰ç ”ç©¶è¯æ˜ï¼Œå¯¹è¯ä¹‰è¿›è¡Œæœ‰æ•ˆæ‰©å±•ï¼Œæˆ–è€…å¯¹å…³é”®è¯åšåŒä¹‰è¯æ›¿æ¢å¯ä»¥æ˜æ˜¾æ”¹å–„ä¿¡æ¯æ£€ç´¢ã€æ–‡æœ¬åˆ†ç±»å’Œè‡ªåŠ¨é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½ã€‚ ä¸‹è½½åçš„è¯å…¸æ–‡ä»¶å¦‚ä¸‹æ‰€ç¤ºï¼š 12345Aa01A01= äºº å£« äººç‰© äººå£« äººæ° äººé€‰Aa01A02= äººç±» ç”Ÿäºº å…¨äººç±»Aa01A03= äººæ‰‹ äººå‘˜ äººå£ äººä¸ å£ é£ŸæŒ‡Aa01A04= åŠ³åŠ› åŠ³åŠ¨åŠ› å·¥ä½œè€…Aa01A05= åŒ¹å¤« ä¸ªäºº è¡¨ä¸­çš„ç¼–ç ä½æ˜¯æŒ‰ç…§ä»å·¦åˆ°å³çš„é¡ºåºæ’åˆ—ã€‚ç¬¬å…«ä½çš„æ ‡è®°æœ‰3 ç§ï¼Œåˆ†åˆ«æ˜¯â€œ=â€ã€â€œ#â€ã€â€œ@â€ï¼Œ â€œ=â€ä»£è¡¨â€œç›¸ç­‰â€ã€â€œåŒä¹‰â€ã€‚æœ«å°¾çš„â€œ#â€ä»£è¡¨â€œä¸ç­‰â€ã€â€œåŒç±»â€ï¼Œå±äºç›¸å…³è¯è¯­ã€‚æœ«å°¾çš„â€œ@â€ä»£è¡¨â€œè‡ªæˆ‘å°é—­â€ã€â€œç‹¬ç«‹â€ï¼Œå®ƒåœ¨è¯å…¸ä¸­æ—¢æ²¡æœ‰åŒä¹‰è¯ï¼Œä¹Ÿæ²¡æœ‰ç›¸å…³è¯ã€‚ æºç å¦‚ä¸‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133class WordSimilarity2010(SimilarBase): ''' æœ¬ç±»æ ¹æ®ä¸‹é¢çš„è®ºæ–‡æ–¹æ³•ï¼š åŸºäºåŒä¹‰è¯è¯æ—çš„è¯è¯­ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œç”°ä¹…ä¹, èµµ è”š(ä¸œåŒ—å¸ˆèŒƒå¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸ä¿¡æ¯æŠ€æœ¯å­¦é™¢, é•¿æ˜¥ 130117 ) è®¡ç®—ä¸¤ä¸ªå•è¯æ‰€æœ‰ç¼–ç ç»„åˆçš„ç›¸ä¼¼åº¦ï¼Œå–æœ€å¤§çš„ä¸€ä¸ª ''' def __init__(self): super(WordSimilarity2010, self).__init__() self.a = 0.65 self.b = 0.8 self.c = 0.9 self.d = 0.96 self.e = 0.5 self.f = 0.1 self.degree = 180 self.PI = math.pi def similarity(self, w1, w2): ''' åˆ¤æ–­ä¸¤ä¸ªè¯çš„ç›¸ä¼¼æ€§ã€‚ :param w1: [string] :param w2: [string] :return: [float]0~1ä¹‹é—´ã€‚ ''' code1 = self._data.get(w1, None) code2 = self._data.get(w2, None) if not code1 or not code2: return 0 # åªè¦æœ‰ä¸€ä¸ªä¸åœ¨åº“é‡Œåˆ™ä»£è¡¨æ²¡æœ‰ç›¸ä¼¼æ€§ã€‚ # æœ€ç»ˆè¿”å›çš„æœ€å¤§ç›¸ä¼¼åº¦ sim_max = 0 # ä¸¤ä¸ªè¯å¯èƒ½å¯¹åº”å¤šä¸ªç¼–ç  for c1 in code1: for c2 in code2: cur_sim = self.sim_by_code(c1, c2) # print(c1, c2, 'çš„ç›¸ä¼¼åº¦ä¸ºï¼š', cur_sim) if cur_sim &gt; sim_max: sim_max = cur_sim return sim_max def sim_by_code(self, c1, c2): &quot;&quot;&quot; æ ¹æ®ç¼–ç è®¡ç®—ç›¸ä¼¼åº¦ &quot;&quot;&quot; # å…ˆæŠŠcodeçš„å±‚çº§ä¿¡æ¯æå–å‡ºæ¥ clayer1 = self._parse_code(c1) clayer2 = self._parse_code(c2) common_layer = self.get_common_layer(clayer1,clayer2) length = len(common_layer) # å¦‚æœæœ‰ä¸€ä¸ªç¼–ç ä»¥'@'ç»“å°¾ï¼Œé‚£ä¹ˆè¡¨ç¤ºè‡ªæˆ‘å°é—­ï¼Œè¿™ä¸ªç¼–ç ä¸­åªæœ‰ä¸€ä¸ªè¯ï¼Œç›´æ¥è¿”å›f if c1.endswith('@') or c2.endswith('@') or 0 == length: return self.f cur_sim = 0 if 6 &lt;= length: # å¦‚æœå‰é¢ä¸ƒä¸ªå­—ç¬¦ç›¸åŒï¼Œåˆ™ç¬¬å…«ä¸ªå­—ç¬¦ä¹Ÿç›¸åŒï¼Œè¦ä¹ˆåŒä¸º'='ï¼Œè¦ä¹ˆåŒä¸º'#'' if c1.endswith('=') and c2.endswith('='): cur_sim = 1 elif c1.endswith('#') and c2.endswith('#'): cur_sim = self.e else: k = self.get_k(clayer1, clayer2) n = self.get_n(common_layer) if 1 == length: cur_sim = self.sim_formula(self.a, n, k) elif 2 == length: cur_sim = self.sim_formula(self.b, n, k) elif 3 == length: cur_sim = self.sim_formula(self.c, n, k) elif 4 == length: cur_sim = self.sim_formula(self.d, n, k) return cur_sim def sim_formula(self, coeff, n, k): &quot;&quot;&quot; è®¡ç®—ç›¸ä¼¼åº¦çš„å…¬å¼ï¼Œä¸åŒçš„å±‚ç³»æ•°ä¸åŒ &quot;&quot;&quot; return coeff * math.cos(n * self.PI / self.degree) * ((n - k + 1) / n) def get_common_layer(self, ca, cb): ''' è¿”å›ç›¸åº”çš„layerå±‚ :param ca: [list(str)] åˆ†è§£åçš„ç¼–ç ã€‚ :param cb: [list(str)] åˆ†è§£åçš„ç¼–ç ã€‚ :return: [list(str)]åˆ—è¡¨ä»£è¡¨ç›¸åº”çš„æ ¹ç¼–ç ã€‚ ''' common_layer = [] for i, j in zip(ca, cb): if i == j: common_layer.append(i) else: break return common_layer def get_k(self, c1, c2): &quot;&quot;&quot; è¿”å›ä¸¤ä¸ªç¼–ç å¯¹åº”åˆ†æ”¯çš„è·ç¦»ï¼Œç›¸é‚»è·ç¦»ä¸º1 &quot;&quot;&quot; if c1[0] != c2[0]: return abs(ord(c1[0]) - ord(c2[0])) elif c1[1] != c2[1]: return abs(ord(c1[1]) - ord(c2[1])) elif c1[2] != c2[2]: return abs(int(c1[2]) - int(c2[2])) elif c1[3] != c2[3]: return abs(ord(c1[3]) - ord(c2[3])) else: return abs(int(c1[4]) - int(c2[4])) def get_n(self, common_layer): ''' è¿”å›ç›¸åº”ç»“ç‚¹ä¸‹æœ‰å¤šå°‘ä¸ªåŒçº§å­ç»“ç‚¹ã€‚ :param common_layer: [listr(str)]ç›¸åŒçš„ç»“ç‚¹ã€‚ :return: int ''' end_node = self._code_tree for t_node_name in common_layer: end_node = end_node[t_node_name] if not isinstance(end_node, dict): return end_node return len(end_node.keys()) 1.1.2 ä½¿ç”¨ç¯å¢ƒå‡†å¤‡ï¼špip install WordSimilarity 1234567891011121314151617from word_similarity import WordSimilarity2010import timews_tool = WordSimilarity2010()start = time.time()b_a = &quot;è”ç³»æ–¹å¼&quot;b_b = &quot;ç”µè¯&quot;sim_b = ws_tool.similarity(b_a, b_b)print(b_a, b_b, 'ç›¸ä¼¼åº¦ä¸º', sim_b)end = time.time()print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot;+str(end-start))b_a = &quot;æ‰‹æœº&quot;b_b = &quot;ç”µè¯&quot;sim_b = ws_tool.similarity(b_a, b_b)print(b_a, b_b, 'ç›¸ä¼¼åº¦ä¸º', sim_b)end = time.time()print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot;+str(end-start)) 1234è”ç³»æ–¹å¼ ç”µè¯ ç›¸ä¼¼åº¦ä¸º 0è¿è¡Œæ—¶é—´ï¼š5.793571472167969e-05æ‰‹æœº ç”µè¯ ç›¸ä¼¼åº¦ä¸º 0.30484094213212237è¿è¡Œæ—¶é—´ï¼š0.0001442432403564453 1.2 åŸºäºçŸ¥ç½‘ä¸è¯æ—çš„è¯è¯­è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—1.2.1 åŸç†ç»¼åˆäº†è¯æ—cilinä¸çŸ¥ç½‘hownetçš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œé‡‡ç”¨æ··åˆç­–ç•¥ï¼Œæ··åˆç­–ç•¥å…·ä½“å¯ä»¥å‚è€ƒæºç ï¼Œå¦‚ä¸‹ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485from hownet.howNet import How_Similarityfrom cilin.V3.ciLin import CilinSimilarityclass HybridSim(): ''' æ··åˆç›¸ä¼¼åº¦è®¡ç®—ç­–ç•¥ã€‚ä½¿ç”¨äº†è¯æ—ä¸çŸ¥ç½‘è¯æ±‡é‡çš„å¹¶é›†ã€‚æ‰©å¤§äº†è¯æ±‡è¦†ç›–èŒƒå›´ã€‚ ''' ci_lin = CilinSimilarity() # å®ä¾‹åŒ–è¯æ—ç›¸ä¼¼åº¦è®¡ç®—å¯¹è±¡ how_net = How_Similarity() # å®ä¾‹åŒ–çŸ¥ç½‘ç›¸ä¼¼åº¦è®¡ç®—å¯¹è±¡ Common = ci_lin.vocab &amp; how_net.vocab A = how_net.vocab - ci_lin.vocab B = ci_lin.vocab - how_net.vocab @classmethod def get_Final_sim(cls, w1, w2): lin = cls.ci_lin.sim2018(w1, w2) if w1 in cls.ci_lin.vocab and w2 in cls.ci_lin.vocab else 0 how = cls.how_net.calc(w1, w2) if w1 in cls.how_net.vocab and w2 in cls.how_net.vocab else 0 if w1 in cls.Common and w2 in cls.Common: # ä¸¤ä¸ªè¯éƒ½è¢«è¯æ—å’ŒçŸ¥ç½‘å…±åŒæ”¶å½•ã€‚ # print('ä¸¤ä¸ªè¯éƒ½è¢«è¯æ—å’ŒçŸ¥ç½‘å…±åŒæ”¶å½•ã€‚', end='\\t') # print(w1, w2, 'è¯æ—æ”¹è¿›ç‰ˆç›¸ä¼¼åº¦ï¼š', lin, end='\\t') # print('çŸ¥ç½‘ç›¸ä¼¼åº¦ç»“æœä¸ºï¼š', how, end='\\t') return lin * 1 + how * 0 # å¯ä»¥è°ƒèŠ‚ä¸¤è€…çš„æƒé‡ï¼Œä»¥è·å–æ›´ä¼˜ç»“æœï¼ï¼ if w1 in cls.A and w2 in cls.A: # ä¸¤ä¸ªè¯éƒ½åªè¢«çŸ¥ç½‘æ”¶å½•ã€‚ return how if w1 in cls.B and w2 in cls.B: # ä¸¤ä¸ªè¯éƒ½åªè¢«è¯æ—æ”¶å½•ã€‚ return lin if w1 in cls.A and w2 in cls.B: # ä¸€ä¸ªåªè¢«è¯æ—æ”¶å½•ï¼Œå¦ä¸€ä¸ªåªè¢«çŸ¥ç½‘æ”¶å½•ã€‚ print('è§¦å‘ç­–ç•¥ä¸‰ï¼Œå·¦è¯ä¸ºçŸ¥ç½‘ï¼Œå³è¯ä¸ºè¯æ—') same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w2][0]] if not same_words: return 0.2 all_sims = [cls.how_net.calc(word, w1) for word in same_words] print(same_words, all_sims, end='\\t') return max(all_sims) if w2 in cls.A and w1 in cls.B: print('è§¦å‘ç­–ç•¥ä¸‰ï¼Œå·¦è¯ä¸ºè¯æ—ï¼Œå³è¯ä¸ºçŸ¥ç½‘') same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w1][0]] if not same_words: return 0.2 all_sims = [cls.how_net.calc(word, w2) for word in same_words] print(w1, 'è¯æ—åŒä¹‰è¯æœ‰ï¼š', same_words, all_sims, end='\\t') return max(all_sims) if w1 in cls.A and w2 in cls.Common: print('ç­–ç•¥å››ï¼ˆå·¦çŸ¥ç½‘ï¼‰ï¼šçŸ¥ç½‘ç›¸ä¼¼åº¦ç»“æœä¸ºï¼š', how) same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w2][0]] if not same_words: return how all_sims = [cls.how_net.calc(word, w1) for word in same_words] print(w2, 'è¯æ—åŒä¹‰è¯æœ‰ï¼š', same_words, all_sims, end='\\t') return 0.6 * how + 0.4 * max(all_sims) if w2 in cls.A and w1 in cls.Common: print('ç­–ç•¥å››ï¼ˆå³çŸ¥ç½‘ï¼‰ï¼šçŸ¥ç½‘ç›¸ä¼¼åº¦ç»“æœä¸ºï¼š', how) same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w1][0]] if not same_words: return how all_sims = [cls.how_net.calc(word, w2) for word in same_words] print(same_words, all_sims, end='\\t') return 0.6 * how + 0.4 * max(all_sims) if w1 in cls.B and w2 in cls.Common: print(w1, w2, 'ç­–ç•¥äº”ï¼ˆå·¦è¯æ—ï¼‰ï¼šè¯æ—æ”¹è¿›ç‰ˆç›¸ä¼¼åº¦ï¼š', lin) same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w1][0]] if not same_words: return lin all_sims = [cls.how_net.calc(word, w2) for word in same_words] print(w1, 'è¯æ—åŒä¹‰è¯æœ‰ï¼š', same_words, all_sims, end='\\t') return 0.6 * lin + 0.4 * max(all_sims) if w2 in cls.B and w1 in cls.Common: print(w1, w2, 'ç­–ç•¥äº”ï¼ˆå³è¯æ—ï¼‰ï¼šè¯æ—æ”¹è¿›ç‰ˆç›¸ä¼¼åº¦ï¼š', lin) same_words = cls.ci_lin.code_word[cls.ci_lin.word_code[w2][0]] if not same_words: return lin all_sims = [cls.how_net.calc(word, w1) for word in same_words] print(w2, 'è¯æ—åŒä¹‰è¯æœ‰ï¼š', same_words, all_sims, end='\\t') return 0.6 * lin + 0.4 * max(all_sims) print('å¯¹ä¸èµ·ï¼Œè¯è¯­å¯èƒ½æœªæ”¶å½•ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦ï¼') return -1 1.2.2 ä½¿ç”¨å‚è€ƒhttps://github.com/yaleimeng/Final_word_Similarity 12345678910111213141516171819202122232425from Hybrid_Sim import HybridSimfrom Pearson import *import timeif __name__ == '__main__': print('è¯æ—è¯æ±‡é‡', len(HybridSim.ci_lin.vocab ),'\\tçŸ¥ç½‘è¯æ±‡é‡', len(HybridSim.how_net.vocab)) print('ä¸¤è€…æ€»è¯æ±‡é‡',len(HybridSim.ci_lin.vocab | HybridSim.how_net.vocab),'\\té‡å è¯æ±‡é‡', len(HybridSim.Common)) b_a = &quot;è”ç³»æ–¹å¼&quot; b_b = &quot;ç”µè¯&quot; start = time.time() hybrid = HybridSim.get_Final_sim(b_a, b_a) end = time.time() print(b_a+&quot; &quot;+b_b+&quot;ç›¸ä¼¼åº¦ä¸ºï¼š&quot;, hybrid) print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot;+str(end-start)) b_a = &quot;æ‰‹æœº&quot; b_b = &quot;ç”µè¯&quot; start = time.time() hybrid = HybridSim.get_Final_sim(b_a, b_a) end = time.time() print(b_a+&quot; &quot;+b_b+&quot;ç›¸ä¼¼åº¦ä¸ºï¼š&quot;, hybrid) print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot;+str(end-start)) 1234567è¯æ—è¯æ±‡é‡ 77498 çŸ¥ç½‘è¯æ±‡é‡ 53336ä¸¤è€…æ€»è¯æ±‡é‡ 85817 é‡å è¯æ±‡é‡ 45017å¯¹ä¸èµ·ï¼Œè¯è¯­å¯èƒ½æœªæ”¶å½•ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦ï¼è”ç³»æ–¹å¼ ç”µè¯ç›¸ä¼¼åº¦ä¸ºï¼š -1è¿è¡Œæ—¶é—´ï¼š3.504753112792969e-05æ‰‹æœº ç”µè¯ç›¸ä¼¼åº¦ä¸ºï¼š 1.0è¿è¡Œæ—¶é—´ï¼š0.019332408905029297 äºŒ.åŸºäºè¯å‘é‡åŸºäºæ ·æœ¬æ„å»ºï¼Œåˆ©äºç»´æŠ¤ 2.1 åŸºäºword2vec2.2.1 åŸç†word2vecçš„åŸç†å’Œè¯å‘é‡è·å–è¿‡ç¨‹ä¸åœ¨æ­¤èµ˜è¿°ï¼Œåœ¨æœ¬éƒ¨åˆ†ä¸»è¦è®²è§£åŸºäºword2vecçš„è¯å‘é‡å¦‚ä½•è®¡ç®—è¯è¯­ç›¸ä¼¼åº¦ã€‚æºç å¦‚ä¸‹ 1234567891011121314151617def similarity(self, w1, w2): &quot;&quot;&quot;Compute cosine similarity between two keys. Parameters ---------- w1 : str Input key. w2 : str Input key. Returns ------- float Cosine similarity between `w1` and `w2`. &quot;&quot;&quot; return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2])) 2.2.2 ä½¿ç”¨è®­ç»ƒ 1234567891011from gensim.models.word2vec import Word2Vecimport pandas as pdfrom gensim import modelsimport jieba###traindata=pd.read_csv(data_path)sentences=data.tolist()model= Word2Vec()model.build_vocab(sentences)model.train(sentences,total_examples = model.corpus_count,epochs = 5)model.save(model_path) ä½¿ç”¨ 12345678910111213141516171819from gensim import modelsimport timeif __name__ == '__main__': model=models.Word2Vec.load(model_path) start = time.time() b_a = &quot;è”ç³»æ–¹å¼&quot; b_b = &quot;ç”µè¯&quot; sim_b = model.wv.n_similarity(b_a, b_b) end = time.time() start = time.time() print(b_a, b_b, 'ç›¸ä¼¼åº¦ä¸º', sim_b) print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot; + str(end - start)) b_a = &quot;æ‰‹æœº&quot; b_b = &quot;ç”µè¯&quot; sim_b = model.wv.n_similarity(b_a, b_b) end = time.time() print(b_a, b_b, 'ç›¸ä¼¼åº¦ä¸º', sim_b) print(&quot;è¿è¡Œæ—¶é—´ï¼š&quot; + str(end - start)) 1234è”ç³»æ–¹å¼ ç”µè¯ ç›¸ä¼¼åº¦ä¸º -0.014857853è¿è¡Œæ—¶é—´ï¼š-4.76837158203125e-07æ‰‹æœº ç”µè¯ ç›¸ä¼¼åº¦ä¸º 0.1771852è¿è¡Œæ—¶é—´ï¼š0.0004227161407470703 å‚è€ƒæ–‡çŒ®https://blog.csdn.net/sinat_33741547/article/details/80016713 https://github.com/yaleimeng/Final_word_Similarity","link":"/2021/07/21/word-similarity/"},{"title":"word2vec","text":"ä¸€.åŸç†ä¸¤ç§è®­ç»ƒæ¨¡å‹ å¦‚æœæ˜¯ç”¨ä¸€ä¸ªè¯è¯­ä½œä¸ºè¾“å…¥ï¼Œæ¥é¢„æµ‹å®ƒå‘¨å›´çš„ä¸Šä¸‹æ–‡ï¼Œé‚£è¿™ä¸ªæ¨¡å‹å«åšã€Skip-gram æ¨¡å‹ã€ è€Œå¦‚æœæ˜¯æ‹¿ä¸€ä¸ªè¯è¯­çš„ä¸Šä¸‹æ–‡ä½œä¸ºè¾“å…¥ï¼Œæ¥é¢„æµ‹è¿™ä¸ªè¯è¯­æœ¬èº«ï¼Œåˆ™æ˜¯ ã€CBOW æ¨¡å‹ã€ è®­ç»ƒæŠ€å·§ hierarchical softmax å’Œ negative sampling äºŒ.ä»£ç è®­ç»ƒä»£ç  12345678910111213from gensim.models.word2vec import Word2Vecimport pandas as pdfrom gensim import modelsimport jieba###traindata=pd.read_csv(data_path)sentences=data.tolist()model= Word2Vec()model.build_vocab(sentences)model.train(sentences,total_examples = model.corpus_count,epochs = 5)model.save(model_path) è¯å‘é‡çŸ©é˜µ 12345678from gensim import modelsif __name__ == '__main__': model=models.KeyedVectors.load_word2vec_format(model_path,binary=True) print(model.vectors) ##(779845, 400)) print(&quot;\\n&quot;) print(model.index_to_key) print(&quot;\\n&quot;) print(model[&quot;çš„&quot;]) 12345array([[-1.3980628e+00, -4.6281612e-01, 5.8368486e-01, ..., 5.3952241e-01, 4.4697687e-01, 1.3505782e+00], [ 4.9143720e-01, -1.4818899e-01, -2.8366420e-01, ..., 1.1110669e+00, 2.1992767e-01, 7.0457202e-01], [-8.5650706e-01, 8.2832746e-02, -8.4218192e-01, ..., 2.1654253e+00, 6.4846051e-01, -5.7714492e-01], ..., [ 7.5072781e-03, -1.3543828e-02, 2.3101490e-02, ..., 4.2363801e-03, -5.6749382e-03, 6.3404259e-03], [-2.6244391e-04, -3.0459568e-02, 5.9752418e-03, ..., 1.7844304e-02, -4.7109672e-04, 7.7916058e-03], [ 7.2062697e-04, -6.5988898e-03, 1.1346856e-02, ..., -3.7340564e-03, -1.8825980e-02, 2.7245486e-03]], dtype=float32)['ï¼Œ', 'çš„', 'ã€‚', 'ã€', 'ï¼', 'ï¼‘', 'åœ¨', 'â€', 'ï¼’', 'äº†', 'â€œ', 'å’Œ', 'æ˜¯', 'ï¼•', ...]array([ 4.9143720e-01, -1.4818899e-01, -2.8366420e-01, -3.6405793e-01, 1.0851435e-01, 4.9507666e-02, -7.1219063e-01, -5.4614645e-01, -1.3581418e+00, 3.0274218e-01, 6.1700332e-01, 3.5553512e-01, 1.6602433e+00, 7.5298291e-01, -1.4151905e-01, -2.1077128e-01, -2.6325354e-01, 1.6108564e+00, -4.6750236e-01, -1.6261842e+00, 1.3063166e-01, 8.0702168e-01, 4.0011466e-01, 1.2198541e+00, -6.2879241e-01, ... 2.1928079e-01, 7.1725255e-01, -2.3430648e-01, -1.2066336e+00, 9.7590965e-01, -1.5906478e-01, -3.5802779e-01, -3.8005975e-01, 1.9056025e-01, 1.1110669e+00, 2.1992767e-01, 7.0457202e-01], dtype=float32) å‚è€ƒhttps://zhuanlan.zhihu.com/p/26306795 https://arxiv.org/abs/1301.3781v3 https://arxiv.org/abs/1405.4053","link":"/2021/08/04/word2vec/"},{"title":"xgboost","text":"a scalable tree boosting system æ˜¯å¯¹gbdtçš„é«˜æ•ˆå®ç° åŸºå­¦ä¹ å™¨ï¼šXGBoostçš„å¯ä»¥ä½¿ç”¨cartå›å½’æ ‘ä½œä¸ºåŸºå­¦ä¹ å™¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨çº¿æ€§åˆ†ç±»å™¨ä½œä¸ºåŸºå­¦ä¹ å™¨ï¼›gbdtçš„åŸºå­¦ä¹ å™¨åªèƒ½æ˜¯cartå›å½’æ ‘ XGBoostç®—æ³•åŸç†å°ç»“ https://www.cnblogs.com/pinard/p/10979808.html XGBoostç±»åº“ä½¿ç”¨å°ç»“ https://www.cnblogs.com/pinard/p/11114748.html paperåŸæ–‡ https://arxiv.org/pdf/1603.02754.pdf","link":"/2021/10/11/xgboost/"},{"title":"XLNet Generalized Autoregressive Pretraining for Language Understanding","text":"1 ä¸»è¦æ”¹åŠ¨relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. (3) , XLNet integrates ideas from Transformer-XL exampleï¼š[New, York, is, a, city] . select the two tokens [New, York] as the prediction targets and maximize log p ï¼ˆNew York | is a cityï¼‰ In this case, BERT and XLNet respectively reduce to the following objectives: 2 ç°æœ‰PTMçš„é—®é¢˜1 AR language modeling å¯¹äºç»™å®šçš„å¥å­$\\textbf{x}=[x_1,â€¦,x_T]$ï¼ŒAR language modeling performs pretraining by maximizing the likelihood under the forward autoregressive factorization \\max \\limits_{\\theta} \\quad logp_{\\theta}(\\textbf{x})=\\sum_{t=1}^{T}logp_{\\theta}(x_t|\\textbf{x}_{","link":"/2021/08/27/xlnet/"},{"title":"youtubednn","text":"åŸæ–‡ï¼š https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45530.pdf å‡ ç¯‡ä¼˜ç§€åšå®¢ï¼š https://zhuanlan.zhihu.com/p/52169807 https://zhuanlan.zhihu.com/p/52504407 https://zhuanlan.zhihu.com/p/61827629 https://zhuanlan.zhihu.com/p/46247835 ä¸‹æ–‡ä¸ºæœ¬äººæ€»ç»“ã€‚ 2.SYSTEM OVERVIEW 3.CANDIDATE GENERATION3.1 Recommendation as ClassificationæŠŠæ¨èé—®é¢˜è½¬æ¢æˆå¤šåˆ†ç±»é—®é¢˜ where $u \\in \\mathbb{R}^{N}$ represents a high-dimensional embeddingâ€of the user, context pair and the $ v_j \\in \\mathbb{R}^{N}$ represent embeddings of each candidate video. trainï¼š to efficiently train such a model with millions of classes 1.hierarchical softmaxï¼Œæ•ˆæœä¸ä½³ 2.é‡‡ç”¨candidate samplingï¼Œcorrect for this sampling via importance weighting At serving time 3.2 CANDIDATE GENERATION 3.3 Heterogeneous Signals3.4 Label and Context Selection 3.5 Experiments with Features and Depth 4.RANKING","link":"/2021/10/25/youtubednn/"},{"title":"ZooKeeper","text":"æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„ï¼Œå¼€æ”¾æºç çš„åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºåè°ƒæœåŠ¡ï¼Œæ˜¯Googleçš„Chubbyä¸€ä¸ªå¼€æºçš„å®ç°ï¼Œæ˜¯Hadoopå’ŒHbaseçš„é‡è¦ç»„ä»¶ã€‚å®ƒæ˜¯ä¸€ä¸ªä¸ºåˆ†å¸ƒå¼åº”ç”¨æä¾›ä¸€è‡´æ€§æœåŠ¡çš„è½¯ä»¶ï¼Œæä¾›çš„åŠŸèƒ½åŒ…æ‹¬ï¼šé…ç½®ç»´æŠ¤ã€åŸŸåæœåŠ¡ã€åˆ†å¸ƒå¼åŒæ­¥ã€ç»„æœåŠ¡ç­‰ã€‚ ç®€å•æ“ä½œ1 æŸ¥çœ‹çŠ¶æ€ bin/zkServer.sh status æœ‰leader follower shellè„šæœ¬ç¼–å†™ï¼šstartï¼Œstopï¼Œstatus é—®é¢˜1 æŸä¸ªèŠ‚ç‚¹èµ·ä¸æ¥ https://blog.csdn.net/qq_48268603/article/details/117687875 https://blog.csdn.net/u012453843/article/details/70878117 å‚è€ƒhttps://geek-docs.com/zookeeper/zookeeper-tutorial/zookeeper-profile.html#","link":"/2022/01/30/zookeeper/"}],"tags":[{"name":"äºŒåˆ†ç±»","slug":"äºŒåˆ†ç±»","link":"/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/"},{"name":"å³å¸­æŸ¥è¯¢","slug":"å³å¸­æŸ¥è¯¢","link":"/tags/%E5%8D%B3%E5%B8%AD%E6%9F%A5%E8%AF%A2/"},{"name":"Atlas","slug":"Atlas","link":"/tags/Atlas/"},{"name":"Azkaban","slug":"Azkaban","link":"/tags/Azkaban/"},{"name":"å†·å¯åŠ¨","slug":"å†·å¯åŠ¨","link":"/tags/%E5%86%B7%E5%90%AF%E5%8A%A8/"},{"name":"DGL","slug":"DGL","link":"/tags/DGL/"},{"name":"Wide&amp;Deepå’ŒDeepFM","slug":"Wide-Deepå’ŒDeepFM","link":"/tags/Wide-Deep%E5%92%8CDeepFM/"},{"name":"FM","slug":"FM","link":"/tags/FM/"},{"name":"GCN","slug":"GCN","link":"/tags/GCN/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"GNNæ ¸å¿ƒæ„æˆ","slug":"GNNæ ¸å¿ƒæ„æˆ","link":"/tags/GNN%E6%A0%B8%E5%BF%83%E6%9E%84%E6%88%90/"},{"name":"Kerberos","slug":"Kerberos","link":"/tags/Kerberos/"},{"name":"Kylin","slug":"Kylin","link":"/tags/Kylin/"},{"name":"L2R","slug":"L2R","link":"/tags/L2R/"},{"name":"æå¤§ä¼¼ç„¶ä¼°è®¡","slug":"æå¤§ä¼¼ç„¶ä¼°è®¡","link":"/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"name":"å¤šè·¯å¬å›","slug":"å¤šè·¯å¬å›","link":"/tags/%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E/"},{"name":"NER","slug":"NER","link":"/tags/NER/"},{"name":"Negative Sampling è´Ÿé‡‡æ ·","slug":"Negative-Sampling-è´Ÿé‡‡æ ·","link":"/tags/Negative-Sampling-%E8%B4%9F%E9%87%87%E6%A0%B7/"},{"name":"NLPå­ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡","slug":"NLPå­ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡","link":"/tags/NLP%E5%AD%90%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"name":"å½’ä¸€åŒ–","slug":"å½’ä¸€åŒ–","link":"/tags/%E5%BD%92%E4%B8%80%E5%8C%96/"},{"name":"Presto","slug":"Presto","link":"/tags/Presto/"},{"name":"Prompt","slug":"Prompt","link":"/tags/Prompt/"},{"name":"PTM","slug":"PTM","link":"/tags/PTM/"},{"name":"Zabbix","slug":"Zabbix","link":"/tags/Zabbix/"},{"name":"å¯¹æ¯”å­¦ä¹ åœ¨NLPåº”ç”¨","slug":"å¯¹æ¯”å­¦ä¹ åœ¨NLPåº”ç”¨","link":"/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E5%9C%A8NLP%E5%BA%94%E7%94%A8/"},{"name":"æ¿€æ´»å‡½æ•°","slug":"æ¿€æ´»å‡½æ•°","link":"/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"name":"ad hocå’Œrouting","slug":"ad-hocå’Œrouting","link":"/tags/ad-hoc%E5%92%8Crouting/"},{"name":"lossä¸ä¸‹é™çš„è§£å†³æ–¹æ³•","slug":"lossä¸ä¸‹é™çš„è§£å†³æ–¹æ³•","link":"/tags/loss%E4%B8%8D%E4%B8%8B%E9%99%8D%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"name":"è°ƒå‚","slug":"è°ƒå‚","link":"/tags/%E8%B0%83%E5%8F%82/"},{"name":"answer select","slug":"answer-select","link":"/tags/answer-select/"},{"name":"itçš„æŠ€æœ¯åœºæ™¯","slug":"itçš„æŠ€æœ¯åœºæ™¯","link":"/tags/it%E7%9A%84%E6%8A%80%E6%9C%AF%E5%9C%BA%E6%99%AF/"},{"name":"attention","slug":"attention","link":"/tags/attention/"},{"name":"AutoTokenizer","slug":"AutoTokenizer","link":"/tags/AutoTokenizer/"},{"name":"auxiliary loss(è¾…åŠ©æŸå¤±ï¼‰","slug":"auxiliary-loss-è¾…åŠ©æŸå¤±ï¼‰","link":"/tags/auxiliary-loss-%E8%BE%85%E5%8A%A9%E6%8D%9F%E5%A4%B1%EF%BC%89/"},{"name":"basic algorithm","slug":"basic-algorithm","link":"/tags/basic-algorithm/"},{"name":"Bertæ–‡æœ¬è¡¨ç¤º","slug":"Bertæ–‡æœ¬è¡¨ç¤º","link":"/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"},{"name":"åˆ†ç±»å›å½’æ¨¡å‹æ€»ç»“","slug":"åˆ†ç±»å›å½’æ¨¡å‹æ€»ç»“","link":"/tags/%E5%88%86%E7%B1%BB%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93/"},{"name":"bert_serving","slug":"bert-serving","link":"/tags/bert-serving/"},{"name":"BertGCN","slug":"BertGCN","link":"/tags/BertGCN/"},{"name":"bertviz:attentionå¯è§†åŒ–å·¥å…·","slug":"bertviz-attentionå¯è§†åŒ–å·¥å…·","link":"/tags/bertviz-attention%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/"},{"name":"å¤§æ•°æ®ç»„ä»¶","slug":"å¤§æ•°æ®ç»„ä»¶","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6/"},{"name":"å¤§æ•°æ®","slug":"å¤§æ•°æ®","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"bm25","slug":"bm25","link":"/tags/bm25/"},{"name":"GB, GBDT, XGBoost, LightGBM","slug":"GB-GBDT-XGBoost-LightGBM","link":"/tags/GB-GBDT-XGBoost-LightGBM/"},{"name":"bpç®—æ³•","slug":"bpç®—æ³•","link":"/tags/bp%E7%AE%97%E6%B3%95/"},{"name":"ç¦»çº¿æ•°ä»“æ­å»ºä¾‹å­","slug":"ç¦»çº¿æ•°ä»“æ­å»ºä¾‹å­","link":"/tags/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%90%AD%E5%BB%BA%E4%BE%8B%E5%AD%90/"},{"name":"CDCï¼ˆChange Data Captureï¼‰å·¥å…·å¯¹æ¯”","slug":"CDCï¼ˆChange-Data-Captureï¼‰å·¥å…·å¯¹æ¯”","link":"/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"},{"name":"å¬å›","slug":"å¬å›","link":"/tags/%E5%8F%AC%E5%9B%9E/"},{"name":"chatbot","slug":"chatbot","link":"/tags/chatbot/"},{"name":"checkpoints_iterator","slug":"checkpoints-iterator","link":"/tags/checkpoints-iterator/"},{"name":"ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information","slug":"ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information","link":"/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"},{"name":"åˆ†ç±»ä»»åŠ¡çš„è¡¡é‡æŒ‡æ ‡","slug":"åˆ†ç±»ä»»åŠ¡çš„è¡¡é‡æŒ‡æ ‡","link":"/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87/"},{"name":"clickhouse","slug":"clickhouse","link":"/tags/clickhouse/"},{"name":"é—­åŒ…","slug":"é—­åŒ…","link":"/tags/%E9%97%AD%E5%8C%85/"},{"name":"sparkéƒ¨ç½²æ–¹å¼","slug":"sparkéƒ¨ç½²æ–¹å¼","link":"/tags/spark%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F/"},{"name":"Google colab","slug":"Google-colab","link":"/tags/Google-colab/"},{"name":"è¡¨å­—æ®µçš„æ•°æ®ç±»å‹","slug":"è¡¨å­—æ®µçš„æ•°æ®ç±»å‹","link":"/tags/%E8%A1%A8%E5%AD%97%E6%AE%B5%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"æ–‡æœ¬è¡¨ç¤º","slug":"æ–‡æœ¬è¡¨ç¤º","link":"/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"},{"name":"ä½¿ç”¨DGLæ„é€ å›¾","slug":"ä½¿ç”¨DGLæ„é€ å›¾","link":"/tags/%E4%BD%BF%E7%94%A8DGL%E6%9E%84%E9%80%A0%E5%9B%BE/"},{"name":"SparkSessionã€SparkContextã€HiveContextã€SQLContext","slug":"SparkSessionã€SparkContextã€HiveContextã€SQLContext","link":"/tags/SparkSession%E3%80%81SparkContext%E3%80%81HiveContext%E3%80%81SQLContext/"},{"name":"convtrans","slug":"convtrans","link":"/tags/convtrans/"},{"name":"CRFå’ŒHMM","slug":"CRFå’ŒHMM","link":"/tags/CRF%E5%92%8CHMM/"},{"name":"å¸¸è§é—®é¢˜","slug":"å¸¸è§é—®é¢˜","link":"/tags/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"DMR","slug":"DMR","link":"/tags/DMR/"},{"name":"DAG","slug":"DAG","link":"/tags/DAG/"},{"name":"æ•°æ®é‡‡é›†","slug":"æ•°æ®é‡‡é›†","link":"/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"},{"name":"æ•°æ®å­—å…¸","slug":"æ•°æ®å­—å…¸","link":"/tags/%E6%95%B0%E6%8D%AE%E5%AD%97%E5%85%B8/"},{"name":"æ•°æ®é›†æˆ","slug":"æ•°æ®é›†æˆ","link":"/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90/"},{"name":"æ•°æ®ä¸å¹³è¡¡","slug":"æ•°æ®ä¸å¹³è¡¡","link":"/tags/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/"},{"name":"æ•°æ®è´¨é‡","slug":"æ•°æ®è´¨é‡","link":"/tags/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/"},{"name":"æ•°æ®å®‰å…¨","slug":"æ•°æ®å®‰å…¨","link":"/tags/%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/"},{"name":"æ•°æ®é›†åˆ’åˆ†","slug":"æ•°æ®é›†åˆ’åˆ†","link":"/tags/%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86/"},{"name":"æ•°æ®ç»“æ„æ±‡æ€»","slug":"æ•°æ®ç»“æ„æ±‡æ€»","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B1%87%E6%80%BB/"},{"name":"æ•°æ®åŒæ­¥","slug":"æ•°æ®åŒæ­¥","link":"/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"},{"name":"æ•°æ®ä»“åº“ä¹¦å•","slug":"æ•°æ®ä»“åº“ä¹¦å•","link":"/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B9%A6%E5%8D%95/"},{"name":"æ•°æ®åº“åˆ†ç±»","slug":"æ•°æ®åº“åˆ†ç±»","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/"},{"name":"æ•°æ®åº“å»ºæ¨¡","slug":"æ•°æ®åº“å»ºæ¨¡","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BB%BA%E6%A8%A1/"},{"name":"åˆ†åº“åˆ†è¡¨","slug":"åˆ†åº“åˆ†è¡¨","link":"/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"datastream","slug":"datastream","link":"/tags/datastream/"},{"name":"å¤§æ•°æ®å·¥å…·","slug":"å¤§æ•°æ®å·¥å…·","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B7%A5%E5%85%B7/"},{"name":"æ„å»ºæ•°æ®ä»“åº“","slug":"æ„å»ºæ•°æ®ä»“åº“","link":"/tags/%E6%9E%84%E5%BB%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"},{"name":"æ•°ä»“æ¶æ„","slug":"æ•°ä»“æ¶æ„","link":"/tags/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84/"},{"name":"æ•°ä»“ä¸»é¢˜å’Œä¸»é¢˜åŸŸ","slug":"æ•°ä»“ä¸»é¢˜å’Œä¸»é¢˜åŸŸ","link":"/tags/%E6%95%B0%E4%BB%93%E4%B8%BB%E9%A2%98%E5%92%8C%E4%B8%BB%E9%A2%98%E5%9F%9F/"},{"name":"æ»å","slug":"æ»å","link":"/tags/%E6%BB%9E%E5%90%8E/"},{"name":"å†³ç­–æ ‘vsé€»è¾‘å›å½’","slug":"å†³ç­–æ ‘vsé€»è¾‘å›å½’","link":"/tags/%E5%86%B3%E7%AD%96%E6%A0%91vs%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"å†³ç­–æ ‘","slug":"å†³ç­–æ ‘","link":"/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"è£…é¥°å™¨","slug":"è£…é¥°å™¨","link":"/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"name":"ç»´åº¦é€€åŒ–","slug":"ç»´åº¦é€€åŒ–","link":"/tags/%E7%BB%B4%E5%BA%A6%E9%80%80%E5%8C%96/"},{"name":"dfsï¼Œbfs","slug":"dfsï¼Œbfs","link":"/tags/dfs%EF%BC%8Cbfs/"},{"name":"DGL notice","slug":"DGL-notice","link":"/tags/DGL-notice/"},{"name":"listï¼Œdictï¼Œsetçš„æ—¶é—´å¤æ‚åº¦","slug":"listï¼Œdictï¼Œsetçš„æ—¶é—´å¤æ‚åº¦","link":"/tags/list%EF%BC%8Cdict%EF%BC%8Cset%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/"},{"name":"è¯è¡¨ç‰¹æ®Šè¯çš„å«ä¹‰","slug":"è¯è¡¨ç‰¹æ®Šè¯çš„å«ä¹‰","link":"/tags/%E8%AF%8D%E8%A1%A8%E7%89%B9%E6%AE%8A%E8%AF%8D%E7%9A%84%E5%90%AB%E4%B9%89/"},{"name":"DIEN","slug":"DIEN","link":"/tags/DIEN/"},{"name":"é™ç»´","slug":"é™ç»´","link":"/tags/%E9%99%8D%E7%BB%B4/"},{"name":"æ•°ä»“å»ºæ¨¡","slug":"æ•°ä»“å»ºæ¨¡","link":"/tags/%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1/"},{"name":"DIN","slug":"DIN","link":"/tags/DIN/"},{"name":"è·ç¦»&#x2F;ç›¸ä¼¼åº¦","slug":"è·ç¦»-ç›¸ä¼¼åº¦","link":"/tags/%E8%B7%9D%E7%A6%BB-%E7%9B%B8%E4%BC%BC%E5%BA%A6/"},{"name":"è¶…é•¿æ–‡æœ¬","slug":"è¶…é•¿æ–‡æœ¬","link":"/tags/%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC/"},{"name":"dockerå®¹å™¨ä¸è™šæ‹Ÿæœºæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ","slug":"dockerå®¹å™¨ä¸è™šæ‹Ÿæœºæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ","link":"/tags/docker%E5%AE%B9%E5%99%A8%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"},{"name":"DSSM","slug":"DSSM","link":"/tags/DSSM/"},{"name":"ç”µå•†ä¸šåŠ¡","slug":"ç”µå•†ä¸šåŠ¡","link":"/tags/%E7%94%B5%E5%95%86%E4%B8%9A%E5%8A%A1/"},{"name":"early stop","slug":"early-stop","link":"/tags/early-stop/"},{"name":"ELMo","slug":"ELMo","link":"/tags/ELMo/"},{"name":"Enhanced-RCNN","slug":"Enhanced-RCNN","link":"/tags/Enhanced-RCNN/"},{"name":"ç‰¹å¾å‘é‡åŒ–","slug":"ç‰¹å¾å‘é‡åŒ–","link":"/tags/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%8C%96/"},{"name":"entropy","slug":"entropy","link":"/tags/entropy/"},{"name":"é›†æˆå­¦ä¹ ","slug":"é›†æˆå­¦ä¹ ","link":"/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"ETL","slug":"ETL","link":"/tags/ETL/"},{"name":"åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°é‡å¾ˆå¤§","slug":"åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°é‡å¾ˆå¤§","link":"/tags/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E7%B1%BB%E5%88%AB%E6%95%B0%E9%87%8F%E5%BE%88%E5%A4%A7/"},{"name":"facebookæ¨èç³»ç»Ÿ","slug":"facebookæ¨èç³»ç»Ÿ","link":"/tags/facebook%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"æ–‡æœ¬åˆ†ç±»","slug":"æ–‡æœ¬åˆ†ç±»","link":"/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"},{"name":"å®¹é”™æœºåˆ¶","slug":"å®¹é”™æœºåˆ¶","link":"/tags/%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/"},{"name":"ç‰¹å¾å·¥ç¨‹","slug":"ç‰¹å¾å·¥ç¨‹","link":"/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"ç‰¹å¾æå–","slug":"ç‰¹å¾æå–","link":"/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"},{"name":"feature scale","slug":"feature-scale","link":"/tags/feature-scale/"},{"name":"æ–‡æœ¬æ”¹å†™","slug":"æ–‡æœ¬æ”¹å†™","link":"/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"},{"name":"å°æ ·æœ¬","slug":"å°æ ·æœ¬","link":"/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"å‰é¦ˆç¥ç»ç½‘ç»œ","slug":"å‰é¦ˆç¥ç»ç½‘ç»œ","link":"/tags/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"finetune","slug":"finetune","link":"/tags/finetune/"},{"name":"flask","slug":"flask","link":"/tags/flask/"},{"name":"flinkåˆ†å±‚api","slug":"flinkåˆ†å±‚api","link":"/tags/flink%E5%88%86%E5%B1%82api/"},{"name":"æµæ‰¹é€‰æ‹©","slug":"æµæ‰¹é€‰æ‹©","link":"/tags/%E6%B5%81%E6%89%B9%E9%80%89%E6%8B%A9/"},{"name":"flink cdc","slug":"flink-cdc","link":"/tags/flink-cdc/"},{"name":"flink cep","slug":"flink-cep","link":"/tags/flink-cep/"},{"name":"flinkéƒ¨ç½²","slug":"flinkéƒ¨ç½²","link":"/tags/flink%E9%83%A8%E7%BD%B2/"},{"name":"ç®—å­é“¾","slug":"ç®—å­é“¾","link":"/tags/%E7%AE%97%E5%AD%90%E9%93%BE/"},{"name":"flinkä¼˜åŒ–","slug":"flinkä¼˜åŒ–","link":"/tags/flink%E4%BC%98%E5%8C%96/"},{"name":"å¹¶è¡Œåº¦è®¾ç½®","slug":"å¹¶è¡Œåº¦è®¾ç½®","link":"/tags/%E5%B9%B6%E8%A1%8C%E5%BA%A6%E8%AE%BE%E7%BD%AE/"},{"name":"å¤„ç†å‡½æ•°(process funtion)","slug":"å¤„ç†å‡½æ•°-process-funtion","link":"/tags/%E5%A4%84%E7%90%86%E5%87%BD%E6%95%B0-process-funtion/"},{"name":"Flinkç¨‹åºæ„æˆéƒ¨åˆ†","slug":"Flinkç¨‹åºæ„æˆéƒ¨åˆ†","link":"/tags/Flink%E7%A8%8B%E5%BA%8F%E6%9E%84%E6%88%90%E9%83%A8%E5%88%86/"},{"name":"flink vs spark","slug":"flink-vs-spark","link":"/tags/flink-vs-spark/"},{"name":"Flinkæ¶æ„åŸç†","slug":"Flinkæ¶æ„åŸç†","link":"/tags/Flink%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/"},{"name":"çŠ¶æ€ç¼–ç¨‹","slug":"çŠ¶æ€ç¼–ç¨‹","link":"/tags/%E7%8A%B6%E6%80%81%E7%BC%96%E7%A8%8B/"},{"name":"Table APIå’ŒSQL","slug":"Table-APIå’ŒSQL","link":"/tags/Table-API%E5%92%8CSQL/"},{"name":"ä»»åŠ¡ç”Ÿæˆå’Œåˆ†é…","slug":"ä»»åŠ¡ç”Ÿæˆå’Œåˆ†é…","link":"/tags/%E4%BB%BB%E5%8A%A1%E7%94%9F%E6%88%90%E5%92%8C%E5%88%86%E9%85%8D/"},{"name":"ä»»åŠ¡æ§½ task slots","slug":"ä»»åŠ¡æ§½-task-slots","link":"/tags/%E4%BB%BB%E5%8A%A1%E6%A7%BD-task-slots/"},{"name":"flinkæäº¤ä»»åŠ¡","slug":"flinkæäº¤ä»»åŠ¡","link":"/tags/flink%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1/"},{"name":"flinkæ—¶é—´è¯­ä¹‰","slug":"flinkæ—¶é—´è¯­ä¹‰","link":"/tags/flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/"},{"name":"watermark(æ°´ä½çº¿)","slug":"watermark-æ°´ä½çº¿","link":"/tags/watermark-%E6%B0%B4%E4%BD%8D%E7%BA%BF/"},{"name":"flume","slug":"flume","link":"/tags/flume/"},{"name":"forward","slug":"forward","link":"/tags/forward/"},{"name":"GBDT","slug":"GBDT","link":"/tags/GBDT/"},{"name":"PyG,DGL","slug":"PyG-DGL","link":"/tags/PyG-DGL/"},{"name":"gradient_accumulate_stepsï¼Œè°ƒèŠ‚å­¦ä¹ ç‡","slug":"gradient-accumulate-stepsï¼Œè°ƒèŠ‚å­¦ä¹ ç‡","link":"/tags/gradient-accumulate-steps%EF%BC%8C%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87/"},{"name":"æ¢¯åº¦çˆ†ç‚¸ã€æ¢¯åº¦æ¶ˆå¤±","slug":"æ¢¯åº¦çˆ†ç‚¸ã€æ¢¯åº¦æ¶ˆå¤±","link":"/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/"},{"name":"gradient boosting","slug":"gradient-boosting","link":"/tags/gradient-boosting/"},{"name":"GNNç»¼è¿°","slug":"GNNç»¼è¿°","link":"/tags/GNN%E7%BB%BC%E8%BF%B0/"},{"name":"Graphå’ŒSession","slug":"Graphå’ŒSession","link":"/tags/Graph%E5%92%8CSession/"},{"name":"hadoopæ¶æ„","slug":"hadoopæ¶æ„","link":"/tags/hadoop%E6%9E%B6%E6%9E%84/"},{"name":"Hadoopéƒ¨ç½²æ–¹å¼","slug":"Hadoopéƒ¨ç½²æ–¹å¼","link":"/tags/Hadoop%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F/"},{"name":"hadoopå®‰å…¨æ¨¡å¼","slug":"hadoopå®‰å…¨æ¨¡å¼","link":"/tags/hadoop%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F/"},{"name":"Hadoop in Secure Mode","slug":"Hadoop-in-Secure-Mode","link":"/tags/Hadoop-in-Secure-Mode/"},{"name":"hadoop trick","slug":"hadoop-trick","link":"/tags/hadoop-trick/"},{"name":"å“ˆå¸Œè¡¨","slug":"å“ˆå¸Œè¡¨","link":"/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"HBase","slug":"HBase","link":"/tags/HBase/"},{"name":"hcan(Hybrid Co-Attention Network)","slug":"hcan-Hybrid-Co-Attention-Network","link":"/tags/hcan-Hybrid-Co-Attention-Network/"},{"name":"å †ï¼Œä¼˜å…ˆé˜Ÿåˆ—","slug":"å †ï¼Œä¼˜å…ˆé˜Ÿåˆ—","link":"/tags/%E5%A0%86%EF%BC%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"},{"name":"hiveæ•°æ®å¯¼å…¥å¯¼å‡º","slug":"hiveæ•°æ®å¯¼å…¥å¯¼å‡º","link":"/tags/hive%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"hiveæ¶æ„","slug":"hiveæ¶æ„","link":"/tags/hive%E6%9E%B6%E6%9E%84/"},{"name":"Hive MetaStore","slug":"Hive-MetaStore","link":"/tags/Hive-MetaStore/"},{"name":"Hiveä¸ä¼ ç»Ÿæ•°æ®åº“å¯¹æ¯”","slug":"Hiveä¸ä¼ ç»Ÿæ•°æ®åº“å¯¹æ¯”","link":"/tags/Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/"},{"name":"hiveä¼˜åŒ–","slug":"hiveä¼˜åŒ–","link":"/tags/hive%E4%BC%98%E5%8C%96/"},{"name":"hive","slug":"hive","link":"/tags/hive/"},{"name":"hqlå»ºè¡¨","slug":"hqlå»ºè¡¨","link":"/tags/hql%E5%BB%BA%E8%A1%A8/"},{"name":"hqlå¸¸è§æ“ä½œ","slug":"hqlå¸¸è§æ“ä½œ","link":"/tags/hql%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"},{"name":"hqlå¢åˆ æ”¹æŸ¥","slug":"hqlå¢åˆ æ”¹æŸ¥","link":"/tags/hql%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"name":"hqlå‡½æ•°","slug":"hqlå‡½æ•°","link":"/tags/hql%E5%87%BD%E6%95%B0/"},{"name":"sql,hqlåŒºåˆ«","slug":"sql-hqlåŒºåˆ«","link":"/tags/sql-hql%E5%8C%BA%E5%88%AB/"},{"name":"hqlåŠ è½½æ•°æ®","slug":"hqlåŠ è½½æ•°æ®","link":"/tags/hql%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/"},{"name":"huggingface","slug":"huggingface","link":"/tags/huggingface/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"å…‹éš†è™šæ‹Ÿæœºä¿®æ”¹é™æ€IPä¸æˆåŠŸè§£å†³åŠæ³•","slug":"å…‹éš†è™šæ‹Ÿæœºä¿®æ”¹é™æ€IPä¸æˆåŠŸè§£å†³åŠæ³•","link":"/tags/%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BF%AE%E6%94%B9%E9%9D%99%E6%80%81IP%E4%B8%8D%E6%88%90%E5%8A%9F%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"name":"å€’æ’ç´¢å¼•","slug":"å€’æ’ç´¢å¼•","link":"/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"},{"name":"ä¿¡æ¯æŠ½å– Information Extraction","slug":"ä¿¡æ¯æŠ½å–-Information-Extraction","link":"/tags/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-Information-Extraction/"},{"name":"Informer","slug":"Informer","link":"/tags/Informer/"},{"name":"æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……","slug":"æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……","link":"/tags/%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB%E5%92%8C%E6%A7%BD%E4%BD%8D%E5%A1%AB%E5%85%85/"},{"name":"æ„å›¾è¯†åˆ«","slug":"æ„å›¾è¯†åˆ«","link":"/tags/%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/"},{"name":"javaåº”ç”¨åœºæ™¯","slug":"javaåº”ç”¨åœºæ™¯","link":"/tags/java%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"},{"name":"javaæ¡†æ¶","slug":"javaæ¡†æ¶","link":"/tags/java%E6%A1%86%E6%9E%B6/"},{"name":"å¤šçº¿ç¨‹ç¼–ç¨‹","slug":"å¤šçº¿ç¨‹ç¼–ç¨‹","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"},{"name":"ç½‘ç»œç¼–ç¨‹","slug":"ç½‘ç»œç¼–ç¨‹","link":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"javaå¸¸è§é—®é¢˜","slug":"javaå¸¸è§é—®é¢˜","link":"/tags/java%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"javaå­¦ä¹ ç½‘ç«™","slug":"javaå­¦ä¹ ç½‘ç«™","link":"/tags/java%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"},{"name":"jdbc","slug":"jdbc","link":"/tags/jdbc/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"jupyter notebook","slug":"jupyter-notebook","link":"/tags/jupyter-notebook/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"k-fold","slug":"k-fold","link":"/tags/k-fold/"},{"name":"kafkaå¸¸è§è®¡ç®—","slug":"kafkaå¸¸è§è®¡ç®—","link":"/tags/kafka%E5%B8%B8%E8%A7%81%E8%AE%A1%E7%AE%97/"},{"name":"kafkaå¸¸è§é—®é¢˜","slug":"kafkaå¸¸è§é—®é¢˜","link":"/tags/kafka%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"kafkaå¸¸è§å‘½ä»¤","slug":"kafkaå¸¸è§å‘½ä»¤","link":"/tags/kafka%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/"},{"name":"kafkaä¸Zookeeperçš„å…³ç³»","slug":"kafkaä¸Zookeeperçš„å…³ç³»","link":"/tags/kafka%E4%B8%8EZookeeper%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"name":"KafkaåŸç†ç»“æ„","slug":"KafkaåŸç†ç»“æ„","link":"/tags/Kafka%E5%8E%9F%E7%90%86%E7%BB%93%E6%9E%84/"},{"name":"ä¸»å¤–é”®","slug":"ä¸»å¤–é”®","link":"/tags/%E4%B8%BB%E5%A4%96%E9%94%AE/"},{"name":"key&#x2F;value","slug":"key-value","link":"/tags/key-value/"},{"name":"KG-BERT","slug":"KG-BERT","link":"/tags/KG-BERT/"},{"name":"KNN","slug":"KNN","link":"/tags/KNN/"},{"name":"çŸ¥è¯†å›¾è°±ç»¼è¿°","slug":"çŸ¥è¯†å›¾è°±ç»¼è¿°","link":"/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%BC%E8%BF%B0/"},{"name":"LambdaMART","slug":"LambdaMART","link":"/tags/LambdaMART/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"åˆ·é¢˜æŒ‡å—","slug":"åˆ·é¢˜æŒ‡å—","link":"/tags/%E5%88%B7%E9%A2%98%E6%8C%87%E5%8D%97/"},{"name":"å¸¸è§é¢˜ç›®","slug":"å¸¸è§é¢˜ç›®","link":"/tags/%E5%B8%B8%E8%A7%81%E9%A2%98%E7%9B%AE/"},{"name":"lightgbm","slug":"lightgbm","link":"/tags/lightgbm/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"å¸¸è§æ“ä½œ","slug":"å¸¸è§æ“ä½œ","link":"/tags/%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"listwise","slug":"listwise","link":"/tags/listwise/"},{"name":"listnet","slug":"listnet","link":"/tags/listnet/"},{"name":"æŸå¤±å‡½æ•°","slug":"æŸå¤±å‡½æ•°","link":"/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"name":"é€»è¾‘å›å½’","slug":"é€»è¾‘å›å½’","link":"/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"è¶…é•¿æ–‡æœ¬å¤„ç†","slug":"è¶…é•¿æ–‡æœ¬å¤„ç†","link":"/tags/%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/"},{"name":"è°ƒèŠ‚å­¦ä¹ ç‡","slug":"è°ƒèŠ‚å­¦ä¹ ç‡","link":"/tags/%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87/"},{"name":"æ¶ˆæ¯ä¼ é€’","slug":"æ¶ˆæ¯ä¼ é€’","link":"/tags/%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92/"},{"name":"Spark vs MapReduce","slug":"Spark-vs-MapReduce","link":"/tags/Spark-vs-MapReduce/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"æ’åºå­¦ä¹ ","slug":"æ’åºå­¦ä¹ ","link":"/tags/%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0/"},{"name":"å…ƒæ•°æ®ç®¡ç†","slug":"å…ƒæ•°æ®ç®¡ç†","link":"/tags/%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"},{"name":"ç»†ç²’åº¦NLPä»»åŠ¡","slug":"ç»†ç²’åº¦NLPä»»åŠ¡","link":"/tags/%E7%BB%86%E7%B2%92%E5%BA%A6NLP%E4%BB%BB%E5%8A%A1/"},{"name":"è¿­ä»£åˆ†æ","slug":"è¿­ä»£åˆ†æ","link":"/tags/%E8%BF%AD%E4%BB%A3%E5%88%86%E6%9E%90/"},{"name":"æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²","slug":"æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/"},{"name":"é›†ç¾¤ç›‘æ§","slug":"é›†ç¾¤ç›‘æ§","link":"/tags/%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/"},{"name":"å•è°ƒæ ˆ","slug":"å•è°ƒæ ˆ","link":"/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"},{"name":"å¤šæ ‡ç­¾","slug":"å¤šæ ‡ç­¾","link":"/tags/%E5%A4%9A%E6%A0%87%E7%AD%BE/"},{"name":"å¤šæµè½¬æ¢","slug":"å¤šæµè½¬æ¢","link":"/tags/%E5%A4%9A%E6%B5%81%E8%BD%AC%E6%8D%A2/"},{"name":"å¤šä»»åŠ¡å­¦ä¹ ","slug":"å¤šä»»åŠ¡å­¦ä¹ ","link":"/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"æœ´ç´ è´å¶æ–¯","slug":"æœ´ç´ è´å¶æ–¯","link":"/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"ipå’Œç«¯å£","slug":"ipå’Œç«¯å£","link":"/tags/ip%E5%92%8C%E7%AB%AF%E5%8F%A3/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"ä¸­æ–‡æ•°æ®å¢å¼º","slug":"ä¸­æ–‡æ•°æ®å¢å¼º","link":"/tags/%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"},{"name":"nlpæ•™æ","slug":"nlpæ•™æ","link":"/tags/nlp%E6%95%99%E6%9D%90/"},{"name":"ç®—æ³•å¯¼è®º","slug":"ç®—æ³•å¯¼è®º","link":"/tags/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"},{"name":"nvidia-smi æŸ¥çœ‹GPUä½¿ç”¨ç‡å¾ˆé«˜ä½†æ˜¯çœ‹ä¸åˆ°è¿›ç¨‹","slug":"nvidia-smi-æŸ¥çœ‹GPUä½¿ç”¨ç‡å¾ˆé«˜ä½†æ˜¯çœ‹ä¸åˆ°è¿›ç¨‹","link":"/tags/nvidia-smi-%E6%9F%A5%E7%9C%8BGPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%BE%88%E9%AB%98%E4%BD%86%E6%98%AF%E7%9C%8B%E4%B8%8D%E5%88%B0%E8%BF%9B%E7%A8%8B/"},{"name":"OLAPå’ŒOLTPçš„åŒºåˆ«","slug":"OLAPå’ŒOLTPçš„åŒºåˆ«","link":"/tags/OLAP%E5%92%8COLTP%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"name":"ä»£ä»·å‡½æ•°ï¼ŒæŸå¤±å‡½æ•°ï¼Œç›®æ ‡å‡½æ•°åŒºåˆ«","slug":"ä»£ä»·å‡½æ•°ï¼ŒæŸå¤±å‡½æ•°ï¼Œç›®æ ‡å‡½æ•°åŒºåˆ«","link":"/tags/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E5%8C%BA%E5%88%AB/"},{"name":"oovæ€ä¹ˆè§£å†³","slug":"oovæ€ä¹ˆè§£å†³","link":"/tags/oov%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3/"},{"name":"open set recognization","slug":"open-set-recognization","link":"/tags/open-set-recognization/"},{"name":"ä¼˜åŒ–ç®—æ³•","slug":"ä¼˜åŒ–ç®—æ³•","link":"/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"},{"name":"è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆ","slug":"è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆ","link":"/tags/%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88/"},{"name":"pairwise","slug":"pairwise","link":"/tags/pairwise/"},{"name":"æ„ŸçŸ¥æœº","slug":"æ„ŸçŸ¥æœº","link":"/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"name":"æŒä¹…åŒ–","slug":"æŒä¹…åŒ–","link":"/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"ç‰©ç†åˆ†åŒº","slug":"ç‰©ç†åˆ†åŒº","link":"/tags/%E7%89%A9%E7%90%86%E5%88%86%E5%8C%BA/"},{"name":"phoenix","slug":"phoenix","link":"/tags/phoenix/"},{"name":"pointwise vs pairwise","slug":"pointwise-vs-pairwise","link":"/tags/pointwise-vs-pairwise/"},{"name":"pom","slug":"pom","link":"/tags/pom/"},{"name":"pointwise","slug":"pointwise","link":"/tags/pointwise/"},{"name":"postman","slug":"postman","link":"/tags/postman/"},{"name":"é¢„è®­ç»ƒä»»åŠ¡","slug":"é¢„è®­ç»ƒä»»åŠ¡","link":"/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1/"},{"name":"ç²—æ’","slug":"ç²—æ’","link":"/tags/%E7%B2%97%E6%8E%92/"},{"name":"pretrain","slug":"pretrain","link":"/tags/pretrain/"},{"name":"Prompt-learningå°å¸®æ‰‹-openprompt","slug":"Prompt-learningå°å¸®æ‰‹-openprompt","link":"/tags/Prompt-learning%E5%B0%8F%E5%B8%AE%E6%89%8B-openprompt/"},{"name":"æ¦‚ç‡ç»Ÿè®¡","slug":"æ¦‚ç‡ç»Ÿè®¡","link":"/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"},{"name":"prompt trick","slug":"prompt-trick","link":"/tags/prompt-trick/"},{"name":"ptmä¹‹é—´çš„è”ç³»","slug":"ptmä¹‹é—´çš„è”ç³»","link":"/tags/ptm%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB/"},{"name":"pysparkä¾èµ–","slug":"pysparkä¾èµ–","link":"/tags/pyspark%E4%BE%9D%E8%B5%96/"},{"name":"pyspark","slug":"pyspark","link":"/tags/pyspark/"},{"name":"python bif","slug":"python-bif","link":"/tags/python-bif/"},{"name":"è¿ç®—","slug":"è¿ç®—","link":"/tags/%E8%BF%90%E7%AE%97/"},{"name":"pythonä¸å¯å˜å¯¹è±¡å’Œå¯å˜å¯¹è±¡","slug":"pythonä¸å¯å˜å¯¹è±¡å’Œå¯å˜å¯¹è±¡","link":"/tags/python%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1/"},{"name":"collections","slug":"collections","link":"/tags/collections/"},{"name":"pythonç¯å¢ƒ","slug":"pythonç¯å¢ƒ","link":"/tags/python%E7%8E%AF%E5%A2%83/"},{"name":"å¯è¿­ä»£å¯¹è±¡ã€è¿­ä»£å™¨ä¸ç”Ÿæˆå™¨","slug":"å¯è¿­ä»£å¯¹è±¡ã€è¿­ä»£å™¨ä¸ç”Ÿæˆå™¨","link":"/tags/%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8/"},{"name":"å‡½æ•°å‚æ•°","slug":"å‡½æ•°å‚æ•°","link":"/tags/%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0/"},{"name":"æ­£åˆ™","slug":"æ­£åˆ™","link":"/tags/%E6%AD%A3%E5%88%99/"},{"name":"pythonåœ¨Ubuntuç³»ç»Ÿä¸‹çš„è°ƒè¯•å·¥å…·pdb","slug":"pythonåœ¨Ubuntuç³»ç»Ÿä¸‹çš„è°ƒè¯•å·¥å…·pdb","link":"/tags/python%E5%9C%A8Ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7pdb/"},{"name":"ç¼–ç¨‹è§„èŒƒ","slug":"ç¼–ç¨‹è§„èŒƒ","link":"/tags/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83/"},{"name":"python ide","slug":"python-ide","link":"/tags/python-ide/"},{"name":"å­—ç¬¦ä¸²","slug":"å­—ç¬¦ä¸²","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"é­”æ³•æ–¹æ³•","slug":"é­”æ³•æ–¹æ³•","link":"/tags/%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95/"},{"name":"ç»§æ‰¿","slug":"ç»§æ‰¿","link":"/tags/%E7%BB%A7%E6%89%BF/"},{"name":"pytorchå¸¸è§é—®é¢˜","slug":"pytorchå¸¸è§é—®é¢˜","link":"/tags/pytorch%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"name":"queryç†è§£","slug":"queryç†è§£","link":"/tags/query%E7%90%86%E8%A7%A3/"},{"name":"Ranger","slug":"Ranger","link":"/tags/Ranger/"},{"name":"ranking survey","slug":"ranking-survey","link":"/tags/ranking-survey/"},{"name":"ranknetå¯¹æ¯”listnet","slug":"ranknetå¯¹æ¯”listnet","link":"/tags/ranknet%E5%AF%B9%E6%AF%94listnet/"},{"name":"å®æ—¶æ•°ä»“æ¡ˆä¾‹ï¼ˆç”µå•†ï¼‰","slug":"å®æ—¶æ•°ä»“æ¡ˆä¾‹ï¼ˆç”µå•†ï¼‰","link":"/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%A1%88%E4%BE%8B%EF%BC%88%E7%94%B5%E5%95%86%EF%BC%89/"},{"name":"å®æ—¶æ•°ä»“åˆ†å±‚","slug":"å®æ—¶æ•°ä»“åˆ†å±‚","link":"/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82/"},{"name":"æ¨èç³»ç»Ÿè¯„ä»·æŒ‡æ ‡","slug":"æ¨èç³»ç»Ÿè¯„ä»·æŒ‡æ ‡","link":"/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"name":"æ¨èç³»ç»Ÿ","slug":"æ¨èç³»ç»Ÿ","link":"/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"é€’å½’,è¿­ä»£","slug":"é€’å½’-è¿­ä»£","link":"/tags/%E9%80%92%E5%BD%92-%E8%BF%AD%E4%BB%A3/"},{"name":"é€’å½’","slug":"é€’å½’","link":"/tags/%E9%80%92%E5%BD%92/"},{"name":"Use reduceByKey instead of groupByKey","slug":"Use-reduceByKey-instead-of-groupByKey","link":"/tags/Use-reduceByKey-instead-of-groupByKey/"},{"name":"æ­£åˆ™åŒ–","slug":"æ­£åˆ™åŒ–","link":"/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"},{"name":"å®ä½“å…³ç³»æŠ½å–","slug":"å®ä½“å…³ç³»æŠ½å–","link":"/tags/%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"æœç´¢ç³»ç»Ÿ","slug":"æœç´¢ç³»ç»Ÿ","link":"/tags/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/"},{"name":"IaaSã€PaaSå’ŒSaaS","slug":"IaaSã€PaaSå’ŒSaaS","link":"/tags/IaaS%E3%80%81PaaS%E5%92%8CSaaS/"},{"name":"seq2seq","slug":"seq2seq","link":"/tags/seq2seq/"},{"name":"åºåˆ—æ ‡æ³¨","slug":"åºåˆ—æ ‡æ³¨","link":"/tags/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/"},{"name":"æ–‡æœ¬åŒ¹é…","slug":"æ–‡æœ¬åŒ¹é…","link":"/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"},{"name":"shellå‘½ä»¤æ‰§è¡Œhiveè„šæœ¬","slug":"shellå‘½ä»¤æ‰§è¡Œhiveè„šæœ¬","link":"/tags/shell%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8Chive%E8%84%9A%E6%9C%AC/"},{"name":"åŠç›‘ç£å’Œè‡ªç›‘ç£","slug":"åŠç›‘ç£å’Œè‡ªç›‘ç£","link":"/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%92%8C%E8%87%AA%E7%9B%91%E7%9D%A3/"},{"name":"Solr","slug":"Solr","link":"/tags/Solr/"},{"name":"sota","slug":"sota","link":"/tags/sota/"},{"name":"Spark æ•°æ®å€¾æ–œ","slug":"Spark-æ•°æ®å€¾æ–œ","link":"/tags/Spark-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"},{"name":"sparkå®¹é”™æœºåˆ¶","slug":"sparkå®¹é”™æœºåˆ¶","link":"/tags/spark%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/"},{"name":"sparkå¸¸è§é”™è¯¯","slug":"sparkå¸¸è§é”™è¯¯","link":"/tags/spark%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"},{"name":"sparkäº¤äº’å·¥å…·","slug":"sparkäº¤äº’å·¥å…·","link":"/tags/spark%E4%BA%A4%E4%BA%92%E5%B7%A5%E5%85%B7/"},{"name":"æ•°æ®åˆ’åˆ†,rddåˆ†åŒº","slug":"æ•°æ®åˆ’åˆ†-rddåˆ†åŒº","link":"/tags/%E6%95%B0%E6%8D%AE%E5%88%92%E5%88%86-rdd%E5%88%86%E5%8C%BA/"},{"name":"sparkæ¨¡å—","slug":"sparkæ¨¡å—","link":"/tags/spark%E6%A8%A1%E5%9D%97/"},{"name":"spark oom(out of memory)é—®é¢˜","slug":"spark-oom-out-of-memory-é—®é¢˜","link":"/tags/spark-oom-out-of-memory-%E9%97%AE%E9%A2%98/"},{"name":"sparkä¼˜åŒ–","slug":"sparkä¼˜åŒ–","link":"/tags/spark%E4%BC%98%E5%8C%96/"},{"name":"sparkä¼˜åŒ–æ‰‹æ®µ","slug":"sparkä¼˜åŒ–æ‰‹æ®µ","link":"/tags/spark%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5/"},{"name":"RDDã€DataFrameã€DataSet","slug":"RDDã€DataFrameã€DataSet","link":"/tags/RDD%E3%80%81DataFrame%E3%80%81DataSet/"},{"name":"shuffle","slug":"shuffle","link":"/tags/shuffle/"},{"name":"Sparkæ”¯æŒçš„å­˜å‚¨ä»‹è´¨","slug":"Sparkæ”¯æŒçš„å­˜å‚¨ä»‹è´¨","link":"/tags/Spark%E6%94%AF%E6%8C%81%E7%9A%84%E5%AD%98%E5%82%A8%E4%BB%8B%E8%B4%A8/"},{"name":"Sparkæ¶æ„","slug":"Sparkæ¶æ„","link":"/tags/Spark%E6%9E%B6%E6%9E%84/"},{"name":"æäº¤Sparkä»»åŠ¡","slug":"æäº¤Sparkä»»åŠ¡","link":"/tags/%E6%8F%90%E4%BA%A4Spark%E4%BB%BB%E5%8A%A1/"},{"name":"RDDä¾èµ–å…³ç³»","slug":"RDDä¾èµ–å…³ç³»","link":"/tags/RDD%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB/"},{"name":"sparkèµ„æºå‚æ•°è°ƒä¼˜","slug":"sparkèµ„æºå‚æ•°è°ƒä¼˜","link":"/tags/spark%E8%B5%84%E6%BA%90%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/"},{"name":"sparkcore","slug":"sparkcore","link":"/tags/sparkcore/"},{"name":"Sparkcoreè¿è¡Œæµç¨‹","slug":"Sparkcoreè¿è¡Œæµç¨‹","link":"/tags/Sparkcore%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B/"},{"name":"Spark on Hive &amp; Hive on Spark","slug":"Spark-on-Hive-Hive-on-Spark","link":"/tags/Spark-on-Hive-Hive-on-Spark/"},{"name":"sparksqlå¯¹æ¯”hive sql","slug":"sparksqlå¯¹æ¯”hive-sql","link":"/tags/sparksql%E5%AF%B9%E6%AF%94hive-sql/"},{"name":"Sparksqlè¿è¡Œæµç¨‹","slug":"Sparksqlè¿è¡Œæµç¨‹","link":"/tags/Sparksql%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B/"},{"name":"sparksql","slug":"sparksql","link":"/tags/sparksql/"},{"name":"ç‰¹å¾ç¨€ç–","slug":"ç‰¹å¾ç¨€ç–","link":"/tags/%E7%89%B9%E5%BE%81%E7%A8%80%E7%96%8F/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"å»ºè¡¨","slug":"å»ºè¡¨","link":"/tags/%E5%BB%BA%E8%A1%A8/"},{"name":"sqlå¸¸è§æ“ä½œ","slug":"sqlå¸¸è§æ“ä½œ","link":"/tags/sql%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"},{"name":"sqlå¢åˆ æ”¹æŸ¥","slug":"sqlå¢åˆ æ”¹æŸ¥","link":"/tags/sql%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"name":"sqlå‡½æ•°","slug":"sqlå‡½æ•°","link":"/tags/sql%E5%87%BD%E6%95%B0/"},{"name":"sqlä¼˜åŒ–","slug":"sqlä¼˜åŒ–","link":"/tags/sql%E4%BC%98%E5%8C%96/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"sqoop","slug":"sqoop","link":"/tags/sqoop/"},{"name":"sugar","slug":"sugar","link":"/tags/sugar/"},{"name":"superset","slug":"superset","link":"/tags/superset/"},{"name":"SVM","slug":"SVM","link":"/tags/SVM/"},{"name":"å„ç§è¡¨","slug":"å„ç§è¡¨","link":"/tags/%E5%90%84%E7%A7%8D%E8%A1%A8/"},{"name":"Embedding based Product Retrieval in Taobao Search","slug":"Embedding-based-Product-Retrieval-in-Taobao-Search","link":"/tags/Embedding-based-Product-Retrieval-in-Taobao-Search/"},{"name":"ä¸­æ–‡æ–‡æœ¬åˆ†ç±»","slug":"ä¸­æ–‡æ–‡æœ¬åˆ†ç±»","link":"/tags/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"},{"name":"text edit","slug":"text-edit","link":"/tags/text-edit/"},{"name":"æ–‡æœ¬ç”Ÿæˆè¯„ä»·æŒ‡æ ‡","slug":"æ–‡æœ¬ç”Ÿæˆè¯„ä»·æŒ‡æ ‡","link":"/tags/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"name":"Evaluation of Text Generation A Survey","slug":"Evaluation-of-Text-Generation-A-Survey","link":"/tags/Evaluation-of-Text-Generation-A-Survey/"},{"name":"æ–‡æœ¬æ”¹å†™å’Œtermåˆ†æ","slug":"æ–‡æœ¬æ”¹å†™å’Œtermåˆ†æ","link":"/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99%E5%92%8Cterm%E5%88%86%E6%9E%90/"},{"name":"TextGCN","slug":"TextGCN","link":"/tags/TextGCN/"},{"name":"tensorflow export","slug":"tensorflow-export","link":"/tags/tensorflow-export/"},{"name":"tf ranking","slug":"tf-ranking","link":"/tags/tf-ranking/"},{"name":"Tensorflowä¸­çš„Seq2Seqå…¨å®¶æ¡¶","slug":"Tensorflowä¸­çš„Seq2Seqå…¨å®¶æ¡¶","link":"/tags/Tensorflow%E4%B8%AD%E7%9A%84Seq2Seq%E5%85%A8%E5%AE%B6%E6%A1%B6/"},{"name":"PyTorch VS TensorFlow","slug":"PyTorch-VS-TensorFlow","link":"/tags/PyTorch-VS-TensorFlow/"},{"name":"tensorflow2.x å’Œtensorflow1.xçš„åŒºåˆ«","slug":"tensorflow2-x-å’Œtensorflow1-xçš„åŒºåˆ«","link":"/tags/tensorflow2-x-%E5%92%8Ctensorflow1-x%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"name":"å¤©æ± æ–°é—»æ¨è","slug":"å¤©æ± æ–°é—»æ¨è","link":"/tags/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90/"},{"name":"æ—¶é—´å¤æ‚åº¦è®¡ç®—","slug":"æ—¶é—´å¤æ‚åº¦è®¡ç®—","link":"/tags/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AE%A1%E7%AE%97/"},{"name":"æ—¶é—´åºåˆ—é¢„æµ‹æ€»ç»“","slug":"æ—¶é—´åºåˆ—é¢„æµ‹æ€»ç»“","link":"/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E6%80%BB%E7%BB%93/"},{"name":"token embedding","slug":"token-embedding","link":"/tags/token-embedding/"},{"name":"Tokenization","slug":"Tokenization","link":"/tags/Tokenization/"},{"name":"æ¡†æ¶ä¾èµ–","slug":"æ¡†æ¶ä¾èµ–","link":"/tags/%E6%A1%86%E6%9E%B6%E4%BE%9D%E8%B5%96/"},{"name":"pytorch GPUè®­ç»ƒ","slug":"pytorch-GPUè®­ç»ƒ","link":"/tags/pytorch-GPU%E8%AE%AD%E7%BB%83/"},{"name":"pytorchå¸¸è§æ“ä½œ","slug":"pytorchå¸¸è§æ“ä½œ","link":"/tags/pytorch%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"},{"name":"torchå¯ä»¥æŠŠstringå˜Tensorå—ï¼Ÿ","slug":"torchå¯ä»¥æŠŠstringå˜Tensorå—ï¼Ÿ","link":"/tags/torch%E5%8F%AF%E4%BB%A5%E6%8A%8Astring%E5%8F%98Tensor%E5%90%97%EF%BC%9F/"},{"name":"pytorchæ­å»ºç¥ç»ç½‘ç»œ","slug":"pytorchæ­å»ºç¥ç»ç½‘ç»œ","link":"/tags/pytorch%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"æ¨¡å‹è”åˆè®­ç»ƒ","slug":"æ¨¡å‹è”åˆè®­ç»ƒ","link":"/tags/%E6%A8%A1%E5%9E%8B%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83/"},{"name":"è®­ç»ƒ,éªŒè¯åŒæ­¥è¿›è¡Œ","slug":"è®­ç»ƒ-éªŒè¯åŒæ­¥è¿›è¡Œ","link":"/tags/%E8%AE%AD%E7%BB%83-%E9%AA%8C%E8%AF%81%E5%90%8C%E6%AD%A5%E8%BF%9B%E8%A1%8C/"},{"name":"transformerç»¼è¿°","slug":"transformerç»¼è¿°","link":"/tags/transformer%E7%BB%BC%E8%BF%B0/"},{"name":"Transformeræ—¶é—´åºåˆ—é¢„æµ‹","slug":"Transformeræ—¶é—´åºåˆ—é¢„æµ‹","link":"/tags/Transformer%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/"},{"name":"Transformer-XL","slug":"Transformer-XL","link":"/tags/Transformer-XL/"},{"name":"transformer","slug":"transformer","link":"/tags/transformer/"},{"name":"å­—å…¸æ ‘","slug":"å­—å…¸æ ‘","link":"/tags/%E5%AD%97%E5%85%B8%E6%A0%91/"},{"name":"åŒæŒ‡é’ˆ","slug":"åŒæŒ‡é’ˆ","link":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"text SpanæŠ½å–","slug":"text-SpanæŠ½å–","link":"/tags/text-Span%E6%8A%BD%E5%8F%96/"},{"name":"å¤„ç†æ— ç•Œå’Œæœ‰ç•Œæ•°æ®","slug":"å¤„ç†æ— ç•Œå’Œæœ‰ç•Œæ•°æ®","link":"/tags/%E5%A4%84%E7%90%86%E6%97%A0%E7%95%8C%E5%92%8C%E6%9C%89%E7%95%8C%E6%95%B0%E6%8D%AE/"},{"name":"å¯è§†åŒ–æŠ¥è¡¨","slug":"å¯è§†åŒ–æŠ¥è¡¨","link":"/tags/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%A5%E8%A1%A8/"},{"name":"å„ç»„ä»¶web uiçš„åœ°å€","slug":"å„ç»„ä»¶web-uiçš„åœ°å€","link":"/tags/%E5%90%84%E7%BB%84%E4%BB%B6web-ui%E7%9A%84%E5%9C%B0%E5%9D%80/"},{"name":"æƒé‡åˆå§‹åŒ–","slug":"æƒé‡åˆå§‹åŒ–","link":"/tags/%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"name":"xgboost","slug":"xgboost","link":"/tags/xgboost/"},{"name":"XLNet","slug":"XLNet","link":"/tags/XLNet/"},{"name":"youtubednn","slug":"youtubednn","link":"/tags/youtubednn/"},{"name":"ZooKeeper","slug":"ZooKeeper","link":"/tags/ZooKeeper/"}],"categories":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"å¤§æ•°æ®","slug":"å¤§æ•°æ®","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"æ¨¡å‹ç»“æ„","slug":"æœºå™¨å­¦ä¹ /æ¨¡å‹ç»“æ„","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/"},{"name":"æ¨èç³»ç»Ÿ","slug":"æ¨èç³»ç»Ÿ","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"GNN","slug":"GNN","link":"/categories/GNN/"},{"name":"æ•°æ®ä»“åº“","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"},{"name":"å¹¿å‘Šç³»ç»Ÿ","slug":"å¹¿å‘Šç³»ç»Ÿ","link":"/categories/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/"},{"name":"åŸºç¡€ç»„ä»¶","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/"},{"name":"æ’åº","slug":"æ¨èç³»ç»Ÿ/æ’åº","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/"},{"name":"æ¨èç³»ç»Ÿ","slug":"æ¨èç³»ç»Ÿ/æ¨èç³»ç»Ÿ","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"æ•°å­¦åŸºç¡€","slug":"æœºå™¨å­¦ä¹ /æ•°å­¦åŸºç¡€","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"},{"name":"å¬å›","slug":"æ¨èç³»ç»Ÿ/å¬å›","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/"},{"name":"NLP","slug":"NLP","link":"/categories/NLP/"},{"name":"å°å¸®æ‰‹","slug":"GNN/å°å¸®æ‰‹","link":"/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"},{"name":"æ•°æ®æ„é€ ","slug":"æœºå™¨å­¦ä¹ /æ•°æ®æ„é€ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E6%9E%84%E9%80%A0/"},{"name":"å³å¸­æŸ¥è¯¢","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/å³å¸­æŸ¥è¯¢","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E5%8D%B3%E5%B8%AD%E6%9F%A5%E8%AF%A2/"},{"name":"Atlas","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Atlas","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Atlas/"},{"name":"æœç´¢ç³»ç»Ÿ","slug":"æœç´¢ç³»ç»Ÿ","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/"},{"name":"GCN","slug":"GNN/GCN","link":"/categories/GNN/GCN/"},{"name":"è®­ç»ƒæŠ€å·§","slug":"æœºå™¨å­¦ä¹ /è®­ç»ƒæŠ€å·§","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"},{"name":"Grafana","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Grafana","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Grafana/"},{"name":"å¯¹è¯ç³»ç»Ÿ","slug":"å¯¹è¯ç³»ç»Ÿ","link":"/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"Azkaban","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Azkaban","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Azkaban/"},{"name":"GNN","slug":"GNN/GNN","link":"/categories/GNN/GNN/"},{"name":"loss","slug":"æœºå™¨å­¦ä¹ /loss","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/loss/"},{"name":"åŸºç¡€ç®—æ³•","slug":"åŸºç¡€ç®—æ³•","link":"/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"name":"Kerberos","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Kerberos","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Kerberos/"},{"name":"Kylin","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Kylin","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Kylin/"},{"name":"æ’åº","slug":"æ¨èç³»ç»Ÿ/æ’åº/æ’åº","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E6%8E%92%E5%BA%8F/"},{"name":"åŸºç¡€ç»„ä»¶","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/åŸºç¡€ç»„ä»¶","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/"},{"name":"å¤§æ•°æ®","slug":"å¤§æ•°æ®/å¤§æ•°æ®","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"é›†æˆå­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ /é›†æˆå­¦ä¹ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ /æœºå™¨å­¦ä¹ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"ä¿¡æ¯æŠ½å–","slug":"NLP/ä¿¡æ¯æŠ½å–","link":"/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/"},{"name":"æ•°ä»“","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°ä»“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E4%BB%93/"},{"name":"PTM","slug":"NLP/PTM","link":"/categories/NLP/PTM/"},{"name":"æ·±åº¦å­¦ä¹ æ¡†æ¶","slug":"æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ æ¡†æ¶","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/"},{"name":"NLP","slug":"NLP/NLP","link":"/categories/NLP/NLP/"},{"name":"è¯„ä»·æŒ‡æ ‡","slug":"æœºå™¨å­¦ä¹ /è¯„ä»·æŒ‡æ ‡","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"name":"æ•°æ®åº“","slug":"å¤§æ•°æ®/æ•°æ®åº“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"spark","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/spark","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/spark/"},{"name":"Prompt","slug":"NLP/Prompt","link":"/categories/NLP/Prompt/"},{"name":"æ–‡æœ¬è¡¨ç¤º","slug":"NLP/æ–‡æœ¬è¡¨ç¤º","link":"/categories/NLP/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"},{"name":"æ—¶é—´åºåˆ—é¢„æµ‹","slug":"æ—¶é—´åºåˆ—é¢„æµ‹","link":"/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/"},{"name":"Zabbix","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Zabbix","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Zabbix/"},{"name":"å¯¹æ¯”å­¦ä¹ ","slug":"NLP/å¯¹æ¯”å­¦ä¹ ","link":"/categories/NLP/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"æ•°æ®é›†æˆ","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°æ®é›†æˆ","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90/"},{"name":"æ•°æ®è´¨é‡","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°æ®è´¨é‡","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/"},{"name":"æœç´¢ç³»ç»Ÿ","slug":"æœç´¢ç³»ç»Ÿ/æœç´¢ç³»ç»Ÿ","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/"},{"name":"æ•°æ®å®‰å…¨","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°æ®å®‰å…¨","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/"},{"name":"flink","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/flink","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/flink/"},{"name":"java","slug":"java/java","link":"/categories/java/java/"},{"name":"ç‰¹å¾æå–å™¨","slug":"NLP/ç‰¹å¾æå–å™¨","link":"/categories/NLP/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8/"},{"name":"å°å¸®æ‰‹","slug":"NLP/å°å¸®æ‰‹","link":"/categories/NLP/%E5%B0%8F%E5%B8%AE%E6%89%8B/"},{"name":"æ–‡æœ¬åˆ†ç±»","slug":"NLP/æ–‡æœ¬åˆ†ç±»","link":"/categories/NLP/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"},{"name":"ç®—æ³•å¯¼è®º","slug":"åŸºç¡€ç®—æ³•/ç®—æ³•å¯¼è®º","link":"/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"},{"name":"éƒ¨ç½²","slug":"éƒ¨ç½²","link":"/categories/%E9%83%A8%E7%BD%B2/"},{"name":"æ’åº","slug":"æœç´¢ç³»ç»Ÿ/æ’åº","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/"},{"name":"ä¸šåŠ¡","slug":"ä¸šåŠ¡","link":"/categories/%E4%B8%9A%E5%8A%A1/"},{"name":"æ–‡æœ¬åŒ¹é…","slug":"NLP/æ–‡æœ¬åŒ¹é…","link":"/categories/NLP/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"},{"name":"ç‰¹å¾å·¥ç¨‹","slug":"æœºå™¨å­¦ä¹ /ç‰¹å¾å·¥ç¨‹","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"ETL","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/ETL","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/ETL/"},{"name":"æ–‡æœ¬ç”Ÿæˆ","slug":"NLP/æ–‡æœ¬ç”Ÿæˆ","link":"/categories/NLP/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/"},{"name":"å°æ ·æœ¬","slug":"NLP/å°æ ·æœ¬","link":"/categories/NLP/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"webå‰åç«¯","slug":"webå‰åç«¯","link":"/categories/web%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"boosting","slug":"æœºå™¨å­¦ä¹ /é›†æˆå­¦ä¹ /boosting","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/boosting/"},{"name":"ç¦»çº¿æ•°ä»“","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°ä»“/ç¦»çº¿æ•°ä»“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E4%BB%93/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/"},{"name":"flume","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/flume","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/flume/"},{"name":"tensorflow","slug":"æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ æ¡†æ¶/tensorflow","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/tensorflow/"},{"name":"pytorch","slug":"æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ æ¡†æ¶/pytorch","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/pytorch/"},{"name":"å…³ç³»å‹","slug":"å¤§æ•°æ®/æ•°æ®åº“/å…³ç³»å‹","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B/"},{"name":"hadoop","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/hadoop","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/hadoop/"},{"name":"ä½¿ç”¨","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/spark/ä½¿ç”¨","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/spark/%E4%BD%BF%E7%94%A8/"},{"name":"æ•°æ®ç»“æ„","slug":"åŸºç¡€ç®—æ³•/æ•°æ®ç»“æ„","link":"/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"éå…³ç³»å‹","slug":"å¤§æ•°æ®/æ•°æ®åº“/éå…³ç³»å‹","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B/"},{"name":"hive","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/hive","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/hive/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"æ•°æ®åº“","slug":"å¤§æ•°æ®/æ•°æ®åº“/æ•°æ®åº“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"sql","slug":"å¤§æ•°æ®/æ•°æ®åº“/sql","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/sql/"},{"name":"ide","slug":"java/ide","link":"/categories/java/ide/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"å¬å›","slug":"æœç´¢ç³»ç»Ÿ/å¬å›","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/"},{"name":"åŸç†","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/spark/åŸç†","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/spark/%E5%8E%9F%E7%90%86/"},{"name":"queryç†è§£","slug":"æœç´¢ç³»ç»Ÿ/queryç†è§£","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/query%E7%90%86%E8%A7%A3/"},{"name":"æ¡†æ¶","slug":"java/æ¡†æ¶","link":"/categories/java/%E6%A1%86%E6%9E%B6/"},{"name":"å¤šçº¿ç¨‹ç¼–ç¨‹","slug":"java/å¤šçº¿ç¨‹ç¼–ç¨‹","link":"/categories/java/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"},{"name":"ç½‘ç»œç¼–ç¨‹","slug":"java/ç½‘ç»œç¼–ç¨‹","link":"/categories/java/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"åŸºç¡€è¯­æ³•","slug":"java/åŸºç¡€è¯­æ³•","link":"/categories/java/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"name":"jvm","slug":"java/jvm","link":"/categories/java/jvm/"},{"name":"éªŒè¯","slug":"æœºå™¨å­¦ä¹ /éªŒè¯","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%AA%8C%E8%AF%81/"},{"name":"Kafka","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Kafka","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Kafka/"},{"name":"çŸ¥è¯†å›¾è°±","slug":"çŸ¥è¯†å›¾è°±","link":"/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"listwise","slug":"æ¨èç³»ç»Ÿ/æ’åº/listwise","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/listwise/"},{"name":"leetcode","slug":"åŸºç¡€ç®—æ³•/leetcode","link":"/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/leetcode/"},{"name":"ä½¿ç”¨","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/flink/ä½¿ç”¨","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/flink/%E4%BD%BF%E7%94%A8/"},{"name":"å®æ—¶æ•°ä»“","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/æ•°ä»“/å®æ—¶æ•°ä»“","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E4%BB%93/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"},{"name":"å…ƒæ•°æ®ç®¡ç†","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/å…ƒæ•°æ®ç®¡ç†","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"},{"name":"è¿­ä»£åˆ†æ","slug":"æœºå™¨å­¦ä¹ /è¿­ä»£åˆ†æ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%AD%E4%BB%A3%E5%88%86%E6%9E%90/"},{"name":"é›†ç¾¤ç›‘æ§","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/é›†ç¾¤ç›‘æ§","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7/"},{"name":"å¤šæ ‡ç­¾","slug":"æœºå™¨å­¦ä¹ /å¤šæ ‡ç­¾","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E6%A0%87%E7%AD%BE/"},{"name":"å¤šä»»åŠ¡å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ /å¤šä»»åŠ¡å­¦ä¹ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/"},{"name":"è®¡ç®—æœºç½‘ç»œ","slug":"è®¡ç®—æœºç½‘ç»œ","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"nginx","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/nginx","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/nginx/"},{"name":"æ·±åº¦å­¦ä¹ æ¡†æ¶","slug":"æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ æ¡†æ¶/æ·±åº¦å­¦ä¹ æ¡†æ¶","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/"},{"name":"open set recognization","slug":"æœºå™¨å­¦ä¹ /open-set-recognization","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/open-set-recognization/"},{"name":"docker","slug":"éƒ¨ç½²/docker","link":"/categories/%E9%83%A8%E7%BD%B2/docker/"},{"name":"pairwise","slug":"æ¨èç³»ç»Ÿ/æ’åº/pairwise","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/pairwise/"},{"name":"ç²—æ’","slug":"æœç´¢ç³»ç»Ÿ/æ’åº/ç²—æ’","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E7%B2%97%E6%8E%92/"},{"name":"ä¼˜åŒ–","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/spark/ä¼˜åŒ–","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/spark/%E4%BC%98%E5%8C%96/"},{"name":"ç”µå•†","slug":"ä¸šåŠ¡/ç”µå•†","link":"/categories/%E4%B8%9A%E5%8A%A1/%E7%94%B5%E5%95%86/"},{"name":"phoenix","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/phoenix","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/phoenix/"},{"name":"pointwise","slug":"æ¨èç³»ç»Ÿ/æ’åº/pointwise","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/pointwise/"},{"name":"é›†æˆå­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ /é›†æˆå­¦ä¹ /é›†æˆå­¦ä¹ ","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"åŸç†","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/flink/åŸç†","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/flink/%E5%8E%9F%E7%90%86/"},{"name":"Ranger","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Ranger","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Ranger/"},{"name":"flask","slug":"webå‰åç«¯/flask","link":"/categories/web%E5%89%8D%E5%90%8E%E7%AB%AF/flask/"},{"name":"shell","slug":"shell","link":"/categories/shell/"},{"name":"Solr","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/Solr","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/Solr/"},{"name":"ä¼˜åŒ–","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/flink/ä¼˜åŒ–","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/flink/%E4%BC%98%E5%8C%96/"},{"name":"sqoop","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/sqoop","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/sqoop/"},{"name":"å¯è§†åŒ–æŠ¥è¡¨","slug":"å¤§æ•°æ®/æ•°æ®ä»“åº“/å¯è§†åŒ–æŠ¥è¡¨","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%A5%E8%A1%A8/"},{"name":"superset","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/superset","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/superset/"},{"name":"clickhouse","slug":"å¤§æ•°æ®/æ•°æ®åº“/å…³ç³»å‹/clickhouse","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B/clickhouse/"},{"name":"å°å¸®æ‰‹","slug":"æ¨èç³»ç»Ÿ/æ’åº/å°å¸®æ‰‹","link":"/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E5%B0%8F%E5%B8%AE%E6%89%8B/"},{"name":"Tokenization","slug":"NLP/Tokenization","link":"/categories/NLP/Tokenization/"},{"name":"HBase","slug":"å¤§æ•°æ®/æ•°æ®åº“/éå…³ç³»å‹/HBase","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B/HBase/"},{"name":"hql","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/hive/hql","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/hive/hql/"},{"name":"hive","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/hive/hive","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/hive/hive/"},{"name":"å€’æ’ç´¢å¼•","slug":"æœç´¢ç³»ç»Ÿ/å¬å›/å€’æ’ç´¢å¼•","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"},{"name":"æ¡†æ¶","slug":"java/æ¡†æ¶/æ¡†æ¶","link":"/categories/java/%E6%A1%86%E6%9E%B6/%E6%A1%86%E6%9E%B6/"},{"name":"jdbc","slug":"java/æ¡†æ¶/jdbc","link":"/categories/java/%E6%A1%86%E6%9E%B6/jdbc/"},{"name":"maven","slug":"java/æ¡†æ¶/maven","link":"/categories/java/%E6%A1%86%E6%9E%B6/maven/"},{"name":"æ·±åº¦å­¦ä¹ ","slug":"éƒ¨ç½²/æ·±åº¦å­¦ä¹ ","link":"/categories/%E9%83%A8%E7%BD%B2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"postman","slug":"webå‰åç«¯/postman","link":"/categories/web%E5%89%8D%E5%90%8E%E7%AB%AF/postman/"},{"name":"springboot","slug":"java/æ¡†æ¶/springboot","link":"/categories/java/%E6%A1%86%E6%9E%B6/springboot/"},{"name":"å‘é‡å¬å›","slug":"æœç´¢ç³»ç»Ÿ/å¬å›/å‘é‡å¬å›","link":"/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/%E5%90%91%E9%87%8F%E5%8F%AC%E5%9B%9E/"},{"name":"ZooKeeper","slug":"å¤§æ•°æ®/åŸºç¡€ç»„ä»¶/ZooKeeper","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6/ZooKeeper/"}]}