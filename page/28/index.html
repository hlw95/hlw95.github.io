<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-12  <a class="commentCountImg" href="/2021/12/12/Prompt_survey/#comment-container"><span class="display-none-class">1a6cb8f58eadb9f20eae53a070af5922</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1a6cb8f58eadb9f20eae53a070af5922">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>5 m  <i class="fas fa-pencil-alt"> </i>0.8 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/12/Prompt_survey/">Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing</a></h1><div class="content"><h2 id="0-和pre-train，finetune区别"><a href="#0-和pre-train，finetune区别" class="headerlink" title="0 和pre-train，finetune区别"></a>0 和pre-train，finetune区别</h2><p><img src="/2021/12/12/Prompt_survey/11.JPG" alt></p>
<p><img src="/2021/12/12/Prompt_survey/1.JPG" alt></p>
<p>prompt感觉是一种特殊的finetune方式，还是先pre-train然后prompt tuning</p>
<p>目的：prompt narrowing the gap between pre-training and fine-tuning</p>
<h2 id="1-怎么做"><a href="#1-怎么做" class="headerlink" title="1 怎么做"></a>1 怎么做</h2><p>3步</p>
<h4 id="1-Prompt-Addition"><a href="#1-Prompt-Addition" class="headerlink" title="1 Prompt Addition"></a>1 Prompt Addition</h4><p><img src="/2021/12/12/Prompt_survey/0.JPG" alt></p>
<p>$x^{‘}=f_{prompt}(x)$ x是input text</p>
<ol>
<li>Apply a template, which is a textual string that has two slots: an input slot [X] for input x and an answer slot<br>[Z] for an intermediate generated answer text z that will later be mapped into y.</li>
<li>Fill slot [X] with the input text x.</li>
</ol>
<h4 id="2-Answer-Search"><a href="#2-Answer-Search" class="headerlink" title="2 Answer Search"></a>2 Answer Search</h4><p><img src="/2021/12/12/Prompt_survey/5.JPG" alt></p>
<p>f：fills in the location [Z] in prompt $x^{‘}$ with the potential answer z</p>
<p>Z：a set of permissible values for z</p>
<h4 id="3-Answer-Mapping"><a href="#3-Answer-Mapping" class="headerlink" title="3 Answer Mapping"></a>3 Answer Mapping</h4><p>因为上面的 $\hat{z}$ 还不是  $\hat{y}$，比如情感分析，“excellent”, “fabulous”, “wonderful” -》positive</p>
<p>go from the highest-scoring answer $\hat{z}$ to the highest-scoring output  $\hat{y}$ </p>
<h4 id="4-举个例子，文本情感分类的任务"><a href="#4-举个例子，文本情感分类的任务" class="headerlink" title="4 举个例子，文本情感分类的任务"></a>4 举个例子，文本情感分类的任务</h4><p><strong>原来</strong></p>
<p> “ I love this movie.”  -》 positive</p>
<p><strong>现在</strong></p>
<p>1 $x=$ “ I love this movie.”  -》模板为： “ [x] Overall, it was a [z] movie.” -》$x^{‘}$为”I love this movie. Overall ,it was a [z] movie.”</p>
<p>2 下一步会进行答案搜索，顾名思义就是LM寻找填在[z] 处可以使得分数最高的文本 $\hat{z}$(比如”excellent”, “great”, “wonderful” )</p>
<p>3 最后是答案映射。有时LM填充的文本并非任务需要的最终形式(最终为positive，上述为”excellent”, “great”, “wonderful”)，因此要将此文本映射到最终的输出$\hat{y}$</p>
<h2 id="2-Prompt方法分类"><a href="#2-Prompt方法分类" class="headerlink" title="2 Prompt方法分类"></a>2 Prompt方法分类</h2><p><img src="/2021/12/12/Prompt_survey/2.JPG" alt></p>
<h2 id="3-Prompt-Engineering"><a href="#3-Prompt-Engineering" class="headerlink" title="3 Prompt Engineering"></a>3 Prompt Engineering</h2><p>1 one must first consider the prompt shape,</p>
<p>2 then decide whether to take a manual or automated approach to create prompts of the desired shape</p>
<h3 id="1-Prompt-Shape"><a href="#1-Prompt-Shape" class="headerlink" title="1 Prompt Shape"></a>1 Prompt Shape</h3><p>Prompt的形状主要指的是[X]和[Z]的位置和数量。</p>
<p>如果在句中，一般称这种prompt为<strong>cloze prompt</strong>；如果在句末，一般称这种prompt为<strong>prefix prompt</strong>。</p>
<p>在实际应用过程中选择哪一种主要取决于任务的形式和模型的类别。cloze prompts和Masked Language Model的训练方式非常类似，因此对于使用MLM的任务来说cloze prompts更加合适；对于生成任务来说，或者使用自回归LM解决的任务，prefix prompts就会更加合适；Full text reconstruction models较为通用，因此两种prompt均适用。另外，对于文本对的分类，prompt模板通常要给输入预留两个空，[x1]和[x2]。</p>
<h3 id="2-create-prompts"><a href="#2-create-prompts" class="headerlink" title="2 create prompts"></a>2 create prompts</h3><h4 id="1-Manual-Template-Engineering"><a href="#1-Manual-Template-Engineering" class="headerlink" title="1 Manual Template Engineering"></a>1 Manual Template Engineering</h4><h4 id="2-Automated-Template-Learning"><a href="#2-Automated-Template-Learning" class="headerlink" title="2 Automated Template Learning"></a>2 Automated Template Learning</h4><h5 id="1-Discrete-Prompts"><a href="#1-Discrete-Prompts" class="headerlink" title="1 Discrete Prompts"></a>1 Discrete Prompts</h5><p>the prompt 作用在文本上</p>
<p>D1: Prompt Mining</p>
<p>D2: Prompt Paraphrasing</p>
<p>D3: Gradient-based Search</p>
<p>D4: Prompt Generation</p>
<p>D5: Prompt Scoring</p>
<h5 id="2-Continuous-Prompts"><a href="#2-Continuous-Prompts" class="headerlink" title="2 Continuous Prompts"></a>2 Continuous Prompts</h5><p>the prompt 直接作用到模型的embedding空间</p>
<p>C1: Prefix Tuning</p>
<p>C2: Tuning Initialized with Discrete Prompts</p>
<p>C3: Hard-Soft Prompt Hybrid Tuning</p>
<h2 id="4-Answer-Engineering"><a href="#4-Answer-Engineering" class="headerlink" title="4 Answer Engineering"></a>4 Answer Engineering</h2><p>two dimensions that must be considered when performing answer<br>engineering:1  deciding the answer shape and 2  choosing an answer design method.</p>
<h4 id="1-Answer-Shape"><a href="#1-Answer-Shape" class="headerlink" title="1 Answer Shape"></a>1 Answer Shape</h4><p>和Prompt Shape啥区别？？？</p>
<h4 id="2-Answer-Space-Design-Methods"><a href="#2-Answer-Space-Design-Methods" class="headerlink" title="2 Answer Space Design Methods"></a>2 Answer Space Design Methods</h4><h5 id="1-Manual-Design"><a href="#1-Manual-Design" class="headerlink" title="1 Manual Design"></a>1 Manual Design</h5><h5 id="2-automatic-automatic"><a href="#2-automatic-automatic" class="headerlink" title="2 automatic automatic"></a>2 automatic automatic</h5><h6 id="1-Discrete-Answer-Search"><a href="#1-Discrete-Answer-Search" class="headerlink" title="1 Discrete Answer Search"></a>1 Discrete Answer Search</h6><h6 id="2-Continuous-Answer-Search"><a href="#2-Continuous-Answer-Search" class="headerlink" title="2 Continuous Answer Search"></a>2 Continuous Answer Search</h6><h2 id="5-Multi-Prompt-Learning"><a href="#5-Multi-Prompt-Learning" class="headerlink" title="5 Multi-Prompt Learning"></a>5 Multi-Prompt Learning</h2><p>之前在讨论single prompt，现在介绍multiple prompts</p>
<p><img src="/2021/12/12/Prompt_survey/3.JPG" alt></p>
<h2 id="6-Training-Strategies-for-Prompting-Methods"><a href="#6-Training-Strategies-for-Prompting-Methods" class="headerlink" title="6 Training Strategies for Prompting Methods"></a>6 Training Strategies for Prompting Methods</h2><p>1 Training Settings</p>
<p>full-data</p>
<p>few-shot /zero-shot</p>
<p>2 Parameter Update Methods</p>
<p><img src="/2021/12/12/Prompt_survey/4.JPG" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.13586">https://arxiv.org/abs/2107.13586</a></p>
<p>刘鹏飞博士 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395115779">https://zhuanlan.zhihu.com/p/395115779</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/399295895">https://zhuanlan.zhihu.com/p/399295895</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/440169921">https://zhuanlan.zhihu.com/p/440169921</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/399295895">https://zhuanlan.zhihu.com/p/399295895</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/Prompt/">Prompt</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/Prompt/">Prompt</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-12  <a class="commentCountImg" href="/2021/12/12/few-shot/#comment-container"><span class="display-none-class">27305810d8db04e9529bfb0657ccb1e8</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="27305810d8db04e9529bfb0657ccb1e8">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>14 m  <i class="fas fa-pencil-alt"> </i>2.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/12/few-shot/">Generalizing from a Few Examples A Survey on Few-Shot Learning</a></h1><div class="content"><p>paper：  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.05046">https://arxiv.org/abs/1904.05046</a></p>
<p>git:  <a target="_blank" rel="noopener" href="https://github.com/tata1661/FSL-Mate/tree/master/FewShotPapers#Applications">https://github.com/tata1661/FSL-Mate/tree/master/FewShotPapers#Applications</a></p>
<p>原文按应用对FSL做了总结，与NLP相关的有：</p>
<ol>
<li><strong>High-risk learning: Acquiring new word vectors from tiny data,</strong> in EMNLP, 2017. <em>A. Herbelot and M. Baroni.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D17-1030.pdf">paper</a></li>
<li><strong>MetaEXP: Interactive explanation and exploration of large knowledge graphs,</strong> in TheWebConf, 2018. <em>F. Behrens, S. Bischoff, P. Ladenburger, J. Rückin, L. Seidel, F. Stolp, M. Vaichenker, A. Ziegler, D. Mottin, F. Aghaei, E. Müller, M. Preusse, N. Müller, and M. Hunger.</em> <a target="_blank" rel="noopener" href="https://meta-exp.github.io/resources/paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://hpi.de/en/mueller/metaex">code</a></li>
<li><strong>Few-shot representation learning for out-of-vocabulary words,</strong> in ACL, 2019. <em>Z. Hu, T. Chen, K.-W. Chang, and Y. Sun.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P19-1402.pdf">paper</a></li>
<li><strong>Learning to customize model structures for few-shot dialogue generation tasks,</strong> in ACL, 2020. <em>Y. Song, Z. Liu, W. Bi, R. Yan, and M. Zhang.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.517.pdf">paper</a></li>
<li><strong>Few-shot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network,</strong> in ACL, 2020. <em>Y. Hou, W. Che, Y. Lai, Z. Zhou, Y. Liu, H. Liu, and T. Liu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.128.pdf">paper</a></li>
<li><strong>Meta-reinforced multi-domain state generator for dialogue systems,</strong> in ACL, 2020. <em>Y. Huang, J. Feng, M. Hu, X. Wu, X. Du, and S. Ma.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.636.pdf">paper</a></li>
<li><strong>Few-shot knowledge graph completion,</strong> in AAAI, 2020. <em>C. Zhang, H. Yao, C. Huang, M. Jiang, Z. Li, and N. V. Chawla.</em> <a target="_blank" rel="noopener" href="https://aaai.org/ojs/index.php/AAAI/article/view/5698">paper</a></li>
<li><strong>Universal natural language processing with limited annotations: Try few-shot textual entailment as a start,</strong> in EMNLP, 2020. <em>W. Yin, N. F. Rajani, D. Radev, R. Socher, and C. Xiong.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.660.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/salesforce/UniversalFewShotNLP">code</a></li>
<li><strong>Simple and effective few-shot named entity recognition with structured nearest neighbor learning,</strong> in EMNLP, 2020. <em>Y. Yang, and A. Katiyar.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.516.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/asappresearch/structshot">code</a></li>
<li><strong>Discriminative nearest neighbor few-shot intent detection by transferring natural language inference,</strong> in EMNLP, 2020. <em>J. Zhang, K. Hashimoto, W. Liu, C. Wu, Y. Wan, P. Yu, R. Socher, and C. Xiong.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.411.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/salesforce/DNNC-few-shot-intent">code</a></li>
<li><strong>Few-shot learning for opinion summarization,</strong> in EMNLP, 2020. <em>A. Bražinskas, M. Lapata, and I. Titov.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.337.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/abrazinskas/FewSum">code</a></li>
<li><strong>Adaptive attentional network for few-shot knowledge graph completion,</strong> in EMNLP, 2020. <em>J. Sheng, S. Guo, Z. Chen, J. Yue, L. Wang, T. Liu, and H. Xu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.131.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/JiaweiSheng/FAAN">code</a></li>
<li><strong>Few-shot complex knowledge base question answering via meta reinforcement learning,</strong> in EMNLP, 2020. <em>Y. Hua, Y. Li, G. Haffari, G. Qi, and T. Wu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.469.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/DevinJake/MRL-CQA">code</a></li>
<li><strong>Self-supervised meta-learning for few-shot natural language classification tasks,</strong> in EMNLP, 2020. <em>T. Bansal, R. Jha, T. Munkhdalai, and A. McCallum.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.38.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/iesl/metanlp">code</a></li>
<li><strong>Uncertainty-aware self-training for few-shot text classification,</strong> in NeurIPS, 2020. <em>S. Mukherjee, and A. Awadallah.</em> <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2020/file/f23d125da1e29e34c552f448610ff25f-Paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/UST">code</a></li>
<li><strong>Learning to extrapolate knowledge: Transductive few-shot out-of-graph link prediction,</strong> in NeurIPS, 2020:. <em>J. Baek, D. B. Lee, and S. J. Hwang.</em> <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2020/file/0663a4ddceacb40b095eda264a85f15c-Paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/JinheonBaek/GEN">code</a></li>
<li><strong>MetaNER: Named entity recognition with meta-learning,</strong> in TheWebConf, 2020. <em>J. Li, S. Shang, and L. Shao.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3366423.3380127">paper</a></li>
<li><strong>Conditionally adaptive multi-task learning: Improving transfer learning in NLP using fewer parameters &amp; less data,</strong> in ICLR, 2021. <em>J. Pilault, A. E. hattami, and C. Pal.</em> <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=de11dbHzAMF">paper</a> <a target="_blank" rel="noopener" href="https://github.com/CAMTL/CA-MTL">code</a></li>
<li><strong>Revisiting few-sample BERT fine-tuning,</strong> in ICLR, 2021. <em>T. Zhang, F. Wu, A. Katiyar, K. Q. Weinberger, and Y. Artzi.</em> <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=cO1IH43yUF">paper</a> <a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.4.0/_modules/torch/optim/adamw.html">code</a></li>
<li><strong>Few-shot conversational dense retrieval,</strong> in SIGIR, 2021. <em>S. Yu, Z. Liu, C. Xiong, T. Feng, and Z. Liu.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462856">paper</a> <a target="_blank" rel="noopener" href="https://github.com/thunlp/ConvDR">code</a></li>
<li><strong>Relational learning with gated and attentive neighbor aggregator for few-shot knowledge graph completion,</strong> in SIGIR, 2021. <em>G. Niu, Y. Li, C. Tang, R. Geng, J. Dai, Q. Liu, H. Wang, J. Sun, F. Huang, and L. Si.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462925">paper</a></li>
<li><strong>Few-shot language coordination by modeling theory of mind,</strong> in ICML, 2021. <em>H. Zhu, G. Neubig, and Y. Bisk.</em> <a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v139/zhu21d/zhu21d.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/CLAW-Lab/ToM">code</a></li>
<li><strong>Graph-evolving meta-learning for low-resource medical dialogue generation,</strong> in AAAI, 2021. <em>S. Lin, P. Zhou, X. Liang, J. Tang, R. Zhao, Z. Chen, and L. Lin.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17577/17384">paper</a></li>
<li><strong>KEML: A knowledge-enriched meta-learning framework for lexical relation classification,</strong> in AAAI, 2021. <em>C. Wang, M. Qiu, J. Huang, and X. He.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17640/17447">paper</a></li>
<li><strong>Few-shot learning for multi-label intent detection,</strong> in AAAI, 2021. <em>Y. Hou, Y. Lai, Y. Wu, W. Che, and T. Liu.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17541/17348">paper</a> <a target="_blank" rel="noopener" href="https://github.com/AtmaHou/FewShotMultiLabel">code</a></li>
<li><strong>SALNet: Semi-supervised few-shot text classification with attention-based lexicon construction,</strong> in AAAI, 2021. <em>J.-H. Lee, S.-K. Ko, and Y.-S. Han.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17558/17365">paper</a></li>
<li><strong>Learning from my friends: Few-shot personalized conversation systems via social networks,</strong> in AAAI, 2021. <em>Z. Tian, W. Bi, Z. Zhang, D. Lee, Y. Song, and N. L. Zhang.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17638/17445">paper</a> <a target="_blank" rel="noopener" href="https://github.com/tianzhiliang/FewShotPersonaConvData">code</a></li>
<li><strong>Relative and absolute location embedding for few-shot node classification on graph,</strong> in AAAI, 2021. <em>Z. Liu, Y. Fang, C. Liu, and S. C.H. Hoi.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16551/16358">paper</a></li>
<li><strong>Few-shot question answering by pretraining span selection,</strong> in ACL-IJCNLP, 2021. <em>O. Ram, Y. Kirstain, J. Berant, A. Globerson, and O. Levy.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.239.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/oriram/splinter">code</a></li>
<li><strong>A closer look at few-shot crosslingual transfer: The choice of shots matters,</strong> in ACL-IJCNLP, 2021. <em>M. Zhao, Y. Zhu, E. Shareghi, I. Vulic, R. Reichart, A. Korhonen, and H. Schütze.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.447.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/fsxlt">code</a></li>
<li><strong>Learning from miscellaneous other-classwords for few-shot named entity recognition,</strong> in ACL-IJCNLP, 2021. <em>M. Tong, S. Wang, B. Xu, Y. Cao, M. Liu, L. Hou, and J. Li.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.487.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/shuaiwa16/OtherClassNER.git">code</a></li>
<li><strong>Distinct label representations for few-shot text classification,</strong> in ACL-IJCNLP, 2021. <em>S. Ohashi, J. Takayama, T. Kajiwara, and Y. Arase.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.105.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/21335732529sky/difference_extractor">code</a></li>
<li><strong>Entity concept-enhanced few-shot relation extraction,</strong> in ACL-IJCNLP, 2021. <em>S. Yang, Y. Zhang, G. Niu, Q. Zhao, and S. Pu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.124.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/LittleGuoKe/ConceptFERE">code</a></li>
<li><strong>On training instance selection for few-shot neural text generation,</strong> in ACL-IJCNLP, 2021. <em>E. Chang, X. Shen, H.-S. Yeh, and V. Demberg.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.2.pdf">paper</a> <a target="_blank" rel="noopener" href="https://gitlab.com/erniecyc/few-selector">code</a></li>
<li><strong>Unsupervised neural machine translation for low-resource domains via meta-learning,</strong> in ACL-IJCNLP, 2021. <em>C. Park, Y. Tae, T. Kim, S. Yang, M. A. Khan, L. Park, and J. Choo.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.225.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/papago-lab/MetaGUMT">code</a></li>
<li><strong>Meta-learning with variational semantic memory for word sense disambiguation,</strong> in ACL-IJCNLP, 2021. <em>Y. Du, N. Holla, X. Zhen, C. Snoek, and E. Shutova.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.409.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/YDU-uva/VSM_WSD">code</a></li>
<li><strong>Multi-label few-shot learning for aspect category detection,</strong> in ACL-IJCNLP, 2021. <em>M. Hu, S. Z. H. Guo, C. Xue, H. Gao, T. Gao, R. Cheng, and Z. Su.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.495.pdf">paper</a></li>
<li><strong>TextSETTR: Few-shot text style extraction and tunable targeted restyling,</strong> in ACL-IJCNLP, 2021. <em>P. Rileya, N. Constantb, M. Guob, G. Kumarc, D. Uthusb, and Z. Parekh.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.293.pdf">paper</a></li>
<li><strong>Few-shot text ranking with meta adapted synthetic weak supervision,</strong> in ACL-IJCNLP, 2021. <em>S. Sun, Y. Qian, Z. Liu, C. Xiong, K. Zhang, J. Bao, Z. Liu, and P. Bennett.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.390.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/thunlp/MetaAdaptRank">code</a></li>
<li><strong>PROTAUGMENT: Intent detection meta-learning through unsupervised diverse paraphrasing,</strong> in ACL-IJCNLP, 2021. <em>T. Dopierre, C. Gravier, and W. Logerais.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.191.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/tdopierre/ProtAugment">code</a></li>
<li><strong>AUGNLG: Few-shot natural language generation using self-trained data augmentation,</strong> in ACL-IJCNLP, 2021. <em>X. Xu, G. Wang, Y.-B. Kim, and S. Lee.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.95.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/XinnuoXu/AugNLG">code</a></li>
<li><strong>Meta self-training for few-shot neural sequence labeling,</strong> in KDD, 2021. <em>Y. Wang, S. Mukherjee, H. Chu, Y. Tu, M. Wu, J. Gao, and A. H. Awadallah.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467235">paper</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/MetaST">code</a></li>
<li><strong>Knowledge-enhanced domain adaptation in few-shot relation classification,</strong> in KDD, 2021. <em>J. Zhang, J. Zhu, Y. Yang, W. Shi, C. Zhang, and H. Wang.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467438">paper</a> <a target="_blank" rel="noopener" href="https://github.com/imJiawen/KEFDA">code</a></li>
<li><strong>Few-shot text classification with triplet networks, data augmentation, and curriculum learning,</strong> in NAACL-HLT, 2021. <em>J. Wei, C. Huang, S. Vosoughi, Y. Cheng, and S. Xu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.434.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/jasonwei20/triplet-loss">code</a></li>
<li><strong>Few-shot intent classification and slot filling with retrieved examples,</strong> in NAACL-HLT, 2021. <em>D. Yu, L. He, Y. Zhang, X. Du, P. Pasupat, and Q. Li.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.59.pdf">paper</a></li>
<li><strong>Non-parametric few-shot learning for word sense disambiguation,</strong> in NAACL-HLT, 2021. <em>H. Chen, M. Xia, and D. Chen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.142.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/princeton-nlp/metric-wsd">code</a></li>
<li><strong>Towards few-shot fact-checking via perplexity,</strong> in NAACL-HLT, 2021. <em>N. Lee, Y. Bang, A. Madotto, and P. Fung.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.158.pdf">paper</a></li>
<li><strong>ConVEx: Data-efficient and few-shot slot labeling,</strong> in NAACL-HLT, 2021. <em>M. Henderson, and I. Vulic.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.264.pdf">paper</a></li>
<li><strong>Few-shot text generation with natural language instructions,</strong> in EMNLP, 2021. <em>T. Schick, and H. Schütze.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.32.pdf">paper</a></li>
<li><strong>Towards realistic few-shot relation extraction,</strong> in EMNLP, 2021. <em>S. Brody, S. Wu, and A. Benton.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.433.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/bloomberg/emnlp21_fewrel">code</a></li>
<li><strong>Few-shot emotion recognition in conversation with sequential prototypical networks,</strong> in EMNLP, 2021. <em>G. Guibon, M. Labeau, H. Flamein, L. Lefeuvre, and C. Clavel.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.549.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/gguibon/protoseq">code</a></li>
<li><strong>Learning prototype representations across few-shot tasks for event detection,</strong> in EMNLP, 2021. <em>V. Lai, F. Dernoncourt, and T. H. Nguyen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.427.pdf">paper</a></li>
<li><strong>Exploring task difficulty for few-shot relation extraction,</strong> in EMNLP, 2021. <em>J. Han, B. Cheng, and W. Lu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.204.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/hanjiale/hcrp">code</a></li>
<li><strong>Honey or poison? Solving the trigger curse in few-shot event detection via causal intervention,</strong> in EMNLP, 2021. <em>J. Chen, H. Lin, X. Han, and L. Sun.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.637.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/chen700564/causalfsed">code</a></li>
<li><strong>Nearest neighbour few-shot learning for cross-lingual classification,</strong> in EMNLP, 2021. <em>M. S. Bari, B. Haider, and S. Mansour.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.131.pdf">paper</a></li>
<li><strong>Knowledge-aware meta-learning for low-resource text classification,</strong> in EMNLP, 2021. <em>H. Yao, Y. Wu, M. Al-Shedivat, and E. P. Xing.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.136.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/huaxiuyao/KGML">code</a></li>
<li><strong>Few-shot named entity recognition: An empirical baseline study,</strong> in EMNLP, 2021. <em>J. Huang, C. Li, K. Subudhi, D. Jose, S. Balakrishnan, W. Chen, B. Peng, J. Gao, and J. Han.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.813.pdf">paper</a></li>
<li><strong>MetaTS: Meta teacher-student network for multilingual sequence labeling with minimal supervision,</strong> in EMNLP, 2021. <em>Z. Li, D. Zhang, T. Cao, Y. Wei, Y. Song, and B. Yin.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.255.pdf">paper</a></li>
<li><strong>Meta-LMTC: Meta-learning for large-scale multi-label text classification,</strong> in EMNLP, 2021. <em>R. Wang, X. Su, S. Long, X. Dai, S. Huang, and J. Chen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.679.pdf">paper</a></li>
</ol>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E6%A0%B7%E6%9C%AC/">小样本</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/">小样本</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-09  <a class="commentCountImg" href="/2021/12/09/autotokenizer/#comment-container"><span class="display-none-class">d811ccb886d4564a5d237abcea635e61</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d811ccb886d4564a5d237abcea635e61">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/09/autotokenizer/">AutoTokenizer和BertTokenizer区别</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/issues/5587">https://github.com/huggingface/transformers/issues/5587</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E5%B8%AE%E6%89%8B/">小帮手</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/AutoTokenizer/">AutoTokenizer</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-09  <a class="commentCountImg" href="/2021/12/09/python_succed/#comment-container"><span class="display-none-class">41f67037ea30c74d9a64aaffd980fe99</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="41f67037ea30c74d9a64aaffd980fe99">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/09/python_succed/">继承</a></h1><div class="content"><h2 id="1-继承"><a href="#1-继承" class="headerlink" title="1 继承"></a>1 继承</h2><p>子没有重写，则继承父</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class A:</span><br><span class="line">    x=1</span><br><span class="line">class B(A):</span><br><span class="line">    pass</span><br><span class="line">class C(A):</span><br><span class="line">    pass</span><br><span class="line">B.x=2</span><br><span class="line">print(A.x,B.x,C.x)</span><br><span class="line">A.x=3</span><br><span class="line">print(A.x,B.x,C.x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1 2 1</span><br><span class="line">3 2 3</span><br></pre></td></tr></table></figure>
<h2 id="2-super"><a href="#2-super" class="headerlink" title="2 super"></a>2 super</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40734030/article/details/122861895">https://blog.csdn.net/weixin_40734030/article/details/122861895</a></p>
<p>目的：使得子类初始化的时候调用父类的init</p>
<p>例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class test1:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.a=1</span><br><span class="line"></span><br><span class="line">class test2(test1):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(test2, self).__init__()</span><br><span class="line">        self.b=2</span><br><span class="line"></span><br><span class="line">tt=test2()</span><br><span class="line"># print(tt.a)</span><br><span class="line">print(tt.b)</span><br><span class="line">print(tt.a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2</span><br><span class="line">1</span><br><span class="line">############################</span><br><span class="line">class test1:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.a=1</span><br><span class="line"></span><br><span class="line">class test2(test1):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # super(test2, self).__init__()</span><br><span class="line">        self.b=2</span><br><span class="line"></span><br><span class="line">tt=test2()</span><br><span class="line"># print(tt.a)</span><br><span class="line">print(tt.b)</span><br><span class="line">print(tt.a)</span><br><span class="line"></span><br><span class="line">2</span><br><span class="line">AttributeError: &#x27;test2&#x27; object has no attribute &#x27;a&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">class pointwise_hybird_contrasive(hybird):</span><br><span class="line">    def __init__(self,config_roberta, path,num):</span><br><span class="line">        super(pointwise_hybird_contrasive, self).__init__(config_roberta, path,num)</span><br><span class="line">super(pointwise_hybird_contrasive, self).\__init\__(config_roberta, path,num)就是对父类hybird的属性进行初始化</span><br></pre></td></tr></table></figure>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/python/">python</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E7%BB%A7%E6%89%BF/">继承</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-09  <a class="commentCountImg" href="/2021/12/09/torch-normal/#comment-container"><span class="display-none-class">8b5797ab7deb9d62dbfec54f2659ac6b</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="8b5797ab7deb9d62dbfec54f2659ac6b">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/09/torch-normal/">pytorch常见操作</a></h1><div class="content"><h2 id="1-pytorch中对tensor操作"><a href="#1-pytorch中对tensor操作" class="headerlink" title="1 pytorch中对tensor操作"></a>1 pytorch中对tensor操作</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/HailinPan/article/details/109818774">https://blog.csdn.net/HailinPan/article/details/109818774</a></p>
<h2 id="2-模型加载"><a href="#2-模型加载" class="headerlink" title="2 模型加载"></a>2 模型加载</h2><p>1 model.load_state_dict(torch.load(path))</p>
<p>2 model=BertModel.from_pretrained</p>
<p>后者的底层为前者</p>
<p>用法不同，前者model为一个对象，然后用load_state_dict加载权重；后者BertModel为一个类，然后用from_pretrained创建对象并加载权重</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/pytorch/">pytorch</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/pytorch%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/">pytorch常见操作</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-07  <a class="commentCountImg" href="/2021/12/07/huggingface/#comment-container"><span class="display-none-class">9432b49a79086904a621b6c0f4f85c94</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="9432b49a79086904a621b6c0f4f85c94">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/07/huggingface/">huggingface</a></h1><div class="content"><p>NLP小帮手，huggingface的transformer</p>
<p>git： <a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p>paper： <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.03771v5">https://arxiv.org/abs/1910.03771v5</a></p>
<p>整体结构</p>
<p><img src="/2021/12/07/huggingface/11.JPG" alt></p>
<p>简单教程：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44614687/article/details/106800244">https://blog.csdn.net/weixin_44614687/article/details/106800244</a></p>
<h2 id="from-pretrained"><a href="#from-pretrained" class="headerlink" title="from_pretrained"></a>from_pretrained</h2><p> 底层为load_state_dict</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Some weights of the model checkpoint at ../../../../test/data/chinese-roberta-wwm-ext were not used when initializing listnet_bert: [&#x27;cls.predictions.transform.dense.weight&#x27;, &#x27;cls.seq_relationship.bias&#x27;, &#x27;cls.predictions.transform.dense.bias&#x27;, &#x27;cls.predictions.decoder.weight&#x27;, &#x27;cls.predictions.transform.LayerNorm.bias&#x27;, &#x27;cls.seq_relationship.weight&#x27;, &#x27;cls.predictions.bias&#x27;, &#x27;cls.predictions.transform.LayerNorm.weight&#x27;]</span><br><span class="line">- This IS expected if you are initializing listnet_bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span><br><span class="line">- This IS NOT expected if you are initializing listnet_bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</span><br><span class="line">Some weights of listnet_bert were not initialized from the model checkpoint at ../../../../test/data/chinese-roberta-wwm-ext and are newly initialized: [&#x27;Linear2.weight&#x27;, &#x27;Linear1.weight&#x27;, &#x27;Linear1.bias&#x27;, &#x27;Linear2.bias&#x27;]</span><br><span class="line">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">两部分：1 加载的预训练模型中有参数没有用到  2 自己的模型有参数没有初始化</span><br><span class="line">finetune的时候报这个 很正常</span><br><span class="line">predict的时候应该不会有</span><br></pre></td></tr></table></figure>
<h2 id="关于model"><a href="#关于model" class="headerlink" title="关于model"></a>关于model</h2><p>BertModel -&gt; our model </p>
<p>1 加载transformers中的模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from transformers import BertPreTrainedModel, BertModel,AutoTokenizer,AutoConfig</span><br></pre></td></tr></table></figure>
<p>2  基于1中的模型搭建自己的结构</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E5%B8%AE%E6%89%8B/">小帮手</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/huggingface/">huggingface</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-07  <a class="commentCountImg" href="/2021/12/07/forward/#comment-container"><span class="display-none-class">f8fa3be661233b441ec54e38baa7b1cf</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="f8fa3be661233b441ec54e38baa7b1cf">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/07/forward/">pytorch中模型的forward方法是如何被自动调用的</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41912543/article/details/108147378">https://blog.csdn.net/weixin_41912543/article/details/108147378</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/pytorch/">pytorch</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/forward/">forward</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-06  <a class="commentCountImg" href="/2021/12/06/transformer-xl/#comment-container"><span class="display-none-class">3d8bcf90c1ebc82a648361c567d855a6</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3d8bcf90c1ebc82a648361c567d855a6">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.4 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/06/transformer-xl/">Transformer-XL  Attentive Language Models Beyond a Fixed-Length Context</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<p>Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling ( memory and computation受限，长度不可能很大 ).  propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence.</p>
<h2 id="3-Model"><a href="#3-Model" class="headerlink" title="3 Model"></a>3 Model</h2><h3 id="3-1-Vanilla-Transformer-Language-Models"><a href="#3-1-Vanilla-Transformer-Language-Models" class="headerlink" title="3.1 Vanilla Transformer Language Models"></a>3.1 Vanilla Transformer Language Models</h3><p><img src="/2021/12/06/transformer-xl/1.JPG" alt></p>
<p>问题：In order to apply Transformer or self-attention to language modeling, the central problem is how to train a Transformer to effectively encode an arbitrarily long context into a fixed size representation.通常做法为vanilla model。 vanilla model就是说把长文本分隔成固定长度的seg来处理，如上图。</p>
<p>During  training，There are two critical limitations of using a fixed length context. First, the largest possible dependency length is upper bounded by the segment length. Second. simply chunking a sequence into fixed-length segments will lead to the context fragmentation problem</p>
<p>During evaluation, As shown in Fig. 1b, this procedure ensures that each prediction utilizes the longest possible context exposed during training, and also relieves context fragmentation issue encountered in training. However, this evaluation procedure is extremely expensive.</p>
<h3 id="3-2-Segment-Level-Recurrence-with-State-Reuse"><a href="#3-2-Segment-Level-Recurrence-with-State-Reuse" class="headerlink" title="3.2 Segment-Level Recurrence with State Reuse"></a>3.2 Segment-Level Recurrence with State Reuse</h3><p> introduce a <strong>recurrence mechanism</strong> to the Transformer architecture.</p>
<p>定义变量</p>
<p><img src="/2021/12/06/transformer-xl/2.JPG" alt></p>
<p>转换过程</p>
<p><img src="/2021/12/06/transformer-xl/3.JPG" alt></p>
<p>SG(） stands for stop-gradient，$\circ$ 表示矩阵拼接</p>
<p>具体过程如下图</p>
<p><img src="/2021/12/06/transformer-xl/4.JPG" alt></p>
<p>During training, the hidden state sequence computed for the previous segment is fixed and cached to be reused as an extended context when the model processes the next new segment, as shown in Fig. 2a.</p>
<p>during evaluation, the representations from the previous segments can be reused instead of being computed from scratch as in the case of the vanilla model.</p>
<h3 id="3-3-Relative-Positional-Encodings"><a href="#3-3-Relative-Positional-Encodings" class="headerlink" title="3.3 Relative Positional Encodings"></a>3.3 Relative Positional Encodings</h3><p>how can we keep the positional information coherent when we reuse the states? 如果保留原来的位置编码形式，可以得到如下</p>
<p><img src="/2021/12/06/transformer-xl/5.JPG" alt></p>
<p>这种方式存在问题：</p>
<p><img src="/2021/12/06/transformer-xl/9.JPG" alt></p>
<p>为了解决这个问题提出了relative positional information。</p>
<p>standard Transformer</p>
<p><img src="/2021/12/06/transformer-xl/6.JPG" alt></p>
<p>we propose</p>
<p><img src="/2021/12/06/transformer-xl/7.JPG" alt></p>
<h3 id="3-4-完整算法流程"><a href="#3-4-完整算法流程" class="headerlink" title="3.4 完整算法流程"></a>3.4 完整算法流程</h3><p><img src="/2021/12/06/transformer-xl/8.JPG" alt></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8/">特征提取器</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/Transformer-XL/">Transformer-XL</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-02  <a class="commentCountImg" href="/2021/12/02/hcan/#comment-container"><span class="display-none-class">3583958f6b3e83c8267c2cca0140962f</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3583958f6b3e83c8267c2cca0140962f">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/02/hcan/">Bridging the Gap Between Relevance Matching and Semantic Matching for Short Text Similarity Modeling</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://cs.uwaterloo.ca/~jimmylin/publications/Rao_etal_EMNLP2019.pdf">https://cs.uwaterloo.ca/~jimmylin/publications/Rao_etal_EMNLP2019.pdf</a></p>
<h2 id="2-HCAN-Hybrid-Co-Attention-Network"><a href="#2-HCAN-Hybrid-Co-Attention-Network" class="headerlink" title="2 HCAN: Hybrid Co-Attention Network"></a>2 HCAN: Hybrid Co-Attention Network</h2><p><img src="/2021/12/02/hcan/11.JPG" alt></p>
<p>three major components: (1) a hybrid encoder (2) a relevance matching module (3) a semantic matching module</p>
<h3 id="2-1-Hybrid-Encoders"><a href="#2-1-Hybrid-Encoders" class="headerlink" title="2.1 Hybrid Encoders"></a>2.1 Hybrid Encoders</h3><p>hybrid encoder module that explores three types of encoders: <strong>deep, wide, and contextual</strong></p>
<p>query and context words :$\{w_1^q,w_2^q,…,w_n^q\},\{w_1^c,w_2^c,…,w_m^c\}$, embedding representations $\textbf{Q}\in \mathbb{R}^{n\times L},\textbf{C}\in \mathbb{R}^{m\times L}$</p>
<p><strong>Deep Encoder</strong></p>
<p><img src="/2021/12/02/hcan/2.JPG" alt></p>
<p>$\textbf{U}$表示$\textbf{Q},\textbf{C}$</p>
<p><strong>Wide Encoder</strong></p>
<p>Unlike the deep encoder that stacks multiple convolutional layers hierarchically, the wide encoder organizes convolutional layers in parallel, with each convolutional layer having a different window size k</p>
<p><strong>Contextual Encoder</strong></p>
<p><img src="/2021/12/02/hcan/3.JPG" alt></p>
<h3 id="2-2-Relevance-Matching"><a href="#2-2-Relevance-Matching" class="headerlink" title="2.2 Relevance Matching"></a>2.2 Relevance Matching</h3><p><img src="/2021/12/02/hcan/4.JPG" alt></p>
<p><img src="/2021/12/02/hcan/5.JPG" alt></p>
<p><img src="/2021/12/02/hcan/6.JPG" alt></p>
<h3 id="2-3-Semantic-Matching"><a href="#2-3-Semantic-Matching" class="headerlink" title="2.3 Semantic Matching"></a>2.3 Semantic Matching</h3><p><img src="/2021/12/02/hcan/7.JPG" alt></p>
<p><img src="/2021/12/02/hcan/8.JPG" alt></p>
<p><img src="/2021/12/02/hcan/9.JPG" alt></p>
<h3 id="2-4-Final-Classification"><a href="#2-4-Final-Classification" class="headerlink" title="2.4 Final Classification"></a>2.4 Final Classification</h3><p><img src="/2021/12/02/hcan/12.JPG" alt></p>
<p><img src="/2021/12/02/hcan/10.JPG" alt></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/">文本匹配</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/hcan-Hybrid-Co-Attention-Network/">hcan(Hybrid Co-Attention Network)</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-11-30  <a class="commentCountImg" href="/2021/11/30/text-classifying/#comment-container"><span class="display-none-class">a8dd0c79b98cafd5914c0f5bcfcc136d</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="a8dd0c79b98cafd5914c0f5bcfcc136d">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/11/30/text-classifying/">中文文本分类工具</a></h1><div class="content"><p>感谢大佬开源</p>
<p><a target="_blank" rel="noopener" href="https://github.com/649453932/Chinese-Text-Classification-Pytorch">https://github.com/649453932/Chinese-Text-Classification-Pytorch</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E5%B8%AE%E6%89%8B/">小帮手</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">中文文本分类</a></div><hr></div></article></div><!--!--><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/27/">Previous</a></div><div class="pagination-next"><a href="/page/29/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/27/">27</a></li><li><a class="pagination-link is-current" href="/page/28/">28</a></li><li><a class="pagination-link" href="/page/29/">29</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/41/">41</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">405</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">141</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">386</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:58:45.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/gray-test/">灰度测试</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> / <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:53:30.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/abtest/">abtest</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> / <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:51:45.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/diff/">diff评测</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:44:10.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/seach-evluation/">搜索系统评价指标</a></p><p class="categories"><a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a> / <a href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-10T16:29:10.000Z">2024-04-11</time></p><p class="title"><a href="/2024/04/11/nlp_evalution/">NLP评价指标</a></p><p class="categories"><a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/NLP/">NLP</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/LTR/LTR/"><span class="level-start"><span class="level-item">LTR</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/listwise/"><span class="level-start"><span class="level-item">listwise</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pairwise/"><span class="level-start"><span class="level-item">pairwise</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/pointwise/"><span class="level-start"><span class="level-item">pointwise</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/LTR/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96/"><span class="tag">优化</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIEN/"><span class="tag">DIEN</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2024 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>