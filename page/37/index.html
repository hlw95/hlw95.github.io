<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-29  <a class="commentCountImg" href="/2021/08/29/prior-Posterior/#comment-container"><span class="display-none-class">3dd0c522f612523fd1463e04899e1be2</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3dd0c522f612523fd1463e04899e1be2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/prior-Posterior/">先验概率与后验概率</a></h1><div class="content"><p>$P(X=玩 lol)=0.6；P(X=不玩lol)=0.4$，这个概率是统计得到的,或者你自身依据经验给出的一个概率值，我们称其为<strong>先验概率(prior probability)</strong>；</p>
<p>$P(X=玩lol|Y=男性)$称之为$X$的<strong>后验概率</strong>，即它获得是在观察到事件$Y=男性$发生后得到的</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26464206">https://zhuanlan.zhihu.com/p/26464206</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/">概率统计</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-27  <a class="commentCountImg" href="/2021/08/27/xlnet/#comment-container"><span class="display-none-class">1938a114a2321582b8811dce19579c75</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1938a114a2321582b8811dce19579c75">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/27/xlnet/">XLNet Generalized Autoregressive Pretraining for Language Understanding</a></h1><div class="content"><h2 id="1-主要改动"><a href="#1-主要改动" class="headerlink" title="1 主要改动"></a>1 主要改动</h2><p>relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy.</p>
<p>propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation.  (3) , XLNet integrates ideas from Transformer-XL</p>
<p>example：[New, York, is, a, city] . select the two tokens [New, York] as the prediction targets and maximize log p （New York | is a city）</p>
<p>In this case, BERT and XLNet respectively reduce to the following objectives:</p>
<p><img src="/2021/08/27/xlnet/2.JPG" alt></p>
<h2 id="2-现有PTM的问题"><a href="#2-现有PTM的问题" class="headerlink" title="2 现有PTM的问题"></a>2 现有PTM的问题</h2><p><strong>1 AR language modeling</strong></p>
<p>对于给定的句子$\textbf{x}=[x_1,…,x_T]$，AR language modeling performs pretraining by maximizing the likelihood under the forward autoregressive factorization</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \quad logp_{\theta}(\textbf{x})=\sum_{t=1}^{T}logp_{\theta}(x_t|\textbf{x}_{<t})=\sum_{t=1}^{T} log\frac{e^{h_{\theta}(\textbf{x}_{1:t-1})^\top e(x_t)}}{\sum_{x^{'}} e^{h_{\theta}(\textbf{x}_{1:t-1})^\top e(x^{'})}}  \tag{1}</script><p>其中$h_{\theta}(\textbf{x}_{1:t-1})$是考虑上下文的文本表示，$e(x_t)$为$x_t$的词向量</p>
<p><strong>2 AE anguage modeling</strong></p>
<p>对于BERT这种AE模型，首先利用$\textbf{x}$构造遮盖的tokens$\overline{\textbf{x}}$和未遮盖的tokens$\hat{\textbf{x}}$，然后the training objective is to reconstruct $\overline{\textbf{x}}$ from $\hat{\textbf{x}}$:</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \quad logp_{\theta}(\overline{\textbf{x}}\ |\ \hat{\textbf{x}})\approx \sum_{t=1}^{T}m_tlogp_{\theta}(x_t\ |\ \hat{\textbf{x}})=\sum_{t=1}^{T} \ m_t log \frac{e^{H_{\theta}(\hat{\textbf{x}})_t^\top e(x_t)}}{\sum_{x^{'}}e^{H_{\theta}(\hat{\textbf{x}})_t^\top e(x^{'})}} \tag{2}</script><p>其中$m_t=1$表示$x_t$被遮盖了，AR语言模型$t$时刻只能看到之前的时刻，因此记号是$h_{\theta}(\textbf{x}_{1:t-1})$；而AE模型可以同时看到整个句子的所有Token，因此记号是$H_{\theta}(\hat{\textbf{x}})_t$</p>
<p>这两个模型的优缺点分别为：</p>
<p><strong>3 对比</strong></p>
<p>1.AE因为遮盖词只是假设相互独立不是严格相互独立，因此为$\approx$。</p>
<p>2.AE在预训练时会出现特殊的token为[MASK]，但是它在下游的fine-tuning中不会出现，这就出现了预训练 — finetune的不一致问题。而AR语言模型不会有这个问题。</p>
<p>3.AR语言模型只能参考一个方向的上下文，而AE可以参考双向的上下文。</p>
<h2 id="3-改动"><a href="#3-改动" class="headerlink" title="3 改动"></a>3 改动</h2><h3 id="3-1-排列语言模型"><a href="#3-1-排列语言模型" class="headerlink" title="3.1 排列语言模型"></a>3.1 排列语言模型</h3><p>we propose the permutation language modeling objective that not only retains the benefits of AR models but also allows models to capture bidirectional context</p>
<p>给定长度为$T$的序列，总共有$T!$种排列方法。注意输入顺序是不会变的，因为模型在微调期间只会遇到具有自然顺序的文本序列。作者就是通<strong>Attention Mask</strong>，把其它没有被选到的单词Mask掉，不让它们在预测单词$x_i$的时候发生作用，看着就类似于把这些被选中的单词放到了上文。</p>
<p>举个例子，如下图，输入序列为$\{x_1,x_2,x_3,x_4\}$，总共有4!，24种情况，作者取了其中4个。假如预测$x_3$，第一个排列为$x_3 \rightarrow x_2 \rightarrow x_4 \rightarrow x_1 $，没有排在$x_3$前面对象，所以只连接了mem，对于真实情况就是输入还是$x_1 \rightarrow x_2 \rightarrow x_3 \rightarrow x_4 $，然后mask掉全部输入，即只利用mem预测$ x_3 $；第二个排列为$x_2 \rightarrow x_4 \rightarrow x_3 \rightarrow x_1 $，$x_2,x_4$排在$x_3$前面，所以连接了$x_2,x_4$对应的向量表示，对于真实情况就是输入还是$x_1 \rightarrow x_2 \rightarrow x_3 \rightarrow x_4 $，然后mask掉$x_1,x_3$，剩余$x_2,x_4$，即利用mem，$x_2,x_4$预测$ x_3 $。</p>
<p><img src="/2021/08/27/xlnet/22.JPG" alt></p>
<p>排列语言模型的目标是调整模型参数使得下面的似然概率最大</p>
<script type="math/tex; mode=display">
\max \limits_{\theta} \ \mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[\sum_{t=1}^Tlogp_{\theta}(x_{z_t}|\textbf{x}_{\textbf{z}_{<t}})] \tag{3}</script><p>其中$\textbf{z}$为随机变量，表示某个位置排列，$\mathcal{Z}_T$表示全部的排列，$z_t$，$\textbf{z}_{&lt;t}$分别表示某个位置排列的第$t$个元素和与其挨着的前面$t-1$个元素。</p>
<h3 id="3-2-Two-Stream-Self-Attention"><a href="#3-2-Two-Stream-Self-Attention" class="headerlink" title="3.2 Two-Stream Self-Attention"></a>3.2 Two-Stream Self-Attention</h3><p><strong>Target-Aware Representations</strong></p>
<p>采用AE原来的表达形式来描述下一个token的分布$p_{\theta}(X_{z_t}|\textbf{x}_{\textbf{z}_{&lt;t}})$如下</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t}=x|\textbf{x}_{\textbf{z}_{<t}})= \frac{e^{ e(x)^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}{\sum_{x^{'}} e^{ e(x^{'})^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}</script><p>这样表达有一个问题就是没有考虑预测目标词的位置，即没有考虑$ z_t$，这会导致ambiguity in target prediction。证明如下：假设有两个不同的排列$\textbf{z}^{(1)}$和$\textbf{z}^{(2)}$，并且满足如下关系：</p>
<script type="math/tex; mode=display">
\textbf{z}^{(1)}_{<t}=\textbf{z}^{(2)}_{<t}=\textbf{z}_{<t} \ but \ {z}^{(1)}_{t}\neq{z}^{(2)}_{t}</script><p>可以推导出</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t^{(1)}}=x|\textbf{x}_{\textbf{z}_{<t}^{(1)}})=p_{\theta}(X_{z_t^{(2)}}=x|\textbf{x}_{\textbf{z}_{<t}^{(2)}})=\frac{e^{ e(x)^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}{\sum_{x^{'}} e^{ e(x^{'})^\top h_{\theta}(\textbf{x}_{\textbf{z}_{<t}})}}</script><p>但是$p_{\theta}(X_{z_t^{(1)}}=x|\textbf{x}_{\textbf{z}_{&lt;t}^{(1)}}),p_{\theta}(X_{z_t^{(2)}}=x|\textbf{x}_{\textbf{z}_{&lt;t}^{(2)}})$应该不一样，因为目标词的位置不同</p>
<p>为了解决这个问题，提出了Target-Aware Representations，其实就是考虑了目标词的位置</p>
<script type="math/tex; mode=display">
p_{\theta}(X_{z_t}=x|\textbf{x}_{\textbf{z}_{<t}})= \frac{e^{ e(x)^\top g_{\theta}(\textbf{x}_{\textbf{z}_{<t}},z_t)}}{\sum_{x^{'}} e^{ e(x^{'})^\top g_{\theta}(\textbf{x}_{\textbf{z}_{<t}},z_t)}} \tag{4}</script><p><strong>Two-Stream Self-Attention</strong></p>
<p> contradiction</p>
<p><img src="/2021/08/27/xlnet/4.JPG" alt></p>
<p>To resolve such a contradiction，we propose to use two sets of hidden representations instead of one:</p>
<p><img src="/2021/08/27/xlnet/3.JPG" alt></p>
<p>假设有self-attention的层号为$m=1,2,…,M$，$g_i^{(0)}=w$，$h_i^{(0)}=e(x_i)$，Two-Stream Self-Attention可以表示为</p>
<script type="math/tex; mode=display">
g_{z_t}^{(m)}\leftarrow Attention(Q=g_{z_t}^{(m-1)},KV=\textbf{h}^{(m-1)}_{z_{<t}};\theta)
\\h_{z_t}^{(m)}\leftarrow Attention(Q=h_{z_t}^{(m-1)},KV=\textbf{h}^{(m-1)}_{z_{\le t}};\theta)</script><p>举个例子，如下图</p>
<p><img src="/2021/08/27/xlnet/11.JPG" alt></p>
<p>预训练最终使用$g_{z_t}^{(M)}$计算公式（4）,during finetuning, we can simply drop the query stream and use the content stream </p>
<p>during  pretrain， we can use the last-layer query representation $g_{z_t}^{(M)}$  to compute Eq. (4).</p>
<p>during finetuning, we can simply drop the query stream and use the content stream as a normal Transformer(-XL). </p>
<h3 id="3-3-Partial-Prediction"><a href="#3-3-Partial-Prediction" class="headerlink" title="3.3 Partial Prediction"></a>3.3 Partial Prediction</h3><p>因为排序很多，计算量很大，所以需要采样。将$z$分隔成$z_{t_\le c}$和 $z_{t_&gt;c}$，$c$为分隔点，我们选择预测后面的词语，因为后面的词语包含的信息更加丰富。引入超参数$K$调整$c$，使得需要预测$\frac{1}{K}$的词（$\frac{|z|-c}{|z|}\approx\frac{1}{K}$），优化目标为:</p>
<script type="math/tex; mode=display">
\max \limits_{\theta}\mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[logp_{\theta}(\textbf{x}_{\textbf{z}_{>c}}|\textbf{x}_{\textbf{z}_{ \le c}})]=\mathbb{E}_{\textbf{z}\sim \mathcal{Z}_T}[\sum_{t=c+1}^{|\textbf{z}|}logp_{\theta}(x_{z_t}|\textbf{x}_{\textbf{z}_{<t}})]</script><h3 id="3-4-融合Transformer-XL的思想"><a href="#3-4-融合Transformer-XL的思想" class="headerlink" title="3.4 融合Transformer-XL的思想"></a>3.4 融合Transformer-XL的思想</h3><p>We integrate two important techniques in Transformer-XL, namely the relative positional encoding scheme and the segment recurrence mechanism</p>
<p><strong>Relative Segment Encodings</strong></p>
<p><strong>recurrence mechanism</strong></p>
<p><img src="/2021/08/27/xlnet/1.JPG" alt></p>
<h3 id="3-5-Modeling-Multiple-Segments"><a href="#3-5-Modeling-Multiple-Segments" class="headerlink" title="3.5  Modeling Multiple Segments"></a>3.5  Modeling Multiple Segments</h3><p>the input to our model is the same as BERT: [CLS, A, SEP, B, SEP], where “SEP” and “CLS” are two special symbols and “A” and “B” are the two segments. Although we follow the two-segment data format, XLNet-Large does not use the objective of next sentence prediction</p>
<p>BERT that adds an absolute segment embedding，这里采用Relative Segment Encodings</p>
<p>There are two benefits of using relative segment encodings. First, the inductive bias of relative encodings improves generalization [9]. Second, it opens the possibility of finetuning on tasks that have more than two input segments, which is not possible using absolute segment encodings.</p>
<p>这里有个疑问，对于多于两个seg的情况，比如3个seg，输入格式是否变成[CLS, A, SEP, B, SEP,C,SEP]</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/107350079">https://zhuanlan.zhihu.com/p/107350079</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_37947156/article/details/93035607">https://blog.csdn.net/weixin_37947156/article/details/93035607</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/nsw0419/p/12892241.html">https://www.cnblogs.com/nsw0419/p/12892241.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/mantch/archive/2019/09/30/11611554.html">https://www.cnblogs.com/mantch/archive/2019/09/30/11611554.html</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1492776">https://cloud.tencent.com/developer/article/1492776</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/96023284">https://zhuanlan.zhihu.com/p/96023284</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.08237.pdf">https://arxiv.org/pdf/1906.08237.pdf</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/XLNet/">XLNet</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-27  <a class="commentCountImg" href="/2021/08/27/consert/#comment-container"><span class="display-none-class">e6753e8b5df65d65ffd41f2474584eb9</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="e6753e8b5df65d65ffd41f2474584eb9">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>8 m  <i class="fas fa-pencil-alt"> </i>1.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/27/consert/">ConSERT A Contrastive Framework for Self-Supervised Sentence Representation Transfer</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.11741">https://arxiv.org/abs/2105.11741</a></p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html">https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html</a></p>
<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h2><p>首先，BERT其自身导出的句向量（不经过Fine-tune，对所有词向量求平均）会出现“坍缩（Collapse）”现象，即所有的句子都倾向于编码到一个较小的空间区域内，如图。为了解决这个问题，将对比学习结合到finetune过程，借助无标签数据来提升模型的能力。</p>
<p><img src="/2021/08/27/consert/11.JPG" alt></p>
<h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2.原理"></a>2.原理</h2><p>给定一个类似BERT的预训练语言模型$\textbf{M}$，以及从目标领域数据分布中收集的无标签文本语料库$\mathcal{D}$，我们希望通过构建自监督任务在$\mathcal{D}$上对$\textbf{M}$进行Fine-tune，使得Fine-tune后的模型能够在目标任务（文本语义匹配）上表现最好。</p>
<h3 id="2-1-整体框架"><a href="#2-1-整体框架" class="headerlink" title="2.1 整体框架"></a>2.1 整体框架</h3><p><img src="/2021/08/27/consert/22.JPG" alt></p>
<p>模型整体结构如上图所示，主要由三个部分组成</p>
<p>A <strong>data augmentation module</strong> that generates different views for input samples at the token embedding layer.</p>
<p>A <strong>shared BERT encoder</strong> that computes sentence representations for each input text. During training, we use the average pooling of the token embeddings at the last layer to obtain sentence representations.</p>
<p>A <strong>contrastive loss layer</strong> on top of the BERT encoder. It maximizes the agreement between one representation and its corresponding version that is augmented from the same sentence while keeping it distant from other sentence representations in the same batch.</p>
<p>对于任意一个句子输入$x$，得到其对应的两个增强向量$e_i=T_1(x),e_j=T_2(x),e_i,e_j\in \mathbb{R}^{L\times d}$，然后经过shared BERT encoder编码为$r_i,r_j$,其中$T_1,T_2$为不同的数据增强方式，$L$为句子$x$的长度，$d$为隐藏单元的数量。对于每个train step，从$\mathcal{D}$随机选取$N$个样本作为mini-batch，然后得到$2N$个增强样本，使用NT-Xent构造loss为</p>
<script type="math/tex; mode=display">
\mathcal{L}_{i,j}=-log\frac{exp(sim(r_i,r_j)/\tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k\neq i]}exp(sim(r_i,r_k)/\tau)}
\\\mathcal{L}_{con}=\frac{1}{2N}\sum_{(i,j)}\mathcal{L}_{i,j}</script><p>其中$sim(.)$为余弦相似度计算，$\tau$表示temperature，是一个超参数，实验中取0.1,$\mathbb{1}$是指示器，当$k=i$时，值为0。上式分子为正样本，分母为全部（但是基本为负样本，所以可以看成负样本），所以loss变小就是让分子变大，分母变小，也就是让正样本相似度变大，负样本相似度变小</p>
<h3 id="2-2-数据增强策略"><a href="#2-2-数据增强策略" class="headerlink" title="2.2 数据增强策略"></a>2.2 数据增强策略</h3><p><strong>显式生成增强样本</strong>的方法包括：回译、同义词替换、意译等，然而这些方法一方面不一定能保证语义一致。所以考虑了在Embedding层<strong>隐式生成增强样本</strong>的方法。</p>
<p><img src="/2021/08/27/consert/44.JPG" alt></p>
<ul>
<li><p><strong>对抗攻击（Adversarial Attack）</strong>：这一方法通过梯度反传生成对抗扰动，将该扰动加到原本的Embedding矩阵上，就能得到增强后的样本。由于生成对抗扰动需要梯度反传，因此这一数据增强方法仅适用于有监督训练的场景。</p>
</li>
<li><p><strong>打乱词序（Token Shuffling）</strong>：这一方法扰乱输入样本的词序。由于Transformer结构没有“位置”的概念，模型对Token位置的感知全靠Embedding中的Position Ids得到。因此在实现上，我们只需要将Position Ids进行Shuffle即可。</p>
</li>
<li><p><strong>裁剪（Cutoff）</strong></p>
<p>：又可以进一步分为两种：</p>
<ul>
<li>Token Cutoff：随机选取Token，将对应Token的Embedding整行置为零。</li>
<li>Feature Cutoff：随机选取Embedding的Feature，将选取的Feature维度整列置为零。</li>
</ul>
</li>
<li><p><strong>Dropout</strong>：Embedding中的每一个元素都以一定概率置为零，与Cutoff不同的是，该方法并没有按行或者按列的约束。</p>
</li>
</ul>
<h3 id="2-3-融合监督信号"><a href="#2-3-融合监督信号" class="headerlink" title="2.3 融合监督信号"></a>2.3 融合监督信号</h3><p>除了无监督训练以外，作者给出3种进一步融合监督信号的策略，以NLI任务为例：</p>
<script type="math/tex; mode=display">
f=Concat(r_1,r_2,|r_1-r_2|)
\\\mathcal{L}_{ce}=CrossEntropy(Wf+b,y)</script><p><strong>Joint training (joint)</strong>:</p>
<script type="math/tex; mode=display">
\mathcal{L}_{joint}=\mathcal{L}_{ce}+\alpha\mathcal{L}_{con}\ \# on\ NLI
\ dataset</script><p><strong>Supervised training then unsupervised transfer (sup-unsup)</strong>:</p>
<p>first train the model with $\mathcal{L}_{ce}$on NLI dataset, then use $\mathcal{L}_{con}$to finetune it on the target dataset.</p>
<p><strong>Joint training then unsupervised transfer (joint-unsup)</strong>:</p>
<p>first train the model with the $\mathcal{L}_{joint}$on NLI dataset, then use $\mathcal{L}_{con }$to fine-tune it on the target dataset.</p>
<h2 id="3-定性分析"><a href="#3-定性分析" class="headerlink" title="3.定性分析"></a>3.定性分析</h2><p>后又发现BERT句向量表示的坍缩和句子中的高频词有关。具体来说，当通过平均词向量的方式计算句向量时，那些高频词的词向量将会主导句向量，使之难以体现其原本的语义。当计算句向量时去除若干高频词时，坍缩现象可以在一定程度上得到缓解（如图2蓝色曲线所示）。</p>
<p><img src="/2021/08/27/consert/33.JPG" alt></p>
<h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a>4 实验结果</h2><h3 id="4-1-Unsupervised-Results"><a href="#4-1-Unsupervised-Results" class="headerlink" title="4.1 Unsupervised Results"></a>4.1 Unsupervised Results</h3><p><img src="/2021/08/27/consert/1.JPG" alt></p>
<h3 id="4-2-Supervised-Results"><a href="#4-2-Supervised-Results" class="headerlink" title="4.2 Supervised Results"></a>4.2 Supervised Results</h3><p><img src="/2021/08/27/consert/2.JPG" alt></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/">文本表示</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/">文本表示</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-26  <a class="commentCountImg" href="/2021/08/26/gpt/#comment-container"><span class="display-none-class">3521a71f5e83cbc0585d9ef84abedc3f</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3521a71f5e83cbc0585d9ef84abedc3f">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>9 m  <i class="fas fa-pencil-alt"> </i>1.4 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/26/gpt/">gpt</a></h1><div class="content"><p>GPT三部曲宣告NLP的“预训练+微调”时代的崛起和走向辉煌。</p>
<p>原文分别为：</p>
<p>《Improving Language Understanding by Generative Pre-Training》</p>
<p>《Language Models are Unsupervised Multitask Learners》</p>
<p>《Language Models are Few-Shot Learners》</p>
<h2 id="1-GPT1"><a href="#1-GPT1" class="headerlink" title="1.GPT1"></a>1.GPT1</h2><p><img src="/2021/08/26/gpt/aa.jpg" alt></p>
<p><img src="/2021/08/26/gpt/aaa.png" alt="img"></p>
<p>模型的整体结构如上图所示。使用过程过程分为两步：第一步预训练，利用大量语料学习得到high-capacity的语言模型；第二步是fine_tuning，利用标签数据使其拟合到特定任务。</p>
<h3 id="1-1-Unsupervised-pre-training"><a href="#1-1-Unsupervised-pre-training" class="headerlink" title="1.1 Unsupervised pre-training"></a>1.1 Unsupervised pre-training</h3><p>作者将transformer decoder中Encoder-Decoder Attention层去掉后作为基本单元，然后多层堆叠作为语言模型的主体，然后将输出经过一个softmax层，来得到目标词的输出分布：</p>
<script type="math/tex; mode=display">
h_0=UW_e+W_p
\\h_l=transformer\_block(h_{l-1}),\ \forall l \in [1,n]
\\P(u|u_{-k},...,u_{-1})    =softmax(h_nW_e^T)\</script><p>其中$U=\{u_{-k},…,u_{-1}\}$ 是预测词$u $前$k$个token的独热编码序列，$n$是模型的层数，$W_e$是token embedding matrix，$W_p$是position embedding matrix。</p>
<p>给定一个无监督的语料库$\mathcal{U}$，use a standard language modeling objective to maximize the following likelihood</p>
<script type="math/tex; mode=display">
L_1(\mathcal{U})=\sum_ilog P(u_i|u_{i-k},...,u_{i-1})</script><p>其中$k$ 是上下文窗口大小。</p>
<h3 id="1-2-Supervised-fine-tuning"><a href="#1-2-Supervised-fine-tuning" class="headerlink" title="1.2 Supervised fine-tuning"></a>1.2 Supervised fine-tuning</h3><p>对于数据集$\mathcal{C}$，有数据$(x^1,x^2,…,x^m,y)$</p>
<script type="math/tex; mode=display">
P(y|x^1,x^2,...,x^m)=softmax(h_l^mW_y)
\\L_2(\mathcal{C})=\sum_{(x,y)}log P(y|x^1,x^2,...,x^m)</script><p>其中$W_y$为全连接层的参数</p>
<p>作者发现，使用语言模型来辅助监督学习进行微调，有两个好处：</p>
<ol>
<li>提高监督模型的泛化能力；</li>
<li>加速收敛。</li>
</ol>
<p>所以，最终下游使用的监督模型损失函数为：</p>
<script type="math/tex; mode=display">
L_3(\mathcal{C})=L_2(\mathcal{C})+\lambda*L_1(\mathcal{C})</script><h3 id="1-3-Task-specific-input-transformations"><a href="#1-3-Task-specific-input-transformations" class="headerlink" title="1.3 Task-specific input transformations"></a>1.3 Task-specific input transformations</h3><p><img src="/2021/08/26/gpt/gpt1.JPG" alt></p>
<p>所有的输入文本都会加上开始和结合token$(s),(e)$</p>
<p><strong>分类</strong></p>
<p>分类过程可如上1.2，输入表示为$[(s);Context;(e)]$</p>
<p><strong>文本蕴含</strong></p>
<p>将输入拼接成$[(s); premise; ($) ; hypothesis ; (e)]$</p>
<p><strong>相似度</strong></p>
<p>由于文本相似度与两个比较文本的前后顺序没有关系，因此将两种文本顺序都考虑进来，如上图所示</p>
<p><strong>问答与常识推理</strong></p>
<p>假设文档为$z$，问题为$q$，一系列答案为$\{a_k\}$，将其输入表示为$[(s); z; q; ($);  a_k;(e)]$，然后多个回答组合的形式，如上图。</p>
<h2 id="2-GPT2"><a href="#2-GPT2" class="headerlink" title="2.GPT2"></a>2.GPT2</h2><p>总结就是：多任务预训练+超大数据集+超大规模模型。通过一个超大数据集涵盖NLP的大多任务，然后使用一个超大规模模型进行多任务预训练，使其无需任何下游任务的finetune就可以做到多个NLP任务的SOTA。举个例子，拿高考为例，人的智力和脑容量可以理解为参数大小，由于个体差异，可以将不同的学生理解为不同参数量的模型，卷子可以理解为数据集，不同的学科可以理解为不同任务。GPT2有点类似学霸，就是有超高的智力和脑容量，然后刷大量不同学科的题目，因此对高考这个多任务的下游任务就可以取得好成绩。</p>
<p><strong>GPT2相对于GPT1有哪些不同呢？</strong></p>
<ol>
<li><p><strong>GPT2去掉了fine-tuning</strong>：不再针对不同任务分别进行微调建模，模型会自动识别出来需要做什么任务。这就好比一个人博览群书，你问他什么类型的问题，他都可以顺手拈来，GPT2就是这样一个博览群书的模型。</p>
</li>
<li><p><strong>超大数据集</strong>：WebText，该数据集做了一些简单的数据清理，并且实验结果表明目前模型仍然处于一个欠拟合的情况。</p>
</li>
<li><p><strong>增加网络参数</strong>：GPT2将Transformer堆叠的层数增加到48层，隐层的维度为1600，参数量更是达到了15亿。15亿什么概念呢，Bert的参数量也才只有3亿哦~当然，这样的参数量也不是说谁都能达到的，这也得取决于money的多少啊~</p>
</li>
<li><p><strong>调整transformer</strong>：将layer normalization放到每个sub-block之前，并在最后一个transformer后再增加一个layer normalization，如下图。</p>
<p><img src="/2021/08/26/gpt/11.jpg" alt></p>
</li>
<li><p><strong>输入表示</strong>：GPT2采用了BPE这种subword的结构作为输入</p>
</li>
<li><p><strong>其他</strong>：GPT2将词汇表数量增加到50257个；最大的上下文大小 (context size) 从GPT的512提升到了1024 tokens；batchsize增加到512。</p>
</li>
</ol>
<p><strong>GPT2的输入是完全的文本，什么提示都不加吗？</strong></p>
<p>当然不是，它也会加入提示词，比如：$TL;DR:$，GPT2模型就会知道是做摘要工作了，输入的格式就是 $文本+TL;DR:$，然后就等待输出就行了~</p>
<h2 id="3-GPT3"><a href="#3-GPT3" class="headerlink" title="3.GPT3"></a>3.GPT3</h2><p>GPT3，这是一种具有1750亿个参数的超大规模模型，比GPT2大100倍，感觉真是进入算力时代了。距离个人用户太远了，就不深挖了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/146719974">https://zhuanlan.zhihu.com/p/146719974</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/125139937">https://zhuanlan.zhihu.com/p/125139937</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yifanrensheng/p/13167796.html#_label1_0">https://www.cnblogs.com/yifanrensheng/p/13167796.html#_label1_0</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/96c5d5d5c468">https://www.jianshu.com/p/96c5d5d5c468</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35128926/article/details/111399679">https://blog.csdn.net/qq_35128926/article/details/111399679</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/96791725">https://zhuanlan.zhihu.com/p/96791725</a></p>
<p><a target="_blank" rel="noopener" href="https://terrifyzhao.github.io/2019/02/18/GPT2.0论文解读.html">https://terrifyzhao.github.io/2019/02/18/GPT2.0%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/56865533">https://zhuanlan.zhihu.com/p/56865533</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/PTM/">PTM</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-23  <a class="commentCountImg" href="/2021/08/23/text-cnn/#comment-container"><span class="display-none-class">4e2b48a121bb0f97a9742bd9e3cf6e2c</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="4e2b48a121bb0f97a9742bd9e3cf6e2c">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>6 m  <i class="fas fa-pencil-alt"> </i>1.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/23/text-cnn/">TextCNN TextRNN TextRCNN</a></h1><div class="content"><h2 id="1-TextCNN-Convolutional-Neural-Networks-for-Sentence-Classification"><a href="#1-TextCNN-Convolutional-Neural-Networks-for-Sentence-Classification" class="headerlink" title="1.TextCNN (Convolutional Neural Networks for Sentence Classification)"></a>1.TextCNN (Convolutional Neural Networks for Sentence Classification)</h2><p>原文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1408.5882">https://arxiv.org/abs/1408.5882</a></p>
<p>调参论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1510.03820">https://arxiv.org/abs/1510.03820</a></p>
<p><img src="/2021/08/23/text-cnn/textcnn1.JPG" alt></p>
<p><img src="/2021/08/23/text-cnn/1111.JPG" alt></p>
<p>模型的整体结构如上所示。Feature Map是输入图像经过神经网络卷积产生的结果，filter是卷积核。</p>
<p><strong>输入表示：</strong></p>
<p>假设输入文本的长度为$n$，对于长度不够的需要做padding，任意一个单词可以用一个$k$维的向量表示，即$X_i \in \mathbb{R}^{k}$，那么一个句子可以表示为</p>
<script type="math/tex; mode=display">
X_{1:n}=X_1 \oplus X_2\oplus...\oplus X_n</script><p>其中$\oplus$是向量拼接操作，$X_{1:n} \in \mathbb{R}^{nk\times 1}$。</p>
<p><strong>卷积</strong>：</p>
<p>对于某个滑窗$X_{i,i+h-1}=\{X_i,X_{i+1},…,X_{i+h-1}\}$经过某个卷积核$W_j$可得</p>
<script type="math/tex; mode=display">
c_{i,j}=f(W_j\cdot X_{i,i+h-1}+b)</script><p>其中$f=tanh(\cdot)$，$W_j\in \mathbb{R}^{ 1\times hk}，c_{i,j} $是标量</p>
<p>假设卷积通道数为$m$，在NLP中，卷积滑动步伐$k=1$，那么经过卷积层后得到的完整的特征矩阵为</p>
<script type="math/tex; mode=display">
C=[[c_{1,1},c_{2,1},...,c_{n-h+1,1}]^T,[c_{1,2},c_{2,2},...,c_{n-h+1,2}]^T,...,[c_{1,m},c_{2,m},...,c_{n-h+1,m}]^T]</script><p>其中$C \in \mathbb{R}^{(n-h+1)\times m}$</p>
<p><strong>maxpooling</strong>：</p>
<script type="math/tex; mode=display">
\hat{C}=max\{C\} , \hat{C}\in \mathbb{R}^{m}</script><p><strong>全连接</strong>：</p>
<p>然后将$\hat{C}$接个全连接，就可以做分类或者回归任务了。</p>
<h2 id="2-TextRNN-Recurrent-Neural-Network-for-Text-Classification-with-Multi-Task-Learning"><a href="#2-TextRNN-Recurrent-Neural-Network-for-Text-Classification-with-Multi-Task-Learning" class="headerlink" title="2.TextRNN (Recurrent Neural Network for Text Classification with Multi-Task Learning)"></a>2.TextRNN (Recurrent Neural Network for Text Classification with Multi-Task Learning)</h2><p>原文 <a target="_blank" rel="noopener" href="https://www.ijcai.org/Proceedings/16/Papers/408.pdf">https://www.ijcai.org/Proceedings/16/Papers/408.pdf</a></p>
<p><img src="/2021/08/23/text-cnn/textrnn.JPG" alt></p>
<p><img src="/2021/08/23/text-cnn/11.png" alt></p>
<p>该文的场景为Recurrent Neural Network for Text Classification with Multi-Task Learning，就是论文的题目。文中给出了三种结构，如上图所示，图中的RNN单元为LSTM。</p>
<p><strong>Model-I: Uniform-Layer Architecture</strong></p>
<p>对于任务$m$，输入$\hat X_t$包含两个部分</p>
<script type="math/tex; mode=display">
\hat{X}_t^{(m)}=X_{t}^{(m)}\oplus X_{t}^{(s)}</script><p>其中$X_{t}^{(m)}$表示特定任务的词向量，$X_{t}^{(s)}$表示共享的词向量，$\oplus$表示向量拼接的操作。</p>
<p><strong>Model-II: Coupled-Layer Architecture</strong></p>
<script type="math/tex; mode=display">
\hat{c}_t=tanh(W_cX_t+U_ch_{t-1}) \ \#原来
\\\downarrow

\\\hat{c}_t^{(m)}=tanh(W_c^{(m)}X_t+\sum_{i\in\{m,n\}}g^{(i\longrightarrow m)}U_c^{(i\longrightarrow m)}h_{t-1}^{(i)}) \ \#现在
\\g^{(i\longrightarrow m)}=\sigma(W_{g}^{(m)}x_t+U_g^{(i)}h_{t-1}^{(i)})</script><p><strong>Model-III: Shared-Layer Architecture</strong></p>
<script type="math/tex; mode=display">
\hat{c}_t=tanh(W_cX_t+U_ch_{t-1}) \ \#原来
\\\downarrow

\\\hat{c}_t^{(m)}=tanh(W_c^{(m)}X_t+g^{(m)}U_c^{(m)}h_{t-1}^{(m)}+g^{(s\longrightarrow m)}U_c^{(s)}h_{t}^{(s)} \ \#现在
\\g^{( m)}=\sigma(W_{g}^{(m)}x_t+U_g^{(m)}h_{t-1}^{(m)}),
g^{( s\longrightarrow m)}=\sigma(W_{g}^{(m)}x_t+U_g^{(s\longrightarrow m)}h_{t}^{(s)}),
h_t^{(s)}=\overrightarrow{h_t^{(s)}}\oplus\overleftarrow{h_t^{(s)}}</script><h2 id="3-TextRCNN-Recurrent-Convolutional-Neural-Networks-for-Text-Classification"><a href="#3-TextRCNN-Recurrent-Convolutional-Neural-Networks-for-Text-Classification" class="headerlink" title="3.TextRCNN(Recurrent Convolutional Neural Networks for Text Classification)"></a>3.TextRCNN(Recurrent Convolutional Neural Networks for Text Classification)</h2><p>原文 <a target="_blank" rel="noopener" href="https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf">https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf</a></p>
<p><img src="/2021/08/23/text-cnn/textrcnn1.JPG" alt></p>
<p>整体结构如上图所示，解释一下为啥叫RCNN，一般的 CNN 网络，都是卷积层 + 池化层，这里是将卷积层换成了双向 RNN，所以结果是，双向 RNN + 池化层。作者原话为：From the perspective of convolutional neural networks, the recurrent structure we previously mentioned is the convolutional layer.</p>
<p><strong>词语表示</strong></p>
<p>对于一个词语$w_i$，可以用一个三元组表示为</p>
<script type="math/tex; mode=display">
x_i=[c_l(w_i);e(w_i);c_r(w_i)]</script><p>其中$e(w_i)$表示$w_i$的词向量，$c_l(w_i)$表示$w_i$句子左边的内容的向量表示，$c_r(w_i)$表示$w_i$句子右边的内容的向量表示，用式子表示如下</p>
<script type="math/tex; mode=display">
c_l(w_i)=f(W^{l}c_l(w_{i-1})+W^{(sl)}e(w_{i-1}))
\\c_r(w_i)=f(W^{r}c_r(w_{i-1})+W^{(sr)}e(w_{i-1}))</script><p>然后将$x_i$经过全连接得到$y_i^{(2)}$，$y_i^{(2)}$is a latent semantic vector</p>
<script type="math/tex; mode=display">
y_i^{(2)}=tanh(W^{(2)}x_i+b^{(2)})</script><p><strong>语句表示</strong></p>
<p>获取众多的词语表示后，通过max-pooling得到句子表示</p>
<script type="math/tex; mode=display">
y^{(3)}=\mathop{\max}_{i=1}^{n}y_i^{(2)}</script><p>然后接全连接和softmax</p>
<script type="math/tex; mode=display">
y^{(4)}=W^{(4)}y^{(3)}+b^{(4)}
\\p=softmax(y^{(4)})</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangduo/p/6773601.html">https://www.cnblogs.com/wangduo/p/6773601.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">文本分类</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">文本分类</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-21  <a class="commentCountImg" href="/2021/08/21/meituan/#comment-container"><span class="display-none-class">0621e1cfe84648350430593241d756d2</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0621e1cfe84648350430593241d756d2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/21/meituan/">BERT在美团搜索核心排序的探索和实践</a></h1><div class="content"><p>很有启发，抱着学习态度，mark一下</p>
<h2 id="模型层面"><a href="#模型层面" class="headerlink" title="模型层面"></a>模型层面</h2><p>整体结构如下</p>
<p><img src="/2021/08/21/meituan/1.png" alt></p>
<p>1 BERT预训练</p>
<p>2 多任务学习</p>
<p>​    场景层：根据业务场景进行划分，每个业务场景单独设计网络结构</p>
<p>3 联合训练</p>
<p>两个任务分别为：</p>
<p>​    1 相关性任务：相关性+NER（多任务增强相关性）</p>
<p>​    2 排序任务</p>
<p>怎么联合没看出来</p>
<p>之前是两阶段finetune： 1. 先相关性任务 2 然后排序任务</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html">https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html</a> </p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E6%8E%92%E5%BA%8F/">排序</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0/">排序学习</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-19  <a class="commentCountImg" href="/2021/08/19/elmo/#comment-container"><span class="display-none-class">0c9b0086f0310ef439a36d4a03dea104</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0c9b0086f0310ef439a36d4a03dea104">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>5 m  <i class="fas fa-pencil-alt"> </i>0.8 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/19/elmo/">ELMo(Deep contextualized word representations)</a></h1><div class="content"><p>引入了新的深度考虑上下文的词语表示，模型考虑了两个方面：（1）词语的复杂特性，包括语法和语义，（2）在语境中的不同含义。模型使用了深度双向语言模型，并且在大预料库上做了预训练。这个模型可以很方便地和现有的模型结合，并且在NLP的6个任务上取得了SOTA。作者还揭露了预训练网络的深层构件是关键，这使得下游模型能够混合不同类型的半监督信号。</p>
<h2 id="3-ELMo-Embeddings-from-Language-Models"><a href="#3-ELMo-Embeddings-from-Language-Models" class="headerlink" title="3 ELMo: Embeddings from Language Models"></a>3 ELMo: Embeddings from Language Models</h2><p><img src="/2021/08/19/elmo/elmo1.JPG" alt></p>
<p>模型的整体机构如上所示，由左右两个单向的多层LSTM网络构成，左边为正向，右边为反向。</p>
<h3 id="3-1-Bidirectional-language-models（预训练）"><a href="#3-1-Bidirectional-language-models（预训练）" class="headerlink" title="3.1 Bidirectional language models（预训练）"></a>3.1 Bidirectional language models（预训练）</h3><p>假定一个句子有$N$个token，分别为$(t_1,t_2,…,t_N)$，正向的语言模型的句子概率为：</p>
<script type="math/tex; mode=display">
p(t_1,t_2,...,t_N)=\prod_{k=1}^{N}p(t_k|t_1,t_2,...,t_{k-1})</script><p>反向的语言模型的句子概率为：</p>
<script type="math/tex; mode=display">
p(t_1,t_2,...,t_N)=\prod_{k=1}^{N}p(t_k|t_{k+1},t_{k+2},...,t_{N})</script><p>得到正向和反向的语言后，将其结合可以得到双向的语言模型，这里取对数表示为：</p>
<script type="math/tex; mode=display">
\sum_{k=1}^N(log\ p(t_k|t_1,t_2,...,t_{k-1};\Theta_x,\overrightarrow{\Theta}_{LSTM} ,\Theta_s )+log \ p(t_k|t_{k+1},t_{k+2},...,t_{N};\Theta_x,\overleftarrow{\Theta}_{LSTM} ,\Theta_s) )\\</script><p>其中$\Theta_x$为token表示的参数，$\Theta_s$为softmax层的参数，$\overrightarrow{\Theta}_{LSTM}$表示前向语言模型的参数，$\overleftarrow{\Theta}_{LSTM}$表示反向语言模型的参数。</p>
<h3 id="3-2-ELMo（如何表示词向量）"><a href="#3-2-ELMo（如何表示词向量）" class="headerlink" title="3.2 ELMo（如何表示词向量）"></a>3.2 ELMo（如何表示词向量）</h3><p>得到$L$层的预训练双向深度语言模型后，对于token $t_k$，一共包含了$2L+1$个相关的表示，集合如下</p>
<script type="math/tex; mode=display">
R_k=\{x_{k}^{LM},\overrightarrow{h^{LM}_{k,j}},\overleftarrow{h^{LM}_{k,j}}|j=1,2,...,L \}\\=\{h_{k,j}^{LM} | j=0,...,L\}</script><p>注意$h_{k,0}^{LM}=x_{k}^{LM}，h_{k,j}^{LM}=[\overrightarrow{h^{LM}_{k,j}};\overleftarrow{h^{LM}_{k,j}}]$,其中$x_{k}^{LM}$为token表示，$\overrightarrow{h^{LM}_{k,j}},\overleftarrow{h^{LM}_{k,j}}$分别为正反向语言模型的表示</p>
<p>对于下游任务，需要将$2L+1$个表示压缩到一个向量$ELmo_k^{task}$，最简单的做法是只取顶层的表示，即</p>
<script type="math/tex; mode=display">
ELmo_k^{task}=E(R_k)=h_{k,L}^{LM}</script><p>更加通用的做法为线形组合输出，如下图，公式表达为</p>
<script type="math/tex; mode=display">
ELmo_k^{task}=E(R_k,\Theta^{task})=\gamma^{task}\sum_{j=0}^{L}s_{j}^{task}h_{k,j}^{LM}</script><p>其中$\gamma^{task}$用于缩放向量，$s_{j}^{task}$表示权重，通过下游任务学习。</p>
<p><img src="/2021/08/19/elmo/11.jpg" alt></p>
<h3 id="3-3-Using-biLMs-for-supervised-NLP-tasks（fine-tune）"><a href="#3-3-Using-biLMs-for-supervised-NLP-tasks（fine-tune）" class="headerlink" title="3.3 Using biLMs for supervised NLP tasks（fine tune）"></a>3.3 Using biLMs for supervised NLP tasks（fine tune）</h3><p>对于下游任务模型，可以得到不考虑上下文的静态词向量$x_k$和考虑上下文的向量表示$h_k$</p>
<p>对于一部分任务，将$x_k$和$ ELMo_k^{task}$ 拼接作为下游任务的特征：$[x_k;ELMo_k^{task}]$</p>
<p>对于一部分任务，将 $h_k$和 $ ELMo_k^{task}$ 拼接可提升效果：$[h_k;ELMo_k^{task}]$</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/linchuhai/article/details/97170541">https://blog.csdn.net/linchuhai/article/details/97170541</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/63115885">https://zhuanlan.zhihu.com/p/63115885</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/88993965">https://zhuanlan.zhihu.com/p/88993965</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05365">https://arxiv.org/abs/1802.05365</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/PTM/">PTM</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/ELMo/">ELMo</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-18  <a class="commentCountImg" href="/2021/08/18/dssm/#comment-container"><span class="display-none-class">570287b2ff5e99b7d97bfc663dbb86fb</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="570287b2ff5e99b7d97bfc663dbb86fb">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>9 m  <i class="fas fa-pencil-alt"> </i>1.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/18/dssm/">DSSM双塔模型系列</a></h1><div class="content"><p>简单介绍微软出品的DSSM,CNN-DSSM,LSTM-DSSM</p>
<p>原文分别为：</p>
<p>《Learning Deep Structured Semantic Models for Web Search using Clickthrough Data》</p>
<p>《A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval》</p>
<p>《SEMANTIC MODELLING WITH LONG-SHORT-TERM MEMORY FOR INFORMATION RETRIEVAL》</p>
<p>首先为什么叫做双塔，query塔做在线serving，doc塔离线计算embeding建索引，推到线上即可。</p>
<p>注意， DSSM中query和不同的doc是<strong>共享参数</strong>的， <a target="_blank" rel="noopener" href="https://flashgene.com/archives/72820.html">https://flashgene.com/archives/72820.html</a></p>
<h2 id="一-DSSM"><a href="#一-DSSM" class="headerlink" title="一.DSSM"></a>一.DSSM</h2><h3 id="1-1-模型整体结构"><a href="#1-1-模型整体结构" class="headerlink" title="1.1 模型整体结构"></a>1.1 模型整体结构</h3><p><img src="/2021/08/18/dssm/dssm1.JPG" alt></p>
<p>模型的整体结构如上图所示，$Q$为query，$D_i$为文档。</p>
<p>文本的初始词袋表示为$x$，因为参数过多，不利于训练，所以降低维度，就提出了word hashing</p>
<script type="math/tex; mode=display">
l_1=W_1x</script><p>word hashing其实就是利于char n-gram分词，然后用向量表示（只是这里依然用词袋表示向量，而不是稠密向量），如下所示</p>
<p><img src="/2021/08/18/dssm/cnn_dssm4.JPG" alt></p>
<p>这里有个顾虑为是否存在不同的词使用相同的向量表示。关于这个作者做了实验，结果如下。</p>
<p><img src="/2021/08/18/dssm/dssm2.JPG" alt></p>
<p>对于词汇数量500K大小的词表，采用3-gram后，此表压缩到30k，而且重复表示的仅为22个。重复表示率为0.0044%，维度压缩到原来6%，可以说非常有效。</p>
<p>然后为多层的非线性映射，每层都为全连接网络，得到</p>
<script type="math/tex; mode=display">
l_i=f(W_il_{i-1}+b_{i}),i=2,...,N-1\\</script><p>非线性映射层的最后一层得到语义特征$y$为</p>
<script type="math/tex; mode=display">
y=f(W_Nl_{N-1}+b_N)\\
f(x)=tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}</script><p>利用余弦相似度衡量$Q$和$D$相似度得到</p>
<script type="math/tex; mode=display">
R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^Ty_D}{||y_Q||||y_D||}</script><p>最后的概率输出为</p>
<script type="math/tex; mode=display">
P(D|Q)=\frac{e^{\gamma R(Q,D)}}{\sum_{D^{'}\in \textbf{D}}e^{\gamma R(Q,D^{'})}}</script><p>其中$\gamma$为smoothing factor。</p>
<h3 id="1-2-训练"><a href="#1-2-训练" class="headerlink" title="1.2 训练"></a>1.2 训练</h3><p>样本集构造，对每个正样本$(Q,D^+)$，搭配4个随机负样本$(Q,D_j^-;j=1,..,4)$</p>
<p>损失函数为：</p>
<script type="math/tex; mode=display">
L(\wedge)=-log \prod \limits_{(Q,D^+)}P(D^+|Q)</script><p>其中$\wedge$为模型参数。</p>
<h2 id="二-CNN-DSSM"><a href="#二-CNN-DSSM" class="headerlink" title="二.CNN-DSSM"></a>二.CNN-DSSM</h2><h3 id="2-1-CLSM结构"><a href="#2-1-CLSM结构" class="headerlink" title="2.1 CLSM结构"></a>2.1 CLSM结构</h3><p><img src="/2021/08/18/dssm/cnn_dssm1.JPG" alt></p>
<p>模型包括几个部分：(1) a word-n-gram layer obtained by running a contextual sliding window over the input word sequence (2) a letter-trigram layer that transforms each word-trigram into a letter-trigram representation vector (3) a convolutional layer that extracts contextual features for each word with its neighboring words defined by a window (4) a max-pooling layer that discovers and combines salient word-n-gram features to form a fixed-length sentence-level feature vector  (5) a semantic layer that extracts a high-level semantic feature vector for the input word sequence.</p>
<h3 id="2-2-Letter-trigram-based-Word-n-gram-Representation"><a href="#2-2-Letter-trigram-based-Word-n-gram-Representation" class="headerlink" title="2.2 Letter-trigram based Word-n-gram Representation"></a>2.2 Letter-trigram based Word-n-gram Representation</h3><p>在DSSM的Letter-trigram的基础上加了Word-n-gram，Word-n-gram就是对原始输入文本做滑窗，对于第$t$个word-n-gram可以表示为：</p>
<script type="math/tex; mode=display">
l_t=[f^T_{t-d},...,f^T_{t},...,f^T_{t+d}]^T,\ t=1,2,...,T</script><p>其中$n=2d+1,f_t$为的第$t$个词语的letter-trigram。一个letter-trigram的维度为$30K$，那么一个word-n-gram维度为$n\times30K$</p>
<p>举个例子，如上图，输入文本为$(s) \ online \ auto\ body \ (s)$，滑动窗口大小为n=3，可得$(s)\ online \ auto，\ online \ auto  \ body ，auto\  body \ (s)  $，那么</p>
<p>$l_1=[f^T((s)),f^T(online ),f^T(auto)]^T,\\l_2=[f^T(online ),f^T(auto),f^T(body)]^T,\\l_3=[f^T(auto),f^T(body),f^T((s))]^T$</p>
<h3 id="2-3-Modeling-Word-n-gram-Level-Contextual-Features-at-the-Convolutional-Layer"><a href="#2-3-Modeling-Word-n-gram-Level-Contextual-Features-at-the-Convolutional-Layer" class="headerlink" title="2.3 Modeling Word-n-gram-Level Contextual Features at the Convolutional Layer"></a>2.3 Modeling Word-n-gram-Level Contextual Features at the Convolutional Layer</h3><p>语境相关特征向量$h_t$可以表示为：</p>
<script type="math/tex; mode=display">
h_t=tanh(W_c\cdot l_t),\ t=1,...,T</script><p>其中$W_c$为特征转换矩阵，也就是卷积矩阵，对于全部的word n-grams，$W_c$共享。有小伙伴肯定好奇，这不就是全连接吗，和卷积什么关系，俺也疑惑？</p>
<p>下图为作者做的一个实验。</p>
<p><img src="/2021/08/18/dssm/cnn_dssm2.JPG" alt></p>
<h3 id="2-4-Modeling-Sentence-Level-Semantic-Features-Using-Max-Pooling"><a href="#2-4-Modeling-Sentence-Level-Semantic-Features-Using-Max-Pooling" class="headerlink" title="2.4 Modeling Sentence-Level Semantic Features Using Max Pooling"></a>2.4 Modeling Sentence-Level Semantic Features Using Max Pooling</h3><p>获取局部的语境相关的特征向量后，我们需要把它们合在一起组合句子级别的特征向量。由于语句中某些词语不重要，我们可以忽略它，有些词语很重要，要保留。为了达到这个目的，使用了max pooling，用式子描述如下</p>
<script type="math/tex; mode=display">
v(i)= \mathop{\max}_{t=1,..,T} \{h_t(i)\},\ i=1,...,K</script><p>其中$v(i)$表示池化层输出$v$的第$i$个元素，$K$为$v$的维度和$h_t$的维度一样，$h_t(i)$是第$t$个局部语境特征向量的第$i$个元素。举个例子如下，</p>
<p><img src="/2021/08/18/dssm/cnn_dssm3.JPG" alt></p>
<h3 id="2-5-Latent-Semantic-Vector-Representations"><a href="#2-5-Latent-Semantic-Vector-Representations" class="headerlink" title="2.5 Latent Semantic Vector Representations"></a>2.5 Latent Semantic Vector Representations</h3><p>语义向量表示$y$，用公式描述如下</p>
<script type="math/tex; mode=display">
y=tanh(W_s\cdot v)</script><h3 id="2-6-Using-the-CLSM-for-IR"><a href="#2-6-Using-the-CLSM-for-IR" class="headerlink" title="2.6 Using the CLSM for IR"></a>2.6 Using the CLSM for IR</h3><p>和DSSM都一样，</p>
<script type="math/tex; mode=display">
R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^Ty_D}{||y_Q||||y_D||}
\\P(D|Q)=\frac{e^{\gamma R(Q,D)}}{\sum_{D^{'}\in \textbf{D}}e^{\gamma R(Q,D^{'})}}</script><h3 id="2-7-损失函数"><a href="#2-7-损失函数" class="headerlink" title="2.7 损失函数"></a>2.7 损失函数</h3><script type="math/tex; mode=display">
L(\wedge)=-log \prod \limits_{(Q,D^+)}P(D^+|Q)</script><h2 id="三-LSTM-DSSM"><a href="#三-LSTM-DSSM" class="headerlink" title="三.LSTM-DSSM"></a>三.LSTM-DSSM</h2><p>cnn-dssm只能捕获局部的文本信息，lstm对于长序列的信息捕获能力强于lstm，因此使用lstm改进dssm。</p>
<h3 id="3-1-模型结构"><a href="#3-1-模型结构" class="headerlink" title="3.1 模型结构"></a>3.1 模型结构</h3><p>整体结构如下图，注意红色的部分为残差传递的方向。</p>
<p><img src="/2021/08/18/dssm/lstm_dssm1.JPG" alt></p>
<p>图中的LSTM单元是LSTM的变种，加入了<strong>peep hole</strong>的 LSTM，具体结构如下。</p>
<p><img src="/2021/08/18/dssm/lstm_dssm2.JPG" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/guoyaohua/p/9229190.html">https://www.cnblogs.com/guoyaohua/p/9229190.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E7%B2%97%E6%8E%92/">粗排</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/DSSM/">DSSM</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-18  <a class="commentCountImg" href="/2021/08/18/entropy/#comment-container"><span class="display-none-class">d7c5f9c356e864c91498d933feea99eb</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d7c5f9c356e864c91498d933feea99eb">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/18/entropy/">熵，KL散度，交叉熵，JS散度</a></h1><div class="content"><p>GAN需要KL散度和JS散度，所以先预热。</p>
<h2 id="1-熵"><a href="#1-熵" class="headerlink" title="1.熵"></a>1.熵</h2><p>信息量为：</p>
<script type="math/tex; mode=display">
\begin{align}
I(x) &= - \log(p(x)) \tag{1}
\end{align}</script><p>熵为信息量的算术平均：</p>
<script type="math/tex; mode=display">
H(x) = - \sum_{i=1}^{n}p(x_i)log(p(x_i)) \tag{2}</script><h2 id="2-交叉熵"><a href="#2-交叉熵" class="headerlink" title="2.交叉熵"></a>2.交叉熵</h2><p>交叉熵为</p>
<script type="math/tex; mode=display">
H(P,Q) = -\sum_{i=1}^np(x_i)logq(x_i)\tag{3}</script><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="3-KL散度"><a href="#3-KL散度" class="headerlink" title="3.KL散度"></a>3.KL散度</h2><p>对于同一个随机变量有两个单独的概率分布，我们可以使用KL散度(Kullback-Leibler divergence)来衡量两个分布的差异。在机器学习的损失函数的计算中，我们可以假设$P$为样本的真实分布，$Q$用来表示模型所预测的分布，使用KL散度来衡量两个分布之间的差异。KL散度等于交叉熵减去熵</p>
<script type="math/tex; mode=display">
\begin{align}
D_{KL}(P||Q) &= \sum_{i=1}^np(x_i)log(\frac{p(x_i)}{q(x_i)}) \notag\\
&=\sum_{i=1}^np(x_i)(logp(x_i)-logq(x_i)) \notag\\
&=\sum_{i=1}^n[p(x_i)logp(x_i)-p(x_i)logq(x_i)] \notag\\
&=\sum_{i=1}^np(x_i)logp(x_i)-\sum_{i=1}^np(x_i)logq(x_i) \\
&=-H(P)+H(P,Q)\tag{4}
\end{align}</script><p>$P$和$Q$概率分布越接近，$D_{KL}(P||Q)$越小。</p>
<p><strong>KL散度与交叉熵区别与联系</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Dby_freedom/article/details/83374650">https://blog.csdn.net/Dby_freedom/article/details/83374650</a></p>
<p><strong>KL散度主要有两个性质：</strong></p>
<p>（1）不对称性</p>
<p>尽管KL散度从直观上是个距离函数，但它并不是一个真正的度量，因为它不具有对称性，即$D_{KL}(P||Q)\neq D_{KL}(Q||P)$。</p>
<p>（2）非负性</p>
<p>即$D_{KL}(P||Q) \geq 0$。</p>
<h2 id="4-JS散度"><a href="#4-JS散度" class="headerlink" title="4.JS散度"></a>4.JS散度</h2><p>JS散度也是用于度量两个概率分布的相似度，其解决了KL散度不对称的缺点</p>
<script type="math/tex; mode=display">
JS(P||Q) = \frac{1}{2}KL(P||\frac{P+Q}{2})+\frac{1}{2}KL(Q||\frac{P+Q}{2}) \tag{5}</script><p><strong>不同于KL主要在两方面：</strong></p>
<p>（1）值域范围</p>
<p>JS散度的值域范围是[0,1]，相同则是0，相反为1。</p>
<p>（2）对称性</p>
<p>即$ JS(P||Q)=JS(Q||P)$，从数学表达式中就可以看出。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Mrfanl/p/11938139.html">https://www.cnblogs.com/Mrfanl/p/11938139.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/346518942">https://zhuanlan.zhihu.com/p/346518942</a></p>
<p><a target="_blank" rel="noopener" href="https://www.w3cschool.cn/article/83016451.html">https://www.w3cschool.cn/article/83016451.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">数学基础</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/entropy/">entropy</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-16  <a class="commentCountImg" href="/2021/08/16/L2R/#comment-container"><span class="display-none-class">b8cf8ddfd7f8e40ee0eef6861a9f1130</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="b8cf8ddfd7f8e40ee0eef6861a9f1130">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/16/L2R/">排序学习</a></h1><div class="content"><p>Literature survey for Learning to rank</p>
<p><a target="_blank" rel="noopener" href="https://www.eecis.udel.edu/~vijay/fall13/snlp/lit-survey/LearningToRank.pdf">https://www.eecis.udel.edu/~vijay/fall13/snlp/lit-survey/LearningToRank.pdf</a></p>
<p>a short introduction to learning to rank（李航）</p>
<p><a target="_blank" rel="noopener" href="https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en">https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en</a></p>
<p>Learning to Rank for Information Retrieval  — By Tie-Yan Liu</p>
<p><a target="_blank" rel="noopener" href="http://didawikinf.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf">http://didawikinf.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf</a></p>
<p>Feature Selection For Ranking</p>
<p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/1277741.1277811">https://dl.acm.org/doi/10.1145/1277741.1277811</a></p>
<p>A Deep Look into Neural Ranking Models for Information Retrieval 中科院</p>
<p><a target="_blank" rel="noopener" href="https://par.nsf.gov/servlets/purl/10277191">https://par.nsf.gov/servlets/purl/10277191</a></p>
<p>相关参考：</p>
<p><a target="_blank" rel="noopener" href="https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en">https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/anshuai_aw1/article/details/86018105">https://blog.csdn.net/anshuai_aw1/article/details/86018105</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/pearl8899/article/details/102920628">https://blog.csdn.net/pearl8899/article/details/102920628</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lipengcn/article/details/80373744">https://blog.csdn.net/lipengcn/article/details/80373744</a></p>
<p>分类</p>
<p><img src="/2021/08/16/L2R/22.png" alt></p>
<p><img src="/2021/08/16/L2R/33.png" alt></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/%E6%8E%92%E5%BA%8F/">排序</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/L2R/">L2R</a></div><hr></div></article></div><!--!--><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/36/">Previous</a></div><div class="pagination-next"><a href="/page/38/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/36/">36</a></li><li><a class="pagination-link is-current" href="/page/37/">37</a></li><li><a class="pagination-link" href="/page/38/">38</a></li><li><a class="pagination-link" href="/page/39/">39</a></li><li><a class="pagination-link" href="/page/40/">40</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">396</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">142</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">378</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-17T11:54:11.000Z">2024-03-17</time></p><p class="title"><a href="/2024/03/17/es/">es</a></p><p class="categories"><a href="/categories/es/">es</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-17T11:33:28.000Z">2024-03-17</time></p><p class="title"><a href="/2024/03/17/design-pattern/">设计模式</a></p><p class="categories"><a href="/categories/C/">C++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-17T11:28:40.000Z">2024-03-17</time></p><p class="title"><a href="/2024/03/17/cpp-high-performance/">高性能变编程</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-03T13:50:10.000Z">2023-05-03</time></p><p class="title"><a href="/2023/05/03/cpp-lang/">c++语法</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-16T13:01:22.000Z">2023-04-16</time></p><p class="title"><a href="/2023/04/16/cpp_init/">编译</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">68</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/PTM/"><span class="level-start"><span class="level-item">PTM</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Prompt/"><span class="level-start"><span class="level-item">Prompt</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Tokenization/"><span class="level-start"><span class="level-item">Tokenization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="tag">设计模式</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIEN/"><span class="tag">DIEN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIN/"><span class="tag">DIN</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2024 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>