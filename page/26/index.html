<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-20  <a class="commentCountImg" href="/2021/12/20/pairwise/#comment-container"><span class="display-none-class">a7b16f1fee5fc32820c885a95c98393a</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="a7b16f1fee5fc32820c885a95c98393a">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/20/pairwise/">pairwise</a></h1><div class="content"><p>pairwise learning to rank 的方法可以分为两大类。</p>
<p>第一类是基于<strong>打分函数</strong>，它们通过一些特殊的设计让模型依靠“样本对”的信息来学习得到每个样本的score。所以得到这类方法最后的全局排序结果很简单，就是用所有样本的score来排序即可。</p>
<p>另一类方法是基于<strong>优先函数</strong>的方法。这类方法的整个过程分为两个阶段，第一阶段是用机器学习模型来学习两个样本之间的优先关系，例如f(x1, x2)=1表示样本x1优先于x2（x1应该排在x2前面），f(x1, x2)=-1表示样本x2优先于x1（x1应该排在x2后面）。从题主的问题来看，可能问的是“当我们已经训练出了优先函数f之后，如何对所有样本进行排序，并且使该排序在最大程度上与f的结果一致”。这个问题在学界被称为Rank Aggregation（排列聚合）。</p>
<p>具体参考 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/389068269">https://www.zhihu.com/question/389068269</a></p>
<p>别的相关参考：</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/235756fbf6b6">https://www.jianshu.com/p/235756fbf6b6</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/318300682">https://zhuanlan.zhihu.com/p/318300682</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65224450">https://zhuanlan.zhihu.com/p/65224450</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65756030">https://zhuanlan.zhihu.com/p/65756030</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/389068269/answer/1180120736">https://www.zhihu.com/question/389068269/answer/1180120736</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/pairwise/">pairwise</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/pairwise/">pairwise</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-20  <a class="commentCountImg" href="/2021/12/20/pointwise/#comment-container"><span class="display-none-class">1ea5cdae2519042bc5e1c51ff4c4e818</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1ea5cdae2519042bc5e1c51ff4c4e818">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/20/pointwise/">pointwise</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113302654#">https://zhuanlan.zhihu.com/p/113302654#</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/">排序</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%92%E5%BA%8F/pointwise/">pointwise</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/pointwise/">pointwise</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-18  <a class="commentCountImg" href="/2021/12/18/lr/#comment-container"><span class="display-none-class">115a685e3e12bd423388f7c8e204e324</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="115a685e3e12bd423388f7c8e204e324">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/18/lr/">调节学习率</a></h1><div class="content"><p>当学习率过大的时候会导致模型难以收敛，过小的时候会收敛速度过慢，合理的学习率才能让模型收敛到最小点而非局部最优点或鞍点</p>
<p>经验值： 0.01 ~ 0.001 </p>
<h2 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h2><p>原因：起初距离目标偏离大，可以设置较大，为了快速收敛，后续逐渐靠近目标，需要精细化一点，所以希望值小一点</p>
<p><strong>分类</strong></p>
<p>1.轮数衰减</p>
<p>每经过k个epochs后学习率减半</p>
<p>2.指数衰减</p>
<script type="math/tex; mode=display">
\alpha_t=decay\_rate^{epoch}*\alpha_{t-1}</script><p>3.分数衰减</p>
<script type="math/tex; mode=display">
\alpha_t=\frac{\alpha_{t-1}}{1+decay\_rate*epoch}</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/LiuPeiP_VIPL/article/details/119581343">https://blog.csdn.net/LiuPeiP_VIPL/article/details/119581343</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">训练技巧</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E8%B0%83%E8%8A%82%E5%AD%A6%E4%B9%A0%E7%8E%87/">调节学习率</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-16  <a class="commentCountImg" href="/2021/12/16/gnn-trick/#comment-container"><span class="display-none-class">fc22eb346de888ff8528afcec9f6f88a</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="fc22eb346de888ff8528afcec9f6f88a">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/16/gnn-trick/">图神经工具</a></h1><div class="content"><p>PyG， DGL对比</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/399802947">https://www.zhihu.com/question/399802947</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/GNN/">GNN</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/">小帮手</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/PyG-DGL/">PyG,DGL</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-15  <a class="commentCountImg" href="/2021/12/15/python-paramerter/#comment-container"><span class="display-none-class">437480ac4b8fefab890d449bd56c1834</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="437480ac4b8fefab890d449bd56c1834">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/15/python-paramerter/">函数参数</a></h1><div class="content"><h2 id="1-默认参数"><a href="#1-默认参数" class="headerlink" title="1 默认参数"></a>1 默认参数</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41972881/article/details/81562731">https://blog.csdn.net/weixin_41972881/article/details/81562731</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45775963/article/details/103696945">https://blog.csdn.net/weixin_45775963/article/details/103696945</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def fun(va1,va2=[]):</span><br><span class="line">    print(va2)</span><br><span class="line">    va2.append(va1)</span><br><span class="line">    return va2</span><br><span class="line">te1=fun(10)</span><br><span class="line">te1=fun(20)</span><br></pre></td></tr></table></figure>
<p>va2如果没有传参，采用默认的，默认的会变化，不是一直是[]</p>
<p>va2如果是外部的传参，以传参为主，会覆盖</p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/python/">python</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0/">函数参数</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-14  <a class="commentCountImg" href="/2021/12/14/enhanced-rcnn/#comment-container"><span class="display-none-class">ebdcdc87ea1e77ac7d009f72b7eb9ef1</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="ebdcdc87ea1e77ac7d009f72b7eb9ef1">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.3 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/14/enhanced-rcnn/">Enhanced-RCNN An Efficient Method for Learning Sentence Similarity</a></h1><div class="content"><p>特点：非预训练，参数量少</p>
<p><img src="/2021/12/14/enhanced-rcnn/1.JPG" alt></p>
<h2 id="1-input-encoding"><a href="#1-input-encoding" class="headerlink" title="1 input encoding"></a>1 input encoding</h2><p>得到两个encoding，RNN Encoding，RCNN Encoding</p>
<p>1 BiGRU</p>
<p><img src="/2021/12/14/enhanced-rcnn/2.JPG" alt></p>
<p>$\textbf{a}=\{a_1,a_2,…,a_{l_a}\},\textbf{a}$ 是句子，$l_a$ 是句子1的长度</p>
<p>得到RNN Encoding，$\overline{\textbf{p}}_i$统一表示$\overline{\textbf{a}}_i,\overline{\textbf{b}}_i$</p>
<p>2 CNN</p>
<p>在 BiGRU 编码的基础上，使用 CNN 来进行二次编码</p>
<p>结构如下，“newtork in network”,k 是卷积核的kernel size，比如k=1,卷积核为$1 \times 1$</p>
<p><img src="/2021/12/14/enhanced-rcnn/3.JPG" alt></p>
<p>对于每个 CNN 单元，具体的计算过程如下:</p>
<p><img src="/2021/12/14/enhanced-rcnn/4.JPG" alt></p>
<p>得到 RCNN Encoding $\widetilde{\textbf{p}}_i$</p>
<h2 id="2-Interactive-Sentence-Representation"><a href="#2-Interactive-Sentence-Representation" class="headerlink" title="2 Interactive Sentence Representation"></a>2 Interactive Sentence Representation</h2><p>1  Soft-attention Alignment</p>
<p>attention：</p>
<p><img src="/2021/12/14/enhanced-rcnn/5.JPG" alt></p>
<p>加了attention的rnn encoding：</p>
<p><img src="/2021/12/14/enhanced-rcnn/6.JPG" alt></p>
<p>2  Interaction Modeling</p>
<p><img src="/2021/12/14/enhanced-rcnn/7.JPG" alt></p>
<p>$\overline{\textbf{p}}$是rnn encoding</p>
<p>$\hat{}$是加了attention的rnn encoding</p>
<p>$\widetilde{}$是rcnn encoding</p>
<p>最终得到Interactive Sentence Representation为$\textbf{o}_a,\textbf{o}_b$</p>
<h2 id="3-Similarity-Modeling"><a href="#3-Similarity-Modeling" class="headerlink" title="3 Similarity Modeling"></a>3 Similarity Modeling</h2><p>1 Fusion Layer</p>
<p><img src="/2021/12/14/enhanced-rcnn/8.JPG" alt></p>
<p><img src="/2021/12/14/enhanced-rcnn/9.JPG" alt></p>
<p>g是门控函数</p>
<p><img src="/2021/12/14/enhanced-rcnn/10.JPG" alt></p>
<p>2  Label Prediction</p>
<p>全连接层</p>
<h2 id="4-loss"><a href="#4-loss" class="headerlink" title="4 loss"></a>4 loss</h2><p>交叉熵</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://sci-hub.st/10.1145/3366423.3379998">https://sci-hub.st/10.1145/3366423.3379998</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/138061003">https://zhuanlan.zhihu.com/p/138061003</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/">文本匹配</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/Enhanced-RCNN/">Enhanced-RCNN</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-12  <a class="commentCountImg" href="/2021/12/12/knowledgegraph/#comment-container"><span class="display-none-class">d933a4d315059012c62d01afce3156e2</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d933a4d315059012c62d01afce3156e2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/12/knowledgegraph/">知识图谱</a></h1><div class="content"><p>东南的课程：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/npubird/KnowledgeGraphCourse">https://github.com/npubird/KnowledgeGraphCourse</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">知识图谱</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%BC%E8%BF%B0/">知识图谱综述</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-12  <a class="commentCountImg" href="/2021/12/12/Prompt_survey/#comment-container"><span class="display-none-class">1a6cb8f58eadb9f20eae53a070af5922</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1a6cb8f58eadb9f20eae53a070af5922">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>5 m  <i class="fas fa-pencil-alt"> </i>0.8 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/12/Prompt_survey/">Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing</a></h1><div class="content"><h2 id="0-和pre-train，finetune区别"><a href="#0-和pre-train，finetune区别" class="headerlink" title="0 和pre-train，finetune区别"></a>0 和pre-train，finetune区别</h2><p><img src="/2021/12/12/Prompt_survey/11.JPG" alt></p>
<p><img src="/2021/12/12/Prompt_survey/1.JPG" alt></p>
<p>prompt感觉是一种特殊的finetune方式，还是先pre-train然后prompt tuning</p>
<p>目的：prompt narrowing the gap between pre-training and fine-tuning</p>
<h2 id="1-怎么做"><a href="#1-怎么做" class="headerlink" title="1 怎么做"></a>1 怎么做</h2><p>3步</p>
<h4 id="1-Prompt-Addition"><a href="#1-Prompt-Addition" class="headerlink" title="1 Prompt Addition"></a>1 Prompt Addition</h4><p><img src="/2021/12/12/Prompt_survey/0.JPG" alt></p>
<p>$x^{‘}=f_{prompt}(x)$ x是input text</p>
<ol>
<li>Apply a template, which is a textual string that has two slots: an input slot [X] for input x and an answer slot<br>[Z] for an intermediate generated answer text z that will later be mapped into y.</li>
<li>Fill slot [X] with the input text x.</li>
</ol>
<h4 id="2-Answer-Search"><a href="#2-Answer-Search" class="headerlink" title="2 Answer Search"></a>2 Answer Search</h4><p><img src="/2021/12/12/Prompt_survey/5.JPG" alt></p>
<p>f：fills in the location [Z] in prompt $x^{‘}$ with the potential answer z</p>
<p>Z：a set of permissible values for z</p>
<h4 id="3-Answer-Mapping"><a href="#3-Answer-Mapping" class="headerlink" title="3 Answer Mapping"></a>3 Answer Mapping</h4><p>因为上面的 $\hat{z}$ 还不是  $\hat{y}$，比如情感分析，“excellent”, “fabulous”, “wonderful” -》positive</p>
<p>go from the highest-scoring answer $\hat{z}$ to the highest-scoring output  $\hat{y}$ </p>
<h4 id="4-举个例子，文本情感分类的任务"><a href="#4-举个例子，文本情感分类的任务" class="headerlink" title="4 举个例子，文本情感分类的任务"></a>4 举个例子，文本情感分类的任务</h4><p><strong>原来</strong></p>
<p> “ I love this movie.”  -》 positive</p>
<p><strong>现在</strong></p>
<p>1 $x=$ “ I love this movie.”  -》模板为： “ [x] Overall, it was a [z] movie.” -》$x^{‘}$为”I love this movie. Overall ,it was a [z] movie.”</p>
<p>2 下一步会进行答案搜索，顾名思义就是LM寻找填在[z] 处可以使得分数最高的文本 $\hat{z}$(比如”excellent”, “great”, “wonderful” )</p>
<p>3 最后是答案映射。有时LM填充的文本并非任务需要的最终形式(最终为positive，上述为”excellent”, “great”, “wonderful”)，因此要将此文本映射到最终的输出$\hat{y}$</p>
<h2 id="2-Prompt方法分类"><a href="#2-Prompt方法分类" class="headerlink" title="2 Prompt方法分类"></a>2 Prompt方法分类</h2><p><img src="/2021/12/12/Prompt_survey/2.JPG" alt></p>
<h2 id="3-Prompt-Engineering"><a href="#3-Prompt-Engineering" class="headerlink" title="3 Prompt Engineering"></a>3 Prompt Engineering</h2><p>1 one must first consider the prompt shape,</p>
<p>2 then decide whether to take a manual or automated approach to create prompts of the desired shape</p>
<h3 id="1-Prompt-Shape"><a href="#1-Prompt-Shape" class="headerlink" title="1 Prompt Shape"></a>1 Prompt Shape</h3><p>Prompt的形状主要指的是[X]和[Z]的位置和数量。</p>
<p>如果在句中，一般称这种prompt为<strong>cloze prompt</strong>；如果在句末，一般称这种prompt为<strong>prefix prompt</strong>。</p>
<p>在实际应用过程中选择哪一种主要取决于任务的形式和模型的类别。cloze prompts和Masked Language Model的训练方式非常类似，因此对于使用MLM的任务来说cloze prompts更加合适；对于生成任务来说，或者使用自回归LM解决的任务，prefix prompts就会更加合适；Full text reconstruction models较为通用，因此两种prompt均适用。另外，对于文本对的分类，prompt模板通常要给输入预留两个空，[x1]和[x2]。</p>
<h3 id="2-create-prompts"><a href="#2-create-prompts" class="headerlink" title="2 create prompts"></a>2 create prompts</h3><h4 id="1-Manual-Template-Engineering"><a href="#1-Manual-Template-Engineering" class="headerlink" title="1 Manual Template Engineering"></a>1 Manual Template Engineering</h4><h4 id="2-Automated-Template-Learning"><a href="#2-Automated-Template-Learning" class="headerlink" title="2 Automated Template Learning"></a>2 Automated Template Learning</h4><h5 id="1-Discrete-Prompts"><a href="#1-Discrete-Prompts" class="headerlink" title="1 Discrete Prompts"></a>1 Discrete Prompts</h5><p>the prompt 作用在文本上</p>
<p>D1: Prompt Mining</p>
<p>D2: Prompt Paraphrasing</p>
<p>D3: Gradient-based Search</p>
<p>D4: Prompt Generation</p>
<p>D5: Prompt Scoring</p>
<h5 id="2-Continuous-Prompts"><a href="#2-Continuous-Prompts" class="headerlink" title="2 Continuous Prompts"></a>2 Continuous Prompts</h5><p>the prompt 直接作用到模型的embedding空间</p>
<p>C1: Prefix Tuning</p>
<p>C2: Tuning Initialized with Discrete Prompts</p>
<p>C3: Hard-Soft Prompt Hybrid Tuning</p>
<h2 id="4-Answer-Engineering"><a href="#4-Answer-Engineering" class="headerlink" title="4 Answer Engineering"></a>4 Answer Engineering</h2><p>two dimensions that must be considered when performing answer<br>engineering:1  deciding the answer shape and 2  choosing an answer design method.</p>
<h4 id="1-Answer-Shape"><a href="#1-Answer-Shape" class="headerlink" title="1 Answer Shape"></a>1 Answer Shape</h4><p>和Prompt Shape啥区别？？？</p>
<h4 id="2-Answer-Space-Design-Methods"><a href="#2-Answer-Space-Design-Methods" class="headerlink" title="2 Answer Space Design Methods"></a>2 Answer Space Design Methods</h4><h5 id="1-Manual-Design"><a href="#1-Manual-Design" class="headerlink" title="1 Manual Design"></a>1 Manual Design</h5><h5 id="2-automatic-automatic"><a href="#2-automatic-automatic" class="headerlink" title="2 automatic automatic"></a>2 automatic automatic</h5><h6 id="1-Discrete-Answer-Search"><a href="#1-Discrete-Answer-Search" class="headerlink" title="1 Discrete Answer Search"></a>1 Discrete Answer Search</h6><h6 id="2-Continuous-Answer-Search"><a href="#2-Continuous-Answer-Search" class="headerlink" title="2 Continuous Answer Search"></a>2 Continuous Answer Search</h6><h2 id="5-Multi-Prompt-Learning"><a href="#5-Multi-Prompt-Learning" class="headerlink" title="5 Multi-Prompt Learning"></a>5 Multi-Prompt Learning</h2><p>之前在讨论single prompt，现在介绍multiple prompts</p>
<p><img src="/2021/12/12/Prompt_survey/3.JPG" alt></p>
<h2 id="6-Training-Strategies-for-Prompting-Methods"><a href="#6-Training-Strategies-for-Prompting-Methods" class="headerlink" title="6 Training Strategies for Prompting Methods"></a>6 Training Strategies for Prompting Methods</h2><p>1 Training Settings</p>
<p>full-data</p>
<p>few-shot /zero-shot</p>
<p>2 Parameter Update Methods</p>
<p><img src="/2021/12/12/Prompt_survey/4.JPG" alt></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.13586">https://arxiv.org/abs/2107.13586</a></p>
<p>刘鹏飞博士 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395115779">https://zhuanlan.zhihu.com/p/395115779</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/399295895">https://zhuanlan.zhihu.com/p/399295895</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/440169921">https://zhuanlan.zhihu.com/p/440169921</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/399295895">https://zhuanlan.zhihu.com/p/399295895</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/Prompt/">Prompt</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/Prompt/">Prompt</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-12  <a class="commentCountImg" href="/2021/12/12/few-shot/#comment-container"><span class="display-none-class">27305810d8db04e9529bfb0657ccb1e8</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="27305810d8db04e9529bfb0657ccb1e8">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>14 m  <i class="fas fa-pencil-alt"> </i>2.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/12/few-shot/">Generalizing from a Few Examples A Survey on Few-Shot Learning</a></h1><div class="content"><p>paper：  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.05046">https://arxiv.org/abs/1904.05046</a></p>
<p>git:  <a target="_blank" rel="noopener" href="https://github.com/tata1661/FSL-Mate/tree/master/FewShotPapers#Applications">https://github.com/tata1661/FSL-Mate/tree/master/FewShotPapers#Applications</a></p>
<p>原文按应用对FSL做了总结，与NLP相关的有：</p>
<ol>
<li><strong>High-risk learning: Acquiring new word vectors from tiny data,</strong> in EMNLP, 2017. <em>A. Herbelot and M. Baroni.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D17-1030.pdf">paper</a></li>
<li><strong>MetaEXP: Interactive explanation and exploration of large knowledge graphs,</strong> in TheWebConf, 2018. <em>F. Behrens, S. Bischoff, P. Ladenburger, J. Rückin, L. Seidel, F. Stolp, M. Vaichenker, A. Ziegler, D. Mottin, F. Aghaei, E. Müller, M. Preusse, N. Müller, and M. Hunger.</em> <a target="_blank" rel="noopener" href="https://meta-exp.github.io/resources/paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://hpi.de/en/mueller/metaex">code</a></li>
<li><strong>Few-shot representation learning for out-of-vocabulary words,</strong> in ACL, 2019. <em>Z. Hu, T. Chen, K.-W. Chang, and Y. Sun.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P19-1402.pdf">paper</a></li>
<li><strong>Learning to customize model structures for few-shot dialogue generation tasks,</strong> in ACL, 2020. <em>Y. Song, Z. Liu, W. Bi, R. Yan, and M. Zhang.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.517.pdf">paper</a></li>
<li><strong>Few-shot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network,</strong> in ACL, 2020. <em>Y. Hou, W. Che, Y. Lai, Z. Zhou, Y. Liu, H. Liu, and T. Liu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.128.pdf">paper</a></li>
<li><strong>Meta-reinforced multi-domain state generator for dialogue systems,</strong> in ACL, 2020. <em>Y. Huang, J. Feng, M. Hu, X. Wu, X. Du, and S. Ma.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.acl-main.636.pdf">paper</a></li>
<li><strong>Few-shot knowledge graph completion,</strong> in AAAI, 2020. <em>C. Zhang, H. Yao, C. Huang, M. Jiang, Z. Li, and N. V. Chawla.</em> <a target="_blank" rel="noopener" href="https://aaai.org/ojs/index.php/AAAI/article/view/5698">paper</a></li>
<li><strong>Universal natural language processing with limited annotations: Try few-shot textual entailment as a start,</strong> in EMNLP, 2020. <em>W. Yin, N. F. Rajani, D. Radev, R. Socher, and C. Xiong.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.660.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/salesforce/UniversalFewShotNLP">code</a></li>
<li><strong>Simple and effective few-shot named entity recognition with structured nearest neighbor learning,</strong> in EMNLP, 2020. <em>Y. Yang, and A. Katiyar.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.516.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/asappresearch/structshot">code</a></li>
<li><strong>Discriminative nearest neighbor few-shot intent detection by transferring natural language inference,</strong> in EMNLP, 2020. <em>J. Zhang, K. Hashimoto, W. Liu, C. Wu, Y. Wan, P. Yu, R. Socher, and C. Xiong.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.411.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/salesforce/DNNC-few-shot-intent">code</a></li>
<li><strong>Few-shot learning for opinion summarization,</strong> in EMNLP, 2020. <em>A. Bražinskas, M. Lapata, and I. Titov.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.337.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/abrazinskas/FewSum">code</a></li>
<li><strong>Adaptive attentional network for few-shot knowledge graph completion,</strong> in EMNLP, 2020. <em>J. Sheng, S. Guo, Z. Chen, J. Yue, L. Wang, T. Liu, and H. Xu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.131.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/JiaweiSheng/FAAN">code</a></li>
<li><strong>Few-shot complex knowledge base question answering via meta reinforcement learning,</strong> in EMNLP, 2020. <em>Y. Hua, Y. Li, G. Haffari, G. Qi, and T. Wu.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.469.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/DevinJake/MRL-CQA">code</a></li>
<li><strong>Self-supervised meta-learning for few-shot natural language classification tasks,</strong> in EMNLP, 2020. <em>T. Bansal, R. Jha, T. Munkhdalai, and A. McCallum.</em> <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/2020.emnlp-main.38.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/iesl/metanlp">code</a></li>
<li><strong>Uncertainty-aware self-training for few-shot text classification,</strong> in NeurIPS, 2020. <em>S. Mukherjee, and A. Awadallah.</em> <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2020/file/f23d125da1e29e34c552f448610ff25f-Paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/UST">code</a></li>
<li><strong>Learning to extrapolate knowledge: Transductive few-shot out-of-graph link prediction,</strong> in NeurIPS, 2020:. <em>J. Baek, D. B. Lee, and S. J. Hwang.</em> <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2020/file/0663a4ddceacb40b095eda264a85f15c-Paper.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/JinheonBaek/GEN">code</a></li>
<li><strong>MetaNER: Named entity recognition with meta-learning,</strong> in TheWebConf, 2020. <em>J. Li, S. Shang, and L. Shao.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3366423.3380127">paper</a></li>
<li><strong>Conditionally adaptive multi-task learning: Improving transfer learning in NLP using fewer parameters &amp; less data,</strong> in ICLR, 2021. <em>J. Pilault, A. E. hattami, and C. Pal.</em> <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=de11dbHzAMF">paper</a> <a target="_blank" rel="noopener" href="https://github.com/CAMTL/CA-MTL">code</a></li>
<li><strong>Revisiting few-sample BERT fine-tuning,</strong> in ICLR, 2021. <em>T. Zhang, F. Wu, A. Katiyar, K. Q. Weinberger, and Y. Artzi.</em> <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=cO1IH43yUF">paper</a> <a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.4.0/_modules/torch/optim/adamw.html">code</a></li>
<li><strong>Few-shot conversational dense retrieval,</strong> in SIGIR, 2021. <em>S. Yu, Z. Liu, C. Xiong, T. Feng, and Z. Liu.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462856">paper</a> <a target="_blank" rel="noopener" href="https://github.com/thunlp/ConvDR">code</a></li>
<li><strong>Relational learning with gated and attentive neighbor aggregator for few-shot knowledge graph completion,</strong> in SIGIR, 2021. <em>G. Niu, Y. Li, C. Tang, R. Geng, J. Dai, Q. Liu, H. Wang, J. Sun, F. Huang, and L. Si.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462925">paper</a></li>
<li><strong>Few-shot language coordination by modeling theory of mind,</strong> in ICML, 2021. <em>H. Zhu, G. Neubig, and Y. Bisk.</em> <a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v139/zhu21d/zhu21d.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/CLAW-Lab/ToM">code</a></li>
<li><strong>Graph-evolving meta-learning for low-resource medical dialogue generation,</strong> in AAAI, 2021. <em>S. Lin, P. Zhou, X. Liang, J. Tang, R. Zhao, Z. Chen, and L. Lin.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17577/17384">paper</a></li>
<li><strong>KEML: A knowledge-enriched meta-learning framework for lexical relation classification,</strong> in AAAI, 2021. <em>C. Wang, M. Qiu, J. Huang, and X. He.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17640/17447">paper</a></li>
<li><strong>Few-shot learning for multi-label intent detection,</strong> in AAAI, 2021. <em>Y. Hou, Y. Lai, Y. Wu, W. Che, and T. Liu.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17541/17348">paper</a> <a target="_blank" rel="noopener" href="https://github.com/AtmaHou/FewShotMultiLabel">code</a></li>
<li><strong>SALNet: Semi-supervised few-shot text classification with attention-based lexicon construction,</strong> in AAAI, 2021. <em>J.-H. Lee, S.-K. Ko, and Y.-S. Han.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17558/17365">paper</a></li>
<li><strong>Learning from my friends: Few-shot personalized conversation systems via social networks,</strong> in AAAI, 2021. <em>Z. Tian, W. Bi, Z. Zhang, D. Lee, Y. Song, and N. L. Zhang.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/17638/17445">paper</a> <a target="_blank" rel="noopener" href="https://github.com/tianzhiliang/FewShotPersonaConvData">code</a></li>
<li><strong>Relative and absolute location embedding for few-shot node classification on graph,</strong> in AAAI, 2021. <em>Z. Liu, Y. Fang, C. Liu, and S. C.H. Hoi.</em> <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16551/16358">paper</a></li>
<li><strong>Few-shot question answering by pretraining span selection,</strong> in ACL-IJCNLP, 2021. <em>O. Ram, Y. Kirstain, J. Berant, A. Globerson, and O. Levy.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.239.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/oriram/splinter">code</a></li>
<li><strong>A closer look at few-shot crosslingual transfer: The choice of shots matters,</strong> in ACL-IJCNLP, 2021. <em>M. Zhao, Y. Zhu, E. Shareghi, I. Vulic, R. Reichart, A. Korhonen, and H. Schütze.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.447.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/fsxlt">code</a></li>
<li><strong>Learning from miscellaneous other-classwords for few-shot named entity recognition,</strong> in ACL-IJCNLP, 2021. <em>M. Tong, S. Wang, B. Xu, Y. Cao, M. Liu, L. Hou, and J. Li.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.487.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/shuaiwa16/OtherClassNER.git">code</a></li>
<li><strong>Distinct label representations for few-shot text classification,</strong> in ACL-IJCNLP, 2021. <em>S. Ohashi, J. Takayama, T. Kajiwara, and Y. Arase.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.105.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/21335732529sky/difference_extractor">code</a></li>
<li><strong>Entity concept-enhanced few-shot relation extraction,</strong> in ACL-IJCNLP, 2021. <em>S. Yang, Y. Zhang, G. Niu, Q. Zhao, and S. Pu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.124.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/LittleGuoKe/ConceptFERE">code</a></li>
<li><strong>On training instance selection for few-shot neural text generation,</strong> in ACL-IJCNLP, 2021. <em>E. Chang, X. Shen, H.-S. Yeh, and V. Demberg.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-short.2.pdf">paper</a> <a target="_blank" rel="noopener" href="https://gitlab.com/erniecyc/few-selector">code</a></li>
<li><strong>Unsupervised neural machine translation for low-resource domains via meta-learning,</strong> in ACL-IJCNLP, 2021. <em>C. Park, Y. Tae, T. Kim, S. Yang, M. A. Khan, L. Park, and J. Choo.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.225.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/papago-lab/MetaGUMT">code</a></li>
<li><strong>Meta-learning with variational semantic memory for word sense disambiguation,</strong> in ACL-IJCNLP, 2021. <em>Y. Du, N. Holla, X. Zhen, C. Snoek, and E. Shutova.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.409.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/YDU-uva/VSM_WSD">code</a></li>
<li><strong>Multi-label few-shot learning for aspect category detection,</strong> in ACL-IJCNLP, 2021. <em>M. Hu, S. Z. H. Guo, C. Xue, H. Gao, T. Gao, R. Cheng, and Z. Su.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.495.pdf">paper</a></li>
<li><strong>TextSETTR: Few-shot text style extraction and tunable targeted restyling,</strong> in ACL-IJCNLP, 2021. <em>P. Rileya, N. Constantb, M. Guob, G. Kumarc, D. Uthusb, and Z. Parekh.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.293.pdf">paper</a></li>
<li><strong>Few-shot text ranking with meta adapted synthetic weak supervision,</strong> in ACL-IJCNLP, 2021. <em>S. Sun, Y. Qian, Z. Liu, C. Xiong, K. Zhang, J. Bao, Z. Liu, and P. Bennett.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.390.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/thunlp/MetaAdaptRank">code</a></li>
<li><strong>PROTAUGMENT: Intent detection meta-learning through unsupervised diverse paraphrasing,</strong> in ACL-IJCNLP, 2021. <em>T. Dopierre, C. Gravier, and W. Logerais.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.191.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/tdopierre/ProtAugment">code</a></li>
<li><strong>AUGNLG: Few-shot natural language generation using self-trained data augmentation,</strong> in ACL-IJCNLP, 2021. <em>X. Xu, G. Wang, Y.-B. Kim, and S. Lee.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.acl-long.95.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/XinnuoXu/AugNLG">code</a></li>
<li><strong>Meta self-training for few-shot neural sequence labeling,</strong> in KDD, 2021. <em>Y. Wang, S. Mukherjee, H. Chu, Y. Tu, M. Wu, J. Gao, and A. H. Awadallah.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467235">paper</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/MetaST">code</a></li>
<li><strong>Knowledge-enhanced domain adaptation in few-shot relation classification,</strong> in KDD, 2021. <em>J. Zhang, J. Zhu, Y. Yang, W. Shi, C. Zhang, and H. Wang.</em> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467438">paper</a> <a target="_blank" rel="noopener" href="https://github.com/imJiawen/KEFDA">code</a></li>
<li><strong>Few-shot text classification with triplet networks, data augmentation, and curriculum learning,</strong> in NAACL-HLT, 2021. <em>J. Wei, C. Huang, S. Vosoughi, Y. Cheng, and S. Xu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.434.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/jasonwei20/triplet-loss">code</a></li>
<li><strong>Few-shot intent classification and slot filling with retrieved examples,</strong> in NAACL-HLT, 2021. <em>D. Yu, L. He, Y. Zhang, X. Du, P. Pasupat, and Q. Li.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.59.pdf">paper</a></li>
<li><strong>Non-parametric few-shot learning for word sense disambiguation,</strong> in NAACL-HLT, 2021. <em>H. Chen, M. Xia, and D. Chen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.142.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/princeton-nlp/metric-wsd">code</a></li>
<li><strong>Towards few-shot fact-checking via perplexity,</strong> in NAACL-HLT, 2021. <em>N. Lee, Y. Bang, A. Madotto, and P. Fung.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.158.pdf">paper</a></li>
<li><strong>ConVEx: Data-efficient and few-shot slot labeling,</strong> in NAACL-HLT, 2021. <em>M. Henderson, and I. Vulic.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.naacl-main.264.pdf">paper</a></li>
<li><strong>Few-shot text generation with natural language instructions,</strong> in EMNLP, 2021. <em>T. Schick, and H. Schütze.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.32.pdf">paper</a></li>
<li><strong>Towards realistic few-shot relation extraction,</strong> in EMNLP, 2021. <em>S. Brody, S. Wu, and A. Benton.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.433.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/bloomberg/emnlp21_fewrel">code</a></li>
<li><strong>Few-shot emotion recognition in conversation with sequential prototypical networks,</strong> in EMNLP, 2021. <em>G. Guibon, M. Labeau, H. Flamein, L. Lefeuvre, and C. Clavel.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.549.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/gguibon/protoseq">code</a></li>
<li><strong>Learning prototype representations across few-shot tasks for event detection,</strong> in EMNLP, 2021. <em>V. Lai, F. Dernoncourt, and T. H. Nguyen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.427.pdf">paper</a></li>
<li><strong>Exploring task difficulty for few-shot relation extraction,</strong> in EMNLP, 2021. <em>J. Han, B. Cheng, and W. Lu.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.204.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/hanjiale/hcrp">code</a></li>
<li><strong>Honey or poison? Solving the trigger curse in few-shot event detection via causal intervention,</strong> in EMNLP, 2021. <em>J. Chen, H. Lin, X. Han, and L. Sun.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.637.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/chen700564/causalfsed">code</a></li>
<li><strong>Nearest neighbour few-shot learning for cross-lingual classification,</strong> in EMNLP, 2021. <em>M. S. Bari, B. Haider, and S. Mansour.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.131.pdf">paper</a></li>
<li><strong>Knowledge-aware meta-learning for low-resource text classification,</strong> in EMNLP, 2021. <em>H. Yao, Y. Wu, M. Al-Shedivat, and E. P. Xing.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.136.pdf">paper</a> <a target="_blank" rel="noopener" href="https://github.com/huaxiuyao/KGML">code</a></li>
<li><strong>Few-shot named entity recognition: An empirical baseline study,</strong> in EMNLP, 2021. <em>J. Huang, C. Li, K. Subudhi, D. Jose, S. Balakrishnan, W. Chen, B. Peng, J. Gao, and J. Han.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.813.pdf">paper</a></li>
<li><strong>MetaTS: Meta teacher-student network for multilingual sequence labeling with minimal supervision,</strong> in EMNLP, 2021. <em>Z. Li, D. Zhang, T. Cao, Y. Wei, Y. Song, and B. Yin.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.255.pdf">paper</a></li>
<li><strong>Meta-LMTC: Meta-learning for large-scale multi-label text classification,</strong> in EMNLP, 2021. <em>R. Wang, X. Su, S. Long, X. Dai, S. Huang, and J. Chen.</em> <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.679.pdf">paper</a></li>
</ol>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E6%A0%B7%E6%9C%AC/">小样本</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/">小样本</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-12-09  <a class="commentCountImg" href="/2021/12/09/autotokenizer/#comment-container"><span class="display-none-class">d811ccb886d4564a5d237abcea635e61</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d811ccb886d4564a5d237abcea635e61">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>fast  <i class="fas fa-pencil-alt"> </i>0.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/09/autotokenizer/">AutoTokenizer和BertTokenizer区别</a></h1><div class="content"><p><a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/issues/5587">https://github.com/huggingface/transformers/issues/5587</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/">NLP</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/NLP/%E5%B0%8F%E5%B8%AE%E6%89%8B/">小帮手</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/AutoTokenizer/">AutoTokenizer</a></div><hr></div></article></div><!--!--><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/25/">Previous</a></div><div class="pagination-next"><a href="/page/27/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/25/">25</a></li><li><a class="pagination-link is-current" href="/page/26/">26</a></li><li><a class="pagination-link" href="/page/27/">27</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/40/">40</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">393</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">140</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">376</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-03T13:50:10.000Z">2023-05-03</time></p><p class="title"><a href="/2023/05/03/cpp-lang/">c++语法</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-16T13:01:22.000Z">2023-04-16</time></p><p class="title"><a href="/2023/04/16/cpp_init/">c++简介</a></p><p class="categories"><a href="/categories/c/">c++</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-05T15:23:33.000Z">2022-10-05</time></p><p class="title"><a href="/2022/10/05/python-multi-version/">python多版本兼容</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-04T15:42:29.000Z">2022-10-04</time></p><p class="title"><a href="/2022/10/04/python-multi-thread/">多线程</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-04T14:31:57.000Z">2022-10-04</time></p><p class="title"><a href="/2022/10/04/python-designmode/">设计模式</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">68</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/PTM/"><span class="level-start"><span class="level-item">PTM</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Prompt/"><span class="level-start"><span class="level-item">Prompt</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Tokenization/"><span class="level-start"><span class="level-item">Tokenization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/"><span class="level-start"><span class="level-item">信息抽取</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIEN/"><span class="tag">DIEN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIN/"><span class="tag">DIN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DMR/"><span class="tag">DMR</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2023 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>