<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Lavine Hu</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lavine Hu"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lavine Hu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lavine Hu"><meta property="og:url" content="https://github.com/hlw95?tab=following"><meta property="og:site_name" content="Lavine Hu"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><meta property="article:author" content="Lavine Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Lavine Hu","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Lavine Hu"},"description":""}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Lavine Hu</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-10  <a class="commentCountImg" href="/2021/09/10/python-env/#comment-container"><span class="display-none-class">11a71155e1e45a0951c7148ccf224020</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="11a71155e1e45a0951c7148ccf224020">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 m  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/10/python-env/">python环境</a></h1><div class="content"><h2 id="1-环境管理工具"><a href="#1-环境管理工具" class="headerlink" title="1.环境管理工具"></a>1.环境管理工具</h2><p>python版本主要为2,3两个大版本</p>
<p>anaconda管理python和包的版本</p>
<h2 id="2-包"><a href="#2-包" class="headerlink" title="2.包"></a>2.包</h2><h4 id="2-1-下载包"><a href="#2-1-下载包" class="headerlink" title="2.1 下载包"></a>2.1 下载包</h4><p>下载源有官方源，阿里源，豆瓣源，清华源等</p>
<h5 id="1-离线下载"><a href="#1-离线下载" class="headerlink" title="1 离线下载"></a>1 离线下载</h5><h5 id="2-在线下载"><a href="#2-在线下载" class="headerlink" title="2 在线下载"></a>2 在线下载</h5><p>下载工具有pip，conda</p>
<p><strong>更换pip源</strong></p>
<p>修改文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.pip/pip.conf  # 没有就创建一个，在 ~/.pip/下</span><br></pre></td></tr></table></figure>
<p>增加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url=https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"># index-url=http://pypi.douban.com/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host=pypi.tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></figure>
<p><strong>查看路径</strong></p>
<p>which python, which pip ,which conda （~用户主目录， /根目录）</p>
<h4 id="2-2-使用包"><a href="#2-2-使用包" class="headerlink" title="2.2 使用包"></a>2.2 使用包</h4><p>import </p>
<p>绝对路径：从工程的最外层开始</p>
<p>相对路径：利用.（同级）和..（上级）</p>
<p>怎么添加包的搜路径</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40449300/article/details/79327201">https://blog.csdn.net/weixin_40449300/article/details/79327201</a></p>
<h2 id="3-ubuntu修改python环境变量"><a href="#3-ubuntu修改python环境变量" class="headerlink" title="3 ubuntu修改python环境变量"></a>3 ubuntu修改python环境变量</h2><p>1.vim ~/.bashrc</p>
<p>2.添加如下内容</p>
<p>export PYTHON_HOME=/usr/local/anaconda3/bin</p>
<p>export PATH=$PYTHON_HOME/bin:$PATH</p>
<p>export PATH=/home/user_name/anaconda3/bin:$PATH # 指定python路径</p>
<h2 id="4-ubuntu修改pyton默认版本"><a href="#4-ubuntu修改pyton默认版本" class="headerlink" title="4.ubuntu修改pyton默认版本"></a>4.ubuntu修改pyton默认版本</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/White_Idiot/article/details/78240298">https://blog.csdn.net/White_Idiot/article/details/78240298</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/python/">python</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/python%E7%8E%AF%E5%A2%83/">python环境</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-08  <a class="commentCountImg" href="/2021/09/08/dimension-reduction/#comment-container"><span class="display-none-class">0eb98971f8b7965b646875b43430b474</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="0eb98971f8b7965b646875b43430b474">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>6 m  <i class="fas fa-pencil-alt"> </i>1.0 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/08/dimension-reduction/">降维</a></h1><div class="content"><h2 id="1-意义"><a href="#1-意义" class="headerlink" title="1.意义"></a>1.意义</h2><p>1.高纬空间样本具有稀疏性，容易欠拟合</p>
<p>2.可视化</p>
<p>3.维度过大导致训练时间长，预测慢</p>
<h2 id="2-分类"><a href="#2-分类" class="headerlink" title="2.分类"></a>2.分类</h2><p>大致分为线形降维度和非线性降维，线形降维包括PCA，LDA等，非线性降维包括LLE，t-SNE，auto encoder等。</p>
<h2 id="3-PCA系列"><a href="#3-PCA系列" class="headerlink" title="3.PCA系列"></a>3.PCA系列</h2><h3 id="3-1-PCA"><a href="#3-1-PCA" class="headerlink" title="3.1 PCA"></a>3.1 PCA</h3><p>假设矩阵$x\in \mathbb{R}^{ n}$，假设有$M$个样本，将原始数据按列组成$M$ 行$ n $列矩阵$ X\in \mathbb{R}^{M\times n}$，PCA的使用过程为：</p>
<p>1.计算协方差矩阵$G_t \in \mathbb{R}^{n \times n}$</p>
<script type="math/tex; mode=display">
G_t=\frac{1}{M}\sum_{j=1}^{M}(X-\overline{X})^T(X-\overline{X})</script><p>注意，其中$\overline{X}\in \mathbb{R}^{n}$为列的均值，$X-\overline{X}$表示将$ X$ 的每一列进行零均值化，即减去这一列的均值</p>
<p>2.求出协方差矩阵的特征值及对应的特征向量</p>
<script type="math/tex; mode=display">
(U,\sum,V)=SVD(G_t)</script><p>3.将特征向量按对应的特征值大小排列，取前 $k$ 列组成矩阵 $P\in \mathbb{R}^{n \times k} $</p>
<script type="math/tex; mode=display">
P=U(:,1:k)</script><p>4.实现数据降维</p>
<script type="math/tex; mode=display">
y_{[1\times k]}=x_{[1\times n ]}P_{[n\times k]}</script><p>局限：</p>
<p>​    a. PCA只能针对1D的向量，对于2D的矩阵而言，比如图片数据，需要先flatten成向量</p>
<h3 id="3-2-2DPCA"><a href="#3-2-2DPCA" class="headerlink" title="3.2 2DPCA"></a>3.2 2DPCA</h3><p>将2D的矩阵flatten成向量其实丢失了行列的位置信息，为了直接在2D的矩阵上实现降维，提出了2DPCA。</p>
<p>假设有原始矩阵$A\in\mathbb{R}^{m \times n }$，使用过程如下：</p>
<p>1.计算协方差矩阵</p>
<script type="math/tex; mode=display">
G_t=\frac{1}{M}\sum_{j=1}^{M}(A_j-\overline{A})^{T}(A_j-\overline{A})
\\\overline{A}=\frac{1}{M}\sum_{j=1}^{M}A_j</script><p>2.求出协方差矩阵的特征值及对应的特征向量</p>
<script type="math/tex; mode=display">
(U,\sum,V)=SVD(G_t)</script><p>3.将特征向量按对应的特征值大小排列，取前 $k$ 列组成矩阵</p>
<script type="math/tex; mode=display">
X=U(:,1:k)</script><p>4.实现数据降维</p>
<script type="math/tex; mode=display">
Y_{[m\times k]}=A_{[m\times n ]}X_{[n\times k]}</script><h3 id="3-3-（2D）2PCA"><a href="#3-3-（2D）2PCA" class="headerlink" title="3.3 （2D）2PCA"></a>3.3 （2D）2PCA</h3><p>作者证明了2DPCA只是在行上工作，然后提出了Alternative 2DPCA可以工作在列上，最后将其结合得到（2D）2PCA，使其可以同时在行列工作</p>
<p>假设有原始矩阵$A\in\mathbb{R}^{m \times n }$，使用过程如下：</p>
<p>1.计算协方差矩阵</p>
<script type="math/tex; mode=display">
G_x=\frac{1}{M}\sum_{k=1}^{M}\sum_{i=1}^{m}(A_k^{(i)}-\overline{A}^{(i)})^{T}(A_k^{(i)}-\overline{A}^{(i)})</script><p>其中$A_k=[(A_k^{(1)})^{T} \ (A_k^{(2)})^{T} \ …\ (A_k^{(m)})^{T}]^{T},\overline{A}=[(\overline{A}^{(1)})^{T} \ (\overline{A}^{(2)})^{T} \ …\ (\overline{A}^{(m)})^{T}]^{T}, \ A_k^{(i)}, \overline{A}^{(i)}$表示$A_k,\overline{A}$的第$i$行</p>
<script type="math/tex; mode=display">
\\G_z=\frac{1}{M}\sum_{k=1}^{M}\sum_{j=1}^{n}(A_k^{(j)}-\overline{A}^{(j)})(A_k^{(j)}-\overline{A}^{(j)})^{T}</script><p>其中$A_k=[(A_k^{(1)}) \ (A_k^{(2)}) \ …\ (A_k^{(n)})],\overline{A}=[(\overline{A}^{(1)}) \ (\overline{A}^{(2)}) \ …\ (\overline{A}^{(n)})],A_k^{(j)},\overline{A}^{(j)}$表示$A_k,\overline{A}$的第$j$列</p>
<p>2.求出协方差矩阵的特征值及对应的特征向量</p>
<script type="math/tex; mode=display">
(U_x,\sum x,V_x)=SVD(G_x)
\\(U_z,\sum z,V_z)=SVD(G_z)</script><p>3.将特征向量按对应的特征值大小排列</p>
<script type="math/tex; mode=display">
X=U_x(:,1:k) \in \mathbb{R}^{n\times k}
\\Z=U_z(:,1:q) \in \mathbb{R}^{m\times q}</script><p>4.实现数据降维</p>
<script type="math/tex; mode=display">
C_{[q\times k]}=Z^{T}_{[q\times m]}A_{[m\times n ]}X_{[n\times k]}</script><h2 id="4-t-SNE"><a href="#4-t-SNE" class="headerlink" title="4.t-SNE"></a>4.t-SNE</h2><h3 id="4-1-原理"><a href="#4-1-原理" class="headerlink" title="4.1 原理"></a>4.1 原理</h3><p>可以参考 <a target="_blank" rel="noopener" href="https://blog.csdn.net/scott198510/article/details/76099700">https://blog.csdn.net/scott198510/article/details/76099700</a></p>
<h3 id="4-2代码"><a href="#4-2代码" class="headerlink" title="4.2代码"></a>4.2代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from matplotlib import pylab</span><br><span class="line">import  torch</span><br><span class="line">import  pandas as pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">embdding=torch.load(path1)</span><br><span class="line">words = pd.read_csv(path2)</span><br><span class="line"></span><br><span class="line">words_embedded = TSNE(n_components=2).fit_transform(embdding)</span><br><span class="line"></span><br><span class="line">pylab.figure(figsize=(20, 20))</span><br><span class="line">for i, label in enumerate(words):</span><br><span class="line">  x, y = words_embedded[i, :]</span><br><span class="line">  pylab.scatter(x, y)</span><br><span class="line">  pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords=&#x27;offset points&#x27;,</span><br><span class="line">                 ha=&#x27;right&#x27;, va=&#x27;bottom&#x27;)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>
<h2 id="5-auto-encoder"><a href="#5-auto-encoder" class="headerlink" title="5.auto encoder"></a>5.auto encoder</h2><p><img src="/2021/09/08/dimension-reduction/1.jpg" alt></p>
<p>AutoEncoder在优化过程中无需使用样本的label，通过最小化重构误差希望学习到样本的抽象特征表示z，这种无监督的优化方式大大提升了模型的通用性。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/68903857">https://zhuanlan.zhihu.com/p/68903857</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/scott198510/article/details/76099700">https://blog.csdn.net/scott198510/article/details/76099700</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/">模型结构</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E9%99%8D%E7%BB%B4/">降维</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-07  <a class="commentCountImg" href="/2021/09/07/regulize/#comment-container"><span class="display-none-class">a163153037c01b910d58c60152e6ada9</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="a163153037c01b910d58c60152e6ada9">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/07/regulize/">正则化</a></h1><div class="content"><p>是机器学习中对原始损失函数引入额外信息，以便防止<strong>过拟合</strong>和提高模型泛化性能的一类方法的统称。</p>
<h2 id="1-L1正则（Lasso回归）"><a href="#1-L1正则（Lasso回归）" class="headerlink" title="1.L1正则（Lasso回归）"></a>1.L1正则（<strong>Lasso回归</strong>）</h2><p>L1正则化可以使得参数稀疏化，即得到的参数是一个稀疏矩阵，可以用于特征选择。</p>
<script type="math/tex; mode=display">
\begin{align*}
L_{L1}(w)&=L(w)+\lambda\Vert w \Vert_1=L(w)+\lambda\sum_{i=1}^{N}|w_i|
\\ \frac{\partial L_{L1}}{\partial w_i}&=\frac{\partial L}{\partial w_i}+\lambda \ sgn(w_i)
\\w_i &\rightarrow w_i-\eta(\frac{\partial L}{\partial w_i}+\lambda \ sgn(w_i))
\rightarrow w_i-\eta\lambda \ sgn(w_i)-\eta\frac{\partial L}{\partial w_i}
\end{align*}</script><p>L1是每次减去一个常数的收敛，所以L1更容易收敛到0。</p>
<h2 id="2-L2正则（Ridge回归）"><a href="#2-L2正则（Ridge回归）" class="headerlink" title="2.L2正则（Ridge回归）"></a>2.L2正则（<strong>Ridge回归</strong>）</h2><p>L2正则化使得参数平滑。</p>
<script type="math/tex; mode=display">
\begin{align*}
L_{L2}(w)&=L(w)+\lambda\Vert w \Vert_2^2=L(w)+\lambda\sum_{i=1}^{N}w_i^2
\\ \frac{\partial L_{L2}}{\partial w_i}&=\frac{\partial L}{\partial w_i}+2\lambda w_i
\\w_i& \rightarrow w_i-\eta(\frac{\partial L}{\partial w_i}+2\lambda w_i)
\rightarrow(1-2\eta\lambda)w_i-\eta \frac{\partial L}{\partial w_i}
\end{align*}</script><p>L2是每次乘上一个小于1的倍数进行收敛，所以L2使得参数平滑。</p>
<h2 id="3-dropout"><a href="#3-dropout" class="headerlink" title="3.dropout"></a>3.dropout</h2><p><img src="/2021/09/07/regulize/1.png" alt></p>
<p><strong>使用</strong>：在训练时，每个神经单元以概率$p$被保留(Dropout丢弃率为$1−p$)；在预测阶段，每个神经单元都是存在的。</p>
<p><strong>原理</strong>：神经网络通过Dropout层以一定比例随即的丢弃神经元，使得每次训练的网络模型都不相同，多个Epoch下来相当于训练了多个模型，同时每一个模型都参与了对最终结果的投票，从而提高了模型的泛化能力，类似<strong>bagging</strong>。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zingp/p/11631913.html">https://www.cnblogs.com/zingp/p/11631913.html</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/b876144622/article/details/81276818">https://blog.csdn.net/b876144622/article/details/81276818</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/37096933/answer/70494622">https://www.zhihu.com/question/37096933/answer/70494622</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">训练技巧</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%AD%A3%E5%88%99%E5%8C%96/">正则化</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-07  <a class="commentCountImg" href="/2021/09/07/loss-func/#comment-container"><span class="display-none-class">a1181f0da285c1067e9bf5d83c659fb8</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="a1181f0da285c1067e9bf5d83c659fb8">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/07/loss-func/">损失函数</a></h1><div class="content"><p>损失函数一般都要用可导函数，因为常用的优化算法，比如梯度下降，牛顿法，都需要导数。</p>
<h2 id="1-回归损失"><a href="#1-回归损失" class="headerlink" title="1.回归损失"></a>1.回归损失</h2><h3 id="1-1-Mean-Squared-Error"><a href="#1-1-Mean-Squared-Error" class="headerlink" title="1.1 Mean Squared Error"></a>1.1 Mean Squared Error</h3><script type="math/tex; mode=display">
L=\frac{1}{N}\sum_{i=1}^{N}(y_i-\hat{y}_i)^2</script><h3 id="1-2-Mean-Absolute-Error"><a href="#1-2-Mean-Absolute-Error" class="headerlink" title="1.2 Mean Absolute Error"></a>1.2 Mean Absolute Error</h3><script type="math/tex; mode=display">
L=\frac{1}{N}\sum_{i=1}^{N}|y_i-\hat{y}_i|</script><h3 id="1-3-Huber-Loss-Smooth-Mean-Absolute-Error-Loss"><a href="#1-3-Huber-Loss-Smooth-Mean-Absolute-Error-Loss" class="headerlink" title="1.3 Huber Loss ( Smooth Mean Absolute Error Loss )"></a>1.3 Huber Loss ( Smooth Mean Absolute Error Loss )</h3><script type="math/tex; mode=display">
L=\frac{1}{N}\sum_{i=1}^{N}[\mathbb{1}_{|y_i-\hat{y_i}|\le \delta}\frac{(y_i-\hat{y_i})^2}{2}+\mathbb{1}_{|y_i-\hat{y_i}|> \delta} \ (\delta \cdot |y_i-\hat{y_i}|-\frac{1}{2}\delta^{2})]</script><h2 id="2-分类损失"><a href="#2-分类损失" class="headerlink" title="2.分类损失"></a>2.分类损失</h2><h3 id="2-1-Cross-entropy-loss"><a href="#2-1-Cross-entropy-loss" class="headerlink" title="2.1 Cross-entropy loss"></a>2.1 Cross-entropy loss</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/100921909">https://zhuanlan.zhihu.com/p/100921909</a></p>
<p><img src="/2021/09/07/loss-func/1.JPG" style="zoom:25%;"></p>
<ul>
<li>K是种类数量</li>
<li>y是标签</li>
<li>p是神经网络的输出，也就是指类别是i的概率</li>
</ul>
<h3 id="2-2-Hinge-loss"><a href="#2-2-Hinge-loss" class="headerlink" title="2.2 Hinge loss"></a>2.2 Hinge loss</h3><script type="math/tex; mode=display">
L=max(0,1-y\cdot \hat{y})</script><p>SVM模型的损失函数本质上就是 Hinge Loss + L2 正则化</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_38007695/article/details/114983574">https://blog.csdn.net/m0_38007695/article/details/114983574</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/loss/">loss</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">损失函数</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-06  <a class="commentCountImg" href="/2021/09/06/ensemble/#comment-container"><span class="display-none-class">64d7930bfb2e268ead146758905948c7</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="64d7930bfb2e268ead146758905948c7">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/06/ensemble/">集成学习</a></h1><div class="content"><p>目前常见的集成学习可以分类为：<strong>1.Bagging 2.Boosting 3.Stacking 4.Blending</strong></p>
<h2 id="1-Bagging"><a href="#1-Bagging" class="headerlink" title="1.Bagging"></a>1.Bagging</h2><p><strong>bagging是解决variance问题。</strong></p>
<p><img src="/2021/09/06/ensemble/2.jpg" alt></p>
<h2 id="2-Boosting"><a href="#2-Boosting" class="headerlink" title="2.Boosting"></a>2.Boosting</h2><p><strong>boosting是解决bias问题。</strong></p>
<p>Bagging，Boosting二者之间的区别</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81340270">https://zhuanlan.zhihu.com/p/81340270</a></p>
<p><img src="/2021/09/06/ensemble/4.jpg" alt></p>
<h2 id="3-Stacking"><a href="#3-Stacking" class="headerlink" title="3.Stacking"></a>3.Stacking</h2><p>stacking和boosting的最大区别在于：boosting的基学习器是一个，stacking的基学习器是多个</p>
<p><img src="/2021/09/06/ensemble/6.jpg" alt></p>
<h2 id="4-Blending"><a href="#4-Blending" class="headerlink" title="4.Blending"></a>4.Blending</h2><p>和stacking区别： <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4380cd1def76">https://www.jianshu.com/p/4380cd1def76</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105038453">https://zhuanlan.zhihu.com/p/105038453</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/126968534">https://zhuanlan.zhihu.com/p/126968534</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/starter_____/article/details/79328749">https://blog.csdn.net/starter_____/article/details/79328749</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-06  <a class="commentCountImg" href="/2021/09/06/activate-func/#comment-container"><span class="display-none-class">f6ec69d796f91514753f8400f57d4439</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="f6ec69d796f91514753f8400f57d4439">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>4 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/06/activate-func/">常见激活函数</a></h1><div class="content"><p><strong>作用：激活函数是来向神经网络中引入非线性因素的，通过激活函数，神经网络就可以拟合各种曲线</strong></p>
<h3 id="1-sigmoid"><a href="#1-sigmoid" class="headerlink" title="1.sigmoid"></a>1.sigmoid</h3><p><img src="/2021/09/06/activate-func/1.jpg" alt></p>
<p><img src="/2021/09/06/activate-func/2.jpg" alt></p>
<script type="math/tex; mode=display">
\begin{align*}
y&=\frac{1}{1+e^{-x}}
\\y^{'}&=\frac{1}{1+e^{-x}}(1-\frac{1}{1+e^{-x}})=y(1-y)
\end{align*}</script><p>一般应用在二分类的输出层</p>
<p><strong>缺点</strong>：</p>
<p>​    1.sigmoid 极容易导致梯度消失问题，可以从导数曲线可以看出，绝大多数的导数值为0</p>
<p>​    2.Sigmoid 函数的输出不是以零为中心的（non-zero-centered），这会导致神经网络收敛较慢，详细原因请参考 <a target="_blank" rel="noopener" href="https://liam.page/2018/04/17/zero-centered-active-function/">https://liam.page/2018/04/17/zero-centered-active-function/</a></p>
<h3 id="2-softmax"><a href="#2-softmax" class="headerlink" title="2.softmax"></a>2.softmax</h3><script type="math/tex; mode=display">
S_i=\frac{e^i}{\sum_je^j}</script><p>和sigmoid关系：Softmax函数是二分类函数Sigmoid在多分类上的推广</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
<h3 id="3-tanh"><a href="#3-tanh" class="headerlink" title="3.tanh"></a>3.tanh</h3><p><img src="/2021/09/06/activate-func/3.jpg" alt></p>
<p><img src="/2021/09/06/activate-func/4.jpg" alt></p>
<script type="math/tex; mode=display">
\begin{align*}
y&=tanh(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
\\y^{'}&=1-(tanh(x))^{2}
\end{align*}</script><p><strong>优点</strong>:</p>
<p>​    1.tanh解决了sigmoid中的 zero-centered 问题</p>
<p><strong>缺点</strong>： </p>
<p>​    2.对于梯度消失问题依旧无能为力。</p>
<h3 id="4-Relu系列"><a href="#4-Relu系列" class="headerlink" title="4.Relu系列"></a>4.Relu系列</h3><h3 id="4-1-Relu"><a href="#4-1-Relu" class="headerlink" title="4.1 Relu"></a>4.1 Relu</h3><p><img src="/2021/09/06/activate-func/5.jpg" alt></p>
<script type="math/tex; mode=display">
\begin{align*}
y&=max(0,x)
\\
y^{'}&=\left\{
\begin{array}{cl}
1 &  \ x \ge 0 \\

0 &  \ x < 0 \\
\end{array} \right.

\end{align*}</script><p><strong>优点</strong>:</p>
<p>​    1.可以缓解梯度消失，因为导数在正数部分是恒等于1的</p>
<p><strong>缺点</strong>：</p>
<p>​    1.Relu的输出不是zero-centered</p>
<p>​    2.由于负数部分导数恒为0，会导致一些神经元无法激活，叫做Dead ReLU Problem</p>
<h3 id="4-2-leaky-Relu"><a href="#4-2-leaky-Relu" class="headerlink" title="4.2 leaky Relu"></a>4.2 leaky Relu</h3><p>leaky Relu就是为了解决Relu的0区间带来的影响，其数学表达为：</p>
<script type="math/tex; mode=display">
\begin{align*}
y&=\left\{
\begin{array}{cl}
x &  \ x \ge 0 \\

kx &  \ x < 0 \\
\end{array} \right.

\\
y^{'}&=\left\{
\begin{array}{cl}
1 &  \ x \ge 0 \\

k &  \ x < 0 \\
\end{array} \right.

\end{align*}</script><p>其中$k$是为超参数，一般数值较小，比如0.01</p>
<h3 id="4-3-Elu"><a href="#4-3-Elu" class="headerlink" title="4.3 Elu"></a>4.3 Elu</h3><p><img src="/2021/09/06/activate-func/6.png" alt></p>
<p>Elu激活函数也是为了解决Relu的0区间带来的影响，其数学表达为：</p>
<script type="math/tex; mode=display">
\begin{align*}
y&=\left\{
\begin{array}{cl}
x &  \ x \ge 0 \\

\alpha(e^{x}-1) &  \ x < 0 \\
\end{array} \right.

\\
y^{'}&=\left\{
\begin{array}{cl}
1 &  \ x \ge 0 \\

\alpha e^{x} &  \ x < 0 \\
\end{array} \right.

\end{align*}</script><p>Elu相对于leaky Relu来说，计算要更耗时间一些</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/44398148">https://zhuanlan.zhihu.com/p/44398148</a></p>
<p><a target="_blank" rel="noopener" href="https://liam.page/2018/04/17/zero-centered-active-function/">https://liam.page/2018/04/17/zero-centered-active-function/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/tornadomeet/p/3428843.html">https://www.cnblogs.com/tornadomeet/p/3428843.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/chamie/p/8665251.html">https://www.cnblogs.com/chamie/p/8665251.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33006526?from_voters_page=true">https://zhuanlan.zhihu.com/p/33006526?from_voters_page=true</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84/">模型结构</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">激活函数</a></div><hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-04  <a class="commentCountImg" href="/2021/09/04/overfit-underfit/#comment-container"><span class="display-none-class">1f189f8e824cf01149d323b5bd5e3584</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="1f189f8e824cf01149d323b5bd5e3584">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.4 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/04/overfit-underfit/">过拟合，欠拟合以及解决办法</a></h1><div class="content"><h2 id="1-偏差和方差"><a href="#1-偏差和方差" class="headerlink" title="1.偏差和方差"></a>1.偏差和方差</h2><p><img src="/2021/09/04/overfit-underfit/1.jpg" alt></p>
<script type="math/tex; mode=display">
\overline{f}(\textbf{x})=\mathbb{E}_D[f(\textbf{x};D)]</script><p><strong>a.偏差</strong></p>
<p>期望输出与真实标记的差别称为偏差（bias），即</p>
<script type="math/tex; mode=display">
bias^{2}(\textbf{x})=(\overline{f}(\textbf{x})-y)^{2}</script><p><strong>b.方差</strong></p>
<script type="math/tex; mode=display">
var(\textbf{x})=\mathbb{E}_D[(f(\textbf{x};D)-\overline{f}(x))^2]</script><p><strong>c.噪声</strong></p>
<script type="math/tex; mode=display">
\xi^{2}=\mathbb{E}_D[(y_D-y)^2]</script><p><strong>d.泛化误差（error）</strong></p>
<script type="math/tex; mode=display">
\begin{align*}
error&=\mathbb{E}_D[(f(\textbf{x};D)-y_D)^2]
\\&=...
\\&=(\overline{f}(\textbf{x})-y)^{2}+\mathbb{E}_D[(f(\textbf{x};D)-\overline{f}(x))^2]+\mathbb{E}_D[(y_D-y)^2]
\\&=bias^{2}(\textbf{x})+var(\textbf{x})+\xi^{2}

\end{align*}</script><h2 id="2-过拟合、欠拟合与偏差、方差的关系"><a href="#2-过拟合、欠拟合与偏差、方差的关系" class="headerlink" title="2.过拟合、欠拟合与偏差、方差的关系"></a>2.过拟合、欠拟合与偏差、方差的关系</h2><p><img src="/2021/09/04/overfit-underfit/2.jpg" alt></p>
<p><img src="/2021/09/04/overfit-underfit/3.jfif" alt></p>
<p><strong>欠拟合：模型不能适配训练样本，有一个很大的偏差。</strong></p>
<p><strong>过拟合：模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。</strong></p>
<h2 id="3-如何解决过拟合和欠拟合"><a href="#3-如何解决过拟合和欠拟合" class="headerlink" title="3.如何解决过拟合和欠拟合"></a>3.如何解决过拟合和欠拟合</h2><p><strong>a.模型能力（一个模型参数数量不同，不同模型）</strong></p>
<p><img src="/2021/09/04/overfit-underfit/4.jpg" alt></p>
<p><strong>b.正则化</strong></p>
<p>正则化参数出现的目的其实是防止过拟合情形的出现；如果我们的模型已经出现了欠拟合的情形，就可以通过减少正则化参数来消除欠拟合</p>
<p><strong>c.特征数量</strong></p>
<p>欠拟合：增加特征项</p>
<p>过拟合：减少特征项</p>
<p><strong>d、训练的数据量</strong></p>
<p>欠拟合：减少数据量</p>
<p>过拟合：增加数据量</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38853908">https://zhuanlan.zhihu.com/p/38853908</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hurry0808/article/details/78148756">https://blog.csdn.net/hurry0808/article/details/78148756</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/cltcj/article/details/119155683">https://blog.csdn.net/cltcj/article/details/119155683</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">训练技巧</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88/">过拟合、欠拟合</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-04  <a class="commentCountImg" href="/2021/09/04/data-imbalance/#comment-container"><span class="display-none-class">5a6e62f83c4052377fc6d3f509682b43</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="5a6e62f83c4052377fc6d3f509682b43">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.2 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/04/data-imbalance/">数据不平衡如何解决</a></h1><div class="content"><h2 id="1-基于数据"><a href="#1-基于数据" class="headerlink" title="1.基于数据"></a>1.基于数据</h2><p><strong>a.过采样和欠采样</strong></p>
<p>对少数数据进行有放回的过采样，使原本的数据变的均衡，这样就是对少数数据进行了复制，容易造成过拟合。</p>
<p>对多数数据进行有放回/无放回的欠采样，这样会丢失一些样本，损失信息，模型只学会整体模式的一部分，容易欠拟合。</p>
<p><strong>b.SMOTE算法</strong></p>
<p><strong>c.数据增强</strong></p>
<p>通过人为或算法增加少数数据的数量</p>
<h2 id="2-基于loss"><a href="#2-基于loss" class="headerlink" title="2.基于loss"></a>2.基于loss</h2><p>使用代价函数时，可以增加小类样本的权值，降低大类样本的权值</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/62877337">https://zhuanlan.zhihu.com/p/62877337</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/asialee_bird/article/details/83714612">https://blog.csdn.net/asialee_bird/article/details/83714612</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E6%9E%84%E9%80%A0/">数据构造</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1/">数据不平衡</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-09-02  <a class="commentCountImg" href="/2021/09/02/gradient/#comment-container"><span class="display-none-class">77676acf8cf2b5dd00ba3fb30e35ef79</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="77676acf8cf2b5dd00ba3fb30e35ef79">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>3 m  <i class="fas fa-pencil-alt"> </i>0.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/02/gradient/">梯度爆炸、梯度消失和解决方法</a></h1><div class="content"><h2 id="1-梯度"><a href="#1-梯度" class="headerlink" title="1.梯度"></a>1.梯度</h2><p>设二元函数$z=f(x,y)$ 在平面区域$D$上具有一阶连续偏导数，则对于每一个点$P(x，y)$的梯度为</p>
<script type="math/tex; mode=display">
grad \ f(x,y)=\nabla f(x,y)=f_x(x,y)\vec{j}+ f_y(x,y)\vec{j}</script><h2 id="2-BP算法图示"><a href="#2-BP算法图示" class="headerlink" title="2.BP算法图示"></a>2.BP算法图示</h2><p><img src="/2021/09/02/gradient/11.JPG" alt></p>
<h2 id="3-梯度消失和梯度爆炸"><a href="#3-梯度消失和梯度爆炸" class="headerlink" title="3.梯度消失和梯度爆炸"></a>3.梯度消失和梯度爆炸</h2><p>梯度爆炸和梯度消失问题都是因为<strong>网络太深</strong>，<strong>网络权值更新不稳定</strong>造成的，本质上是因为梯度反向传播中的连乘效应。</p>
<p><img src="/2021/09/02/gradient/22.jpg" alt></p>
<p>举个例子，现有如上链式连接的网络$(x\rightarrow z \rightarrow y)$</p>
<script type="math/tex; mode=display">
\frac{\partial C }{\partial b_1}=\frac{\partial C }{\partial y_4}\frac{\partial y_4 }{\partial z_4}\frac{\partial z_4 }{\partial x_4}\frac{\partial x_4 }{\partial z_3}\frac{\partial z_3 }{\partial x_3}\frac{\partial x_3 }{\partial z_2}\frac{\partial z_2 }{\partial x_2}\frac{\partial x_2 }{\partial z_1}\frac{\partial z_1 }{\partial b_1}=\frac{\partial C }{\partial y_4}g^{'}(z_4)w_4g^{'}(z_3)w_3g^{'}(z_2)w_2g^{'}(z_1)w_1</script><p>假设$g$为sigmoid，那么$g^{‘}(z)$最大值为$\frac{1}{4}$，而我们初始化的网络权值通常都小于1，所以$g^{‘}(z)w \le \frac{1}{4}$，因此对于上面的链式求导，层数越多，求导结果$\frac{\partial C }{\partial b_1}$越小，因而导致梯度消失的情况出现。</p>
<p>这样，梯度爆炸问题的出现原因就显而易见了，当$w$比较大的时候或者激活函数的梯度较大，即$g^{‘}(z)w &gt; 1$，层数越多，求导结果$\frac{\partial C }{\partial b_1}$越大，直到爆炸。</p>
<h2 id="4-梯度消失和梯度爆炸解决方法"><a href="#4-梯度消失和梯度爆炸解决方法" class="headerlink" title="4.梯度消失和梯度爆炸解决方法"></a>4.梯度消失和梯度爆炸解决方法</h2><h3 id="4-1-解决梯度消失"><a href="#4-1-解决梯度消失" class="headerlink" title="4.1 解决梯度消失"></a>4.1 解决梯度消失</h3><p>1.用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。</p>
<p>2.用Batch Normalization。</p>
<p>3.LSTM的结构设计也可以改善RNN中的梯度消失问题。</p>
<p>4.残差网络</p>
<p>5.合适的初始化权重</p>
<h3 id="4-2解决梯度爆炸"><a href="#4-2解决梯度爆炸" class="headerlink" title="4.2解决梯度爆炸"></a>4.2解决梯度爆炸</h3><p>1.梯度剪切：对梯度设定阈值</p>
<p>2.权重正则化(L1 和 L2 )</p>
<p>3.合适的初始化权重</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/">https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25631496">https://zhuanlan.zhihu.com/p/25631496</a></p>
<p><a target="_blank" rel="noopener" href="https://aijishu.com/a/1060000000100195">https://aijishu.com/a/1060000000100195</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">训练技巧</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E3%80%81%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/">梯度爆炸、梯度消失</a></div><hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2021-08-30  <a class="commentCountImg" href="/2021/08/30/recommmend-sys/#comment-container"><span class="display-none-class">6b02f1b1456ae7ce2121e0e53fa94aa5</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="6b02f1b1456ae7ce2121e0e53fa94aa5">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>a minute  <i class="fas fa-pencil-alt"> </i>0.1 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/30/recommmend-sys/">推荐系统</a></h1><div class="content"><p>一般推荐系统的结构拆分为：召回-》粗排-》精排-》重排</p>
<p>大佬总结的干货：    <a target="_blank" rel="noopener" href="https://xieyangyi.blog.csdn.net/article/details/123095982">https://xieyangyi.blog.csdn.net/article/details/123095982</a></p>
<h2 id="0-召回"><a href="#0-召回" class="headerlink" title="0 召回"></a>0 召回</h2><p>缩小规模，减小候选集，不需要十分准确，但不可遗漏</p>
<p>必须轻量快速低延迟</p>
<h2 id="1-粗排"><a href="#1-粗排" class="headerlink" title="1 粗排"></a>1 粗排</h2><p>兼顾精准性和低延迟</p>
<p>一般模型也不能过于复杂</p>
<h2 id="2-精排"><a href="#2-精排" class="headerlink" title="2 精排"></a>2 精排</h2><p>要求准</p>
<p>多特征，复杂模型</p>
<h2 id="3-重排"><a href="#3-重排" class="headerlink" title="3 重排"></a>3 重排</h2><p>业务相关</p>
<p>规则比较多</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://xieyangyi.blog.csdn.net/article/details/123095982">https://xieyangyi.blog.csdn.net/article/details/123095982</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/gczr/p/12564617.html">https://www.cnblogs.com/gczr/p/12564617.html</a></p>
</div><div class="index-category-tag"><div class="level-item"><i class="fas fa-folder-open has-text-grey"> </i><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a><span> </span><a class="article-more button is-small link-muted index-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></div>  <div class="level-item"><i class="fas fa-tags has-text-grey"> </i><a class="article-more button is-small link-muted index-tags" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></div><hr></div></article></div><!--!--><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/34/">Previous</a></div><div class="pagination-next"><a href="/page/36/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/34/">34</a></li><li><a class="pagination-link is-current" href="/page/35/">35</a></li><li><a class="pagination-link" href="/page/36/">36</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/39/">39</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/u/50144751?v=4" alt="Lavine Hu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lavine Hu</p><p class="is-size-6 is-block">我能卖你生瓜蛋子？</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>杭州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">387</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">139</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">370</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hlw95" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hlw95"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="/null"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/18829272646@163.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-12T14:14:32.000Z">2022-09-12</time></p><p class="title"><a href="/2022/09/12/python-cal-symbol/">运算</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-12T14:05:26.000Z">2022-09-12</time></p><p class="title"><a href="/2022/09/12/python-pattern/">正则</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-12T09:54:56.000Z">2022-09-12</time></p><p class="title"><a href="/2022/09/12/lamdba/">lambda</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-12T09:42:33.000Z">2022-09-12</time></p><p class="title"><a href="/2022/09/12/python-string/">字符串</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-12T07:31:39.000Z">2022-09-12</time></p><p class="title"><a href="/2022/09/12/python-iterator/">可迭代对象、迭代器与生成器</a></p><p class="categories"><a href="/categories/python/">python</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/GNN/GCN/"><span class="level-start"><span class="level-item">GCN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/GNN/"><span class="level-start"><span class="level-item">GNN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/GNN/%E5%B0%8F%E5%B8%AE%E6%89%8B/"><span class="level-start"><span class="level-item">小帮手</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">68</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/PTM/"><span class="level-start"><span class="level-item">PTM</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Prompt/"><span class="level-start"><span class="level-item">Prompt</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/Tokenization/"><span class="level-start"><span class="level-item">Tokenization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/"><span class="level-start"><span class="level-item">信息抽取</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">29</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/PTM/"><span class="tag">PTM</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">文本表示</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/"><span class="tag">文本匹配</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AC%E5%9B%9E/"><span class="tag">召回</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"><span class="tag">文本分类</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E6%9C%AC%E6%94%B9%E5%86%99/"><span class="tag">文本改写</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoTokenizer/"><span class="tag">AutoTokenizer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Azkaban/"><span class="tag">Azkaban</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BertGCN/"><span class="tag">BertGCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bert%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"><span class="tag">Bert文本表示</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDC%EF%BC%88Change-Data-Capture%EF%BC%89%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94/"><span class="tag">CDC（Change Data Capture）工具对比</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CRF%E5%92%8CHMM/"><span class="tag">CRF和HMM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChineseBERT-Chinese-Pretraining-Enhanced-by-Glyph-and-Pinyin-Information/"><span class="tag">ChineseBERT Chinese Pretraining Enhanced by Glyph and Pinyin Information</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DAG/"><span class="tag">DAG</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL/"><span class="tag">DGL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DGL-notice/"><span class="tag">DGL notice</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIEN/"><span class="tag">DIEN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIN/"><span class="tag">DIN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DMR/"><span class="tag">DMR</span><span class="tag is-grey-lightest">1</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Lavine Hu</a><p class="size-small"><span>&copy; 2022 Lavine Hu</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2021/07/17 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);})</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('a0eb7de1c4dc4908943b','b466946cbbe843a4a6ef249eb54ae5956d2f91c3','hlw95','hlw95.github.io',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"display":null,"superSample":2,"width":250,"height":500,"position":"right","hOffset":0,"vOffset":-20,"jsonPath":"/live2dw/assets/hijiki.model.json"},"mobile":{"show":true,"scale":0.5,"react":null,"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>